{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P30543_1_250\n",
      "model_file/3_GAFSE_Ki_P30543_1_250_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P30543_1_250_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P30543_1_250_test.csv\"\n",
    "test_active = 100\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/3_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"3_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/3_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  C1=CC=C(C(=C1)C=CC=NNC2=NC3=C(C(=N2)N)N=CN3C4C... -1.732394\n",
      "1  C1=CC=C(C=C1)C(CNC2=NC=NC3=C2N=CN3C4C(C(C(O4)C... -1.875061\n",
      "2  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CC4=C... -2.113943\n",
      "3  C1=CN(C(=O)N=C1N)C2C(C(C(O2)COP(=O)(O)OP(=O)(O... -1.204120\n",
      "4                C1C(C(C(C1N2C=NC3=C2N=CN=C3N)O)O)CO -3.332438\n",
      "number of all smiles:  1286\n",
      "number of successfully processed smiles:  1286\n",
      "                                              smiles     value  \\\n",
      "0  C1=CC=C(C(=C1)C=CC=NNC2=NC3=C(C(=N2)N)N=CN3C4C... -1.732394   \n",
      "1  C1=CC=C(C=C1)C(CNC2=NC=NC3=C2N=CN3C4C(C(C(O4)C... -1.875061   \n",
      "2  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CC4=C... -2.113943   \n",
      "3  C1=CN(C(=O)N=C1N)C2C(C(C(O2)COP(=O)(O)OP(=O)(O... -1.204120   \n",
      "4                C1C(C(C(C1N2C=NC3=C2N=CN=C3N)O)O)CO -3.332438   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Nc1nc(NN=CC=Cc2ccccc2[N+](=O)[O-])nc2c1ncn2C1O...  \n",
      "1  OCC1OC(n2cnc3c(NCC(c4ccccc4)c4ccccc4)ncnc32)C(...  \n",
      "2  CCNC(=O)C1OC(n2cnc3c(N)nc(C#Cc4ccco4)nc32)C(O)C1O  \n",
      "3   Nc1ccn(C2OC(COP(=O)(O)OP(=O)(O)O)C(O)C2O)c(=O)n1  \n",
      "4                      Nc1ncnc2c1ncn2C1CC(CO)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  684\n",
      "number of successfully processed smiles:  684\n",
      "(684, 3)\n",
      "                                              smiles     value  \\\n",
      "0    C1=CC(=CC(=C1)N)C2=CC3=NC(=NN3C(=N2)N)C4=CC=CO4 -0.698970   \n",
      "1  CNC(=O)C1CC(C(O1)N2C=NC3=C2N=C(N=C3NCC4=CC(=CC... -3.668386   \n",
      "2  C1=CC=C(C=C1)CNC(=O)C2=CN3C(=NC(=N3)C4=CC=CO4)... -0.301030   \n",
      "3   CCN1C2=C(C(=O)N(C1=O)CC)N(C(=N2)CCCC3=CC=CC=C3)C -3.594393   \n",
      "4  COCC1C(C(C(O1)N2C=NC3=C2N=CN=C3NCC4=CC(=CC=C4)... -2.571709   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0             Nc1cccc(-c2cc3nc(-c4ccco4)nn3c(N)n2)c1  \n",
      "1  CNC(=O)C1CC(O)C(n2cnc3c(NCc4cccc(I)c4)nc(Cl)nc...  \n",
      "2          Nc1nc(C(=O)NCc2ccccc2)cn2nc(-c3ccco3)nc12  \n",
      "3          CCn1c(=O)c2c(nc(CCCc3ccccc3)n2C)n(CC)c1=O  \n",
      "4       COCC1OC(n2cnc3c(NCc4cccc(I)c4)ncnc32)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P30543_1_250_train.pickle\n",
      "./data/benchmark/Ki_P30543_1_250_train\n",
      "1970\n",
      "feature dicts file saved as ./data/benchmark/Ki_P30543_1_250_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 3) (257, 3) (684, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def py_sigmoid_focal_loss(pred,\n",
    "                          target,\n",
    "                          weight=None,\n",
    "                          gamma=2.0,\n",
    "                          alpha=0.25):\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=alpha, reduce=False)\n",
    "    focal_weight = (1-torch.max(pred * target, -1)[0])**gamma\n",
    "    loss = focal_weight * weighted_CE(pred, torch.argmax(target,-1))\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    run_times = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        atom_weights = 1-x_atom[i,:l,:16].sum(-2)/l\n",
    "        ce_atom_loss = nn.CrossEntropyLoss(weight=atom_weights)\n",
    "#         print(atom_weights[1], refer_atom_list[i,0,torch.argmax(x_atom[i,0,:16],-1)], torch.argmax(x_atom[i,0,:16],-1))\n",
    "#         one_hot_loss += ce_atom_loss(refer_atom_list[i,:l,:16], torch.argmax(x_atom[i,:l,:16],-1))- \\\n",
    "#                          (((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9))).mean(-1)\n",
    "        one_hot_loss += py_sigmoid_focal_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16], alpha=atom_weights)- \\\n",
    "                          (((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-9)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9))).mean(-1)\n",
    "        run_times += 2\n",
    "    total_loss = one_hot_loss/run_times\n",
    "    return total_loss, 0, 0, 0\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "        success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=1)\n",
    "        reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "                                                                                              bond_neighbor, validity_mask, atom_list, \n",
    "                                                                                              bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "        atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "                                                torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "        refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                            torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "                                                            mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "        success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "                            bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "                                                     refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "        test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "        logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "        optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6 * (vat_loss + test_vat_loss) + 0.3 * (reconstruction_loss + test_reconstruction_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "        optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/3_GAFSE_Ki_P30543_1_250_run_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yinmingyue/anaconda3/envs/env/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 245 Step: 24990 Index:-0.2874 R2:0.7668 0.4586 0.5427 RMSE:0.5123 0.8059 0.7411 Tau:0.6897 0.5185 0.4177\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 246 Step: 25092 Index:-0.2918 R2:0.7697 0.4535 0.5160 RMSE:0.5107 0.8043 0.7580 Tau:0.6904 0.5124 0.4129\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 247 Step: 25194 Index:-0.3093 R2:0.7614 0.4395 0.5391 RMSE:0.5163 0.8162 0.7284 Tau:0.6872 0.5069 0.4217\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 248 Step: 25296 Index:-0.2921 R2:0.7664 0.4412 0.5486 RMSE:0.5113 0.8091 0.7189 Tau:0.6914 0.5171 0.4194\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 249 Step: 25398 Index:-0.2970 R2:0.7756 0.4422 0.5134 RMSE:0.5059 0.8086 0.7543 Tau:0.6969 0.5116 0.4258\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 250 Step: 25500 Index:-0.3070 R2:0.7619 0.4493 0.5117 RMSE:0.5317 0.8178 0.7931 Tau:0.6869 0.5108 0.4190\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 251 Step: 25602 Index:-0.3470 R2:0.7703 0.4226 0.5170 RMSE:0.5341 0.8501 0.7911 Tau:0.6948 0.5031 0.4184\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 252 Step: 25704 Index:-0.3542 R2:0.7602 0.4111 0.5289 RMSE:0.5325 0.8607 0.7683 Tau:0.6860 0.5065 0.4302\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 253 Step: 25806 Index:-0.3197 R2:0.7754 0.4231 0.5279 RMSE:0.5023 0.8276 0.7378 Tau:0.6984 0.5079 0.4222\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 254 Step: 25908 Index:-0.3148 R2:0.7732 0.4410 0.5265 RMSE:0.5214 0.8339 0.7789 Tau:0.6957 0.5191 0.4179\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 255 Step: 26010 Index:-0.3278 R2:0.7694 0.4351 0.5059 RMSE:0.5296 0.8353 0.7915 Tau:0.6907 0.5076 0.4135\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 256 Step: 26112 Index:-0.2934 R2:0.7704 0.4488 0.5227 RMSE:0.5108 0.8093 0.7374 Tau:0.6923 0.5159 0.4139\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 257 Step: 26214 Index:-0.2897 R2:0.7738 0.4525 0.5218 RMSE:0.5204 0.8085 0.7336 Tau:0.6956 0.5188 0.4182\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 258 Step: 26316 Index:-0.3164 R2:0.7686 0.4383 0.5205 RMSE:0.5117 0.8263 0.7372 Tau:0.6920 0.5100 0.4254\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 259 Step: 26418 Index:-0.2993 R2:0.7734 0.4528 0.5511 RMSE:0.5005 0.8148 0.7313 Tau:0.6974 0.5155 0.4275\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 260 Step: 26520 Index:-0.3000 R2:0.7726 0.4521 0.5397 RMSE:0.5018 0.8126 0.7435 Tau:0.6954 0.5126 0.4201\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 261 Step: 26622 Index:-0.3107 R2:0.7799 0.4450 0.5357 RMSE:0.5190 0.8267 0.7689 Tau:0.7019 0.5160 0.4283\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 262 Step: 26724 Index:-0.3020 R2:0.7782 0.4498 0.5367 RMSE:0.5065 0.8162 0.7602 Tau:0.6996 0.5143 0.4269\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 263 Step: 26826 Index:-0.3061 R2:0.7721 0.4426 0.5362 RMSE:0.5072 0.8130 0.7420 Tau:0.6940 0.5070 0.4198\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 264 Step: 26928 Index:-0.3107 R2:0.7749 0.4426 0.5252 RMSE:0.5099 0.8258 0.7682 Tau:0.6961 0.5150 0.4192\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 265 Step: 27030 Index:-0.2877 R2:0.7670 0.4569 0.5183 RMSE:0.5179 0.8047 0.7430 Tau:0.6893 0.5171 0.4127\n",
      "Epoch: 266 Step: 27132 Index:-0.2800 R2:0.7756 0.4664 0.5391 RMSE:0.4999 0.8003 0.7450 Tau:0.6968 0.5204 0.4235\n",
      "Epoch: 267 Step: 27234 Index:-0.2789 R2:0.7778 0.4627 0.5270 RMSE:0.4985 0.7943 0.7413 Tau:0.6981 0.5154 0.4171\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 268 Step: 27336 Index:-0.2933 R2:0.7674 0.4457 0.5128 RMSE:0.5092 0.8067 0.7498 Tau:0.6893 0.5133 0.4152\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 269 Step: 27438 Index:-0.3256 R2:0.7742 0.4243 0.5140 RMSE:0.5035 0.8247 0.7477 Tau:0.6959 0.4991 0.4181\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 270 Step: 27540 Index:-0.2805 R2:0.7807 0.4605 0.5262 RMSE:0.4951 0.7958 0.7446 Tau:0.7008 0.5153 0.4199\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 271 Step: 27642 Index:-0.3160 R2:0.7795 0.4511 0.5322 RMSE:0.5201 0.8299 0.7820 Tau:0.7001 0.5139 0.4196\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 272 Step: 27744 Index:-0.3103 R2:0.7813 0.4377 0.5168 RMSE:0.4951 0.8188 0.7451 Tau:0.7026 0.5085 0.4225\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 273 Step: 27846 Index:-0.2836 R2:0.7652 0.4655 0.5294 RMSE:0.5141 0.8057 0.7452 Tau:0.6887 0.5220 0.4119\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 274 Step: 27948 Index:-0.3998 R2:0.7780 0.4301 0.5380 RMSE:0.5948 0.9040 0.8612 Tau:0.7015 0.5042 0.4223\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 275 Step: 28050 Index:-0.3133 R2:0.7750 0.4442 0.5119 RMSE:0.5102 0.8181 0.7740 Tau:0.6964 0.5048 0.4158\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 276 Step: 28152 Index:-0.3269 R2:0.7805 0.4432 0.5191 RMSE:0.5206 0.8355 0.7936 Tau:0.7005 0.5087 0.4150\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 277 Step: 28254 Index:-0.3167 R2:0.7866 0.4506 0.5272 RMSE:0.5100 0.8295 0.7848 Tau:0.7060 0.5128 0.4287\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 278 Step: 28356 Index:-0.3037 R2:0.7737 0.4528 0.5250 RMSE:0.5034 0.8163 0.7433 Tau:0.6967 0.5127 0.4291\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 279 Step: 28458 Index:-0.3237 R2:0.7813 0.4376 0.5431 RMSE:0.5096 0.8377 0.7589 Tau:0.7043 0.5139 0.4271\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 280 Step: 28560 Index:-0.3125 R2:0.7838 0.4445 0.5455 RMSE:0.4924 0.8271 0.7448 Tau:0.7028 0.5146 0.4168\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 281 Step: 28662 Index:-0.3095 R2:0.7869 0.4439 0.5379 RMSE:0.4949 0.8229 0.7577 Tau:0.7079 0.5134 0.4215\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 282 Step: 28764 Index:-0.3545 R2:0.7820 0.4460 0.4999 RMSE:0.6025 0.8655 0.7782 Tau:0.7019 0.5111 0.4303\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 283 Step: 28866 Index:-0.3423 R2:0.7837 0.4478 0.5119 RMSE:0.5365 0.8531 0.8221 Tau:0.7011 0.5107 0.4155\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 284 Step: 28968 Index:-0.3248 R2:0.7886 0.4401 0.4998 RMSE:0.5163 0.8327 0.8048 Tau:0.7072 0.5079 0.4262\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 285 Step: 29070 Index:-0.3177 R2:0.7855 0.4445 0.5298 RMSE:0.4893 0.8243 0.7598 Tau:0.7059 0.5066 0.4267\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 286 Step: 29172 Index:-0.3013 R2:0.7831 0.4521 0.5103 RMSE:0.5105 0.8124 0.7443 Tau:0.7039 0.5111 0.4271\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 287 Step: 29274 Index:-0.3294 R2:0.7766 0.4282 0.5214 RMSE:0.4975 0.8361 0.7426 Tau:0.7014 0.5066 0.4322\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 288 Step: 29376 Index:-0.3118 R2:0.7897 0.4598 0.5356 RMSE:0.5231 0.8305 0.7948 Tau:0.7089 0.5188 0.4331\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 289 Step: 29478 Index:-0.3101 R2:0.7785 0.4411 0.5095 RMSE:0.5211 0.8212 0.7462 Tau:0.7002 0.5111 0.4309\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 290 Step: 29580 Index:-0.3225 R2:0.7883 0.4233 0.5079 RMSE:0.4915 0.8253 0.7480 Tau:0.7078 0.5028 0.4287\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 291 Step: 29682 Index:-0.3396 R2:0.7941 0.4379 0.5257 RMSE:0.5149 0.8487 0.8031 Tau:0.7131 0.5091 0.4339\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 292 Step: 29784 Index:-0.3536 R2:0.7912 0.4323 0.5344 RMSE:0.5241 0.8599 0.8044 Tau:0.7099 0.5063 0.4371\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 293 Step: 29886 Index:-0.3614 R2:0.7931 0.4242 0.5332 RMSE:0.5242 0.8642 0.8037 Tau:0.7136 0.5028 0.4298\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 294 Step: 29988 Index:-0.3347 R2:0.7941 0.4463 0.5286 RMSE:0.5148 0.8450 0.7976 Tau:0.7111 0.5103 0.4327\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 295 Step: 30090 Index:-0.3156 R2:0.7856 0.4502 0.5417 RMSE:0.5159 0.8283 0.7188 Tau:0.7050 0.5127 0.4330\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 296 Step: 30192 Index:-0.3066 R2:0.7946 0.4381 0.5239 RMSE:0.4787 0.8176 0.7421 Tau:0.7123 0.5110 0.4377\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 297 Step: 30294 Index:-0.2919 R2:0.7892 0.4515 0.5213 RMSE:0.4876 0.8044 0.7404 Tau:0.7062 0.5125 0.4239\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 298 Step: 30396 Index:-0.3370 R2:0.7900 0.4477 0.5170 RMSE:0.5244 0.8494 0.8209 Tau:0.7068 0.5124 0.4163\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 299 Step: 30498 Index:-0.2928 R2:0.7979 0.4478 0.5164 RMSE:0.4862 0.8071 0.7387 Tau:0.7152 0.5143 0.4271\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 300 Step: 30600 Index:-0.3639 R2:0.7888 0.4241 0.5224 RMSE:0.5160 0.8583 0.7970 Tau:0.7062 0.4944 0.4305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 301 Step: 30702 Index:-0.3562 R2:0.7814 0.4143 0.5183 RMSE:0.4984 0.8507 0.7676 Tau:0.7029 0.4944 0.4360\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 302 Step: 30804 Index:-0.3159 R2:0.7904 0.4469 0.5274 RMSE:0.4812 0.8191 0.7499 Tau:0.7074 0.5032 0.4314\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 303 Step: 30906 Index:-0.3049 R2:0.8011 0.4498 0.5247 RMSE:0.4757 0.8188 0.7641 Tau:0.7163 0.5138 0.4283\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 304 Step: 31008 Index:-0.3283 R2:0.7940 0.4287 0.5106 RMSE:0.4842 0.8285 0.7688 Tau:0.7118 0.5003 0.4250\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 305 Step: 31110 Index:-0.3094 R2:0.8003 0.4418 0.5103 RMSE:0.4843 0.8162 0.7425 Tau:0.7157 0.5067 0.4341\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 306 Step: 31212 Index:-0.2922 R2:0.7979 0.4566 0.5115 RMSE:0.4752 0.8012 0.7590 Tau:0.7140 0.5090 0.4215\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 307 Step: 31314 Index:-0.3043 R2:0.7885 0.4445 0.5131 RMSE:0.4873 0.8174 0.7518 Tau:0.7064 0.5131 0.4194\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 308 Step: 31416 Index:-0.3399 R2:0.7855 0.4126 0.4880 RMSE:0.4899 0.8382 0.7659 Tau:0.7036 0.4983 0.4270\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 309 Step: 31518 Index:-0.3054 R2:0.8014 0.4522 0.5286 RMSE:0.4852 0.8210 0.7728 Tau:0.7167 0.5156 0.4189\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 310 Step: 31620 Index:-0.3250 R2:0.8001 0.4302 0.5285 RMSE:0.4832 0.8374 0.7654 Tau:0.7179 0.5124 0.4379\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 311 Step: 31722 Index:-0.3387 R2:0.8020 0.4430 0.5076 RMSE:0.5237 0.8480 0.8278 Tau:0.7164 0.5093 0.4265\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 312 Step: 31824 Index:-0.2945 R2:0.7934 0.4577 0.5424 RMSE:0.4778 0.8124 0.7330 Tau:0.7100 0.5179 0.4231\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 313 Step: 31926 Index:-0.3330 R2:0.8011 0.4267 0.5174 RMSE:0.4691 0.8403 0.7599 Tau:0.7167 0.5073 0.4292\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 314 Step: 32028 Index:-0.3230 R2:0.7989 0.4412 0.5229 RMSE:0.4878 0.8345 0.7756 Tau:0.7138 0.5115 0.4234\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 315 Step: 32130 Index:-0.3115 R2:0.8044 0.4390 0.5263 RMSE:0.4692 0.8228 0.7530 Tau:0.7191 0.5113 0.4323\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 316 Step: 32232 Index:-0.3091 R2:0.8015 0.4414 0.5218 RMSE:0.4735 0.8144 0.7558 Tau:0.7179 0.5053 0.4232\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 317 Step: 32334 Index:-0.2877 R2:0.8040 0.4462 0.5242 RMSE:0.4729 0.8046 0.7409 Tau:0.7193 0.5169 0.4258\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 318 Step: 32436 Index:-0.3649 R2:0.7872 0.4066 0.4845 RMSE:0.5076 0.8559 0.7992 Tau:0.7076 0.4910 0.4275\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 319 Step: 32538 Index:-0.3150 R2:0.8075 0.4244 0.5302 RMSE:0.4727 0.8208 0.7265 Tau:0.7226 0.5058 0.4364\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 320 Step: 32640 Index:-0.3026 R2:0.8040 0.4535 0.5221 RMSE:0.4671 0.8159 0.7646 Tau:0.7188 0.5133 0.4266\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 321 Step: 32742 Index:-0.3854 R2:0.7919 0.4158 0.5090 RMSE:0.5293 0.8875 0.8291 Tau:0.7116 0.5021 0.4327\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 322 Step: 32844 Index:-0.3204 R2:0.7997 0.4502 0.5180 RMSE:0.4857 0.8253 0.7884 Tau:0.7166 0.5049 0.4345\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 323 Step: 32946 Index:-0.3000 R2:0.8031 0.4469 0.5219 RMSE:0.4677 0.8148 0.7449 Tau:0.7179 0.5147 0.4331\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 324 Step: 33048 Index:-0.2998 R2:0.8045 0.4477 0.5062 RMSE:0.4756 0.8084 0.7488 Tau:0.7175 0.5086 0.4265\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 325 Step: 33150 Index:-0.3011 R2:0.7986 0.4406 0.5204 RMSE:0.4769 0.8123 0.7448 Tau:0.7159 0.5112 0.4263\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 326 Step: 33252 Index:-0.3164 R2:0.8082 0.4421 0.5288 RMSE:0.4618 0.8197 0.7430 Tau:0.7219 0.5033 0.4320\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 327 Step: 33354 Index:-0.3116 R2:0.8023 0.4455 0.5126 RMSE:0.4823 0.8156 0.7439 Tau:0.7151 0.5040 0.4174\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 328 Step: 33456 Index:-0.3195 R2:0.8043 0.4536 0.5300 RMSE:0.4865 0.8322 0.7941 Tau:0.7183 0.5127 0.4262\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 329 Step: 33558 Index:-0.3086 R2:0.8131 0.4399 0.5191 RMSE:0.4691 0.8191 0.7368 Tau:0.7262 0.5105 0.4333\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 330 Step: 33660 Index:-0.3229 R2:0.8101 0.4222 0.5047 RMSE:0.4697 0.8278 0.7481 Tau:0.7234 0.5049 0.4312\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 331 Step: 33762 Index:-0.3308 R2:0.7938 0.4404 0.5699 RMSE:0.4821 0.8446 0.7323 Tau:0.7113 0.5137 0.4347\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 332 Step: 33864 Index:-0.3743 R2:0.8081 0.4148 0.5144 RMSE:0.4950 0.8715 0.8162 Tau:0.7241 0.4973 0.4376\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 333 Step: 33966 Index:-0.3354 R2:0.8120 0.4316 0.5217 RMSE:0.4736 0.8399 0.7765 Tau:0.7251 0.5045 0.4270\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 334 Step: 34068 Index:-0.2978 R2:0.8057 0.4503 0.5359 RMSE:0.4688 0.8046 0.7302 Tau:0.7216 0.5068 0.4326\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 335 Step: 34170 Index:-0.3120 R2:0.7934 0.4455 0.5497 RMSE:0.4807 0.8223 0.7440 Tau:0.7134 0.5103 0.4335\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 336 Step: 34272 Index:-0.2946 R2:0.7983 0.4516 0.5256 RMSE:0.4752 0.8065 0.7405 Tau:0.7138 0.5119 0.4275\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 337 Step: 34374 Index:-0.3140 R2:0.8076 0.4352 0.5467 RMSE:0.4650 0.8228 0.7195 Tau:0.7236 0.5088 0.4321\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 338 Step: 34476 Index:-0.3081 R2:0.8076 0.4422 0.5406 RMSE:0.4625 0.8175 0.7355 Tau:0.7253 0.5094 0.4459\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 339 Step: 34578 Index:-0.3156 R2:0.8102 0.4441 0.5331 RMSE:0.4604 0.8247 0.7463 Tau:0.7250 0.5091 0.4456\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 340 Step: 34680 Index:-0.3269 R2:0.8101 0.4242 0.5238 RMSE:0.4627 0.8299 0.7458 Tau:0.7277 0.5031 0.4367\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 341 Step: 34782 Index:-0.3149 R2:0.8044 0.4428 0.5262 RMSE:0.4720 0.8236 0.7444 Tau:0.7194 0.5087 0.4358\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 342 Step: 34884 Index:-0.3273 R2:0.8099 0.4259 0.5316 RMSE:0.4601 0.8339 0.7420 Tau:0.7259 0.5066 0.4370\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 343 Step: 34986 Index:-0.3485 R2:0.8113 0.4352 0.5446 RMSE:0.4977 0.8616 0.7930 Tau:0.7252 0.5130 0.4362\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 344 Step: 35088 Index:-0.3566 R2:0.8027 0.4104 0.5107 RMSE:0.4797 0.8546 0.7832 Tau:0.7227 0.4979 0.4436\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 345 Step: 35190 Index:-0.3153 R2:0.8125 0.4412 0.5196 RMSE:0.4682 0.8222 0.7643 Tau:0.7269 0.5068 0.4329\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 346 Step: 35292 Index:-0.3091 R2:0.8097 0.4509 0.5414 RMSE:0.4603 0.8228 0.7535 Tau:0.7236 0.5136 0.4360\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 347 Step: 35394 Index:-0.3449 R2:0.8021 0.4361 0.5417 RMSE:0.5082 0.8525 0.7185 Tau:0.7188 0.5076 0.4477\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 348 Step: 35496 Index:-0.3421 R2:0.8153 0.4260 0.5327 RMSE:0.4629 0.8421 0.7620 Tau:0.7289 0.5000 0.4448\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 349 Step: 35598 Index:-0.3690 R2:0.8033 0.4117 0.5428 RMSE:0.4760 0.8689 0.7562 Tau:0.7218 0.4999 0.4442\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 350 Step: 35700 Index:-0.3105 R2:0.8093 0.4439 0.5460 RMSE:0.4605 0.8207 0.7289 Tau:0.7265 0.5102 0.4400\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 351 Step: 35802 Index:-0.3333 R2:0.8122 0.4335 0.5363 RMSE:0.4566 0.8430 0.7454 Tau:0.7261 0.5097 0.4386\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 352 Step: 35904 Index:-0.3056 R2:0.8123 0.4521 0.5136 RMSE:0.4889 0.8231 0.7478 Tau:0.7243 0.5175 0.4331\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 353 Step: 36006 Index:-0.3147 R2:0.8118 0.4486 0.5435 RMSE:0.4616 0.8247 0.7243 Tau:0.7256 0.5101 0.4418\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 354 Step: 36108 Index:-0.3259 R2:0.8154 0.4321 0.5366 RMSE:0.4531 0.8281 0.7339 Tau:0.7300 0.5022 0.4357\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 355 Step: 36210 Index:-0.3032 R2:0.8179 0.4444 0.5217 RMSE:0.4549 0.8109 0.7533 Tau:0.7292 0.5077 0.4259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 356 Step: 36312 Index:-0.2971 R2:0.8184 0.4510 0.5508 RMSE:0.4499 0.8117 0.7219 Tau:0.7318 0.5146 0.4356\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 357 Step: 36414 Index:-0.3431 R2:0.8043 0.4188 0.5260 RMSE:0.4683 0.8447 0.7376 Tau:0.7193 0.5015 0.4280\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 358 Step: 36516 Index:-0.3797 R2:0.8184 0.4218 0.5147 RMSE:0.5065 0.8763 0.8303 Tau:0.7311 0.4965 0.4337\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 359 Step: 36618 Index:-0.3220 R2:0.8171 0.4354 0.5101 RMSE:0.4728 0.8280 0.7477 Tau:0.7312 0.5059 0.4353\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 360 Step: 36720 Index:-0.3325 R2:0.8142 0.4317 0.5113 RMSE:0.4700 0.8353 0.7808 Tau:0.7265 0.5028 0.4245\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 361 Step: 36822 Index:-0.3577 R2:0.7783 0.4071 0.4819 RMSE:0.5071 0.8354 0.7713 Tau:0.7029 0.4777 0.4183\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 362 Step: 36924 Index:-0.3529 R2:0.8183 0.4216 0.5469 RMSE:0.4638 0.8501 0.7587 Tau:0.7336 0.4972 0.4432\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 363 Step: 37026 Index:-0.3043 R2:0.8169 0.4473 0.5344 RMSE:0.4545 0.8156 0.7542 Tau:0.7312 0.5113 0.4360\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 364 Step: 37128 Index:-0.3372 R2:0.8070 0.4400 0.5474 RMSE:0.4683 0.8362 0.7288 Tau:0.7221 0.4990 0.4372\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 365 Step: 37230 Index:-0.3222 R2:0.8095 0.4425 0.5245 RMSE:0.4717 0.8308 0.7817 Tau:0.7244 0.5086 0.4366\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 366 Step: 37332 Index:-0.2982 R2:0.8162 0.4640 0.5227 RMSE:0.4632 0.8197 0.7872 Tau:0.7288 0.5215 0.4330\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 367 Step: 37434 Index:-0.3909 R2:0.8163 0.4061 0.5245 RMSE:0.5065 0.8895 0.8172 Tau:0.7336 0.4986 0.4461\n",
      "EarlyStopping counter: 101 out of 100\n",
      "Epoch: 368 Step: 37536 Index:-0.3488 R2:0.8116 0.4311 0.4941 RMSE:0.4755 0.8510 0.8131 Tau:0.7248 0.5021 0.4364\n",
      "EarlyStopping counter: 102 out of 100\n",
      "Epoch: 369 Step: 37638 Index:-0.3245 R2:0.8077 0.4404 0.5442 RMSE:0.4612 0.8293 0.7530 Tau:0.7255 0.5048 0.4358\n",
      "EarlyStopping counter: 103 out of 100\n",
      "Epoch: 370 Step: 37740 Index:-0.3481 R2:0.8173 0.4162 0.5529 RMSE:0.4506 0.8466 0.7248 Tau:0.7318 0.4984 0.4405\n",
      "EarlyStopping counter: 104 out of 100\n",
      "Epoch: 371 Step: 37842 Index:-0.3126 R2:0.8224 0.4524 0.5319 RMSE:0.4494 0.8231 0.7769 Tau:0.7351 0.5105 0.4352\n",
      "EarlyStopping counter: 105 out of 100\n",
      "Epoch: 372 Step: 37944 Index:-0.3154 R2:0.8134 0.4431 0.5467 RMSE:0.4605 0.8271 0.7458 Tau:0.7264 0.5117 0.4392\n",
      "EarlyStopping counter: 106 out of 100\n",
      "Epoch: 373 Step: 38046 Index:-0.3506 R2:0.8211 0.4347 0.5305 RMSE:0.4748 0.8477 0.7934 Tau:0.7348 0.4971 0.4336\n",
      "EarlyStopping counter: 107 out of 100\n",
      "Epoch: 374 Step: 38148 Index:-0.3228 R2:0.8205 0.4281 0.5235 RMSE:0.4542 0.8269 0.7502 Tau:0.7317 0.5040 0.4410\n",
      "EarlyStopping counter: 108 out of 100\n",
      "Epoch: 375 Step: 38250 Index:-0.3036 R2:0.8195 0.4585 0.5495 RMSE:0.4471 0.8177 0.7296 Tau:0.7319 0.5141 0.4360\n",
      "EarlyStopping counter: 109 out of 100\n",
      "Epoch: 376 Step: 38352 Index:-0.3095 R2:0.8245 0.4488 0.5448 RMSE:0.4415 0.8201 0.7282 Tau:0.7371 0.5106 0.4428\n",
      "EarlyStopping counter: 110 out of 100\n",
      "Epoch: 377 Step: 38454 Index:-0.3298 R2:0.8258 0.4471 0.5546 RMSE:0.4690 0.8419 0.7682 Tau:0.7374 0.5121 0.4433\n",
      "EarlyStopping counter: 111 out of 100\n",
      "Epoch: 378 Step: 38556 Index:-0.3216 R2:0.8240 0.4424 0.5193 RMSE:0.4498 0.8269 0.7806 Tau:0.7367 0.5053 0.4436\n",
      "EarlyStopping counter: 112 out of 100\n",
      "Epoch: 379 Step: 38658 Index:-0.3238 R2:0.8256 0.4246 0.5371 RMSE:0.4428 0.8296 0.7350 Tau:0.7396 0.5058 0.4411\n",
      "EarlyStopping counter: 113 out of 100\n",
      "Epoch: 380 Step: 38760 Index:-0.3378 R2:0.8276 0.4351 0.5504 RMSE:0.4580 0.8454 0.7657 Tau:0.7388 0.5076 0.4400\n",
      "EarlyStopping counter: 114 out of 100\n",
      "Epoch: 381 Step: 38862 Index:-0.3045 R2:0.8254 0.4491 0.5497 RMSE:0.4417 0.8128 0.7240 Tau:0.7381 0.5083 0.4403\n",
      "EarlyStopping counter: 115 out of 100\n",
      "Epoch: 382 Step: 38964 Index:-0.3420 R2:0.8181 0.4257 0.5180 RMSE:0.4603 0.8420 0.7788 Tau:0.7307 0.5000 0.4319\n",
      "EarlyStopping counter: 116 out of 100\n",
      "Epoch: 383 Step: 39066 Index:-0.3312 R2:0.8239 0.4530 0.5489 RMSE:0.4653 0.8442 0.7803 Tau:0.7365 0.5130 0.4450\n",
      "EarlyStopping counter: 117 out of 100\n",
      "Epoch: 384 Step: 39168 Index:-0.3745 R2:0.8166 0.4298 0.5173 RMSE:0.5227 0.8787 0.8412 Tau:0.7292 0.5042 0.4364\n",
      "EarlyStopping counter: 118 out of 100\n",
      "Epoch: 385 Step: 39270 Index:-0.3371 R2:0.8209 0.4336 0.5462 RMSE:0.4566 0.8452 0.7561 Tau:0.7332 0.5081 0.4448\n",
      "EarlyStopping counter: 119 out of 100\n",
      "Epoch: 386 Step: 39372 Index:-0.3324 R2:0.8346 0.4359 0.5454 RMSE:0.4495 0.8372 0.7619 Tau:0.7456 0.5048 0.4437\n",
      "EarlyStopping counter: 120 out of 100\n",
      "Epoch: 387 Step: 39474 Index:-0.3483 R2:0.8048 0.4354 0.5570 RMSE:0.4736 0.8503 0.7253 Tau:0.7218 0.5020 0.4373\n",
      "EarlyStopping counter: 121 out of 100\n",
      "Epoch: 388 Step: 39576 Index:-0.3284 R2:0.8303 0.4282 0.5266 RMSE:0.4366 0.8316 0.7477 Tau:0.7405 0.5032 0.4426\n",
      "EarlyStopping counter: 122 out of 100\n",
      "Epoch: 389 Step: 39678 Index:-0.3447 R2:0.8248 0.4351 0.5638 RMSE:0.4646 0.8547 0.7608 Tau:0.7377 0.5100 0.4480\n",
      "EarlyStopping counter: 123 out of 100\n",
      "Epoch: 390 Step: 39780 Index:-0.3183 R2:0.8234 0.4390 0.5373 RMSE:0.4438 0.8213 0.7315 Tau:0.7353 0.5030 0.4408\n",
      "EarlyStopping counter: 124 out of 100\n",
      "Epoch: 391 Step: 39882 Index:-0.3126 R2:0.8155 0.4513 0.5461 RMSE:0.4550 0.8270 0.7280 Tau:0.7279 0.5144 0.4431\n",
      "EarlyStopping counter: 125 out of 100\n",
      "Epoch: 392 Step: 39984 Index:-0.3406 R2:0.8318 0.4244 0.5334 RMSE:0.4366 0.8423 0.7522 Tau:0.7412 0.5017 0.4401\n",
      "EarlyStopping counter: 126 out of 100\n",
      "Epoch: 393 Step: 40086 Index:-0.3144 R2:0.8344 0.4399 0.5257 RMSE:0.4338 0.8193 0.7546 Tau:0.7439 0.5049 0.4401\n",
      "EarlyStopping counter: 127 out of 100\n",
      "Epoch: 394 Step: 40188 Index:-0.3472 R2:0.8193 0.4265 0.5325 RMSE:0.4489 0.8458 0.7458 Tau:0.7316 0.4986 0.4478\n",
      "EarlyStopping counter: 128 out of 100\n",
      "Epoch: 395 Step: 40290 Index:-0.3386 R2:0.8280 0.4432 0.5583 RMSE:0.4661 0.8447 0.7760 Tau:0.7405 0.5061 0.4414\n",
      "EarlyStopping counter: 129 out of 100\n",
      "Epoch: 396 Step: 40392 Index:-0.3025 R2:0.8328 0.4498 0.5297 RMSE:0.4375 0.8151 0.7577 Tau:0.7423 0.5126 0.4359\n",
      "EarlyStopping counter: 130 out of 100\n",
      "Epoch: 397 Step: 40494 Index:-0.3284 R2:0.8323 0.4322 0.5472 RMSE:0.4340 0.8290 0.7334 Tau:0.7441 0.5007 0.4376\n",
      "EarlyStopping counter: 131 out of 100\n",
      "Epoch: 398 Step: 40596 Index:-0.3345 R2:0.8307 0.4275 0.5200 RMSE:0.4341 0.8333 0.7552 Tau:0.7416 0.4987 0.4423\n",
      "EarlyStopping counter: 132 out of 100\n",
      "Epoch: 399 Step: 40698 Index:-0.3662 R2:0.8368 0.4352 0.5498 RMSE:0.4745 0.8729 0.8057 Tau:0.7470 0.5068 0.4475\n",
      "EarlyStopping counter: 133 out of 100\n",
      "Epoch: 400 Step: 40800 Index:-0.3428 R2:0.8313 0.4253 0.5471 RMSE:0.4383 0.8450 0.7590 Tau:0.7430 0.5022 0.4416\n",
      "EarlyStopping counter: 135 out of 100\n",
      "Epoch: 402 Step: 41004 Index:-0.3326 R2:0.8315 0.4240 0.5518 RMSE:0.4418 0.8390 0.7422 Tau:0.7429 0.5063 0.4371\n",
      "EarlyStopping counter: 136 out of 100\n",
      "Epoch: 403 Step: 41106 Index:-0.3650 R2:0.8128 0.4264 0.5567 RMSE:0.4971 0.8723 0.7843 Tau:0.7269 0.5073 0.4457\n",
      "EarlyStopping counter: 137 out of 100\n",
      "Epoch: 404 Step: 41208 Index:-0.3357 R2:0.8328 0.4285 0.5523 RMSE:0.4315 0.8436 0.7236 Tau:0.7452 0.5079 0.4545\n",
      "EarlyStopping counter: 138 out of 100\n",
      "Epoch: 405 Step: 41310 Index:-0.3708 R2:0.8293 0.4392 0.5408 RMSE:0.5075 0.8813 0.8320 Tau:0.7416 0.5104 0.4411\n",
      "EarlyStopping counter: 139 out of 100\n",
      "Epoch: 406 Step: 41412 Index:-0.3156 R2:0.8281 0.4477 0.5425 RMSE:0.4515 0.8236 0.7684 Tau:0.7373 0.5080 0.4258\n",
      "EarlyStopping counter: 140 out of 100\n",
      "Epoch: 407 Step: 41514 Index:-0.3211 R2:0.8332 0.4428 0.5207 RMSE:0.4396 0.8259 0.7720 Tau:0.7420 0.5048 0.4379\n",
      "EarlyStopping counter: 141 out of 100\n",
      "Epoch: 408 Step: 41616 Index:-0.3124 R2:0.8408 0.4424 0.5445 RMSE:0.4239 0.8229 0.7265 Tau:0.7506 0.5105 0.4475\n",
      "EarlyStopping counter: 142 out of 100\n",
      "Epoch: 409 Step: 41718 Index:-0.3386 R2:0.8185 0.4319 0.5509 RMSE:0.4499 0.8386 0.7421 Tau:0.7309 0.5000 0.4457\n",
      "EarlyStopping counter: 143 out of 100\n",
      "Epoch: 410 Step: 41820 Index:-0.3114 R2:0.8351 0.4499 0.5493 RMSE:0.4281 0.8252 0.7379 Tau:0.7434 0.5138 0.4449\n",
      "EarlyStopping counter: 144 out of 100\n",
      "Epoch: 411 Step: 41922 Index:-0.3255 R2:0.8339 0.4337 0.5620 RMSE:0.4340 0.8326 0.7313 Tau:0.7465 0.5071 0.4537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 145 out of 100\n",
      "Epoch: 412 Step: 42024 Index:-0.3272 R2:0.8283 0.4424 0.5638 RMSE:0.4588 0.8357 0.7489 Tau:0.7400 0.5085 0.4425\n",
      "EarlyStopping counter: 146 out of 100\n",
      "Epoch: 413 Step: 42126 Index:-0.3319 R2:0.8270 0.4254 0.5289 RMSE:0.4414 0.8306 0.7511 Tau:0.7395 0.4987 0.4470\n",
      "EarlyStopping counter: 147 out of 100\n",
      "Epoch: 414 Step: 42228 Index:-0.3441 R2:0.8299 0.4297 0.5458 RMSE:0.4414 0.8487 0.7511 Tau:0.7405 0.5046 0.4490\n",
      "EarlyStopping counter: 148 out of 100\n",
      "Epoch: 415 Step: 42330 Index:-0.3121 R2:0.8419 0.4494 0.5494 RMSE:0.4299 0.8224 0.7501 Tau:0.7519 0.5103 0.4455\n",
      "EarlyStopping counter: 149 out of 100\n",
      "Epoch: 416 Step: 42432 Index:-0.3382 R2:0.8360 0.4322 0.5352 RMSE:0.4323 0.8352 0.7570 Tau:0.7454 0.4970 0.4430\n",
      "EarlyStopping counter: 150 out of 100\n",
      "Epoch: 417 Step: 42534 Index:-0.3494 R2:0.8327 0.4358 0.5750 RMSE:0.4449 0.8573 0.7448 Tau:0.7438 0.5079 0.4495\n",
      "EarlyStopping counter: 151 out of 100\n",
      "Epoch: 418 Step: 42636 Index:-0.3403 R2:0.8284 0.4385 0.5394 RMSE:0.4395 0.8386 0.7440 Tau:0.7387 0.4983 0.4468\n",
      "EarlyStopping counter: 152 out of 100\n",
      "Epoch: 419 Step: 42738 Index:-0.3269 R2:0.8415 0.4350 0.5423 RMSE:0.4229 0.8301 0.7404 Tau:0.7514 0.5032 0.4455\n",
      "EarlyStopping counter: 153 out of 100\n",
      "Epoch: 420 Step: 42840 Index:-0.3106 R2:0.8388 0.4446 0.5500 RMSE:0.4242 0.8217 0.7216 Tau:0.7485 0.5111 0.4420\n",
      "EarlyStopping counter: 154 out of 100\n",
      "Epoch: 421 Step: 42942 Index:-0.3667 R2:0.8257 0.4091 0.5248 RMSE:0.4711 0.8622 0.7782 Tau:0.7375 0.4956 0.4360\n",
      "EarlyStopping counter: 155 out of 100\n",
      "Epoch: 422 Step: 43044 Index:-0.3101 R2:0.8424 0.4455 0.5568 RMSE:0.4297 0.8188 0.7100 Tau:0.7519 0.5087 0.4415\n",
      "EarlyStopping counter: 156 out of 100\n",
      "Epoch: 423 Step: 43146 Index:-0.3747 R2:0.8408 0.4203 0.5361 RMSE:0.4718 0.8719 0.8102 Tau:0.7506 0.4972 0.4460\n",
      "EarlyStopping counter: 157 out of 100\n",
      "Epoch: 424 Step: 43248 Index:-0.3276 R2:0.8370 0.4234 0.5208 RMSE:0.4429 0.8271 0.7581 Tau:0.7488 0.4996 0.4342\n",
      "EarlyStopping counter: 158 out of 100\n",
      "Epoch: 425 Step: 43350 Index:-0.3208 R2:0.8405 0.4471 0.5714 RMSE:0.4285 0.8319 0.7343 Tau:0.7514 0.5111 0.4521\n",
      "EarlyStopping counter: 159 out of 100\n",
      "Epoch: 426 Step: 43452 Index:-0.3371 R2:0.8406 0.4318 0.5568 RMSE:0.4416 0.8444 0.7639 Tau:0.7524 0.5073 0.4550\n",
      "EarlyStopping counter: 160 out of 100\n",
      "Epoch: 427 Step: 43554 Index:-0.3462 R2:0.8279 0.4278 0.5528 RMSE:0.4434 0.8415 0.7445 Tau:0.7399 0.4953 0.4534\n",
      "EarlyStopping counter: 161 out of 100\n",
      "Epoch: 428 Step: 43656 Index:-0.3437 R2:0.8408 0.4383 0.5856 RMSE:0.4342 0.8487 0.7323 Tau:0.7504 0.5049 0.4443\n",
      "EarlyStopping counter: 162 out of 100\n",
      "Epoch: 429 Step: 43758 Index:-0.3011 R2:0.8293 0.4582 0.5599 RMSE:0.4352 0.8123 0.7199 Tau:0.7404 0.5111 0.4467\n",
      "EarlyStopping counter: 163 out of 100\n",
      "Epoch: 430 Step: 43860 Index:-0.3453 R2:0.8345 0.4312 0.5645 RMSE:0.4474 0.8462 0.7439 Tau:0.7471 0.5009 0.4423\n",
      "EarlyStopping counter: 164 out of 100\n",
      "Epoch: 431 Step: 43962 Index:-0.3490 R2:0.8407 0.4344 0.5503 RMSE:0.4585 0.8505 0.7857 Tau:0.7499 0.5015 0.4428\n",
      "EarlyStopping counter: 165 out of 100\n",
      "Epoch: 432 Step: 44064 Index:-0.3279 R2:0.8365 0.4502 0.5650 RMSE:0.4561 0.8413 0.7702 Tau:0.7479 0.5135 0.4543\n",
      "EarlyStopping counter: 166 out of 100\n",
      "Epoch: 433 Step: 44166 Index:-0.3534 R2:0.8352 0.4252 0.5662 RMSE:0.4268 0.8546 0.7206 Tau:0.7454 0.5011 0.4484\n",
      "EarlyStopping counter: 167 out of 100\n",
      "Epoch: 434 Step: 44268 Index:-0.3092 R2:0.8370 0.4435 0.5327 RMSE:0.4354 0.8141 0.7280 Tau:0.7457 0.5049 0.4457\n",
      "EarlyStopping counter: 168 out of 100\n",
      "Epoch: 435 Step: 44370 Index:-0.3577 R2:0.8444 0.4228 0.5726 RMSE:0.4409 0.8620 0.7494 Tau:0.7547 0.5042 0.4518\n",
      "EarlyStopping counter: 169 out of 100\n",
      "Epoch: 436 Step: 44472 Index:-0.3721 R2:0.8369 0.4309 0.5638 RMSE:0.4836 0.8755 0.8031 Tau:0.7483 0.5034 0.4524\n",
      "EarlyStopping counter: 170 out of 100\n",
      "Epoch: 437 Step: 44574 Index:-0.3357 R2:0.8483 0.4329 0.5462 RMSE:0.4287 0.8369 0.7622 Tau:0.7573 0.5012 0.4506\n",
      "EarlyStopping counter: 171 out of 100\n",
      "Epoch: 438 Step: 44676 Index:-0.3395 R2:0.8409 0.4299 0.5565 RMSE:0.4337 0.8484 0.7511 Tau:0.7515 0.5089 0.4443\n",
      "EarlyStopping counter: 172 out of 100\n",
      "Epoch: 439 Step: 44778 Index:-0.3334 R2:0.8400 0.4426 0.5724 RMSE:0.4331 0.8457 0.7447 Tau:0.7487 0.5123 0.4476\n",
      "EarlyStopping counter: 173 out of 100\n",
      "Epoch: 440 Step: 44880 Index:-0.3514 R2:0.8334 0.4353 0.5569 RMSE:0.4560 0.8590 0.7693 Tau:0.7442 0.5076 0.4523\n",
      "EarlyStopping counter: 174 out of 100\n",
      "Epoch: 441 Step: 44982 Index:-0.3337 R2:0.8397 0.4297 0.5526 RMSE:0.4317 0.8440 0.7438 Tau:0.7501 0.5103 0.4550\n",
      "EarlyStopping counter: 175 out of 100\n",
      "Epoch: 442 Step: 45084 Index:-0.3373 R2:0.8478 0.4477 0.5552 RMSE:0.4635 0.8524 0.7966 Tau:0.7556 0.5151 0.4435\n",
      "EarlyStopping counter: 176 out of 100\n",
      "Epoch: 443 Step: 45186 Index:-0.3191 R2:0.8500 0.4387 0.5649 RMSE:0.4080 0.8292 0.7157 Tau:0.7595 0.5101 0.4512\n",
      "EarlyStopping counter: 177 out of 100\n",
      "Epoch: 444 Step: 45288 Index:-0.4358 R2:0.8395 0.3986 0.5370 RMSE:0.5520 0.9271 0.8815 Tau:0.7532 0.4913 0.4530\n",
      "EarlyStopping counter: 178 out of 100\n",
      "Epoch: 445 Step: 45390 Index:-0.3457 R2:0.8507 0.4311 0.5531 RMSE:0.4317 0.8518 0.7719 Tau:0.7602 0.5060 0.4523\n",
      "EarlyStopping counter: 179 out of 100\n",
      "Epoch: 446 Step: 45492 Index:-0.3525 R2:0.8442 0.4356 0.5777 RMSE:0.4297 0.8585 0.7446 Tau:0.7532 0.5060 0.4566\n",
      "EarlyStopping counter: 180 out of 100\n",
      "Epoch: 447 Step: 45594 Index:-0.3266 R2:0.8525 0.4353 0.5792 RMSE:0.4090 0.8364 0.7157 Tau:0.7609 0.5098 0.4552\n",
      "EarlyStopping counter: 181 out of 100\n",
      "Epoch: 448 Step: 45696 Index:-0.3423 R2:0.8476 0.4149 0.5426 RMSE:0.4172 0.8387 0.7295 Tau:0.7573 0.4964 0.4516\n",
      "EarlyStopping counter: 182 out of 100\n",
      "Epoch: 449 Step: 45798 Index:-0.3818 R2:0.8360 0.4086 0.5461 RMSE:0.4399 0.8722 0.7670 Tau:0.7451 0.4904 0.4470\n",
      "EarlyStopping counter: 183 out of 100\n",
      "Epoch: 450 Step: 45900 Index:-0.3232 R2:0.8546 0.4442 0.5529 RMSE:0.4177 0.8356 0.7631 Tau:0.7607 0.5124 0.4498\n",
      "EarlyStopping counter: 184 out of 100\n",
      "Epoch: 451 Step: 46002 Index:-0.3370 R2:0.8506 0.4497 0.5660 RMSE:0.4516 0.8501 0.7817 Tau:0.7597 0.5131 0.4487\n",
      "EarlyStopping counter: 185 out of 100\n",
      "Epoch: 452 Step: 46104 Index:-0.3924 R2:0.8509 0.4325 0.5527 RMSE:0.4998 0.8998 0.8369 Tau:0.7598 0.5074 0.4508\n",
      "EarlyStopping counter: 186 out of 100\n",
      "Epoch: 453 Step: 46206 Index:-0.3351 R2:0.8473 0.4407 0.5893 RMSE:0.4298 0.8484 0.7354 Tau:0.7573 0.5133 0.4547\n",
      "EarlyStopping counter: 187 out of 100\n",
      "Epoch: 454 Step: 46308 Index:-0.3098 R2:0.8521 0.4400 0.5871 RMSE:0.4097 0.8213 0.7033 Tau:0.7598 0.5115 0.4466\n",
      "EarlyStopping counter: 188 out of 100\n",
      "Epoch: 455 Step: 46410 Index:-0.3422 R2:0.8477 0.4353 0.5422 RMSE:0.4531 0.8409 0.7815 Tau:0.7567 0.4986 0.4471\n",
      "EarlyStopping counter: 189 out of 100\n",
      "Epoch: 456 Step: 46512 Index:-0.3328 R2:0.8505 0.4331 0.5619 RMSE:0.4148 0.8363 0.7414 Tau:0.7595 0.5035 0.4573\n",
      "EarlyStopping counter: 190 out of 100\n",
      "Epoch: 457 Step: 46614 Index:-0.3099 R2:0.8517 0.4410 0.5536 RMSE:0.4086 0.8214 0.7245 Tau:0.7589 0.5116 0.4538\n",
      "EarlyStopping counter: 191 out of 100\n",
      "Epoch: 458 Step: 46716 Index:-0.3272 R2:0.8517 0.4362 0.5620 RMSE:0.4057 0.8349 0.7242 Tau:0.7591 0.5077 0.4564\n",
      "EarlyStopping counter: 192 out of 100\n",
      "Epoch: 459 Step: 46818 Index:-0.3122 R2:0.8519 0.4580 0.5697 RMSE:0.4154 0.8282 0.7402 Tau:0.7585 0.5160 0.4551\n",
      "EarlyStopping counter: 193 out of 100\n",
      "Epoch: 460 Step: 46920 Index:-0.3122 R2:0.8488 0.4574 0.5867 RMSE:0.4109 0.8267 0.7012 Tau:0.7582 0.5145 0.4580\n",
      "EarlyStopping counter: 194 out of 100\n",
      "Epoch: 461 Step: 47022 Index:-0.3212 R2:0.8550 0.4365 0.5688 RMSE:0.4030 0.8313 0.7174 Tau:0.7620 0.5101 0.4512\n",
      "EarlyStopping counter: 195 out of 100\n",
      "Epoch: 462 Step: 47124 Index:-0.3149 R2:0.8512 0.4354 0.5302 RMSE:0.4143 0.8195 0.7336 Tau:0.7595 0.5046 0.4521\n",
      "EarlyStopping counter: 196 out of 100\n",
      "Epoch: 463 Step: 47226 Index:-0.3463 R2:0.8491 0.4388 0.5720 RMSE:0.4304 0.8528 0.7526 Tau:0.7573 0.5065 0.4465\n",
      "EarlyStopping counter: 197 out of 100\n",
      "Epoch: 464 Step: 47328 Index:-0.3188 R2:0.8544 0.4354 0.5706 RMSE:0.4072 0.8307 0.7190 Tau:0.7625 0.5119 0.4539\n",
      "EarlyStopping counter: 198 out of 100\n",
      "Epoch: 465 Step: 47430 Index:-0.3177 R2:0.8512 0.4402 0.5457 RMSE:0.4069 0.8270 0.7322 Tau:0.7586 0.5093 0.4558\n",
      "EarlyStopping counter: 199 out of 100\n",
      "Epoch: 466 Step: 47532 Index:-0.3140 R2:0.8502 0.4473 0.5560 RMSE:0.4089 0.8239 0.7393 Tau:0.7585 0.5099 0.4499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 200 out of 100\n",
      "Epoch: 467 Step: 47634 Index:-0.3368 R2:0.8415 0.4327 0.5914 RMSE:0.4185 0.8443 0.7017 Tau:0.7520 0.5074 0.4510\n",
      "EarlyStopping counter: 201 out of 100\n",
      "Epoch: 468 Step: 47736 Index:-0.3402 R2:0.8529 0.4241 0.5619 RMSE:0.4050 0.8480 0.7175 Tau:0.7603 0.5078 0.4563\n",
      "EarlyStopping counter: 202 out of 100\n",
      "Epoch: 469 Step: 47838 Index:-0.3457 R2:0.8577 0.4223 0.5552 RMSE:0.4139 0.8481 0.7489 Tau:0.7640 0.5024 0.4531\n",
      "EarlyStopping counter: 203 out of 100\n",
      "Epoch: 470 Step: 47940 Index:-0.2953 R2:0.8595 0.4507 0.5602 RMSE:0.3968 0.8129 0.7204 Tau:0.7666 0.5177 0.4508\n",
      "EarlyStopping counter: 204 out of 100\n",
      "Epoch: 471 Step: 48042 Index:-0.3093 R2:0.8485 0.4402 0.5569 RMSE:0.4137 0.8215 0.7247 Tau:0.7562 0.5122 0.4411\n",
      "EarlyStopping counter: 205 out of 100\n",
      "Epoch: 472 Step: 48144 Index:-0.3218 R2:0.8326 0.4451 0.5529 RMSE:0.4457 0.8240 0.7676 Tau:0.7432 0.5022 0.4388\n",
      "EarlyStopping counter: 206 out of 100\n",
      "Epoch: 473 Step: 48246 Index:-0.3892 R2:0.8571 0.4282 0.5723 RMSE:0.4988 0.8929 0.8212 Tau:0.7659 0.5037 0.4538\n",
      "EarlyStopping counter: 207 out of 100\n",
      "Epoch: 474 Step: 48348 Index:-0.3857 R2:0.8589 0.4243 0.5603 RMSE:0.4847 0.8916 0.8181 Tau:0.7670 0.5059 0.4586\n",
      "EarlyStopping counter: 208 out of 100\n",
      "Epoch: 475 Step: 48450 Index:-0.4281 R2:0.8334 0.4019 0.5241 RMSE:0.5237 0.9146 0.8603 Tau:0.7448 0.4866 0.4476\n",
      "EarlyStopping counter: 209 out of 100\n",
      "Epoch: 476 Step: 48552 Index:-0.3348 R2:0.8582 0.4324 0.5692 RMSE:0.4061 0.8427 0.7400 Tau:0.7665 0.5079 0.4587\n",
      "EarlyStopping counter: 210 out of 100\n",
      "Epoch: 477 Step: 48654 Index:-0.3299 R2:0.8605 0.4494 0.5643 RMSE:0.4353 0.8413 0.7806 Tau:0.7682 0.5115 0.4530\n",
      "EarlyStopping counter: 211 out of 100\n",
      "Epoch: 478 Step: 48756 Index:-0.3579 R2:0.8567 0.4232 0.5731 RMSE:0.4299 0.8633 0.7623 Tau:0.7653 0.5054 0.4590\n",
      "EarlyStopping counter: 212 out of 100\n",
      "Epoch: 479 Step: 48858 Index:-0.3677 R2:0.8160 0.4223 0.5335 RMSE:0.4554 0.8555 0.7498 Tau:0.7310 0.4878 0.4381\n",
      "EarlyStopping counter: 213 out of 100\n",
      "Epoch: 480 Step: 48960 Index:-0.2979 R2:0.8569 0.4564 0.5785 RMSE:0.4234 0.8147 0.7367 Tau:0.7656 0.5167 0.4530\n",
      "EarlyStopping counter: 214 out of 100\n",
      "Epoch: 481 Step: 49062 Index:-0.3404 R2:0.8530 0.4431 0.5730 RMSE:0.4280 0.8530 0.7558 Tau:0.7592 0.5125 0.4591\n",
      "EarlyStopping counter: 215 out of 100\n",
      "Epoch: 482 Step: 49164 Index:-0.3556 R2:0.8364 0.4236 0.5813 RMSE:0.4510 0.8585 0.6865 Tau:0.7456 0.5029 0.4495\n",
      "EarlyStopping counter: 216 out of 100\n",
      "Epoch: 483 Step: 49266 Index:-0.3145 R2:0.8621 0.4376 0.5682 RMSE:0.3960 0.8268 0.7041 Tau:0.7707 0.5123 0.4594\n",
      "EarlyStopping counter: 217 out of 100\n",
      "Epoch: 484 Step: 49368 Index:-0.3269 R2:0.8638 0.4411 0.5677 RMSE:0.4226 0.8394 0.7636 Tau:0.7711 0.5125 0.4496\n",
      "EarlyStopping counter: 218 out of 100\n",
      "Epoch: 485 Step: 49470 Index:-0.3136 R2:0.8608 0.4431 0.5709 RMSE:0.3939 0.8266 0.7170 Tau:0.7668 0.5130 0.4581\n",
      "EarlyStopping counter: 219 out of 100\n",
      "Epoch: 486 Step: 49572 Index:-0.3307 R2:0.8511 0.4392 0.5773 RMSE:0.4064 0.8373 0.7225 Tau:0.7603 0.5066 0.4577\n",
      "EarlyStopping counter: 220 out of 100\n",
      "Epoch: 487 Step: 49674 Index:-0.3291 R2:0.8579 0.4401 0.5798 RMSE:0.3994 0.8339 0.7010 Tau:0.7660 0.5048 0.4588\n",
      "EarlyStopping counter: 221 out of 100\n",
      "Epoch: 488 Step: 49776 Index:-0.3459 R2:0.8636 0.4413 0.5691 RMSE:0.4374 0.8589 0.7758 Tau:0.7703 0.5130 0.4580\n",
      "EarlyStopping counter: 222 out of 100\n",
      "Epoch: 489 Step: 49878 Index:-0.3564 R2:0.8442 0.4200 0.5639 RMSE:0.4351 0.8628 0.7520 Tau:0.7532 0.5063 0.4488\n",
      "EarlyStopping counter: 223 out of 100\n",
      "Epoch: 490 Step: 49980 Index:-0.3637 R2:0.8497 0.4155 0.5808 RMSE:0.4146 0.8577 0.7271 Tau:0.7592 0.4940 0.4542\n",
      "EarlyStopping counter: 224 out of 100\n",
      "Epoch: 491 Step: 50082 Index:-0.3548 R2:0.8451 0.4288 0.5660 RMSE:0.4286 0.8617 0.7529 Tau:0.7529 0.5069 0.4470\n",
      "EarlyStopping counter: 225 out of 100\n",
      "Epoch: 492 Step: 50184 Index:-0.3419 R2:0.8633 0.4347 0.5839 RMSE:0.4386 0.8478 0.7634 Tau:0.7718 0.5060 0.4504\n",
      "EarlyStopping counter: 226 out of 100\n",
      "Epoch: 493 Step: 50286 Index:-0.3162 R2:0.8591 0.4487 0.5787 RMSE:0.3951 0.8327 0.7222 Tau:0.7659 0.5164 0.4507\n",
      "EarlyStopping counter: 227 out of 100\n",
      "Epoch: 494 Step: 50388 Index:-0.3600 R2:0.8628 0.4367 0.5542 RMSE:0.4446 0.8670 0.8068 Tau:0.7679 0.5070 0.4521\n",
      "EarlyStopping counter: 228 out of 100\n",
      "Epoch: 495 Step: 50490 Index:-0.3250 R2:0.8627 0.4336 0.5889 RMSE:0.3987 0.8355 0.7113 Tau:0.7713 0.5105 0.4538\n",
      "EarlyStopping counter: 229 out of 100\n",
      "Epoch: 496 Step: 50592 Index:-0.3370 R2:0.8567 0.4437 0.5759 RMSE:0.4121 0.8470 0.7530 Tau:0.7646 0.5099 0.4599\n",
      "EarlyStopping counter: 230 out of 100\n",
      "Epoch: 497 Step: 50694 Index:-0.2990 R2:0.8645 0.4497 0.5874 RMSE:0.3894 0.8171 0.6949 Tau:0.7703 0.5181 0.4563\n",
      "EarlyStopping counter: 231 out of 100\n",
      "Epoch: 498 Step: 50796 Index:-0.3150 R2:0.8648 0.4451 0.5932 RMSE:0.3983 0.8238 0.6808 Tau:0.7706 0.5088 0.4551\n",
      "EarlyStopping counter: 232 out of 100\n",
      "Epoch: 499 Step: 50898 Index:-0.3621 R2:0.8601 0.4195 0.5594 RMSE:0.4011 0.8644 0.7496 Tau:0.7665 0.5023 0.4600\n",
      "EarlyStopping counter: 233 out of 100\n",
      "Epoch: 500 Step: 51000 Index:-0.3487 R2:0.8605 0.4380 0.5844 RMSE:0.4179 0.8523 0.7516 Tau:0.7675 0.5036 0.4533\n",
      "EarlyStopping counter: 234 out of 100\n",
      "Epoch: 501 Step: 51102 Index:-0.3034 R2:0.8654 0.4461 0.5720 RMSE:0.3910 0.8153 0.7109 Tau:0.7719 0.5119 0.4537\n",
      "EarlyStopping counter: 235 out of 100\n",
      "Epoch: 502 Step: 51204 Index:-0.3459 R2:0.8651 0.4271 0.5798 RMSE:0.3973 0.8496 0.7316 Tau:0.7720 0.5037 0.4596\n",
      "EarlyStopping counter: 236 out of 100\n",
      "Epoch: 503 Step: 51306 Index:-0.3486 R2:0.8476 0.4290 0.5618 RMSE:0.4280 0.8553 0.7530 Tau:0.7550 0.5067 0.4394\n",
      "EarlyStopping counter: 237 out of 100\n",
      "Epoch: 504 Step: 51408 Index:-0.3526 R2:0.8582 0.4068 0.5761 RMSE:0.4027 0.8471 0.7056 Tau:0.7648 0.4945 0.4529\n",
      "EarlyStopping counter: 238 out of 100\n",
      "Epoch: 505 Step: 51510 Index:-0.3225 R2:0.8629 0.4305 0.5935 RMSE:0.4109 0.8315 0.6762 Tau:0.7712 0.5090 0.4543\n",
      "EarlyStopping counter: 239 out of 100\n",
      "Epoch: 506 Step: 51612 Index:-0.3416 R2:0.8679 0.4194 0.5816 RMSE:0.3929 0.8455 0.6902 Tau:0.7738 0.5039 0.4543\n",
      "EarlyStopping counter: 240 out of 100\n",
      "Epoch: 507 Step: 51714 Index:-0.3483 R2:0.8495 0.4284 0.5835 RMSE:0.4494 0.8531 0.6899 Tau:0.7575 0.5048 0.4420\n",
      "EarlyStopping counter: 241 out of 100\n",
      "Epoch: 508 Step: 51816 Index:-0.3301 R2:0.8693 0.4285 0.5830 RMSE:0.3964 0.8387 0.7230 Tau:0.7764 0.5086 0.4558\n",
      "EarlyStopping counter: 242 out of 100\n",
      "Epoch: 509 Step: 51918 Index:-0.3419 R2:0.8620 0.4312 0.5762 RMSE:0.4137 0.8505 0.7430 Tau:0.7680 0.5086 0.4520\n",
      "EarlyStopping counter: 243 out of 100\n",
      "Epoch: 510 Step: 52020 Index:-0.3448 R2:0.8651 0.4304 0.5675 RMSE:0.3917 0.8505 0.7416 Tau:0.7717 0.5057 0.4638\n",
      "EarlyStopping counter: 244 out of 100\n",
      "Epoch: 511 Step: 52122 Index:-0.3512 R2:0.8682 0.4236 0.5650 RMSE:0.4140 0.8595 0.7673 Tau:0.7748 0.5082 0.4543\n",
      "EarlyStopping counter: 245 out of 100\n",
      "Epoch: 512 Step: 52224 Index:-0.3350 R2:0.8601 0.4339 0.5767 RMSE:0.3945 0.8491 0.7242 Tau:0.7664 0.5141 0.4527\n",
      "EarlyStopping counter: 246 out of 100\n",
      "Epoch: 513 Step: 52326 Index:-0.3089 R2:0.8691 0.4415 0.5952 RMSE:0.3845 0.8212 0.6881 Tau:0.7752 0.5122 0.4575\n",
      "EarlyStopping counter: 247 out of 100\n",
      "Epoch: 514 Step: 52428 Index:-0.3380 R2:0.8691 0.4215 0.5863 RMSE:0.3898 0.8432 0.7119 Tau:0.7767 0.5052 0.4616\n",
      "EarlyStopping counter: 248 out of 100\n",
      "Epoch: 515 Step: 52530 Index:-0.3292 R2:0.8647 0.4336 0.5800 RMSE:0.3998 0.8340 0.7325 Tau:0.7727 0.5048 0.4512\n",
      "EarlyStopping counter: 249 out of 100\n",
      "Epoch: 516 Step: 52632 Index:-0.3940 R2:0.8596 0.4026 0.5703 RMSE:0.4169 0.8917 0.7618 Tau:0.7691 0.4978 0.4526\n",
      "EarlyStopping counter: 250 out of 100\n",
      "Epoch: 517 Step: 52734 Index:-0.3164 R2:0.8709 0.4410 0.5784 RMSE:0.3833 0.8260 0.7210 Tau:0.7775 0.5096 0.4563\n",
      "EarlyStopping counter: 251 out of 100\n",
      "Epoch: 518 Step: 52836 Index:-0.3231 R2:0.8554 0.4530 0.6034 RMSE:0.4161 0.8371 0.7361 Tau:0.7634 0.5140 0.4534\n",
      "EarlyStopping counter: 252 out of 100\n",
      "Epoch: 519 Step: 52938 Index:-0.3108 R2:0.8729 0.4452 0.5890 RMSE:0.3933 0.8260 0.7278 Tau:0.7809 0.5152 0.4577\n",
      "EarlyStopping counter: 253 out of 100\n",
      "Epoch: 520 Step: 53040 Index:-0.2997 R2:0.8671 0.4506 0.5884 RMSE:0.3852 0.8161 0.7011 Tau:0.7733 0.5164 0.4575\n",
      "EarlyStopping counter: 254 out of 100\n",
      "Epoch: 521 Step: 53142 Index:-0.3397 R2:0.8515 0.4304 0.5742 RMSE:0.4139 0.8380 0.7341 Tau:0.7613 0.4983 0.4563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 255 out of 100\n",
      "Epoch: 522 Step: 53244 Index:-0.3307 R2:0.8738 0.4319 0.5806 RMSE:0.3892 0.8403 0.7273 Tau:0.7800 0.5096 0.4606\n",
      "EarlyStopping counter: 256 out of 100\n",
      "Epoch: 523 Step: 53346 Index:-0.3455 R2:0.8672 0.4309 0.5940 RMSE:0.3909 0.8555 0.7249 Tau:0.7730 0.5099 0.4541\n",
      "EarlyStopping counter: 257 out of 100\n",
      "Epoch: 524 Step: 53448 Index:-0.3163 R2:0.8729 0.4402 0.5994 RMSE:0.3780 0.8341 0.7026 Tau:0.7800 0.5178 0.4609\n",
      "EarlyStopping counter: 258 out of 100\n",
      "Epoch: 525 Step: 53550 Index:-0.3176 R2:0.8706 0.4341 0.5929 RMSE:0.3838 0.8268 0.7008 Tau:0.7784 0.5093 0.4549\n",
      "EarlyStopping counter: 259 out of 100\n",
      "Epoch: 526 Step: 53652 Index:-0.3093 R2:0.8748 0.4458 0.6037 RMSE:0.3761 0.8274 0.7012 Tau:0.7816 0.5181 0.4607\n",
      "EarlyStopping counter: 260 out of 100\n",
      "Epoch: 527 Step: 53754 Index:-0.3700 R2:0.8597 0.4337 0.5851 RMSE:0.4624 0.8800 0.7960 Tau:0.7662 0.5100 0.4519\n",
      "EarlyStopping counter: 261 out of 100\n",
      "Epoch: 528 Step: 53856 Index:-0.3657 R2:0.8636 0.4109 0.5411 RMSE:0.4115 0.8585 0.7680 Tau:0.7698 0.4928 0.4551\n",
      "EarlyStopping counter: 262 out of 100\n",
      "Epoch: 529 Step: 53958 Index:-0.3522 R2:0.8631 0.4241 0.5851 RMSE:0.3898 0.8554 0.7143 Tau:0.7697 0.5032 0.4523\n",
      "EarlyStopping counter: 263 out of 100\n",
      "Epoch: 530 Step: 54060 Index:-0.3125 R2:0.8729 0.4437 0.6033 RMSE:0.3823 0.8284 0.6783 Tau:0.7805 0.5159 0.4552\n",
      "EarlyStopping counter: 264 out of 100\n",
      "Epoch: 531 Step: 54162 Index:-0.3205 R2:0.8758 0.4488 0.5900 RMSE:0.3950 0.8420 0.7450 Tau:0.7812 0.5214 0.4537\n",
      "EarlyStopping counter: 265 out of 100\n",
      "Epoch: 532 Step: 54264 Index:-0.3401 R2:0.8738 0.4298 0.5748 RMSE:0.4024 0.8483 0.7607 Tau:0.7802 0.5082 0.4582\n",
      "EarlyStopping counter: 266 out of 100\n",
      "Epoch: 533 Step: 54366 Index:-0.3202 R2:0.8762 0.4345 0.5699 RMSE:0.3819 0.8339 0.7001 Tau:0.7823 0.5137 0.4603\n",
      "EarlyStopping counter: 267 out of 100\n",
      "Epoch: 534 Step: 54468 Index:-0.3328 R2:0.8753 0.4373 0.5863 RMSE:0.3718 0.8499 0.7153 Tau:0.7817 0.5171 0.4590\n",
      "EarlyStopping counter: 268 out of 100\n",
      "Epoch: 535 Step: 54570 Index:-0.3004 R2:0.8645 0.4518 0.5952 RMSE:0.3874 0.8211 0.6940 Tau:0.7716 0.5207 0.4548\n",
      "EarlyStopping counter: 269 out of 100\n",
      "Epoch: 536 Step: 54672 Index:-0.3270 R2:0.8660 0.4357 0.5873 RMSE:0.3924 0.8329 0.7293 Tau:0.7723 0.5059 0.4568\n",
      "EarlyStopping counter: 270 out of 100\n",
      "Epoch: 537 Step: 54774 Index:-0.3222 R2:0.8586 0.4314 0.5870 RMSE:0.4152 0.8259 0.6867 Tau:0.7655 0.5037 0.4489\n",
      "EarlyStopping counter: 271 out of 100\n",
      "Epoch: 538 Step: 54876 Index:-0.2990 R2:0.8728 0.4474 0.5839 RMSE:0.3909 0.8205 0.6901 Tau:0.7808 0.5214 0.4573\n",
      "EarlyStopping counter: 272 out of 100\n",
      "Epoch: 539 Step: 54978 Index:-0.3562 R2:0.8640 0.4112 0.5780 RMSE:0.3882 0.8634 0.7088 Tau:0.7719 0.5073 0.4549\n",
      "EarlyStopping counter: 273 out of 100\n",
      "Epoch: 540 Step: 55080 Index:-0.3145 R2:0.8695 0.4377 0.5824 RMSE:0.3863 0.8237 0.7098 Tau:0.7766 0.5092 0.4572\n",
      "EarlyStopping counter: 274 out of 100\n",
      "Epoch: 541 Step: 55182 Index:-0.3014 R2:0.8689 0.4557 0.5928 RMSE:0.3857 0.8275 0.6908 Tau:0.7757 0.5261 0.4616\n",
      "EarlyStopping counter: 275 out of 100\n",
      "Epoch: 542 Step: 55284 Index:-0.2984 R2:0.8635 0.4469 0.5907 RMSE:0.3915 0.8213 0.6922 Tau:0.7705 0.5229 0.4612\n",
      "EarlyStopping counter: 276 out of 100\n",
      "Epoch: 543 Step: 55386 Index:-0.3490 R2:0.8613 0.4399 0.6107 RMSE:0.4501 0.8657 0.7652 Tau:0.7688 0.5166 0.4498\n",
      "EarlyStopping counter: 277 out of 100\n",
      "Epoch: 544 Step: 55488 Index:-0.3107 R2:0.8765 0.4464 0.6032 RMSE:0.3755 0.8266 0.6798 Tau:0.7817 0.5160 0.4612\n",
      "EarlyStopping counter: 278 out of 100\n",
      "Epoch: 545 Step: 55590 Index:-0.3036 R2:0.8753 0.4487 0.5914 RMSE:0.4079 0.8220 0.6766 Tau:0.7819 0.5184 0.4607\n",
      "EarlyStopping counter: 279 out of 100\n",
      "Epoch: 546 Step: 55692 Index:-0.3204 R2:0.8699 0.4464 0.6057 RMSE:0.3849 0.8401 0.7140 Tau:0.7753 0.5197 0.4599\n",
      "EarlyStopping counter: 280 out of 100\n",
      "Epoch: 547 Step: 55794 Index:-0.3350 R2:0.8816 0.4301 0.5881 RMSE:0.3666 0.8454 0.7114 Tau:0.7874 0.5104 0.4651\n",
      "EarlyStopping counter: 281 out of 100\n",
      "Epoch: 548 Step: 55896 Index:-0.3118 R2:0.8722 0.4516 0.5997 RMSE:0.3802 0.8377 0.7112 Tau:0.7790 0.5259 0.4624\n",
      "EarlyStopping counter: 282 out of 100\n",
      "Epoch: 549 Step: 55998 Index:-0.3246 R2:0.8784 0.4335 0.5897 RMSE:0.3801 0.8375 0.6875 Tau:0.7828 0.5129 0.4578\n",
      "EarlyStopping counter: 283 out of 100\n",
      "Epoch: 550 Step: 56100 Index:-0.3178 R2:0.8749 0.4431 0.5977 RMSE:0.3824 0.8420 0.6823 Tau:0.7807 0.5242 0.4616\n",
      "EarlyStopping counter: 284 out of 100\n",
      "Epoch: 551 Step: 56202 Index:-0.3003 R2:0.8783 0.4515 0.5928 RMSE:0.4004 0.8227 0.6781 Tau:0.7842 0.5224 0.4575\n",
      "EarlyStopping counter: 285 out of 100\n",
      "Epoch: 552 Step: 56304 Index:-0.3515 R2:0.8772 0.4367 0.5951 RMSE:0.4075 0.8654 0.7659 Tau:0.7820 0.5139 0.4645\n",
      "EarlyStopping counter: 286 out of 100\n",
      "Epoch: 553 Step: 56406 Index:-0.3198 R2:0.8723 0.4468 0.6234 RMSE:0.3781 0.8350 0.6968 Tau:0.7788 0.5152 0.4620\n",
      "EarlyStopping counter: 287 out of 100\n",
      "Epoch: 554 Step: 56508 Index:-0.3333 R2:0.8787 0.4336 0.5956 RMSE:0.3687 0.8433 0.6913 Tau:0.7838 0.5099 0.4610\n",
      "EarlyStopping counter: 288 out of 100\n",
      "Epoch: 555 Step: 56610 Index:-0.3258 R2:0.8799 0.4383 0.5970 RMSE:0.3838 0.8406 0.7241 Tau:0.7860 0.5148 0.4614\n",
      "EarlyStopping counter: 289 out of 100\n",
      "Epoch: 556 Step: 56712 Index:-0.3486 R2:0.8793 0.4335 0.6209 RMSE:0.3824 0.8657 0.7165 Tau:0.7857 0.5171 0.4642\n",
      "EarlyStopping counter: 290 out of 100\n",
      "Epoch: 557 Step: 56814 Index:-0.3321 R2:0.8812 0.4327 0.6046 RMSE:0.3867 0.8485 0.7229 Tau:0.7875 0.5164 0.4658\n",
      "EarlyStopping counter: 291 out of 100\n",
      "Epoch: 558 Step: 56916 Index:-0.3412 R2:0.8756 0.4325 0.5966 RMSE:0.3732 0.8474 0.6891 Tau:0.7800 0.5062 0.4516\n",
      "EarlyStopping counter: 292 out of 100\n",
      "Epoch: 559 Step: 57018 Index:-0.3157 R2:0.8792 0.4431 0.6134 RMSE:0.3764 0.8308 0.6646 Tau:0.7858 0.5150 0.4620\n",
      "EarlyStopping counter: 293 out of 100\n",
      "Epoch: 560 Step: 57120 Index:-0.3799 R2:0.8747 0.4196 0.5912 RMSE:0.4130 0.8813 0.7674 Tau:0.7814 0.5014 0.4661\n",
      "EarlyStopping counter: 294 out of 100\n",
      "Epoch: 561 Step: 57222 Index:-0.3015 R2:0.8770 0.4529 0.5892 RMSE:0.3817 0.8264 0.7289 Tau:0.7829 0.5248 0.4615\n",
      "EarlyStopping counter: 295 out of 100\n",
      "Epoch: 562 Step: 57324 Index:-0.3538 R2:0.8707 0.4327 0.5998 RMSE:0.3894 0.8652 0.7331 Tau:0.7765 0.5114 0.4651\n",
      "EarlyStopping counter: 296 out of 100\n",
      "Epoch: 563 Step: 57426 Index:-0.3304 R2:0.8771 0.4380 0.5921 RMSE:0.3798 0.8441 0.7221 Tau:0.7813 0.5137 0.4579\n",
      "EarlyStopping counter: 297 out of 100\n",
      "Epoch: 564 Step: 57528 Index:-0.3450 R2:0.8836 0.4205 0.5826 RMSE:0.3746 0.8526 0.7329 Tau:0.7878 0.5077 0.4640\n",
      "EarlyStopping counter: 298 out of 100\n",
      "Epoch: 565 Step: 57630 Index:-0.3465 R2:0.8724 0.4329 0.5810 RMSE:0.4126 0.8619 0.7564 Tau:0.7760 0.5154 0.4530\n",
      "EarlyStopping counter: 299 out of 100\n",
      "Epoch: 566 Step: 57732 Index:-0.3355 R2:0.8842 0.4280 0.6015 RMSE:0.3618 0.8492 0.7013 Tau:0.7894 0.5137 0.4622\n",
      "EarlyStopping counter: 300 out of 100\n",
      "Epoch: 567 Step: 57834 Index:-0.3484 R2:0.8812 0.4328 0.5847 RMSE:0.4124 0.8632 0.7664 Tau:0.7868 0.5149 0.4597\n",
      "EarlyStopping counter: 301 out of 100\n",
      "Epoch: 568 Step: 57936 Index:-0.3383 R2:0.8845 0.4161 0.5732 RMSE:0.3672 0.8463 0.7147 Tau:0.7893 0.5080 0.4669\n",
      "EarlyStopping counter: 302 out of 100\n",
      "Epoch: 569 Step: 58038 Index:-0.3300 R2:0.8800 0.4296 0.6064 RMSE:0.3707 0.8406 0.6973 Tau:0.7855 0.5106 0.4645\n",
      "EarlyStopping counter: 303 out of 100\n",
      "Epoch: 570 Step: 58140 Index:-0.3614 R2:0.8851 0.4274 0.5996 RMSE:0.4222 0.8754 0.7596 Tau:0.7908 0.5140 0.4678\n",
      "EarlyStopping counter: 304 out of 100\n",
      "Epoch: 571 Step: 58242 Index:-0.3103 R2:0.8777 0.4375 0.6187 RMSE:0.3782 0.8302 0.6603 Tau:0.7835 0.5199 0.4646\n",
      "EarlyStopping counter: 305 out of 100\n",
      "Epoch: 572 Step: 58344 Index:-0.3493 R2:0.8724 0.4265 0.6024 RMSE:0.3766 0.8648 0.6927 Tau:0.7782 0.5155 0.4642\n",
      "EarlyStopping counter: 306 out of 100\n",
      "Epoch: 573 Step: 58446 Index:-0.3615 R2:0.8836 0.4302 0.5796 RMSE:0.4105 0.8804 0.7754 Tau:0.7888 0.5189 0.4642\n",
      "EarlyStopping counter: 307 out of 100\n",
      "Epoch: 574 Step: 58548 Index:-0.3224 R2:0.8816 0.4408 0.5978 RMSE:0.3645 0.8400 0.6856 Tau:0.7866 0.5176 0.4635\n",
      "EarlyStopping counter: 308 out of 100\n",
      "Epoch: 575 Step: 58650 Index:-0.3475 R2:0.8726 0.4117 0.5365 RMSE:0.3911 0.8490 0.7584 Tau:0.7803 0.5015 0.4613\n",
      "EarlyStopping counter: 309 out of 100\n",
      "Epoch: 576 Step: 58752 Index:-0.3847 R2:0.8700 0.4155 0.5931 RMSE:0.3951 0.8896 0.7520 Tau:0.7749 0.5049 0.4621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 310 out of 100\n",
      "Epoch: 577 Step: 58854 Index:-0.3257 R2:0.8871 0.4355 0.5888 RMSE:0.3739 0.8452 0.7312 Tau:0.7937 0.5195 0.4612\n",
      "EarlyStopping counter: 311 out of 100\n",
      "Epoch: 578 Step: 58956 Index:-0.3055 R2:0.8859 0.4322 0.5843 RMSE:0.3687 0.8275 0.6890 Tau:0.7923 0.5219 0.4576\n",
      "EarlyStopping counter: 312 out of 100\n",
      "Epoch: 579 Step: 59058 Index:-0.3287 R2:0.8851 0.4344 0.5928 RMSE:0.3652 0.8469 0.7227 Tau:0.7906 0.5182 0.4630\n",
      "EarlyStopping counter: 313 out of 100\n",
      "Epoch: 580 Step: 59160 Index:-0.3366 R2:0.8781 0.4338 0.5849 RMSE:0.3880 0.8541 0.7436 Tau:0.7839 0.5175 0.4567\n",
      "EarlyStopping counter: 314 out of 100\n",
      "Epoch: 581 Step: 59262 Index:-0.3344 R2:0.8872 0.4267 0.6180 RMSE:0.3550 0.8478 0.6794 Tau:0.7920 0.5134 0.4598\n",
      "EarlyStopping counter: 315 out of 100\n",
      "Epoch: 582 Step: 59364 Index:-0.3250 R2:0.8787 0.4456 0.5903 RMSE:0.3751 0.8424 0.6886 Tau:0.7826 0.5174 0.4499\n",
      "EarlyStopping counter: 316 out of 100\n",
      "Epoch: 583 Step: 59466 Index:-0.3622 R2:0.8824 0.4150 0.5982 RMSE:0.3696 0.8698 0.7145 Tau:0.7883 0.5076 0.4654\n",
      "EarlyStopping counter: 317 out of 100\n",
      "Epoch: 584 Step: 59568 Index:-0.3079 R2:0.8859 0.4525 0.6167 RMSE:0.3554 0.8320 0.6783 Tau:0.7895 0.5240 0.4621\n",
      "EarlyStopping counter: 318 out of 100\n",
      "Epoch: 585 Step: 59670 Index:-0.3280 R2:0.8854 0.4427 0.6048 RMSE:0.4004 0.8506 0.7441 Tau:0.7923 0.5226 0.4623\n",
      "EarlyStopping counter: 319 out of 100\n",
      "Epoch: 586 Step: 59772 Index:-0.3693 R2:0.8871 0.4117 0.5850 RMSE:0.4001 0.8766 0.7537 Tau:0.7927 0.5073 0.4687\n",
      "EarlyStopping counter: 320 out of 100\n",
      "Epoch: 587 Step: 59874 Index:-0.3266 R2:0.8899 0.4306 0.6047 RMSE:0.3530 0.8426 0.6910 Tau:0.7949 0.5160 0.4645\n",
      "EarlyStopping counter: 321 out of 100\n",
      "Epoch: 588 Step: 59976 Index:-0.3352 R2:0.8739 0.4347 0.5747 RMSE:0.4073 0.8551 0.7631 Tau:0.7797 0.5198 0.4577\n",
      "EarlyStopping counter: 322 out of 100\n",
      "Epoch: 589 Step: 60078 Index:-0.3421 R2:0.8832 0.4298 0.5793 RMSE:0.3646 0.8543 0.7312 Tau:0.7879 0.5122 0.4624\n",
      "EarlyStopping counter: 323 out of 100\n",
      "Epoch: 590 Step: 60180 Index:-0.3358 R2:0.8724 0.4460 0.6125 RMSE:0.3893 0.8543 0.7316 Tau:0.7778 0.5184 0.4574\n",
      "EarlyStopping counter: 324 out of 100\n",
      "Epoch: 591 Step: 60282 Index:-0.3505 R2:0.8690 0.4237 0.6414 RMSE:0.4097 0.8625 0.7031 Tau:0.7750 0.5119 0.4587\n",
      "EarlyStopping counter: 325 out of 100\n",
      "Epoch: 592 Step: 60384 Index:-0.3391 R2:0.8903 0.4306 0.5870 RMSE:0.3537 0.8545 0.7218 Tau:0.7952 0.5154 0.4655\n",
      "EarlyStopping counter: 326 out of 100\n",
      "Epoch: 593 Step: 60486 Index:-0.3583 R2:0.8836 0.4191 0.6047 RMSE:0.3802 0.8672 0.7278 Tau:0.7885 0.5089 0.4595\n",
      "EarlyStopping counter: 327 out of 100\n",
      "Epoch: 594 Step: 60588 Index:-0.3334 R2:0.8926 0.4381 0.6007 RMSE:0.3704 0.8544 0.7363 Tau:0.7985 0.5211 0.4602\n",
      "EarlyStopping counter: 328 out of 100\n",
      "Epoch: 595 Step: 60690 Index:-0.3841 R2:0.8812 0.4085 0.5930 RMSE:0.4082 0.8843 0.7611 Tau:0.7861 0.5003 0.4613\n",
      "EarlyStopping counter: 329 out of 100\n",
      "Epoch: 596 Step: 60792 Index:-0.3249 R2:0.8939 0.4296 0.5952 RMSE:0.3499 0.8413 0.6842 Tau:0.7995 0.5164 0.4687\n",
      "EarlyStopping counter: 330 out of 100\n",
      "Epoch: 597 Step: 60894 Index:-0.3528 R2:0.8829 0.4320 0.5782 RMSE:0.3895 0.8620 0.7549 Tau:0.7878 0.5092 0.4604\n",
      "EarlyStopping counter: 331 out of 100\n",
      "Epoch: 598 Step: 60996 Index:-0.3432 R2:0.8742 0.4378 0.6096 RMSE:0.4089 0.8511 0.7535 Tau:0.7804 0.5079 0.4537\n",
      "EarlyStopping counter: 332 out of 100\n",
      "Epoch: 599 Step: 61098 Index:-0.3505 R2:0.8842 0.4239 0.6193 RMSE:0.3622 0.8636 0.7016 Tau:0.7903 0.5131 0.4640\n",
      "EarlyStopping counter: 333 out of 100\n",
      "Epoch: 600 Step: 61200 Index:-0.3449 R2:0.8856 0.4424 0.5942 RMSE:0.4524 0.8652 0.8046 Tau:0.7905 0.5203 0.4621\n",
      "EarlyStopping counter: 334 out of 100\n",
      "Epoch: 601 Step: 61302 Index:-0.3580 R2:0.8927 0.4198 0.5835 RMSE:0.3694 0.8713 0.7531 Tau:0.7984 0.5132 0.4634\n",
      "EarlyStopping counter: 335 out of 100\n",
      "Epoch: 602 Step: 61404 Index:-0.3305 R2:0.8942 0.4277 0.5830 RMSE:0.3463 0.8416 0.7026 Tau:0.8002 0.5111 0.4633\n",
      "EarlyStopping counter: 336 out of 100\n",
      "Epoch: 603 Step: 61506 Index:-0.3533 R2:0.8896 0.4279 0.5900 RMSE:0.3740 0.8687 0.7420 Tau:0.7954 0.5153 0.4642\n",
      "EarlyStopping counter: 337 out of 100\n",
      "Epoch: 604 Step: 61608 Index:-0.3172 R2:0.8948 0.4300 0.6032 RMSE:0.3580 0.8346 0.7007 Tau:0.7996 0.5174 0.4661\n",
      "EarlyStopping counter: 338 out of 100\n",
      "Epoch: 605 Step: 61710 Index:-0.3235 R2:0.8951 0.4278 0.5805 RMSE:0.3507 0.8397 0.6973 Tau:0.8004 0.5162 0.4661\n",
      "EarlyStopping counter: 339 out of 100\n",
      "Epoch: 606 Step: 61812 Index:-0.3298 R2:0.8840 0.4269 0.5769 RMSE:0.3633 0.8391 0.7178 Tau:0.7886 0.5093 0.4579\n",
      "EarlyStopping counter: 340 out of 100\n",
      "Epoch: 607 Step: 61914 Index:-0.3134 R2:0.8889 0.4405 0.6211 RMSE:0.3664 0.8379 0.7051 Tau:0.7934 0.5245 0.4657\n",
      "EarlyStopping counter: 341 out of 100\n",
      "Epoch: 608 Step: 62016 Index:-0.3182 R2:0.8885 0.4330 0.6116 RMSE:0.3556 0.8368 0.6871 Tau:0.7930 0.5186 0.4629\n",
      "EarlyStopping counter: 342 out of 100\n",
      "Epoch: 609 Step: 62118 Index:-0.3023 R2:0.8899 0.4544 0.6167 RMSE:0.3568 0.8290 0.7037 Tau:0.7967 0.5267 0.4644\n",
      "EarlyStopping counter: 343 out of 100\n",
      "Epoch: 610 Step: 62220 Index:-0.3340 R2:0.8864 0.4440 0.6279 RMSE:0.3683 0.8548 0.7170 Tau:0.7909 0.5208 0.4622\n",
      "EarlyStopping counter: 344 out of 100\n",
      "Epoch: 611 Step: 62322 Index:-0.3361 R2:0.8926 0.4266 0.6141 RMSE:0.3459 0.8513 0.6824 Tau:0.7979 0.5152 0.4683\n",
      "EarlyStopping counter: 345 out of 100\n",
      "Epoch: 612 Step: 62424 Index:-0.2945 R2:0.8786 0.4442 0.5649 RMSE:0.3800 0.8159 0.7060 Tau:0.7826 0.5214 0.4585\n",
      "EarlyStopping counter: 346 out of 100\n",
      "Epoch: 613 Step: 62526 Index:-0.3347 R2:0.8955 0.4141 0.5951 RMSE:0.3545 0.8476 0.6802 Tau:0.8021 0.5129 0.4645\n",
      "EarlyStopping counter: 347 out of 100\n",
      "Epoch: 614 Step: 62628 Index:-0.3101 R2:0.8959 0.4391 0.6113 RMSE:0.3492 0.8307 0.6962 Tau:0.8009 0.5206 0.4650\n",
      "EarlyStopping counter: 348 out of 100\n",
      "Epoch: 615 Step: 62730 Index:-0.3331 R2:0.8916 0.4347 0.6134 RMSE:0.3464 0.8489 0.6862 Tau:0.7952 0.5157 0.4600\n",
      "EarlyStopping counter: 349 out of 100\n",
      "Epoch: 616 Step: 62832 Index:-0.3518 R2:0.8959 0.4291 0.6045 RMSE:0.3680 0.8692 0.7362 Tau:0.8011 0.5174 0.4664\n",
      "EarlyStopping counter: 350 out of 100\n",
      "Epoch: 617 Step: 62934 Index:-0.3597 R2:0.8717 0.4126 0.5882 RMSE:0.3779 0.8640 0.7042 Tau:0.7793 0.5043 0.4635\n",
      "EarlyStopping counter: 351 out of 100\n",
      "Epoch: 618 Step: 63036 Index:-0.3320 R2:0.8954 0.4268 0.5897 RMSE:0.3457 0.8486 0.7183 Tau:0.8002 0.5166 0.4668\n",
      "EarlyStopping counter: 352 out of 100\n",
      "Epoch: 619 Step: 63138 Index:-0.3280 R2:0.8955 0.4291 0.5777 RMSE:0.3462 0.8412 0.7203 Tau:0.7994 0.5132 0.4640\n",
      "EarlyStopping counter: 353 out of 100\n",
      "Epoch: 620 Step: 63240 Index:-0.3254 R2:0.8896 0.4439 0.6041 RMSE:0.3758 0.8438 0.7356 Tau:0.7929 0.5184 0.4653\n",
      "EarlyStopping counter: 354 out of 100\n",
      "Epoch: 621 Step: 63342 Index:-0.3644 R2:0.8800 0.4218 0.5916 RMSE:0.3846 0.8730 0.7408 Tau:0.7854 0.5086 0.4561\n",
      "EarlyStopping counter: 355 out of 100\n",
      "Epoch: 622 Step: 63444 Index:-0.3517 R2:0.8966 0.4257 0.5985 RMSE:0.3635 0.8643 0.7409 Tau:0.8017 0.5126 0.4623\n",
      "EarlyStopping counter: 356 out of 100\n",
      "Epoch: 623 Step: 63546 Index:-0.3278 R2:0.8984 0.4206 0.6016 RMSE:0.3459 0.8392 0.6825 Tau:0.8042 0.5115 0.4585\n",
      "EarlyStopping counter: 357 out of 100\n",
      "Epoch: 624 Step: 63648 Index:-0.3571 R2:0.8898 0.4158 0.5977 RMSE:0.3642 0.8688 0.6809 Tau:0.7947 0.5117 0.4639\n",
      "EarlyStopping counter: 358 out of 100\n",
      "Epoch: 625 Step: 63750 Index:-0.3509 R2:0.8932 0.4216 0.5829 RMSE:0.3628 0.8648 0.7435 Tau:0.7985 0.5139 0.4618\n",
      "EarlyStopping counter: 359 out of 100\n",
      "Epoch: 626 Step: 63852 Index:-0.3372 R2:0.8874 0.4197 0.5989 RMSE:0.3615 0.8503 0.6848 Tau:0.7913 0.5131 0.4542\n",
      "EarlyStopping counter: 360 out of 100\n",
      "Epoch: 627 Step: 63954 Index:-0.3169 R2:0.8979 0.4414 0.6087 RMSE:0.3380 0.8391 0.7005 Tau:0.8040 0.5222 0.4671\n",
      "EarlyStopping counter: 361 out of 100\n",
      "Epoch: 628 Step: 64056 Index:-0.3427 R2:0.8920 0.4250 0.5672 RMSE:0.3699 0.8563 0.7550 Tau:0.7974 0.5136 0.4575\n",
      "EarlyStopping counter: 362 out of 100\n",
      "Epoch: 629 Step: 64158 Index:-0.3267 R2:0.8809 0.4181 0.5813 RMSE:0.3807 0.8286 0.6956 Tau:0.7886 0.5019 0.4592\n",
      "EarlyStopping counter: 363 out of 100\n",
      "Epoch: 630 Step: 64260 Index:-0.3316 R2:0.8917 0.4249 0.5957 RMSE:0.3502 0.8450 0.7040 Tau:0.7967 0.5134 0.4616\n",
      "EarlyStopping counter: 364 out of 100\n",
      "Epoch: 631 Step: 64362 Index:-0.3300 R2:0.8965 0.4319 0.5871 RMSE:0.3462 0.8475 0.6990 Tau:0.8013 0.5175 0.4662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 365 out of 100\n",
      "Epoch: 632 Step: 64464 Index:-0.3252 R2:0.8978 0.4399 0.6189 RMSE:0.3453 0.8468 0.7036 Tau:0.8022 0.5217 0.4669\n",
      "EarlyStopping counter: 366 out of 100\n",
      "Epoch: 633 Step: 64566 Index:-0.2965 R2:0.8917 0.4450 0.5902 RMSE:0.3508 0.8201 0.6959 Tau:0.7965 0.5236 0.4619\n",
      "EarlyStopping counter: 367 out of 100\n",
      "Epoch: 634 Step: 64668 Index:-0.2843 R2:0.8913 0.4603 0.6157 RMSE:0.3574 0.8156 0.6661 Tau:0.7957 0.5313 0.4575\n",
      "EarlyStopping counter: 368 out of 100\n",
      "Epoch: 635 Step: 64770 Index:-0.3413 R2:0.8939 0.4168 0.5994 RMSE:0.3489 0.8522 0.7070 Tau:0.7995 0.5109 0.4661\n",
      "EarlyStopping counter: 369 out of 100\n",
      "Epoch: 636 Step: 64872 Index:-0.3467 R2:0.8949 0.4270 0.5965 RMSE:0.3592 0.8652 0.7417 Tau:0.7994 0.5185 0.4629\n",
      "EarlyStopping counter: 370 out of 100\n",
      "Epoch: 637 Step: 64974 Index:-0.3315 R2:0.8949 0.4302 0.5977 RMSE:0.3521 0.8522 0.6838 Tau:0.8000 0.5206 0.4575\n",
      "EarlyStopping counter: 371 out of 100\n",
      "Epoch: 638 Step: 65076 Index:-0.3973 R2:0.8826 0.4121 0.5860 RMSE:0.4046 0.9026 0.7764 Tau:0.7862 0.5054 0.4656\n",
      "EarlyStopping counter: 372 out of 100\n",
      "Epoch: 639 Step: 65178 Index:-0.3433 R2:0.8932 0.4321 0.5921 RMSE:0.3524 0.8558 0.6956 Tau:0.7975 0.5124 0.4606\n",
      "EarlyStopping counter: 373 out of 100\n",
      "Epoch: 640 Step: 65280 Index:-0.3234 R2:0.8986 0.4308 0.6176 RMSE:0.3374 0.8461 0.6809 Tau:0.8044 0.5228 0.4642\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "# if os.path.isdir(log_dir):\n",
    "#     for files in os.listdir(log_dir):\n",
    "#         os.remove(log_dir+\"/\"+files)\n",
    "#     os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)\n",
    "\n",
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 244\n",
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('train/r2', train_r2, global_step)\n",
    "    logger.add_scalar('train/RMSE', train_MSE**0.5, global_step)\n",
    "    logger.add_scalar('train/Tau', train_tau, global_step)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr\n",
    "# epoch: 512 r2:0.5619 RMSE:0.7306 WTI:0.3784 AP:0.7228 Tau:0.5159 \n",
    " \n",
    "#  Top-1:0.0000 Top-1-fp:0.0000 \n",
    "#  Top-5:0.8571 Top-5-fp:0.0000 \n",
    "#  Top-10:0.7857 Top-10-fp:0.0714 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
