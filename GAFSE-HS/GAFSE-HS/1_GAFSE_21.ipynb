{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P25099_1_500\n",
      "model_file/1_GAFSE_Ki_P25099_1_500_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P25099_1_500_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P25099_1_500_test.csv\"\n",
    "test_active = 500\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0    C1CC2CC1CC2NC3=NC(=NC4=C3N=CN4C5C6CC6C(C5O)O)Cl  0.154902\n",
      "1  CNC(=O)C1C(C(C(O1)N2C=NC3=C2N=CN=C3NC(=O)NC4=C... -2.740363\n",
      "2           COCC1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)Cl)O)O -2.227887\n",
      "3  C1=CC=C(C=C1)CCCCC(=O)NC2C(OC(C2O)N3C=NC4=C3N=... -3.831870\n",
      "4  C1CN(CCN1CC2=CC3=CC=CC=C3N=C2Cl)C4=NC5=NC(=NN5... -2.397940\n",
      "number of all smiles:  1822\n",
      "number of successfully processed smiles:  1822\n",
      "                                              smiles     value  \\\n",
      "0    C1CC2CC1CC2NC3=NC(=NC4=C3N=CN4C5C6CC6C(C5O)O)Cl  0.154902   \n",
      "1  CNC(=O)C1C(C(C(O1)N2C=NC3=C2N=CN=C3NC(=O)NC4=C... -2.740363   \n",
      "2           COCC1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)Cl)O)O -2.227887   \n",
      "3  C1=CC=C(C=C1)CCCCC(=O)NC2C(OC(C2O)N3C=NC4=C3N=... -3.831870   \n",
      "4  C1CN(CCN1CC2=CC3=CC=CC=C3N=C2Cl)C4=NC5=NC(=NN5... -2.397940   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0    OC1C(O)C(n2cnc3c(NC4CC5CCC4C5)nc(Cl)nc32)C2CC12  \n",
      "1  CNC(=O)C1OC(n2cnc3c(NC(=O)Nc4cccc(Cl)c4)ncnc32...  \n",
      "2               COCC1OC(n2cnc3c(N)nc(Cl)nc32)C(O)C1O  \n",
      "3     Nc1ncnc2c1ncn2C1OC(CO)C(NC(=O)CCCCc2ccccc2)C1O  \n",
      "4  Nc1nc(N2CCN(Cc3cc4ccccc4nc3Cl)CC2)nc2nc(-c3ccc...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1190\n",
      "number of successfully processed smiles:  1190\n",
      "(1190, 3)\n",
      "                                              smiles     value  \\\n",
      "0          CC1C(C(C(O1)N2C=NC3=C2N=CN=C3NC4CCCC4)O)O -1.845098   \n",
      "1  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CCN4C... -1.723456   \n",
      "2  C1CCC(C1)NC2=NC=NC3=C2N=CN3C4C(C(C(O4)COC5CC5)O)O -1.607455   \n",
      "3                   CCN(CC)C1=NC2=CC=CC=C2N3C1=NN=C3 -3.949390   \n",
      "4         CONC1=NC(=NC2=C1N=CN2C3C(C(C(O3)C=C)O)O)Cl -3.089905   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0              CC1OC(n2cnc3c(NC4CCCC4)ncnc32)C(O)C1O  \n",
      "1  CCNC(=O)C1OC(n2cnc3c(N)nc(C#CCN4CCSCC4)nc32)C(...  \n",
      "2        OC1C(COC2CC2)OC(n2cnc3c(NC4CCCC4)ncnc32)C1O  \n",
      "3                         CCN(CC)c1nc2ccccc2n2cnnc12  \n",
      "4             C=CC1OC(n2cnc3c(NOC)nc(Cl)nc32)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P25099_1_500_train.pickle\n",
      "./data/benchmark/Ki_P25099_1_500_train\n",
      "3012\n",
      "feature dicts file saved as ./data/benchmark/Ki_P25099_1_500_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 3) (364, 3) (1190, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_Ki_P25099_1_500_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 145 Index:-0.8410 R2:0.0883 0.0809 0.0397 RMSE:1.0226 1.0211 1.0213 Tau:0.2045 0.1801 0.1188\n",
      "Epoch: 2 Step: 290 Index:-0.8080 R2:0.1120 0.0921 0.0485 RMSE:0.9989 0.9989 1.0025 Tau:0.2277 0.1909 0.1497\n",
      "Epoch: 3 Step: 435 Index:-0.7621 R2:0.1270 0.1065 0.0598 RMSE:0.9785 0.9652 0.9809 Tau:0.2403 0.2031 0.1719\n",
      "Epoch: 4 Step: 580 Index:-0.7390 R2:0.1490 0.1239 0.0773 RMSE:0.9836 0.9531 0.9791 Tau:0.2558 0.2141 0.1963\n",
      "Epoch: 5 Step: 725 Index:-0.7114 R2:0.1701 0.1390 0.0897 RMSE:0.9568 0.9469 0.9630 Tau:0.2756 0.2355 0.2204\n",
      "Epoch: 6 Step: 870 Index:-0.6844 R2:0.1864 0.1515 0.1060 RMSE:0.9535 0.9353 0.9580 Tau:0.2899 0.2508 0.2391\n",
      "Epoch: 7 Step: 1015 Index:-0.6713 R2:0.1929 0.1661 0.1105 RMSE:0.9436 0.9390 0.9568 Tau:0.2988 0.2678 0.2489\n",
      "Epoch: 8 Step: 1160 Index:-0.6416 R2:0.2077 0.1783 0.1284 RMSE:0.9376 0.9200 0.9436 Tau:0.3082 0.2784 0.2661\n",
      "Epoch: 9 Step: 1305 Index:-0.6084 R2:0.2301 0.1939 0.1494 RMSE:0.9285 0.9156 0.9318 Tau:0.3272 0.3072 0.2931\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 10 Step: 1450 Index:-0.6310 R2:0.2361 0.2112 0.1565 RMSE:0.9882 0.9457 0.9851 Tau:0.3322 0.3147 0.3042\n",
      "Epoch: 11 Step: 1595 Index:-0.5842 R2:0.2472 0.2195 0.1670 RMSE:0.9417 0.9099 0.9420 Tau:0.3390 0.3257 0.3126\n",
      "Epoch: 12 Step: 1740 Index:-0.5769 R2:0.2524 0.2206 0.1706 RMSE:0.9103 0.9030 0.9204 Tau:0.3438 0.3261 0.3132\n",
      "Epoch: 13 Step: 1885 Index:-0.5574 R2:0.2597 0.2308 0.1829 RMSE:0.9042 0.8902 0.9123 Tau:0.3466 0.3328 0.3189\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 14 Step: 2030 Index:-0.5605 R2:0.2600 0.2308 0.1807 RMSE:0.9013 0.8929 0.9139 Tau:0.3470 0.3323 0.3223\n",
      "Epoch: 15 Step: 2175 Index:-0.5446 R2:0.2779 0.2415 0.2015 RMSE:0.8945 0.8872 0.9020 Tau:0.3580 0.3426 0.3330\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 16 Step: 2320 Index:-0.6059 R2:0.2796 0.2484 0.2025 RMSE:0.9383 0.9530 0.9567 Tau:0.3598 0.3472 0.3343\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 17 Step: 2465 Index:-0.5526 R2:0.2889 0.2534 0.2235 RMSE:0.9257 0.8977 0.9192 Tau:0.3619 0.3451 0.3451\n",
      "Epoch: 18 Step: 2610 Index:-0.5380 R2:0.2959 0.2535 0.2283 RMSE:0.9079 0.8870 0.9038 Tau:0.3670 0.3490 0.3491\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 19 Step: 2755 Index:-0.5478 R2:0.2936 0.2611 0.2272 RMSE:0.9235 0.8970 0.9198 Tau:0.3675 0.3492 0.3403\n",
      "Epoch: 20 Step: 2900 Index:-0.5140 R2:0.3055 0.2723 0.2400 RMSE:0.8779 0.8757 0.8838 Tau:0.3745 0.3618 0.3492\n",
      "Epoch: 21 Step: 3045 Index:-0.5026 R2:0.3158 0.2768 0.2455 RMSE:0.8765 0.8649 0.8808 Tau:0.3818 0.3623 0.3604\n",
      "Epoch: 22 Step: 3190 Index:-0.4966 R2:0.3251 0.2772 0.2555 RMSE:0.8761 0.8669 0.8761 Tau:0.3858 0.3703 0.3643\n",
      "Epoch: 23 Step: 3335 Index:-0.4845 R2:0.3296 0.2887 0.2609 RMSE:0.8615 0.8564 0.8675 Tau:0.3913 0.3719 0.3670\n",
      "Epoch: 24 Step: 3480 Index:-0.4741 R2:0.3319 0.2950 0.2625 RMSE:0.8631 0.8537 0.8684 Tau:0.3957 0.3796 0.3678\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 25 Step: 3625 Index:-0.4779 R2:0.3470 0.2946 0.2793 RMSE:0.8534 0.8565 0.8582 Tau:0.3999 0.3785 0.3793\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 26 Step: 3770 Index:-0.5529 R2:0.3519 0.2972 0.2784 RMSE:0.9571 0.9365 0.9569 Tau:0.4044 0.3837 0.3808\n",
      "Epoch: 27 Step: 3915 Index:-0.4580 R2:0.3599 0.3058 0.2835 RMSE:0.8455 0.8464 0.8564 Tau:0.4107 0.3884 0.3837\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 28 Step: 4060 Index:-0.4632 R2:0.3542 0.3009 0.2722 RMSE:0.8461 0.8525 0.8614 Tau:0.4116 0.3893 0.3811\n",
      "Epoch: 29 Step: 4205 Index:-0.4496 R2:0.3731 0.3191 0.2955 RMSE:0.8356 0.8456 0.8506 Tau:0.4198 0.3960 0.3876\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 30 Step: 4350 Index:-0.4676 R2:0.3753 0.3213 0.2915 RMSE:0.8541 0.8687 0.8713 Tau:0.4234 0.4011 0.3880\n",
      "Epoch: 31 Step: 4495 Index:-0.4429 R2:0.3817 0.3202 0.3054 RMSE:0.8260 0.8372 0.8406 Tau:0.4247 0.3944 0.3909\n",
      "Epoch: 32 Step: 4640 Index:-0.4334 R2:0.3915 0.3336 0.3164 RMSE:0.8234 0.8383 0.8396 Tau:0.4320 0.4049 0.3961\n",
      "Epoch: 33 Step: 4785 Index:-0.4295 R2:0.4023 0.3433 0.3256 RMSE:0.8291 0.8439 0.8417 Tau:0.4416 0.4143 0.4033\n",
      "Epoch: 34 Step: 4930 Index:-0.4288 R2:0.4066 0.3332 0.3289 RMSE:0.8251 0.8366 0.8374 Tau:0.4436 0.4078 0.4022\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 35 Step: 5075 Index:-0.4394 R2:0.4174 0.3448 0.3410 RMSE:0.8570 0.8563 0.8628 Tau:0.4512 0.4168 0.4052\n",
      "Epoch: 36 Step: 5220 Index:-0.4047 R2:0.4180 0.3474 0.3399 RMSE:0.8103 0.8216 0.8231 Tau:0.4492 0.4169 0.4061\n",
      "Epoch: 37 Step: 5365 Index:-0.3955 R2:0.4252 0.3599 0.3491 RMSE:0.8015 0.8190 0.8171 Tau:0.4561 0.4236 0.4074\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 38 Step: 5510 Index:-0.3975 R2:0.4255 0.3565 0.3382 RMSE:0.8067 0.8205 0.8293 Tau:0.4583 0.4230 0.4079\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 39 Step: 5655 Index:-0.4444 R2:0.4298 0.3364 0.3370 RMSE:0.8352 0.8569 0.8561 Tau:0.4619 0.4124 0.4052\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 40 Step: 5800 Index:-0.3999 R2:0.4283 0.3587 0.3461 RMSE:0.7943 0.8206 0.8228 Tau:0.4568 0.4207 0.4047\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 41 Step: 5945 Index:-0.4361 R2:0.4385 0.3536 0.3476 RMSE:0.8144 0.8550 0.8501 Tau:0.4646 0.4189 0.4094\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 42 Step: 6090 Index:-0.4372 R2:0.4472 0.3581 0.3557 RMSE:0.8464 0.8645 0.8687 Tau:0.4771 0.4273 0.4132\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 43 Step: 6235 Index:-0.4104 R2:0.4541 0.3513 0.3573 RMSE:0.7954 0.8328 0.8245 Tau:0.4778 0.4224 0.4105\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 44 Step: 6380 Index:-0.4497 R2:0.4615 0.3523 0.3698 RMSE:0.8587 0.8782 0.8742 Tau:0.4827 0.4286 0.4122\n",
      "Epoch: 45 Step: 6525 Index:-0.3873 R2:0.4526 0.3681 0.3598 RMSE:0.7801 0.8195 0.8198 Tau:0.4741 0.4322 0.4139\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 46 Step: 6670 Index:-0.4222 R2:0.4653 0.3498 0.3643 RMSE:0.8124 0.8491 0.8410 Tau:0.4860 0.4269 0.4113\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 47 Step: 6815 Index:-0.4526 R2:0.4661 0.3664 0.3665 RMSE:0.8429 0.8881 0.8727 Tau:0.4857 0.4355 0.4133\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 48 Step: 6960 Index:-0.3903 R2:0.4683 0.3693 0.3630 RMSE:0.7761 0.8234 0.8216 Tau:0.4870 0.4331 0.4153\n",
      "Epoch: 49 Step: 7105 Index:-0.3872 R2:0.4717 0.3705 0.3770 RMSE:0.7712 0.8218 0.8117 Tau:0.4870 0.4346 0.4144\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 50 Step: 7250 Index:-0.3982 R2:0.4756 0.3656 0.3785 RMSE:0.7837 0.8287 0.8174 Tau:0.4890 0.4305 0.4174\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 51 Step: 7395 Index:-0.3916 R2:0.4521 0.3477 0.3466 RMSE:0.7792 0.8206 0.8160 Tau:0.4862 0.4289 0.4077\n",
      "Epoch: 52 Step: 7540 Index:-0.3759 R2:0.4871 0.3673 0.3819 RMSE:0.7589 0.8138 0.8009 Tau:0.5007 0.4379 0.4148\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 53 Step: 7685 Index:-0.3881 R2:0.4879 0.3706 0.3785 RMSE:0.7630 0.8251 0.8147 Tau:0.4994 0.4370 0.4147\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 54 Step: 7830 Index:-0.4605 R2:0.4845 0.3463 0.3819 RMSE:0.8228 0.8838 0.8548 Tau:0.4982 0.4233 0.4179\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 55 Step: 7975 Index:-0.4969 R2:0.4698 0.3494 0.3713 RMSE:0.8744 0.9207 0.8996 Tau:0.4888 0.4239 0.4150\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 56 Step: 8120 Index:-0.3922 R2:0.5030 0.3756 0.3869 RMSE:0.7803 0.8374 0.8289 Tau:0.5141 0.4452 0.4188\n",
      "Epoch: 57 Step: 8265 Index:-0.3610 R2:0.5082 0.3752 0.3943 RMSE:0.7416 0.8028 0.7858 Tau:0.5158 0.4418 0.4235\n",
      "Epoch: 58 Step: 8410 Index:-0.3534 R2:0.5040 0.3835 0.3989 RMSE:0.7413 0.7988 0.7847 Tau:0.5093 0.4453 0.4187\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 59 Step: 8555 Index:-0.4659 R2:0.4346 0.3197 0.3630 RMSE:0.8048 0.8697 0.8355 Tau:0.4595 0.4037 0.3883\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 60 Step: 8700 Index:-0.4074 R2:0.4807 0.3623 0.3660 RMSE:0.7883 0.8461 0.8377 Tau:0.5024 0.4387 0.4127\n",
      "Epoch: 61 Step: 8845 Index:-0.3498 R2:0.5048 0.3881 0.3961 RMSE:0.7409 0.8017 0.7942 Tau:0.5130 0.4520 0.4201\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 62 Step: 8990 Index:-0.4065 R2:0.5043 0.3692 0.4002 RMSE:0.7751 0.8410 0.8163 Tau:0.5071 0.4345 0.4208\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 63 Step: 9135 Index:-0.3893 R2:0.5177 0.3832 0.4065 RMSE:0.7716 0.8390 0.8193 Tau:0.5185 0.4497 0.4263\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 64 Step: 9280 Index:-0.3644 R2:0.4864 0.3726 0.3717 RMSE:0.7624 0.8126 0.8063 Tau:0.5089 0.4482 0.4148\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 65 Step: 9425 Index:-0.3544 R2:0.5139 0.3812 0.3919 RMSE:0.7433 0.8080 0.7947 Tau:0.5252 0.4536 0.4281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 66 Step: 9570 Index:-0.3533 R2:0.5187 0.3863 0.4001 RMSE:0.7359 0.8061 0.7920 Tau:0.5203 0.4529 0.4318\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 67 Step: 9715 Index:-0.4084 R2:0.5221 0.3816 0.4073 RMSE:0.7927 0.8577 0.8375 Tau:0.5246 0.4494 0.4304\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 68 Step: 9860 Index:-0.3539 R2:0.5335 0.3814 0.4027 RMSE:0.7170 0.8037 0.7841 Tau:0.5328 0.4498 0.4288\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 69 Step: 10005 Index:-0.3563 R2:0.5404 0.3847 0.4112 RMSE:0.7314 0.8147 0.7919 Tau:0.5381 0.4584 0.4356\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 70 Step: 10150 Index:-0.3518 R2:0.5347 0.3810 0.4177 RMSE:0.7181 0.8029 0.7741 Tau:0.5314 0.4511 0.4311\n",
      "Epoch: 71 Step: 10295 Index:-0.3410 R2:0.5411 0.3870 0.4155 RMSE:0.7110 0.8013 0.7762 Tau:0.5364 0.4604 0.4302\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 72 Step: 10440 Index:-0.3508 R2:0.5420 0.3778 0.4040 RMSE:0.7101 0.8081 0.7847 Tau:0.5404 0.4574 0.4309\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 73 Step: 10585 Index:-0.3633 R2:0.5401 0.3672 0.3930 RMSE:0.7206 0.8128 0.7909 Tau:0.5392 0.4495 0.4258\n",
      "Epoch: 74 Step: 10730 Index:-0.3311 R2:0.5402 0.3972 0.4209 RMSE:0.7182 0.7923 0.7727 Tau:0.5334 0.4613 0.4304\n",
      "Epoch: 75 Step: 10875 Index:-0.3232 R2:0.5498 0.4008 0.4208 RMSE:0.7086 0.7898 0.7714 Tau:0.5417 0.4667 0.4313\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 76 Step: 11020 Index:-0.4455 R2:0.4226 0.3240 0.3120 RMSE:0.8580 0.8592 0.8731 Tau:0.4707 0.4137 0.4082\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 77 Step: 11165 Index:-0.3467 R2:0.4747 0.3771 0.3537 RMSE:0.7645 0.8031 0.8120 Tau:0.5064 0.4565 0.4332\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 78 Step: 11310 Index:-0.3370 R2:0.5187 0.4002 0.4060 RMSE:0.7602 0.8072 0.8044 Tau:0.5257 0.4702 0.4315\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 79 Step: 11455 Index:-0.3398 R2:0.5311 0.3981 0.4070 RMSE:0.7427 0.8102 0.7964 Tau:0.5337 0.4704 0.4361\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 80 Step: 11600 Index:-0.3379 R2:0.5381 0.3964 0.4115 RMSE:0.7285 0.8060 0.7891 Tau:0.5383 0.4681 0.4317\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 81 Step: 11745 Index:-0.3617 R2:0.5442 0.3989 0.4131 RMSE:0.7517 0.8313 0.8144 Tau:0.5407 0.4696 0.4327\n",
      "Epoch: 82 Step: 11890 Index:-0.3221 R2:0.5437 0.4009 0.4113 RMSE:0.7124 0.7914 0.7789 Tau:0.5409 0.4693 0.4353\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 83 Step: 12035 Index:-0.3235 R2:0.5488 0.3967 0.4132 RMSE:0.7045 0.7997 0.7808 Tau:0.5467 0.4762 0.4364\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 84 Step: 12180 Index:-0.3305 R2:0.5565 0.3967 0.4202 RMSE:0.7165 0.8038 0.7824 Tau:0.5492 0.4733 0.4331\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 85 Step: 12325 Index:-0.3495 R2:0.5566 0.3823 0.4187 RMSE:0.7090 0.8133 0.7813 Tau:0.5474 0.4638 0.4301\n",
      "Epoch: 86 Step: 12470 Index:-0.3116 R2:0.5626 0.4074 0.4293 RMSE:0.6931 0.7896 0.7681 Tau:0.5528 0.4780 0.4331\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 87 Step: 12615 Index:-0.3668 R2:0.5468 0.3977 0.4188 RMSE:0.7503 0.8347 0.8190 Tau:0.5380 0.4680 0.4309\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 88 Step: 12760 Index:-0.3161 R2:0.5601 0.4069 0.4219 RMSE:0.6968 0.7907 0.7762 Tau:0.5497 0.4747 0.4311\n",
      "Epoch: 89 Step: 12905 Index:-0.3086 R2:0.5673 0.4145 0.4343 RMSE:0.6911 0.7882 0.7689 Tau:0.5540 0.4796 0.4324\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 90 Step: 13050 Index:-0.3207 R2:0.5774 0.4001 0.4307 RMSE:0.6931 0.7981 0.7712 Tau:0.5620 0.4774 0.4372\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 91 Step: 13195 Index:-0.3697 R2:0.5725 0.3885 0.4189 RMSE:0.7218 0.8378 0.8070 Tau:0.5598 0.4680 0.4363\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 92 Step: 13340 Index:-0.3531 R2:0.5749 0.3823 0.4179 RMSE:0.6983 0.8180 0.7870 Tau:0.5619 0.4650 0.4323\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 93 Step: 13485 Index:-0.3347 R2:0.5784 0.3977 0.4242 RMSE:0.6841 0.8054 0.7774 Tau:0.5637 0.4707 0.4369\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 94 Step: 13630 Index:-0.3902 R2:0.5696 0.3907 0.4130 RMSE:0.7413 0.8555 0.8321 Tau:0.5580 0.4653 0.4343\n",
      "Epoch: 95 Step: 13775 Index:-0.3056 R2:0.5766 0.4165 0.4342 RMSE:0.7021 0.7899 0.7730 Tau:0.5629 0.4843 0.4435\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 96 Step: 13920 Index:-0.3515 R2:0.5851 0.3997 0.4384 RMSE:0.7146 0.8246 0.7946 Tau:0.5670 0.4730 0.4369\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 97 Step: 14065 Index:-0.3431 R2:0.5736 0.3829 0.4279 RMSE:0.6951 0.8106 0.7758 Tau:0.5628 0.4675 0.4300\n",
      "Epoch: 98 Step: 14210 Index:-0.3009 R2:0.5881 0.4209 0.4349 RMSE:0.6776 0.7859 0.7684 Tau:0.5702 0.4850 0.4432\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 99 Step: 14355 Index:-0.3370 R2:0.5784 0.3853 0.4186 RMSE:0.6840 0.8068 0.7759 Tau:0.5651 0.4699 0.4376\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 100 Step: 14500 Index:-0.3182 R2:0.5968 0.4122 0.4412 RMSE:0.6770 0.7984 0.7711 Tau:0.5744 0.4802 0.4492\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 101 Step: 14645 Index:-0.3625 R2:0.5844 0.3943 0.4249 RMSE:0.7099 0.8335 0.8074 Tau:0.5666 0.4710 0.4442\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 102 Step: 14790 Index:-0.3132 R2:0.5968 0.4155 0.4479 RMSE:0.6759 0.7933 0.7657 Tau:0.5728 0.4801 0.4438\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 103 Step: 14935 Index:-0.3118 R2:0.5984 0.4095 0.4376 RMSE:0.6651 0.7911 0.7638 Tau:0.5766 0.4793 0.4396\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 104 Step: 15080 Index:-0.3707 R2:0.6014 0.4197 0.4395 RMSE:0.7418 0.8541 0.8393 Tau:0.5787 0.4834 0.4444\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 105 Step: 15225 Index:-0.3378 R2:0.6055 0.4100 0.4446 RMSE:0.6959 0.8219 0.7908 Tau:0.5807 0.4841 0.4448\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 106 Step: 15370 Index:-0.3466 R2:0.6007 0.4025 0.4319 RMSE:0.7025 0.8250 0.8033 Tau:0.5795 0.4784 0.4483\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 107 Step: 15515 Index:-0.3033 R2:0.6035 0.4194 0.4416 RMSE:0.6611 0.7927 0.7667 Tau:0.5792 0.4894 0.4487\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 108 Step: 15660 Index:-0.3078 R2:0.6093 0.4062 0.4407 RMSE:0.6591 0.7897 0.7587 Tau:0.5845 0.4819 0.4424\n",
      "Epoch: 109 Step: 15805 Index:-0.2790 R2:0.5991 0.4397 0.4417 RMSE:0.6791 0.7739 0.7696 Tau:0.5788 0.4949 0.4442\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 110 Step: 15950 Index:-0.3076 R2:0.6085 0.4139 0.4437 RMSE:0.6603 0.7907 0.7652 Tau:0.5811 0.4831 0.4496\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 111 Step: 16095 Index:-0.3271 R2:0.5960 0.4022 0.4257 RMSE:0.6839 0.8044 0.7850 Tau:0.5755 0.4773 0.4383\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 112 Step: 16240 Index:-0.3333 R2:0.6148 0.4193 0.4513 RMSE:0.6918 0.8205 0.7939 Tau:0.5858 0.4872 0.4518\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 113 Step: 16385 Index:-0.3038 R2:0.6083 0.4129 0.4320 RMSE:0.6586 0.7869 0.7687 Tau:0.5849 0.4832 0.4435\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 114 Step: 16530 Index:-0.2974 R2:0.6205 0.4241 0.4505 RMSE:0.6590 0.7895 0.7647 Tau:0.5924 0.4922 0.4493\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 115 Step: 16675 Index:-0.3000 R2:0.6167 0.4166 0.4465 RMSE:0.6543 0.7892 0.7613 Tau:0.5897 0.4892 0.4551\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 116 Step: 16820 Index:-0.2821 R2:0.6112 0.4269 0.4425 RMSE:0.6586 0.7730 0.7590 Tau:0.5853 0.4909 0.4490\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 117 Step: 16965 Index:-0.2830 R2:0.6197 0.4263 0.4442 RMSE:0.6520 0.7759 0.7568 Tau:0.5925 0.4929 0.4542\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 118 Step: 17110 Index:-0.3127 R2:0.6159 0.4119 0.4391 RMSE:0.6723 0.8027 0.7764 Tau:0.5901 0.4901 0.4496\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 119 Step: 17255 Index:-0.3911 R2:0.6139 0.4107 0.4436 RMSE:0.7280 0.8714 0.8379 Tau:0.5856 0.4803 0.4539\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 120 Step: 17400 Index:-0.2969 R2:0.6272 0.4287 0.4497 RMSE:0.6489 0.7915 0.7688 Tau:0.5967 0.4945 0.4542\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 121 Step: 17545 Index:-0.2838 R2:0.6306 0.4259 0.4556 RMSE:0.6414 0.7766 0.7499 Tau:0.5990 0.4928 0.4450\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 122 Step: 17690 Index:-0.3157 R2:0.6213 0.4003 0.4466 RMSE:0.6522 0.7943 0.7554 Tau:0.5921 0.4786 0.4451\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 123 Step: 17835 Index:-0.3041 R2:0.6266 0.4228 0.4545 RMSE:0.6538 0.7967 0.7649 Tau:0.5954 0.4926 0.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 Step: 17980 Index:-0.2774 R2:0.6243 0.4368 0.4540 RMSE:0.6511 0.7715 0.7560 Tau:0.5958 0.4942 0.4483\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 125 Step: 18125 Index:-0.3138 R2:0.6227 0.4043 0.4322 RMSE:0.6541 0.8011 0.7729 Tau:0.5936 0.4872 0.4431\n",
      "Epoch: 126 Step: 18270 Index:-0.2757 R2:0.6285 0.4347 0.4512 RMSE:0.6592 0.7741 0.7578 Tau:0.5983 0.4984 0.4368\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 127 Step: 18415 Index:-0.2804 R2:0.6242 0.4318 0.4577 RMSE:0.6439 0.7743 0.7522 Tau:0.5941 0.4939 0.4490\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 128 Step: 18560 Index:-0.2905 R2:0.6326 0.4311 0.4493 RMSE:0.6514 0.7834 0.7668 Tau:0.5989 0.4929 0.4589\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 129 Step: 18705 Index:-0.2806 R2:0.6403 0.4405 0.4540 RMSE:0.6422 0.7808 0.7687 Tau:0.6042 0.5003 0.4555\n",
      "Epoch: 130 Step: 18850 Index:-0.2632 R2:0.6411 0.4416 0.4553 RMSE:0.6294 0.7662 0.7545 Tau:0.6051 0.5030 0.4556\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 131 Step: 18995 Index:-0.2839 R2:0.6446 0.4391 0.4621 RMSE:0.6385 0.7850 0.7605 Tau:0.6080 0.5011 0.4599\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 132 Step: 19140 Index:-0.3111 R2:0.6289 0.4233 0.4439 RMSE:0.6419 0.7993 0.7789 Tau:0.5955 0.4882 0.4493\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 133 Step: 19285 Index:-0.3369 R2:0.6328 0.4146 0.4377 RMSE:0.6675 0.8244 0.7988 Tau:0.5995 0.4875 0.4534\n",
      "Epoch: 134 Step: 19430 Index:-0.2565 R2:0.6401 0.4510 0.4683 RMSE:0.6408 0.7623 0.7461 Tau:0.6060 0.5058 0.4484\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 135 Step: 19575 Index:-0.3668 R2:0.6311 0.4115 0.4493 RMSE:0.7031 0.8520 0.8232 Tau:0.5972 0.4852 0.4511\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 136 Step: 19720 Index:-0.2783 R2:0.6478 0.4352 0.4640 RMSE:0.6387 0.7814 0.7587 Tau:0.6095 0.5031 0.4426\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 137 Step: 19865 Index:-0.2864 R2:0.6436 0.4251 0.4497 RMSE:0.6326 0.7879 0.7653 Tau:0.6061 0.5015 0.4515\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 138 Step: 20010 Index:-0.2750 R2:0.6373 0.4351 0.4557 RMSE:0.6325 0.7761 0.7574 Tau:0.6003 0.5011 0.4575\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 139 Step: 20155 Index:-0.3243 R2:0.6494 0.4420 0.4614 RMSE:0.6711 0.8255 0.8129 Tau:0.6101 0.5012 0.4564\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 140 Step: 20300 Index:-0.3080 R2:0.6396 0.4512 0.4653 RMSE:0.6808 0.8138 0.8080 Tau:0.6035 0.5058 0.4519\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 141 Step: 20445 Index:-0.2726 R2:0.6507 0.4391 0.4584 RMSE:0.6235 0.7768 0.7579 Tau:0.6126 0.5043 0.4533\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 142 Step: 20590 Index:-0.2620 R2:0.6566 0.4473 0.4606 RMSE:0.6142 0.7674 0.7559 Tau:0.6170 0.5055 0.4540\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 143 Step: 20735 Index:-0.2953 R2:0.6604 0.4434 0.4647 RMSE:0.6343 0.8027 0.7842 Tau:0.6177 0.5073 0.4597\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 144 Step: 20880 Index:-0.2648 R2:0.6564 0.4389 0.4566 RMSE:0.6194 0.7690 0.7523 Tau:0.6177 0.5041 0.4474\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 145 Step: 21025 Index:-0.2827 R2:0.6479 0.4426 0.4558 RMSE:0.6357 0.7886 0.7744 Tau:0.6104 0.5059 0.4564\n",
      "Epoch: 146 Step: 21170 Index:-0.2472 R2:0.6640 0.4546 0.4770 RMSE:0.6120 0.7612 0.7403 Tau:0.6207 0.5140 0.4592\n",
      "Epoch: 147 Step: 21315 Index:-0.2468 R2:0.6638 0.4526 0.4746 RMSE:0.6088 0.7611 0.7434 Tau:0.6225 0.5143 0.4518\n",
      "Epoch: 148 Step: 21460 Index:-0.2396 R2:0.6598 0.4613 0.4781 RMSE:0.6149 0.7521 0.7381 Tau:0.6205 0.5125 0.4581\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 149 Step: 21605 Index:-0.2827 R2:0.6691 0.4552 0.4742 RMSE:0.6377 0.7969 0.7800 Tau:0.6245 0.5141 0.4625\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 150 Step: 21750 Index:-0.2603 R2:0.6644 0.4418 0.4602 RMSE:0.6111 0.7731 0.7542 Tau:0.6208 0.5128 0.4588\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 151 Step: 21895 Index:-0.2556 R2:0.6640 0.4579 0.4652 RMSE:0.6142 0.7704 0.7652 Tau:0.6216 0.5148 0.4615\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 152 Step: 22040 Index:-0.2850 R2:0.6717 0.4500 0.4790 RMSE:0.6334 0.7975 0.7726 Tau:0.6248 0.5125 0.4605\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 153 Step: 22185 Index:-0.2769 R2:0.6559 0.4447 0.4625 RMSE:0.6148 0.7793 0.7657 Tau:0.6139 0.5025 0.4637\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 154 Step: 22330 Index:-0.2719 R2:0.6671 0.4412 0.4748 RMSE:0.6394 0.7816 0.7508 Tau:0.6258 0.5097 0.4466\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 155 Step: 22475 Index:-0.2636 R2:0.6674 0.4505 0.4647 RMSE:0.6313 0.7801 0.7671 Tau:0.6234 0.5165 0.4601\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 156 Step: 22620 Index:-0.2625 R2:0.6713 0.4480 0.4673 RMSE:0.6042 0.7773 0.7608 Tau:0.6273 0.5148 0.4589\n",
      "Epoch: 157 Step: 22765 Index:-0.2320 R2:0.6818 0.4621 0.4799 RMSE:0.5932 0.7567 0.7418 Tau:0.6332 0.5247 0.4536\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 158 Step: 22910 Index:-0.3008 R2:0.6682 0.4314 0.4582 RMSE:0.6402 0.8065 0.7841 Tau:0.6246 0.5057 0.4516\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 159 Step: 23055 Index:-0.2385 R2:0.6810 0.4678 0.4819 RMSE:0.6225 0.7638 0.7514 Tau:0.6343 0.5253 0.4554\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 160 Step: 23200 Index:-0.2698 R2:0.6699 0.4538 0.4640 RMSE:0.6221 0.7844 0.7734 Tau:0.6240 0.5146 0.4603\n",
      "Epoch: 161 Step: 23345 Index:-0.2218 R2:0.6654 0.4688 0.4817 RMSE:0.6072 0.7469 0.7365 Tau:0.6217 0.5250 0.4537\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 162 Step: 23490 Index:-0.2649 R2:0.6764 0.4628 0.4742 RMSE:0.6331 0.7849 0.7783 Tau:0.6280 0.5201 0.4654\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 163 Step: 23635 Index:-0.2336 R2:0.6825 0.4660 0.4864 RMSE:0.5964 0.7530 0.7378 Tau:0.6333 0.5194 0.4601\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 164 Step: 23780 Index:-0.2442 R2:0.6750 0.4560 0.4684 RMSE:0.6037 0.7625 0.7520 Tau:0.6282 0.5183 0.4517\n",
      "Epoch: 165 Step: 23925 Index:-0.2134 R2:0.6884 0.4857 0.4924 RMSE:0.5986 0.7482 0.7440 Tau:0.6377 0.5348 0.4605\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 166 Step: 24070 Index:-0.2309 R2:0.6901 0.4710 0.4880 RMSE:0.6086 0.7626 0.7484 Tau:0.6395 0.5317 0.4559\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 167 Step: 24215 Index:-0.2650 R2:0.6772 0.4439 0.4648 RMSE:0.5995 0.7742 0.7562 Tau:0.6294 0.5091 0.4527\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 168 Step: 24360 Index:-0.2378 R2:0.6787 0.4610 0.4845 RMSE:0.5983 0.7590 0.7440 Tau:0.6322 0.5212 0.4560\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 169 Step: 24505 Index:-0.2614 R2:0.6865 0.4695 0.4740 RMSE:0.6492 0.7882 0.7833 Tau:0.6380 0.5268 0.4640\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 170 Step: 24650 Index:-0.2581 R2:0.6776 0.4533 0.4716 RMSE:0.5950 0.7751 0.7568 Tau:0.6312 0.5170 0.4617\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 171 Step: 24795 Index:-0.3653 R2:0.6652 0.4405 0.4661 RMSE:0.7282 0.8740 0.8547 Tau:0.6200 0.5086 0.4550\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 172 Step: 24940 Index:-0.2225 R2:0.6900 0.4734 0.4849 RMSE:0.5890 0.7534 0.7395 Tau:0.6412 0.5308 0.4547\n",
      "Epoch: 173 Step: 25085 Index:-0.2057 R2:0.6875 0.4855 0.4817 RMSE:0.5956 0.7445 0.7450 Tau:0.6390 0.5388 0.4679\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 174 Step: 25230 Index:-0.2567 R2:0.6825 0.4552 0.4815 RMSE:0.6087 0.7745 0.7559 Tau:0.6347 0.5178 0.4529\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 175 Step: 25375 Index:-0.2809 R2:0.6970 0.4574 0.4851 RMSE:0.6283 0.8043 0.7841 Tau:0.6433 0.5234 0.4654\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 176 Step: 25520 Index:-0.2328 R2:0.6920 0.4685 0.4813 RMSE:0.5815 0.7611 0.7529 Tau:0.6418 0.5283 0.4611\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 177 Step: 25665 Index:-0.2200 R2:0.6969 0.4712 0.4871 RMSE:0.5914 0.7525 0.7378 Tau:0.6443 0.5324 0.4575\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 178 Step: 25810 Index:-0.2657 R2:0.6915 0.4640 0.4854 RMSE:0.6274 0.7878 0.7769 Tau:0.6415 0.5221 0.4516\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 179 Step: 25955 Index:-0.2305 R2:0.6860 0.4706 0.4863 RMSE:0.5984 0.7585 0.7477 Tau:0.6360 0.5280 0.4633\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 180 Step: 26100 Index:-0.2475 R2:0.6850 0.4836 0.4955 RMSE:0.6220 0.7781 0.7714 Tau:0.6347 0.5306 0.4653\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 181 Step: 26245 Index:-0.2317 R2:0.6995 0.4733 0.4928 RMSE:0.5929 0.7642 0.7565 Tau:0.6471 0.5325 0.4575\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 182 Step: 26390 Index:-0.2211 R2:0.7012 0.4775 0.5000 RMSE:0.5938 0.7521 0.7333 Tau:0.6478 0.5310 0.4511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 183 Step: 26535 Index:-0.2178 R2:0.7052 0.4789 0.4923 RMSE:0.5838 0.7507 0.7426 Tau:0.6502 0.5329 0.4596\n",
      "Epoch: 184 Step: 26680 Index:-0.2009 R2:0.7036 0.4908 0.4917 RMSE:0.5879 0.7441 0.7431 Tau:0.6497 0.5432 0.4618\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 185 Step: 26825 Index:-0.2364 R2:0.7016 0.4605 0.4798 RMSE:0.5832 0.7611 0.7430 Tau:0.6487 0.5247 0.4519\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 186 Step: 26970 Index:-0.2191 R2:0.6849 0.4804 0.4873 RMSE:0.5880 0.7535 0.7483 Tau:0.6350 0.5344 0.4633\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 187 Step: 27115 Index:-0.2443 R2:0.7027 0.4642 0.4788 RMSE:0.5790 0.7689 0.7538 Tau:0.6499 0.5246 0.4676\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 188 Step: 27260 Index:-0.2065 R2:0.7100 0.4797 0.4908 RMSE:0.5657 0.7450 0.7340 Tau:0.6548 0.5385 0.4635\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 189 Step: 27405 Index:-0.2220 R2:0.7032 0.4707 0.4797 RMSE:0.5734 0.7541 0.7465 Tau:0.6476 0.5321 0.4646\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 190 Step: 27550 Index:-0.2299 R2:0.7145 0.4636 0.4915 RMSE:0.5689 0.7573 0.7384 Tau:0.6561 0.5273 0.4513\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 191 Step: 27695 Index:-0.3020 R2:0.7115 0.4681 0.4881 RMSE:0.6520 0.8315 0.8204 Tau:0.6537 0.5295 0.4630\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 192 Step: 27840 Index:-0.2318 R2:0.7053 0.4647 0.4794 RMSE:0.5836 0.7606 0.7479 Tau:0.6495 0.5289 0.4535\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 193 Step: 27985 Index:-0.2140 R2:0.7141 0.4747 0.4957 RMSE:0.5625 0.7491 0.7316 Tau:0.6557 0.5351 0.4718\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 194 Step: 28130 Index:-0.2436 R2:0.7117 0.4609 0.4919 RMSE:0.5739 0.7695 0.7423 Tau:0.6564 0.5259 0.4628\n",
      "Epoch: 195 Step: 28275 Index:-0.1919 R2:0.7113 0.4970 0.5031 RMSE:0.5686 0.7376 0.7366 Tau:0.6552 0.5457 0.4557\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 196 Step: 28420 Index:-0.2265 R2:0.6962 0.4857 0.5010 RMSE:0.6091 0.7604 0.7477 Tau:0.6426 0.5339 0.4559\n",
      "Epoch: 197 Step: 28565 Index:-0.1858 R2:0.7148 0.4961 0.5063 RMSE:0.5757 0.7334 0.7224 Tau:0.6572 0.5476 0.4592\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 198 Step: 28710 Index:-0.2070 R2:0.7172 0.4812 0.4903 RMSE:0.5573 0.7485 0.7417 Tau:0.6588 0.5416 0.4675\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 199 Step: 28855 Index:-0.1990 R2:0.7196 0.4916 0.5003 RMSE:0.5677 0.7478 0.7403 Tau:0.6603 0.5488 0.4758\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 200 Step: 29000 Index:-0.2540 R2:0.7044 0.4641 0.4951 RMSE:0.6001 0.7796 0.7531 Tau:0.6519 0.5257 0.4616\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 201 Step: 29145 Index:-0.2126 R2:0.7214 0.4763 0.5051 RMSE:0.5573 0.7466 0.7232 Tau:0.6609 0.5340 0.4582\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 202 Step: 29290 Index:-0.2330 R2:0.7023 0.4599 0.4825 RMSE:0.5725 0.7651 0.7393 Tau:0.6504 0.5321 0.4460\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 203 Step: 29435 Index:-0.2055 R2:0.7239 0.4837 0.4985 RMSE:0.5680 0.7486 0.7334 Tau:0.6649 0.5430 0.4741\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 204 Step: 29580 Index:-0.1862 R2:0.7282 0.4921 0.5108 RMSE:0.5527 0.7343 0.7175 Tau:0.6661 0.5481 0.4674\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 205 Step: 29725 Index:-0.2294 R2:0.7242 0.4850 0.5158 RMSE:0.5869 0.7736 0.7526 Tau:0.6633 0.5442 0.4651\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 206 Step: 29870 Index:-0.2059 R2:0.7154 0.4898 0.5128 RMSE:0.5625 0.7457 0.7285 Tau:0.6551 0.5398 0.4690\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 207 Step: 30015 Index:-0.2163 R2:0.7320 0.4836 0.5179 RMSE:0.5728 0.7588 0.7351 Tau:0.6686 0.5425 0.4652\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 208 Step: 30160 Index:-0.2307 R2:0.7270 0.4803 0.5055 RMSE:0.5673 0.7694 0.7465 Tau:0.6662 0.5387 0.4672\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 209 Step: 30305 Index:-0.2059 R2:0.7300 0.4786 0.5051 RMSE:0.5474 0.7481 0.7249 Tau:0.6695 0.5421 0.4667\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 210 Step: 30450 Index:-0.1976 R2:0.7267 0.4923 0.5117 RMSE:0.5478 0.7413 0.7238 Tau:0.6660 0.5438 0.4727\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 211 Step: 30595 Index:-0.1906 R2:0.7265 0.4981 0.5051 RMSE:0.5554 0.7400 0.7375 Tau:0.6656 0.5494 0.4692\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 212 Step: 30740 Index:-0.2022 R2:0.7089 0.4957 0.5123 RMSE:0.5841 0.7423 0.7330 Tau:0.6537 0.5401 0.4521\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 213 Step: 30885 Index:-0.1956 R2:0.7307 0.4977 0.5137 RMSE:0.5553 0.7469 0.7344 Tau:0.6680 0.5512 0.4526\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 214 Step: 31030 Index:-0.1932 R2:0.7251 0.4920 0.5040 RMSE:0.5563 0.7365 0.7272 Tau:0.6629 0.5433 0.4740\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 215 Step: 31175 Index:-0.2678 R2:0.7200 0.4732 0.5085 RMSE:0.6125 0.8028 0.7786 Tau:0.6583 0.5350 0.4648\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 216 Step: 31320 Index:-0.1935 R2:0.7236 0.4958 0.5113 RMSE:0.5508 0.7449 0.7313 Tau:0.6624 0.5514 0.4685\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 217 Step: 31465 Index:-0.1945 R2:0.7365 0.4839 0.5088 RMSE:0.5447 0.7378 0.7178 Tau:0.6718 0.5433 0.4507\n",
      "Epoch: 218 Step: 31610 Index:-0.1856 R2:0.7327 0.5001 0.5187 RMSE:0.5514 0.7345 0.7263 Tau:0.6687 0.5489 0.4635\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 219 Step: 31755 Index:-0.2160 R2:0.7329 0.4766 0.5181 RMSE:0.5634 0.7520 0.7216 Tau:0.6683 0.5360 0.4684\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 220 Step: 31900 Index:-0.2183 R2:0.7384 0.4800 0.5042 RMSE:0.5587 0.7601 0.7479 Tau:0.6727 0.5418 0.4557\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 221 Step: 32045 Index:-0.2121 R2:0.7438 0.4936 0.5251 RMSE:0.5572 0.7579 0.7350 Tau:0.6769 0.5458 0.4627\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 222 Step: 32190 Index:-0.1956 R2:0.7426 0.4922 0.5226 RMSE:0.5409 0.7444 0.7205 Tau:0.6771 0.5488 0.4664\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 223 Step: 32335 Index:-0.1895 R2:0.7411 0.4981 0.5173 RMSE:0.5521 0.7412 0.7226 Tau:0.6760 0.5517 0.4681\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 224 Step: 32480 Index:-0.2053 R2:0.7328 0.4773 0.5081 RMSE:0.5454 0.7448 0.7197 Tau:0.6678 0.5395 0.4493\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 225 Step: 32625 Index:-0.1988 R2:0.7453 0.4977 0.5104 RMSE:0.5518 0.7493 0.7475 Tau:0.6781 0.5505 0.4594\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 226 Step: 32770 Index:-0.1865 R2:0.7428 0.4928 0.5058 RMSE:0.5329 0.7390 0.7282 Tau:0.6789 0.5524 0.4726\n",
      "Epoch: 227 Step: 32915 Index:-0.1819 R2:0.7474 0.4957 0.5229 RMSE:0.5338 0.7361 0.7152 Tau:0.6800 0.5542 0.4703\n",
      "Epoch: 228 Step: 33060 Index:-0.1778 R2:0.7410 0.5113 0.5264 RMSE:0.5478 0.7303 0.7177 Tau:0.6770 0.5525 0.4649\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 229 Step: 33205 Index:-0.1827 R2:0.7477 0.5065 0.5279 RMSE:0.5341 0.7374 0.7212 Tau:0.6806 0.5547 0.4715\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 230 Step: 33350 Index:-0.1874 R2:0.7430 0.4929 0.5279 RMSE:0.5401 0.7333 0.7056 Tau:0.6778 0.5459 0.4612\n",
      "Epoch: 231 Step: 33495 Index:-0.1714 R2:0.7496 0.5039 0.5171 RMSE:0.5351 0.7297 0.7168 Tau:0.6816 0.5583 0.4664\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 232 Step: 33640 Index:-0.1943 R2:0.7396 0.4896 0.5126 RMSE:0.5353 0.7437 0.7251 Tau:0.6743 0.5493 0.4807\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 233 Step: 33785 Index:-0.2109 R2:0.7385 0.4832 0.5114 RMSE:0.5356 0.7593 0.7331 Tau:0.6756 0.5485 0.4648\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 234 Step: 33930 Index:-0.2139 R2:0.7471 0.4997 0.5179 RMSE:0.5524 0.7683 0.7523 Tau:0.6817 0.5544 0.4699\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 235 Step: 34075 Index:-0.1957 R2:0.7471 0.5053 0.5229 RMSE:0.5382 0.7502 0.7423 Tau:0.6789 0.5545 0.4689\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 236 Step: 34220 Index:-0.1983 R2:0.7565 0.4848 0.5217 RMSE:0.5237 0.7446 0.7163 Tau:0.6874 0.5463 0.4577\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 237 Step: 34365 Index:-0.1794 R2:0.7566 0.5010 0.5283 RMSE:0.5182 0.7364 0.7154 Tau:0.6871 0.5571 0.4690\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 238 Step: 34510 Index:-0.2058 R2:0.7368 0.4872 0.5068 RMSE:0.5629 0.7540 0.7332 Tau:0.6761 0.5482 0.4619\n",
      "Epoch: 239 Step: 34655 Index:-0.1688 R2:0.7575 0.5054 0.5284 RMSE:0.5186 0.7275 0.7071 Tau:0.6878 0.5587 0.4680\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 240 Step: 34800 Index:-0.2221 R2:0.7468 0.4859 0.5178 RMSE:0.5444 0.7709 0.7469 Tau:0.6821 0.5488 0.4714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 241 Step: 34945 Index:-0.2158 R2:0.7552 0.5042 0.5213 RMSE:0.5592 0.7751 0.7668 Tau:0.6861 0.5592 0.4662\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 242 Step: 35090 Index:-0.2813 R2:0.7439 0.4611 0.5133 RMSE:0.5780 0.8104 0.7723 Tau:0.6762 0.5291 0.4583\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 243 Step: 35235 Index:-0.2060 R2:0.7482 0.4872 0.5166 RMSE:0.5262 0.7460 0.7244 Tau:0.6812 0.5400 0.4663\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 244 Step: 35380 Index:-0.1865 R2:0.7607 0.4893 0.5217 RMSE:0.5220 0.7334 0.7103 Tau:0.6881 0.5469 0.4431\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 245 Step: 35525 Index:-0.2721 R2:0.7398 0.4984 0.5173 RMSE:0.6136 0.8229 0.8154 Tau:0.6800 0.5508 0.4698\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 246 Step: 35670 Index:-0.2131 R2:0.7658 0.4989 0.5284 RMSE:0.5450 0.7682 0.7535 Tau:0.6931 0.5552 0.4564\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 247 Step: 35815 Index:-0.2300 R2:0.7588 0.4990 0.5255 RMSE:0.5683 0.7836 0.7680 Tau:0.6887 0.5537 0.4674\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 248 Step: 35960 Index:-0.1938 R2:0.7481 0.5259 0.5306 RMSE:0.5747 0.7587 0.7629 Tau:0.6803 0.5649 0.4770\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 249 Step: 36105 Index:-0.1917 R2:0.7537 0.4893 0.5153 RMSE:0.5221 0.7438 0.7189 Tau:0.6874 0.5521 0.4656\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 250 Step: 36250 Index:-0.2340 R2:0.7507 0.4954 0.5120 RMSE:0.5664 0.7866 0.7784 Tau:0.6848 0.5526 0.4757\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 251 Step: 36395 Index:-0.1737 R2:0.7714 0.4999 0.5437 RMSE:0.5146 0.7269 0.6905 Tau:0.6966 0.5531 0.4584\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 252 Step: 36540 Index:-0.3046 R2:0.7432 0.4741 0.5257 RMSE:0.6214 0.8408 0.8102 Tau:0.6768 0.5363 0.4507\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 253 Step: 36685 Index:-0.1922 R2:0.7659 0.4957 0.5320 RMSE:0.5106 0.7456 0.7159 Tau:0.6940 0.5534 0.4728\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 254 Step: 36830 Index:-0.1961 R2:0.7708 0.4954 0.5333 RMSE:0.5189 0.7489 0.7268 Tau:0.6973 0.5527 0.4594\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 255 Step: 36975 Index:-0.2459 R2:0.7512 0.4641 0.5115 RMSE:0.5312 0.7780 0.7400 Tau:0.6827 0.5321 0.4598\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 256 Step: 37120 Index:-0.2086 R2:0.7597 0.4790 0.5234 RMSE:0.5150 0.7530 0.7201 Tau:0.6873 0.5444 0.4656\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 257 Step: 37265 Index:-0.2038 R2:0.7690 0.4847 0.5234 RMSE:0.5108 0.7486 0.7203 Tau:0.6963 0.5448 0.4687\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 258 Step: 37410 Index:-0.1899 R2:0.7738 0.4927 0.5333 RMSE:0.5108 0.7458 0.7076 Tau:0.7011 0.5559 0.4630\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 259 Step: 37555 Index:-0.2042 R2:0.7712 0.4935 0.5328 RMSE:0.5225 0.7536 0.7278 Tau:0.6964 0.5493 0.4629\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 260 Step: 37700 Index:-0.1816 R2:0.7722 0.5039 0.5347 RMSE:0.5021 0.7384 0.7187 Tau:0.6982 0.5568 0.4686\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 261 Step: 37845 Index:-0.2375 R2:0.7567 0.4648 0.5082 RMSE:0.5223 0.7721 0.7359 Tau:0.6867 0.5346 0.4700\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 262 Step: 37990 Index:-0.1751 R2:0.7678 0.5067 0.5419 RMSE:0.5063 0.7300 0.7057 Tau:0.6935 0.5549 0.4653\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 263 Step: 38135 Index:-0.1930 R2:0.7675 0.4924 0.5362 RMSE:0.5109 0.7391 0.7041 Tau:0.6943 0.5461 0.4807\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 264 Step: 38280 Index:-0.1868 R2:0.7734 0.4950 0.5379 RMSE:0.4999 0.7393 0.7097 Tau:0.6978 0.5526 0.4641\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 265 Step: 38425 Index:-0.1746 R2:0.7730 0.5089 0.5298 RMSE:0.5076 0.7355 0.7156 Tau:0.6985 0.5609 0.4727\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 266 Step: 38570 Index:-0.2069 R2:0.7728 0.4885 0.5237 RMSE:0.5087 0.7605 0.7340 Tau:0.6988 0.5535 0.4619\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 267 Step: 38715 Index:-0.2141 R2:0.7728 0.4828 0.5383 RMSE:0.5151 0.7563 0.7055 Tau:0.6983 0.5422 0.4665\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 268 Step: 38860 Index:-0.2212 R2:0.7713 0.4741 0.5326 RMSE:0.5276 0.7589 0.7058 Tau:0.6950 0.5377 0.4523\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 269 Step: 39005 Index:-0.2267 R2:0.7729 0.4761 0.5210 RMSE:0.5120 0.7676 0.7335 Tau:0.6973 0.5409 0.4680\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 270 Step: 39150 Index:-0.2108 R2:0.7592 0.4777 0.5234 RMSE:0.5152 0.7546 0.7197 Tau:0.6859 0.5438 0.4604\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 271 Step: 39295 Index:-0.1898 R2:0.7594 0.5052 0.5383 RMSE:0.5142 0.7435 0.7214 Tau:0.6869 0.5536 0.4737\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 272 Step: 39440 Index:-0.2652 R2:0.7105 0.4374 0.4781 RMSE:0.5752 0.7761 0.7488 Tau:0.6479 0.5109 0.4278\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 273 Step: 39585 Index:-0.1960 R2:0.7740 0.4891 0.5136 RMSE:0.5009 0.7464 0.7270 Tau:0.7009 0.5503 0.4726\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 274 Step: 39730 Index:-0.2468 R2:0.7737 0.4680 0.5226 RMSE:0.5197 0.7873 0.7452 Tau:0.7005 0.5405 0.4719\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 275 Step: 39875 Index:-0.1831 R2:0.7823 0.4935 0.5317 RMSE:0.4949 0.7362 0.7063 Tau:0.7041 0.5532 0.4706\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 276 Step: 40020 Index:-0.1916 R2:0.7771 0.4962 0.5397 RMSE:0.5023 0.7412 0.7082 Tau:0.7001 0.5495 0.4611\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 277 Step: 40165 Index:-0.2193 R2:0.7801 0.4750 0.5218 RMSE:0.4949 0.7630 0.7259 Tau:0.7042 0.5437 0.4630\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 278 Step: 40310 Index:-0.1799 R2:0.7697 0.5064 0.5461 RMSE:0.5038 0.7321 0.7008 Tau:0.6940 0.5522 0.4660\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 279 Step: 40455 Index:-0.2065 R2:0.7808 0.4832 0.5312 RMSE:0.4955 0.7516 0.7164 Tau:0.7023 0.5452 0.4686\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 280 Step: 40600 Index:-0.2014 R2:0.7824 0.4921 0.5241 RMSE:0.4993 0.7510 0.7240 Tau:0.7051 0.5496 0.4713\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 281 Step: 40745 Index:-0.1786 R2:0.7752 0.5053 0.5328 RMSE:0.4972 0.7382 0.7211 Tau:0.7023 0.5596 0.4650\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 282 Step: 40890 Index:-0.1989 R2:0.7861 0.4925 0.5395 RMSE:0.4874 0.7505 0.7187 Tau:0.7083 0.5516 0.4629\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 283 Step: 41035 Index:-0.1869 R2:0.7838 0.5076 0.5273 RMSE:0.5188 0.7477 0.7413 Tau:0.7071 0.5608 0.4820\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 284 Step: 41180 Index:-0.2112 R2:0.7660 0.4810 0.5326 RMSE:0.5085 0.7556 0.7151 Tau:0.6904 0.5444 0.4705\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 285 Step: 41325 Index:-0.2201 R2:0.7898 0.4655 0.5286 RMSE:0.4876 0.7618 0.7076 Tau:0.7125 0.5418 0.4681\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 286 Step: 41470 Index:-0.2072 R2:0.7831 0.4837 0.5275 RMSE:0.4887 0.7547 0.7198 Tau:0.7056 0.5475 0.4776\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 287 Step: 41615 Index:-0.3315 R2:0.6584 0.4084 0.4260 RMSE:0.6274 0.8184 0.8102 Tau:0.6208 0.4869 0.4353\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 288 Step: 41760 Index:-0.1820 R2:0.7869 0.4989 0.5407 RMSE:0.4949 0.7367 0.6980 Tau:0.7093 0.5546 0.4714\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 289 Step: 41905 Index:-0.2240 R2:0.7811 0.4754 0.5164 RMSE:0.4994 0.7700 0.7387 Tau:0.7075 0.5460 0.4590\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 290 Step: 42050 Index:-0.1911 R2:0.7788 0.5132 0.5454 RMSE:0.5092 0.7477 0.7236 Tau:0.7007 0.5566 0.4680\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 291 Step: 42195 Index:-0.2276 R2:0.7816 0.4829 0.5436 RMSE:0.5058 0.7703 0.7351 Tau:0.7054 0.5427 0.4602\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 292 Step: 42340 Index:-0.1708 R2:0.7800 0.5152 0.5478 RMSE:0.4934 0.7284 0.7026 Tau:0.7039 0.5575 0.4732\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 293 Step: 42485 Index:-0.1870 R2:0.7953 0.4995 0.5415 RMSE:0.4936 0.7441 0.7063 Tau:0.7155 0.5571 0.4659\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 294 Step: 42630 Index:-0.1729 R2:0.7908 0.5118 0.5432 RMSE:0.4798 0.7350 0.7112 Tau:0.7120 0.5621 0.4742\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 295 Step: 42775 Index:-0.2218 R2:0.7962 0.4723 0.5280 RMSE:0.5007 0.7650 0.7142 Tau:0.7175 0.5432 0.4600\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 296 Step: 42920 Index:-0.1876 R2:0.7905 0.5055 0.5487 RMSE:0.4913 0.7472 0.7156 Tau:0.7104 0.5595 0.4745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 297 Step: 43065 Index:-0.1954 R2:0.7891 0.4871 0.5440 RMSE:0.4851 0.7487 0.6991 Tau:0.7103 0.5533 0.4622\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 298 Step: 43210 Index:-0.2198 R2:0.7924 0.4743 0.5247 RMSE:0.4819 0.7675 0.7311 Tau:0.7142 0.5477 0.4613\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 299 Step: 43355 Index:-0.1777 R2:0.8035 0.4974 0.5335 RMSE:0.4749 0.7373 0.7132 Tau:0.7217 0.5597 0.4689\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 300 Step: 43500 Index:-0.2482 R2:0.7857 0.4550 0.5157 RMSE:0.4883 0.7810 0.7385 Tau:0.7085 0.5328 0.4567\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 301 Step: 43645 Index:-0.2076 R2:0.8012 0.4797 0.5287 RMSE:0.4727 0.7507 0.7167 Tau:0.7210 0.5432 0.4620\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 302 Step: 43790 Index:-0.1922 R2:0.7916 0.4952 0.5180 RMSE:0.4817 0.7481 0.7312 Tau:0.7135 0.5559 0.4752\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 303 Step: 43935 Index:-0.2326 R2:0.7983 0.4718 0.5193 RMSE:0.4792 0.7738 0.7376 Tau:0.7179 0.5412 0.4734\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 304 Step: 44080 Index:-0.2047 R2:0.7961 0.4870 0.5303 RMSE:0.4808 0.7552 0.7295 Tau:0.7156 0.5505 0.4550\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 305 Step: 44225 Index:-0.2138 R2:0.8008 0.4972 0.5304 RMSE:0.4937 0.7728 0.7545 Tau:0.7216 0.5590 0.4690\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 306 Step: 44370 Index:-0.2145 R2:0.7997 0.4781 0.5299 RMSE:0.4812 0.7603 0.7240 Tau:0.7178 0.5458 0.4674\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 307 Step: 44515 Index:-0.1930 R2:0.7908 0.4999 0.5268 RMSE:0.4889 0.7545 0.7270 Tau:0.7142 0.5614 0.4757\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 308 Step: 44660 Index:-0.1849 R2:0.7916 0.5042 0.5299 RMSE:0.4902 0.7444 0.7241 Tau:0.7128 0.5595 0.4616\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 309 Step: 44805 Index:-0.3141 R2:0.7789 0.4582 0.5077 RMSE:0.5704 0.8369 0.8190 Tau:0.6999 0.5228 0.4567\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 310 Step: 44950 Index:-0.1928 R2:0.8036 0.4975 0.5375 RMSE:0.4660 0.7485 0.7183 Tau:0.7232 0.5557 0.4624\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 311 Step: 45095 Index:-0.2071 R2:0.8029 0.4810 0.5173 RMSE:0.4735 0.7551 0.7311 Tau:0.7221 0.5480 0.4698\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 312 Step: 45240 Index:-0.2167 R2:0.7980 0.4821 0.5174 RMSE:0.4776 0.7620 0.7446 Tau:0.7172 0.5453 0.4682\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 313 Step: 45385 Index:-0.1823 R2:0.8044 0.4976 0.5281 RMSE:0.4811 0.7440 0.7171 Tau:0.7228 0.5617 0.4654\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 314 Step: 45530 Index:-0.1830 R2:0.8011 0.5084 0.5322 RMSE:0.4711 0.7452 0.7342 Tau:0.7198 0.5622 0.4785\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 315 Step: 45675 Index:-0.2421 R2:0.7976 0.4690 0.5101 RMSE:0.5029 0.7811 0.7389 Tau:0.7182 0.5390 0.4578\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 316 Step: 45820 Index:-0.2029 R2:0.8060 0.4807 0.5155 RMSE:0.4683 0.7556 0.7367 Tau:0.7234 0.5527 0.4629\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 317 Step: 45965 Index:-0.2159 R2:0.8094 0.4906 0.5303 RMSE:0.4838 0.7713 0.7502 Tau:0.7271 0.5555 0.4716\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 318 Step: 46110 Index:-0.1904 R2:0.8043 0.4930 0.5274 RMSE:0.4660 0.7454 0.7219 Tau:0.7213 0.5550 0.4639\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 319 Step: 46255 Index:-0.1998 R2:0.8110 0.4886 0.5246 RMSE:0.4613 0.7586 0.7417 Tau:0.7292 0.5589 0.4601\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 320 Step: 46400 Index:-0.2284 R2:0.8046 0.4752 0.5372 RMSE:0.4734 0.7688 0.7361 Tau:0.7220 0.5404 0.4572\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 321 Step: 46545 Index:-0.2199 R2:0.7968 0.4757 0.5175 RMSE:0.4780 0.7611 0.7391 Tau:0.7144 0.5413 0.4460\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 322 Step: 46690 Index:-0.2026 R2:0.7987 0.4855 0.5155 RMSE:0.4734 0.7531 0.7323 Tau:0.7185 0.5504 0.4668\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 323 Step: 46835 Index:-0.2246 R2:0.8118 0.4771 0.5348 RMSE:0.4571 0.7689 0.7299 Tau:0.7293 0.5443 0.4695\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 324 Step: 46980 Index:-0.1942 R2:0.7955 0.4929 0.5314 RMSE:0.4811 0.7452 0.7133 Tau:0.7150 0.5509 0.4619\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 325 Step: 47125 Index:-0.2382 R2:0.8050 0.4777 0.5393 RMSE:0.4875 0.7788 0.7447 Tau:0.7214 0.5406 0.4653\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 326 Step: 47270 Index:-0.2134 R2:0.8097 0.5039 0.5290 RMSE:0.4831 0.7690 0.7649 Tau:0.7255 0.5555 0.4673\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 327 Step: 47415 Index:-0.2118 R2:0.8069 0.4883 0.5274 RMSE:0.4622 0.7659 0.7422 Tau:0.7250 0.5541 0.4665\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 328 Step: 47560 Index:-0.2383 R2:0.7989 0.4796 0.5014 RMSE:0.4848 0.7836 0.7747 Tau:0.7201 0.5453 0.4598\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 329 Step: 47705 Index:-0.1845 R2:0.8160 0.5021 0.5293 RMSE:0.4521 0.7449 0.7293 Tau:0.7310 0.5604 0.4726\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 330 Step: 47850 Index:-0.1829 R2:0.8140 0.5061 0.5403 RMSE:0.4570 0.7436 0.7264 Tau:0.7289 0.5608 0.4648\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 331 Step: 47995 Index:-0.1946 R2:0.8124 0.4948 0.5283 RMSE:0.4568 0.7449 0.7315 Tau:0.7269 0.5503 0.4635\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 332 Step: 48140 Index:-0.2332 R2:0.8082 0.4719 0.5166 RMSE:0.4797 0.7824 0.7564 Tau:0.7280 0.5492 0.4728\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 333 Step: 48285 Index:-0.2224 R2:0.8035 0.4896 0.5375 RMSE:0.4899 0.7733 0.7494 Tau:0.7207 0.5509 0.4676\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 334 Step: 48430 Index:-0.2272 R2:0.8108 0.4735 0.5330 RMSE:0.4672 0.7742 0.7379 Tau:0.7304 0.5471 0.4676\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 335 Step: 48575 Index:-0.2157 R2:0.8021 0.4843 0.5231 RMSE:0.4666 0.7651 0.7387 Tau:0.7213 0.5495 0.4670\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 336 Step: 48720 Index:-0.2607 R2:0.8145 0.4754 0.5279 RMSE:0.4935 0.8081 0.7839 Tau:0.7316 0.5473 0.4625\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 337 Step: 48865 Index:-0.1997 R2:0.8170 0.4962 0.5370 RMSE:0.4582 0.7572 0.7321 Tau:0.7319 0.5575 0.4754\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 338 Step: 49010 Index:-0.1986 R2:0.8194 0.4869 0.5274 RMSE:0.4513 0.7527 0.7197 Tau:0.7350 0.5541 0.4691\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 339 Step: 49155 Index:-0.1829 R2:0.8169 0.5089 0.5304 RMSE:0.4555 0.7462 0.7426 Tau:0.7321 0.5633 0.4653\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 339 r2:0.5284 RMSE:0.7071 WTI:0.3387 AP:0.6715 Tau:0.4680 \n",
      " \n",
      " Top-1:0.1818 Top-1-fp:0.0000 \n",
      " Top-5:0.4915 Top-5-fp:0.1525 \n",
      " Top-10:0.5714 Top-10-fp:0.2185 \n",
      " Top-15:0.6236 Top-15-fp:0.2135 \n",
      " Top-20:0.6639 Top-20-fp:0.2059 \n",
      " Top-25:0.6869 Top-25-fp:0.2222 \n",
      " Top-30:0.7031 Top-30-fp:0.2465 \n",
      " Top-40:0.6912 Top-40-fp:0.3046 \n",
      " Top-50:0.7700 Top-50-fp:0.3529 \n",
      " \n",
      " Top50:0.4200 Top50-fp:0.1600 \n",
      " Top100:0.5400 Top100-fp:0.2000 \n",
      " Top150:0.6067 Top150-fp:0.2133 \n",
      " Top200:0.6100 Top200-fp:0.2200 \n",
      " Top250:0.6720 Top250-fp:0.2120 \n",
      " Top300:0.6900 Top300-fp:0.2233 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
