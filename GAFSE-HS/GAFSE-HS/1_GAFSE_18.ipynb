{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IC50_P41145_1_280\n",
      "model_file/1_GAFSE_IC50_P41145_1_280_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/IC50_P41145_1_280_train.csv\"\n",
    "test_filename = \"./data/benchmark/IC50_P41145_1_280_test.csv\"\n",
    "test_active = 280\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  C1=CC=C(C=C1)C(C2=CC=CC=C2)(C3=CC=CC=C3Cl)N4C=... -3.799547\n",
      "1  CC(C)CC1=CC=C(C=C1)S(=O)(=O)NCC2=CC=C(C=C2)C(=... -3.363142\n",
      "2  CCC(=O)N1CCN(C(C1)CN2CCCC2)C(=O)CC3=CC(=C(C=C3... -0.838849\n",
      "3  CCN(CC)C(=O)C1=CC=C(C=C1)C(=C2CCN(CC2)CC=C(C)C... -2.991226\n",
      "4                         CCN(CC)C(=S)SSC(=S)N(CC)CC -3.785543\n",
      "number of all smiles:  1119\n",
      "number of successfully processed smiles:  1119\n",
      "                                              smiles     value  \\\n",
      "0  C1=CC=C(C=C1)C(C2=CC=CC=C2)(C3=CC=CC=C3Cl)N4C=... -3.799547   \n",
      "1  CC(C)CC1=CC=C(C=C1)S(=O)(=O)NCC2=CC=C(C=C2)C(=... -3.363142   \n",
      "2  CCC(=O)N1CCN(C(C1)CN2CCCC2)C(=O)CC3=CC(=C(C=C3... -0.838849   \n",
      "3  CCN(CC)C(=O)C1=CC=C(C=C1)C(=C2CCN(CC2)CC=C(C)C... -2.991226   \n",
      "4                         CCN(CC)C(=S)SSC(=S)N(CC)CC -3.785543   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0             Clc1ccccc1C(c1ccccc1)(c1ccccc1)n1ccnc1  \n",
      "1  CC(C)Cc1ccc(S(=O)(=O)NCc2ccc(C(=O)NCCN(Cc3cccc...  \n",
      "2  CCC(=O)N1CCN(C(=O)Cc2ccc(Cl)c(Cl)c2)C(CN2CCCC2)C1  \n",
      "3  CCN(CC)C(=O)c1ccc(C(=C2CCN(CC=C(C)C)CC2)c2cccc...  \n",
      "4                         CCN(CC)C(=S)SSC(=S)N(CC)CC  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  773\n",
      "number of successfully processed smiles:  773\n",
      "(773, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1CCN(C(C1)CN2CCC(=CC#N)C2)C(=O)CC3=CC(=C(C=C3...  0.920819   \n",
      "1           CC(C)CN(C1CCNC1)C(=O)C2=C(C(=CC=C2)Cl)Cl -3.763428   \n",
      "2      CC1=NN=C(C(=C1)C2=NOC(=N2)C)N3CCC(CC3)NCC(C)C -1.342423   \n",
      "3  CC1=CC2=CC(=C(N=C2C=C1)N3CCC(C(C3)CO)NC4CCCCC4... -1.579784   \n",
      "4  CC(C)CC(C(=O)N)NC(=O)C(CCCN=C(N)N)NC(=O)C(CCCN... -2.276462   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0      N#CC=C1CCN(CC2CCCCN2C(=O)Cc2ccc(Cl)c(Cl)c2)C1  \n",
      "1                CC(C)CN(C(=O)c1cccc(Cl)c1Cl)C1CCNC1  \n",
      "2          Cc1cc(-c2noc(C)n2)c(N2CCC(NCC(C)C)CC2)nn1  \n",
      "3  Cc1ccc2nc(N3CCC(NC4CCCCC4)C(CO)C3)c(-c3nnc(C)o...  \n",
      "4  CNC(Cc1ccc(O)cc1)C(=O)NCC(=O)NCC(=O)NC(Cc1cccc...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/IC50_P41145_1_280_train.pickle\n",
      "./data/benchmark/IC50_P41145_1_280_train\n",
      "1892\n",
      "feature dicts file saved as ./data/benchmark/IC50_P41145_1_280_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 3) (224, 3) (773, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_IC50_P41145_1_280_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 89 Index:-1.0922 R2:0.0559 0.0203 0.0458 RMSE:1.1795 1.1863 1.2432 Tau:0.1536 0.0941 0.2024\n",
      "Epoch: 2 Step: 178 Index:-0.8383 R2:0.1527 0.1355 0.1189 RMSE:1.0898 1.0825 1.1631 Tau:0.2633 0.2441 0.2867\n",
      "Epoch: 3 Step: 267 Index:-0.7505 R2:0.2073 0.2241 0.1557 RMSE:1.1362 1.1071 1.1830 Tau:0.3407 0.3566 0.3278\n",
      "Epoch: 4 Step: 356 Index:-0.6396 R2:0.2259 0.2413 0.1676 RMSE:1.0440 1.0109 1.1168 Tau:0.3596 0.3714 0.3345\n",
      "Epoch: 5 Step: 445 Index:-0.6095 R2:0.2489 0.2582 0.1827 RMSE:1.0210 0.9978 1.1059 Tau:0.3796 0.3884 0.3397\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 6 Step: 534 Index:-0.6533 R2:0.2760 0.2924 0.2029 RMSE:1.0818 1.0585 1.1797 Tau:0.3914 0.4053 0.3442\n",
      "Epoch: 7 Step: 623 Index:-0.5506 R2:0.3065 0.3166 0.2286 RMSE:1.0002 0.9758 1.0834 Tau:0.4237 0.4252 0.3519\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 8 Step: 712 Index:-0.5573 R2:0.3328 0.3422 0.2541 RMSE:1.0091 0.9871 1.1092 Tau:0.4347 0.4298 0.3574\n",
      "Epoch: 9 Step: 801 Index:-0.5198 R2:0.3258 0.3271 0.2613 RMSE:0.9651 0.9513 1.0602 Tau:0.4401 0.4315 0.3698\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 10 Step: 890 Index:-0.6472 R2:0.3583 0.3487 0.2936 RMSE:1.0886 1.0875 1.1916 Tau:0.4538 0.4404 0.3706\n",
      "Epoch: 11 Step: 979 Index:-0.4985 R2:0.3585 0.3540 0.2979 RMSE:0.9588 0.9413 1.0326 Tau:0.4572 0.4428 0.3807\n",
      "Epoch: 12 Step: 1068 Index:-0.4599 R2:0.3831 0.3850 0.3124 RMSE:0.9305 0.9111 1.0228 Tau:0.4618 0.4512 0.3712\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 13 Step: 1157 Index:-0.4841 R2:0.3866 0.3657 0.3299 RMSE:0.9320 0.9341 1.0230 Tau:0.4676 0.4499 0.3753\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 14 Step: 1246 Index:-0.4605 R2:0.3934 0.3862 0.3381 RMSE:0.9231 0.9128 1.0078 Tau:0.4695 0.4523 0.3852\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 15 Step: 1335 Index:-0.4740 R2:0.4076 0.3918 0.3491 RMSE:0.9408 0.9294 1.0247 Tau:0.4669 0.4554 0.3743\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 16 Step: 1424 Index:-0.4637 R2:0.4028 0.3804 0.3486 RMSE:0.9265 0.9237 0.9966 Tau:0.4736 0.4600 0.3807\n",
      "Epoch: 17 Step: 1513 Index:-0.4422 R2:0.4181 0.4005 0.3602 RMSE:0.9094 0.9040 0.9861 Tau:0.4795 0.4618 0.3832\n",
      "Epoch: 18 Step: 1602 Index:-0.4324 R2:0.4151 0.4005 0.3615 RMSE:0.9003 0.8939 0.9778 Tau:0.4797 0.4615 0.3863\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 19 Step: 1691 Index:-0.4577 R2:0.4159 0.3879 0.3653 RMSE:0.9119 0.9211 0.9962 Tau:0.4817 0.4635 0.3820\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 20 Step: 1780 Index:-0.4367 R2:0.4211 0.4015 0.3698 RMSE:0.9020 0.8996 0.9738 Tau:0.4834 0.4629 0.3912\n",
      "Epoch: 21 Step: 1869 Index:-0.4172 R2:0.4368 0.4060 0.3857 RMSE:0.8826 0.8884 0.9618 Tau:0.4883 0.4711 0.3841\n",
      "Epoch: 22 Step: 1958 Index:-0.4066 R2:0.4414 0.4202 0.3788 RMSE:0.8840 0.8803 0.9708 Tau:0.4858 0.4737 0.3763\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 23 Step: 2047 Index:-0.4396 R2:0.4389 0.4138 0.3903 RMSE:0.8995 0.9061 0.9780 Tau:0.4922 0.4665 0.3934\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 24 Step: 2136 Index:-0.4419 R2:0.4478 0.4178 0.4029 RMSE:0.9077 0.9175 0.9894 Tau:0.4949 0.4756 0.3933\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 25 Step: 2225 Index:-0.4149 R2:0.4360 0.4260 0.3966 RMSE:0.8902 0.8870 0.9651 Tau:0.4871 0.4721 0.4018\n",
      "Epoch: 26 Step: 2314 Index:-0.4040 R2:0.4575 0.4344 0.4072 RMSE:0.8788 0.8812 0.9601 Tau:0.4992 0.4772 0.4027\n",
      "Epoch: 27 Step: 2403 Index:-0.3937 R2:0.4590 0.4309 0.4085 RMSE:0.8688 0.8763 0.9424 Tau:0.5028 0.4826 0.4023\n",
      "Epoch: 28 Step: 2492 Index:-0.3765 R2:0.4693 0.4458 0.4060 RMSE:0.8691 0.8677 0.9584 Tau:0.5013 0.4912 0.3867\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 29 Step: 2581 Index:-0.6069 R2:0.4653 0.4339 0.4183 RMSE:1.0714 1.0841 1.1502 Tau:0.5028 0.4772 0.4022\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 30 Step: 2670 Index:-0.3862 R2:0.4766 0.4437 0.4252 RMSE:0.8641 0.8741 0.9467 Tau:0.5091 0.4879 0.4012\n",
      "Epoch: 31 Step: 2759 Index:-0.3725 R2:0.4782 0.4468 0.4283 RMSE:0.8517 0.8639 0.9310 Tau:0.5144 0.4914 0.4081\n",
      "Epoch: 32 Step: 2848 Index:-0.3715 R2:0.4903 0.4593 0.4342 RMSE:0.8610 0.8673 0.9450 Tau:0.5158 0.4958 0.4007\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 33 Step: 2937 Index:-0.4528 R2:0.4706 0.4407 0.4354 RMSE:0.9222 0.9353 0.9895 Tau:0.5091 0.4825 0.4161\n",
      "Epoch: 34 Step: 3026 Index:-0.3701 R2:0.4741 0.4569 0.4046 RMSE:0.8859 0.8728 0.9716 Tau:0.5036 0.5026 0.3747\n",
      "Epoch: 35 Step: 3115 Index:-0.3433 R2:0.4965 0.4710 0.4350 RMSE:0.8516 0.8502 0.9373 Tau:0.5179 0.5070 0.3938\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 36 Step: 3204 Index:-0.3482 R2:0.4847 0.4562 0.4490 RMSE:0.8423 0.8507 0.9134 Tau:0.5152 0.5026 0.4106\n",
      "Epoch: 37 Step: 3293 Index:-0.3271 R2:0.4999 0.4749 0.4436 RMSE:0.8362 0.8385 0.9176 Tau:0.5232 0.5114 0.4052\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 38 Step: 3382 Index:-0.3736 R2:0.4885 0.4566 0.4486 RMSE:0.8648 0.8732 0.9331 Tau:0.5202 0.4996 0.4160\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 39 Step: 3471 Index:-0.3288 R2:0.5112 0.4752 0.4504 RMSE:0.8313 0.8442 0.9141 Tau:0.5318 0.5155 0.4093\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 40 Step: 3560 Index:-0.3372 R2:0.5040 0.4850 0.4589 RMSE:0.8489 0.8521 0.9278 Tau:0.5242 0.5149 0.4195\n",
      "Epoch: 41 Step: 3649 Index:-0.3252 R2:0.5152 0.4721 0.4516 RMSE:0.8201 0.8415 0.9098 Tau:0.5351 0.5163 0.4078\n",
      "Epoch: 42 Step: 3738 Index:-0.3232 R2:0.5162 0.4702 0.4677 RMSE:0.8181 0.8406 0.8945 Tau:0.5348 0.5175 0.4134\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 3827 Index:-0.3609 R2:0.5232 0.4885 0.4762 RMSE:0.8701 0.8808 0.9486 Tau:0.5336 0.5199 0.4141\n",
      "Epoch: 44 Step: 3916 Index:-0.2941 R2:0.5273 0.5001 0.4664 RMSE:0.8111 0.8160 0.8975 Tau:0.5381 0.5219 0.4133\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 45 Step: 4005 Index:-0.3101 R2:0.5141 0.4842 0.4673 RMSE:0.8181 0.8308 0.8930 Tau:0.5370 0.5207 0.4235\n",
      "Epoch: 46 Step: 4094 Index:-0.2811 R2:0.5322 0.5044 0.4666 RMSE:0.8033 0.8114 0.8941 Tau:0.5400 0.5303 0.4068\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 47 Step: 4183 Index:-0.2869 R2:0.5267 0.5016 0.4758 RMSE:0.8083 0.8142 0.8880 Tau:0.5414 0.5273 0.4250\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 48 Step: 4272 Index:-0.3298 R2:0.5166 0.4855 0.4757 RMSE:0.8382 0.8525 0.9114 Tau:0.5352 0.5227 0.4248\n",
      "Epoch: 49 Step: 4361 Index:-0.2792 R2:0.5425 0.5141 0.4795 RMSE:0.8112 0.8148 0.8992 Tau:0.5443 0.5356 0.4135\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 50 Step: 4450 Index:-0.3072 R2:0.5408 0.5099 0.4753 RMSE:0.8448 0.8450 0.9316 Tau:0.5493 0.5377 0.4128\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 51 Step: 4539 Index:-0.2803 R2:0.5439 0.5242 0.4862 RMSE:0.8244 0.8237 0.8997 Tau:0.5523 0.5434 0.4227\n",
      "Epoch: 52 Step: 4628 Index:-0.2626 R2:0.5484 0.5320 0.4846 RMSE:0.8086 0.8080 0.8936 Tau:0.5502 0.5453 0.4172\n",
      "Epoch: 53 Step: 4717 Index:-0.2475 R2:0.5516 0.5273 0.4817 RMSE:0.7884 0.7939 0.8817 Tau:0.5540 0.5465 0.4135\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 54 Step: 4806 Index:-0.2480 R2:0.5525 0.5306 0.4932 RMSE:0.7921 0.7956 0.8790 Tau:0.5528 0.5476 0.4244\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 55 Step: 4895 Index:-0.2582 R2:0.5481 0.5256 0.4864 RMSE:0.7959 0.8006 0.8881 Tau:0.5493 0.5425 0.4108\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 56 Step: 4984 Index:-0.2919 R2:0.5631 0.5414 0.5104 RMSE:0.8492 0.8463 0.9296 Tau:0.5587 0.5544 0.4256\n",
      "Epoch: 57 Step: 5073 Index:-0.2375 R2:0.5625 0.5334 0.5056 RMSE:0.7812 0.7901 0.8672 Tau:0.5590 0.5526 0.4215\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 58 Step: 5162 Index:-0.3119 R2:0.5660 0.5337 0.5092 RMSE:0.8565 0.8633 0.9444 Tau:0.5587 0.5514 0.4176\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 59 Step: 5251 Index:-0.2559 R2:0.5626 0.5243 0.4998 RMSE:0.7956 0.8107 0.8794 Tau:0.5602 0.5547 0.4082\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 60 Step: 5340 Index:-0.2429 R2:0.5661 0.5281 0.5098 RMSE:0.7761 0.7973 0.8568 Tau:0.5658 0.5545 0.4215\n",
      "Epoch: 61 Step: 5429 Index:-0.2224 R2:0.5704 0.5410 0.5118 RMSE:0.7703 0.7829 0.8547 Tau:0.5678 0.5606 0.4263\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 62 Step: 5518 Index:-0.2942 R2:0.5555 0.5453 0.5035 RMSE:0.8550 0.8503 0.9357 Tau:0.5545 0.5561 0.4292\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 63 Step: 5607 Index:-0.2630 R2:0.5715 0.5565 0.5198 RMSE:0.8354 0.8286 0.9150 Tau:0.5637 0.5655 0.4278\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 64 Step: 5696 Index:-0.2241 R2:0.5765 0.5442 0.5126 RMSE:0.7697 0.7861 0.8646 Tau:0.5722 0.5620 0.4269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 Step: 5785 Index:-0.2021 R2:0.5859 0.5564 0.5169 RMSE:0.7600 0.7712 0.8522 Tau:0.5755 0.5691 0.4180\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 66 Step: 5874 Index:-0.2205 R2:0.5860 0.5659 0.5126 RMSE:0.7900 0.7863 0.8874 Tau:0.5688 0.5658 0.4083\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 67 Step: 5963 Index:-0.2102 R2:0.5788 0.5422 0.5243 RMSE:0.7657 0.7811 0.8512 Tau:0.5676 0.5709 0.4144\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 68 Step: 6052 Index:-0.2249 R2:0.5784 0.5508 0.5111 RMSE:0.7745 0.7904 0.8610 Tau:0.5754 0.5655 0.4277\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 69 Step: 6141 Index:-0.2174 R2:0.5786 0.5611 0.5255 RMSE:0.7868 0.7892 0.8730 Tau:0.5679 0.5718 0.4278\n",
      "Epoch: 70 Step: 6230 Index:-0.1876 R2:0.5948 0.5671 0.5260 RMSE:0.7559 0.7615 0.8493 Tau:0.5788 0.5739 0.4178\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 71 Step: 6319 Index:-0.2112 R2:0.5746 0.5575 0.5383 RMSE:0.7839 0.7832 0.8525 Tau:0.5658 0.5719 0.4277\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 72 Step: 6408 Index:-0.2024 R2:0.5882 0.5568 0.5320 RMSE:0.7609 0.7731 0.8467 Tau:0.5816 0.5707 0.4305\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 73 Step: 6497 Index:-0.2125 R2:0.6014 0.5673 0.5318 RMSE:0.7764 0.7843 0.8743 Tau:0.5811 0.5719 0.4204\n",
      "Epoch: 74 Step: 6586 Index:-0.1753 R2:0.5928 0.5818 0.5144 RMSE:0.7619 0.7521 0.8601 Tau:0.5756 0.5768 0.4037\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 75 Step: 6675 Index:-0.1789 R2:0.6039 0.5853 0.5353 RMSE:0.7657 0.7619 0.8607 Tau:0.5820 0.5830 0.4207\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 76 Step: 6764 Index:-0.1984 R2:0.6020 0.5864 0.5302 RMSE:0.7975 0.7811 0.8882 Tau:0.5805 0.5827 0.4163\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 77 Step: 6853 Index:-0.1897 R2:0.6072 0.5767 0.5440 RMSE:0.7555 0.7712 0.8377 Tau:0.5889 0.5815 0.4245\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 78 Step: 6942 Index:-0.1905 R2:0.6017 0.5732 0.5365 RMSE:0.7534 0.7673 0.8383 Tau:0.5825 0.5768 0.4181\n",
      "Epoch: 79 Step: 7031 Index:-0.1644 R2:0.6068 0.5797 0.5399 RMSE:0.7380 0.7479 0.8334 Tau:0.5871 0.5836 0.4225\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 80 Step: 7120 Index:-0.1892 R2:0.6042 0.5786 0.5266 RMSE:0.7639 0.7619 0.8647 Tau:0.5782 0.5727 0.3992\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 81 Step: 7209 Index:-0.2358 R2:0.5867 0.5411 0.5304 RMSE:0.7846 0.8123 0.8520 Tau:0.5816 0.5765 0.4259\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 82 Step: 7298 Index:-0.1672 R2:0.6189 0.5926 0.5420 RMSE:0.7546 0.7578 0.8588 Tau:0.5930 0.5906 0.4219\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 83 Step: 7387 Index:-0.1819 R2:0.6089 0.5760 0.5436 RMSE:0.7510 0.7635 0.8487 Tau:0.5922 0.5816 0.4300\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 84 Step: 7476 Index:-0.1994 R2:0.6019 0.5747 0.5463 RMSE:0.7718 0.7809 0.8611 Tau:0.5851 0.5815 0.4320\n",
      "Epoch: 85 Step: 7565 Index:-0.1558 R2:0.6155 0.5871 0.5416 RMSE:0.7312 0.7431 0.8348 Tau:0.5914 0.5873 0.4238\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 86 Step: 7654 Index:-0.1671 R2:0.6209 0.5801 0.5442 RMSE:0.7286 0.7527 0.8268 Tau:0.5976 0.5856 0.4186\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 87 Step: 7743 Index:-0.1617 R2:0.6122 0.5814 0.5424 RMSE:0.7360 0.7492 0.8372 Tau:0.5942 0.5875 0.4289\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 88 Step: 7832 Index:-0.1900 R2:0.6211 0.5820 0.5547 RMSE:0.7687 0.7779 0.8655 Tau:0.5966 0.5879 0.4248\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 89 Step: 7921 Index:-0.1869 R2:0.6229 0.5983 0.5437 RMSE:0.7869 0.7791 0.8890 Tau:0.5949 0.5922 0.4214\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 90 Step: 8010 Index:-0.2570 R2:0.6236 0.5983 0.5359 RMSE:0.8618 0.8419 0.9607 Tau:0.5908 0.5849 0.4036\n",
      "Epoch: 91 Step: 8099 Index:-0.1364 R2:0.6281 0.6026 0.5420 RMSE:0.7182 0.7298 0.8277 Tau:0.5958 0.5933 0.4142\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 92 Step: 8188 Index:-0.1564 R2:0.6277 0.5947 0.5411 RMSE:0.7416 0.7501 0.8551 Tau:0.6016 0.5937 0.4228\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 93 Step: 8277 Index:-0.1408 R2:0.6368 0.5984 0.5438 RMSE:0.7087 0.7349 0.8256 Tau:0.6072 0.5941 0.4179\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 94 Step: 8366 Index:-0.1667 R2:0.6252 0.5772 0.5452 RMSE:0.7215 0.7496 0.8298 Tau:0.5999 0.5829 0.4174\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 95 Step: 8455 Index:-0.1420 R2:0.6340 0.5998 0.5418 RMSE:0.7143 0.7356 0.8277 Tau:0.6051 0.5937 0.4176\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 96 Step: 8544 Index:-0.1931 R2:0.6268 0.5875 0.5423 RMSE:0.7571 0.7856 0.8516 Tau:0.6055 0.5925 0.4244\n",
      "Epoch: 97 Step: 8633 Index:-0.1333 R2:0.6375 0.6017 0.5492 RMSE:0.7086 0.7311 0.8206 Tau:0.6057 0.5978 0.4175\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 98 Step: 8722 Index:-0.1532 R2:0.6326 0.6043 0.5348 RMSE:0.7309 0.7489 0.8416 Tau:0.6044 0.5957 0.4055\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 99 Step: 8811 Index:-0.1439 R2:0.6404 0.6003 0.5518 RMSE:0.7257 0.7410 0.8415 Tau:0.6112 0.5971 0.4207\n",
      "Epoch: 100 Step: 8900 Index:-0.1267 R2:0.6431 0.6094 0.5409 RMSE:0.7170 0.7267 0.8412 Tau:0.6110 0.6001 0.4165\n",
      "Epoch: 101 Step: 8989 Index:-0.1224 R2:0.6463 0.6143 0.5478 RMSE:0.7121 0.7237 0.8310 Tau:0.6098 0.6014 0.4127\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 102 Step: 9078 Index:-0.1432 R2:0.6338 0.6013 0.5414 RMSE:0.7227 0.7363 0.8469 Tau:0.6027 0.5932 0.4202\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 103 Step: 9167 Index:-0.1267 R2:0.6453 0.6101 0.5389 RMSE:0.7044 0.7275 0.8305 Tau:0.6135 0.6008 0.4194\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 104 Step: 9256 Index:-0.1354 R2:0.6344 0.6001 0.5458 RMSE:0.7134 0.7320 0.8331 Tau:0.6043 0.5965 0.4217\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 105 Step: 9345 Index:-0.1774 R2:0.6445 0.6129 0.5470 RMSE:0.7692 0.7721 0.8914 Tau:0.6070 0.5947 0.4184\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 106 Step: 9434 Index:-0.1411 R2:0.6395 0.6004 0.5411 RMSE:0.7045 0.7290 0.8314 Tau:0.6057 0.5879 0.4151\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 107 Step: 9523 Index:-0.1392 R2:0.6405 0.6053 0.5473 RMSE:0.7234 0.7335 0.8389 Tau:0.6046 0.5942 0.4153\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 108 Step: 9612 Index:-0.1945 R2:0.6428 0.6002 0.5530 RMSE:0.7817 0.7920 0.8999 Tau:0.6103 0.5975 0.4238\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 109 Step: 9701 Index:-0.1406 R2:0.6506 0.6023 0.5454 RMSE:0.7023 0.7352 0.8253 Tau:0.6145 0.5945 0.4128\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 110 Step: 9790 Index:-0.1327 R2:0.6555 0.5997 0.5484 RMSE:0.6910 0.7293 0.8238 Tau:0.6213 0.5965 0.4169\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 111 Step: 9879 Index:-0.1565 R2:0.6442 0.6070 0.5395 RMSE:0.7361 0.7492 0.8725 Tau:0.6071 0.5927 0.4130\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 112 Step: 9968 Index:-0.1466 R2:0.6360 0.5923 0.5410 RMSE:0.7121 0.7373 0.8363 Tau:0.6086 0.5908 0.4209\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 113 Step: 10057 Index:-0.1410 R2:0.6534 0.5958 0.5450 RMSE:0.6962 0.7334 0.8307 Tau:0.6145 0.5925 0.4103\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 114 Step: 10146 Index:-0.1268 R2:0.6563 0.6120 0.5408 RMSE:0.6937 0.7206 0.8306 Tau:0.6141 0.5938 0.4083\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 115 Step: 10235 Index:-0.1224 R2:0.6578 0.6093 0.5502 RMSE:0.6901 0.7213 0.8278 Tau:0.6203 0.5989 0.4190\n",
      "Epoch: 116 Step: 10324 Index:-0.1219 R2:0.6587 0.6086 0.5496 RMSE:0.6859 0.7215 0.8217 Tau:0.6238 0.5995 0.4228\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 117 Step: 10413 Index:-0.1391 R2:0.6614 0.6128 0.5519 RMSE:0.7031 0.7453 0.8295 Tau:0.6233 0.6062 0.4157\n",
      "Epoch: 118 Step: 10502 Index:-0.1167 R2:0.6549 0.6072 0.5511 RMSE:0.6899 0.7226 0.8239 Tau:0.6232 0.6059 0.4258\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 119 Step: 10591 Index:-0.1377 R2:0.6532 0.6069 0.5402 RMSE:0.6941 0.7324 0.8310 Tau:0.6148 0.5947 0.4111\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 120 Step: 10680 Index:-0.1167 R2:0.6644 0.6128 0.5446 RMSE:0.6913 0.7206 0.8348 Tau:0.6246 0.6039 0.4107\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 121 Step: 10769 Index:-0.1201 R2:0.6589 0.6077 0.5407 RMSE:0.6869 0.7226 0.8311 Tau:0.6240 0.6025 0.4162\n",
      "Epoch: 122 Step: 10858 Index:-0.1098 R2:0.6700 0.6154 0.5539 RMSE:0.6772 0.7151 0.8237 Tau:0.6292 0.6053 0.4191\n",
      "Epoch: 123 Step: 10947 Index:-0.1088 R2:0.6674 0.6162 0.5533 RMSE:0.6788 0.7144 0.8214 Tau:0.6271 0.6056 0.4220\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 124 Step: 11036 Index:-0.1212 R2:0.6555 0.6031 0.5472 RMSE:0.6884 0.7262 0.8261 Tau:0.6210 0.6050 0.4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 125 Step: 11125 Index:-0.1206 R2:0.6711 0.6172 0.5477 RMSE:0.6980 0.7245 0.8371 Tau:0.6248 0.6039 0.4057\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 126 Step: 11214 Index:-0.1260 R2:0.6592 0.6041 0.5386 RMSE:0.6986 0.7309 0.8500 Tau:0.6273 0.6050 0.4211\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 127 Step: 11303 Index:-0.1282 R2:0.6649 0.6043 0.5383 RMSE:0.6960 0.7298 0.8469 Tau:0.6273 0.6016 0.4085\n",
      "Epoch: 128 Step: 11392 Index:-0.1055 R2:0.6719 0.6236 0.5513 RMSE:0.6752 0.7106 0.8190 Tau:0.6278 0.6051 0.4200\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 129 Step: 11481 Index:-0.1155 R2:0.6701 0.6160 0.5530 RMSE:0.6783 0.7153 0.8234 Tau:0.6281 0.5998 0.4193\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 130 Step: 11570 Index:-0.1306 R2:0.6732 0.6226 0.5431 RMSE:0.6877 0.7316 0.8320 Tau:0.6256 0.6010 0.4061\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 131 Step: 11659 Index:-0.1323 R2:0.6675 0.6206 0.5465 RMSE:0.6989 0.7419 0.8402 Tau:0.6309 0.6096 0.4257\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 132 Step: 11748 Index:-0.1195 R2:0.6609 0.6069 0.5393 RMSE:0.6862 0.7228 0.8339 Tau:0.6272 0.6033 0.4240\n",
      "Epoch: 133 Step: 11837 Index:-0.0971 R2:0.6694 0.6289 0.5446 RMSE:0.6849 0.7080 0.8278 Tau:0.6260 0.6110 0.4098\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 134 Step: 11926 Index:-0.1047 R2:0.6757 0.6228 0.5467 RMSE:0.6679 0.7104 0.8286 Tau:0.6308 0.6058 0.4176\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 135 Step: 12015 Index:-0.1367 R2:0.6767 0.6234 0.5448 RMSE:0.6898 0.7366 0.8348 Tau:0.6274 0.5998 0.4072\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 136 Step: 12104 Index:-0.1291 R2:0.6792 0.6083 0.5533 RMSE:0.6792 0.7260 0.8282 Tau:0.6328 0.5969 0.4092\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 137 Step: 12193 Index:-0.1157 R2:0.6826 0.6246 0.5481 RMSE:0.6757 0.7221 0.8227 Tau:0.6332 0.6064 0.4065\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 138 Step: 12282 Index:-0.1021 R2:0.6805 0.6264 0.5515 RMSE:0.6655 0.7074 0.8189 Tau:0.6336 0.6054 0.4196\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 139 Step: 12371 Index:-0.1237 R2:0.6802 0.6223 0.5360 RMSE:0.6990 0.7240 0.8662 Tau:0.6302 0.6003 0.4049\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 140 Step: 12460 Index:-0.1063 R2:0.6819 0.6168 0.5430 RMSE:0.6650 0.7137 0.8339 Tau:0.6386 0.6074 0.4217\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 141 Step: 12549 Index:-0.1653 R2:0.6591 0.5944 0.5398 RMSE:0.7059 0.7527 0.8638 Tau:0.6158 0.5873 0.4150\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 142 Step: 12638 Index:-0.1269 R2:0.6763 0.6111 0.5383 RMSE:0.6716 0.7285 0.8328 Tau:0.6348 0.6017 0.4175\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 143 Step: 12727 Index:-0.1158 R2:0.6881 0.6125 0.5404 RMSE:0.6648 0.7190 0.8403 Tau:0.6401 0.6032 0.4071\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 144 Step: 12816 Index:-0.1264 R2:0.6758 0.6069 0.5423 RMSE:0.6693 0.7305 0.8391 Tau:0.6359 0.6042 0.4229\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 145 Step: 12905 Index:-0.2073 R2:0.6812 0.6074 0.5356 RMSE:0.7788 0.8070 0.9547 Tau:0.6400 0.5997 0.4154\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 146 Step: 12994 Index:-0.1024 R2:0.6870 0.6198 0.5506 RMSE:0.6567 0.7145 0.8225 Tau:0.6408 0.6121 0.4198\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 147 Step: 13083 Index:-0.1297 R2:0.6783 0.6052 0.5432 RMSE:0.6825 0.7322 0.8503 Tau:0.6354 0.6025 0.4132\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 148 Step: 13172 Index:-0.1341 R2:0.6773 0.6047 0.5253 RMSE:0.6680 0.7302 0.8445 Tau:0.6360 0.5961 0.4104\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 149 Step: 13261 Index:-0.1224 R2:0.6852 0.6147 0.5442 RMSE:0.6810 0.7259 0.8553 Tau:0.6366 0.6034 0.4185\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 150 Step: 13350 Index:-0.1206 R2:0.6885 0.6160 0.5435 RMSE:0.6649 0.7292 0.8301 Tau:0.6433 0.6086 0.4196\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 151 Step: 13439 Index:-0.1107 R2:0.6867 0.6214 0.5293 RMSE:0.6658 0.7142 0.8402 Tau:0.6339 0.6035 0.3960\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 152 Step: 13528 Index:-0.1488 R2:0.6892 0.6169 0.5417 RMSE:0.6912 0.7566 0.8414 Tau:0.6414 0.6078 0.4161\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 153 Step: 13617 Index:-0.1052 R2:0.6861 0.6275 0.5551 RMSE:0.6615 0.7128 0.8193 Tau:0.6347 0.6077 0.4162\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 154 Step: 13706 Index:-0.1025 R2:0.6911 0.6205 0.5397 RMSE:0.6535 0.7137 0.8319 Tau:0.6453 0.6112 0.4172\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 155 Step: 13795 Index:-0.1209 R2:0.6986 0.6175 0.5470 RMSE:0.6802 0.7308 0.8605 Tau:0.6482 0.6099 0.4129\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 156 Step: 13884 Index:-0.1175 R2:0.6851 0.6107 0.5512 RMSE:0.6598 0.7226 0.8306 Tau:0.6386 0.6050 0.4215\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 157 Step: 13973 Index:-0.1123 R2:0.6976 0.6226 0.5476 RMSE:0.6633 0.7178 0.8497 Tau:0.6437 0.6055 0.4151\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 158 Step: 14062 Index:-0.0998 R2:0.6956 0.6202 0.5378 RMSE:0.6470 0.7140 0.8402 Tau:0.6487 0.6142 0.4157\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 159 Step: 14151 Index:-0.1310 R2:0.6987 0.6115 0.5361 RMSE:0.6558 0.7354 0.8351 Tau:0.6482 0.6044 0.4082\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 160 Step: 14240 Index:-0.1168 R2:0.6920 0.6105 0.5411 RMSE:0.6588 0.7226 0.8464 Tau:0.6471 0.6058 0.4224\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 161 Step: 14329 Index:-0.1088 R2:0.6939 0.6174 0.5494 RMSE:0.6491 0.7140 0.8266 Tau:0.6416 0.6052 0.4164\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 162 Step: 14418 Index:-0.1357 R2:0.6943 0.6099 0.5533 RMSE:0.6638 0.7386 0.8247 Tau:0.6459 0.6030 0.4235\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 163 Step: 14507 Index:-0.1324 R2:0.7019 0.6138 0.5489 RMSE:0.6574 0.7380 0.8276 Tau:0.6490 0.6056 0.4136\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 164 Step: 14596 Index:-0.1297 R2:0.7047 0.6105 0.5472 RMSE:0.6521 0.7300 0.8230 Tau:0.6491 0.6002 0.4026\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 165 Step: 14685 Index:-0.1105 R2:0.6923 0.6151 0.5389 RMSE:0.6536 0.7150 0.8366 Tau:0.6450 0.6046 0.4179\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 166 Step: 14774 Index:-0.0971 R2:0.6951 0.6267 0.5392 RMSE:0.6567 0.7054 0.8442 Tau:0.6405 0.6082 0.4010\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 167 Step: 14863 Index:-0.1199 R2:0.7061 0.6235 0.5483 RMSE:0.6581 0.7317 0.8293 Tau:0.6502 0.6118 0.4132\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 168 Step: 14952 Index:-0.1391 R2:0.6980 0.6170 0.5331 RMSE:0.6650 0.7433 0.8460 Tau:0.6443 0.6042 0.4022\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 169 Step: 15041 Index:-0.1393 R2:0.6996 0.6101 0.5497 RMSE:0.6777 0.7438 0.8643 Tau:0.6474 0.6046 0.4162\n",
      "Epoch: 170 Step: 15130 Index:-0.0948 R2:0.7084 0.6288 0.5546 RMSE:0.6409 0.7074 0.8158 Tau:0.6520 0.6126 0.4089\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 171 Step: 15219 Index:-0.1689 R2:0.7033 0.6199 0.5452 RMSE:0.7182 0.7713 0.9149 Tau:0.6470 0.6024 0.4048\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 172 Step: 15308 Index:-0.0971 R2:0.7069 0.6220 0.5427 RMSE:0.6392 0.7086 0.8364 Tau:0.6549 0.6115 0.4141\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 173 Step: 15397 Index:-0.1418 R2:0.7116 0.6217 0.5420 RMSE:0.6823 0.7395 0.8829 Tau:0.6484 0.5977 0.4003\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 174 Step: 15486 Index:-0.0993 R2:0.7089 0.6192 0.5466 RMSE:0.6386 0.7116 0.8278 Tau:0.6575 0.6123 0.4173\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 175 Step: 15575 Index:-0.1081 R2:0.7102 0.6182 0.5564 RMSE:0.6357 0.7125 0.8230 Tau:0.6545 0.6044 0.4164\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 176 Step: 15664 Index:-0.1036 R2:0.7082 0.6177 0.5367 RMSE:0.6473 0.7154 0.8461 Tau:0.6563 0.6118 0.4165\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 177 Step: 15753 Index:-0.1019 R2:0.7100 0.6237 0.5448 RMSE:0.6342 0.7122 0.8285 Tau:0.6548 0.6103 0.4158\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 178 Step: 15842 Index:-0.1398 R2:0.7143 0.6152 0.5398 RMSE:0.6564 0.7463 0.8366 Tau:0.6603 0.6065 0.4105\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 179 Step: 15931 Index:-0.1144 R2:0.7151 0.6176 0.5393 RMSE:0.6519 0.7221 0.8532 Tau:0.6582 0.6078 0.4107\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 180 Step: 16020 Index:-0.1018 R2:0.7122 0.6210 0.5431 RMSE:0.6317 0.7106 0.8382 Tau:0.6568 0.6088 0.4116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 181 Step: 16109 Index:-0.1364 R2:0.7103 0.6105 0.5338 RMSE:0.6645 0.7349 0.8779 Tau:0.6555 0.5985 0.4115\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 182 Step: 16198 Index:-0.1099 R2:0.7088 0.6193 0.5555 RMSE:0.6369 0.7194 0.8208 Tau:0.6558 0.6094 0.4211\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 183 Step: 16287 Index:-0.1524 R2:0.7089 0.6146 0.5373 RMSE:0.6581 0.7539 0.8491 Tau:0.6525 0.6015 0.4053\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 184 Step: 16376 Index:-0.1217 R2:0.7114 0.6102 0.5399 RMSE:0.6393 0.7205 0.8358 Tau:0.6540 0.5988 0.4015\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 185 Step: 16465 Index:-0.1190 R2:0.7000 0.6127 0.5376 RMSE:0.6432 0.7234 0.8390 Tau:0.6520 0.6044 0.4254\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 186 Step: 16554 Index:-0.1143 R2:0.7162 0.6137 0.5488 RMSE:0.6380 0.7199 0.8382 Tau:0.6587 0.6055 0.4094\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 187 Step: 16643 Index:-0.1068 R2:0.7175 0.6249 0.5435 RMSE:0.6255 0.7135 0.8328 Tau:0.6600 0.6067 0.4141\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 188 Step: 16732 Index:-0.1340 R2:0.7182 0.6269 0.5498 RMSE:0.6919 0.7445 0.8931 Tau:0.6614 0.6104 0.4191\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 189 Step: 16821 Index:-0.1231 R2:0.7137 0.6050 0.5324 RMSE:0.6313 0.7244 0.8444 Tau:0.6595 0.6014 0.4067\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 190 Step: 16910 Index:-0.1097 R2:0.7185 0.6120 0.5465 RMSE:0.6237 0.7189 0.8278 Tau:0.6626 0.6091 0.4099\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 191 Step: 16999 Index:-0.1167 R2:0.7211 0.6156 0.5408 RMSE:0.6435 0.7216 0.8385 Tau:0.6585 0.6050 0.4052\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 192 Step: 17088 Index:-0.1064 R2:0.7175 0.6191 0.5572 RMSE:0.6306 0.7124 0.8220 Tau:0.6557 0.6060 0.4116\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 193 Step: 17177 Index:-0.1015 R2:0.7228 0.6228 0.5439 RMSE:0.6232 0.7082 0.8366 Tau:0.6633 0.6067 0.4142\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 194 Step: 17266 Index:-0.1026 R2:0.7210 0.6214 0.5479 RMSE:0.6236 0.7132 0.8247 Tau:0.6632 0.6106 0.4153\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 195 Step: 17355 Index:-0.1149 R2:0.7173 0.6164 0.5494 RMSE:0.6377 0.7205 0.8431 Tau:0.6594 0.6055 0.4135\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 196 Step: 17444 Index:-0.1093 R2:0.7239 0.6150 0.5373 RMSE:0.6235 0.7152 0.8415 Tau:0.6652 0.6059 0.4095\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 197 Step: 17533 Index:-0.1343 R2:0.7212 0.6082 0.5273 RMSE:0.6549 0.7321 0.8599 Tau:0.6590 0.5978 0.3991\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 198 Step: 17622 Index:-0.1144 R2:0.7202 0.6152 0.5369 RMSE:0.6252 0.7150 0.8426 Tau:0.6645 0.6005 0.4122\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 199 Step: 17711 Index:-0.1283 R2:0.7169 0.6083 0.5286 RMSE:0.6276 0.7300 0.8450 Tau:0.6635 0.6018 0.4141\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 200 Step: 17800 Index:-0.1363 R2:0.7225 0.6125 0.5431 RMSE:0.6460 0.7460 0.8341 Tau:0.6680 0.6097 0.4126\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 201 Step: 17889 Index:-0.1158 R2:0.7177 0.6125 0.5304 RMSE:0.6239 0.7194 0.8477 Tau:0.6628 0.6037 0.4072\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 202 Step: 17978 Index:-0.1033 R2:0.7230 0.6214 0.5425 RMSE:0.6182 0.7122 0.8320 Tau:0.6677 0.6089 0.4232\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 203 Step: 18067 Index:-0.1500 R2:0.7211 0.6181 0.5478 RMSE:0.6600 0.7561 0.8403 Tau:0.6611 0.6061 0.4147\n",
      "Epoch: 204 Step: 18156 Index:-0.0878 R2:0.7276 0.6304 0.5473 RMSE:0.6193 0.7026 0.8389 Tau:0.6671 0.6148 0.4153\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 205 Step: 18245 Index:-0.0971 R2:0.7269 0.6225 0.5555 RMSE:0.6149 0.7083 0.8223 Tau:0.6672 0.6112 0.4212\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 206 Step: 18334 Index:-0.1113 R2:0.7286 0.6181 0.5370 RMSE:0.6311 0.7181 0.8589 Tau:0.6702 0.6068 0.4093\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 207 Step: 18423 Index:-0.1115 R2:0.7348 0.6221 0.5318 RMSE:0.6336 0.7172 0.8638 Tau:0.6706 0.6058 0.4017\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 208 Step: 18512 Index:-0.1302 R2:0.7302 0.6131 0.5487 RMSE:0.6342 0.7346 0.8648 Tau:0.6682 0.6044 0.4106\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 209 Step: 18601 Index:-0.1035 R2:0.7352 0.6226 0.5363 RMSE:0.6150 0.7123 0.8557 Tau:0.6748 0.6089 0.4178\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 210 Step: 18690 Index:-0.1348 R2:0.7230 0.6135 0.5517 RMSE:0.6363 0.7393 0.8273 Tau:0.6653 0.6045 0.4235\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 211 Step: 18779 Index:-0.2370 R2:0.6489 0.5686 0.5322 RMSE:0.7813 0.8260 0.8852 Tau:0.6283 0.5890 0.4222\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 212 Step: 18868 Index:-0.0901 R2:0.7270 0.6296 0.5395 RMSE:0.6145 0.7017 0.8384 Tau:0.6645 0.6116 0.4087\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 213 Step: 18957 Index:-0.1191 R2:0.7271 0.6194 0.5509 RMSE:0.6389 0.7246 0.8509 Tau:0.6645 0.6055 0.4203\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 214 Step: 19046 Index:-0.1266 R2:0.7329 0.6180 0.5322 RMSE:0.6274 0.7354 0.8413 Tau:0.6721 0.6088 0.4077\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 215 Step: 19135 Index:-0.1153 R2:0.7343 0.6104 0.5466 RMSE:0.6117 0.7213 0.8391 Tau:0.6743 0.6060 0.4190\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 216 Step: 19224 Index:-0.0953 R2:0.7396 0.6208 0.5449 RMSE:0.6020 0.7108 0.8283 Tau:0.6765 0.6155 0.4150\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 217 Step: 19313 Index:-0.1060 R2:0.7327 0.6222 0.5499 RMSE:0.6153 0.7173 0.8252 Tau:0.6717 0.6113 0.4250\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 218 Step: 19402 Index:-0.1190 R2:0.7345 0.6179 0.5531 RMSE:0.6157 0.7218 0.8171 Tau:0.6680 0.6028 0.4073\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 219 Step: 19491 Index:-0.1237 R2:0.7349 0.6174 0.5511 RMSE:0.6160 0.7302 0.8560 Tau:0.6722 0.6066 0.4256\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 220 Step: 19580 Index:-0.1369 R2:0.7327 0.6005 0.5427 RMSE:0.6359 0.7412 0.8631 Tau:0.6749 0.6043 0.4200\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 221 Step: 19669 Index:-0.1141 R2:0.7451 0.6195 0.5426 RMSE:0.6279 0.7240 0.8608 Tau:0.6807 0.6099 0.4152\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 222 Step: 19758 Index:-0.1150 R2:0.7355 0.6226 0.5454 RMSE:0.6122 0.7250 0.8352 Tau:0.6769 0.6100 0.4238\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 223 Step: 19847 Index:-0.1005 R2:0.7415 0.6234 0.5497 RMSE:0.5976 0.7116 0.8267 Tau:0.6772 0.6111 0.4154\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 224 Step: 19936 Index:-0.1329 R2:0.7295 0.6090 0.5263 RMSE:0.6182 0.7293 0.8702 Tau:0.6660 0.5964 0.4010\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 225 Step: 20025 Index:-0.1336 R2:0.7437 0.6298 0.5493 RMSE:0.6436 0.7494 0.8411 Tau:0.6800 0.6158 0.4195\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 226 Step: 20114 Index:-0.0983 R2:0.7456 0.6265 0.5378 RMSE:0.5944 0.7099 0.8377 Tau:0.6822 0.6116 0.4183\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 227 Step: 20203 Index:-0.0982 R2:0.7464 0.6229 0.5449 RMSE:0.5981 0.7093 0.8270 Tau:0.6832 0.6111 0.4176\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 228 Step: 20292 Index:-0.1066 R2:0.7302 0.6164 0.5313 RMSE:0.6104 0.7156 0.8449 Tau:0.6703 0.6090 0.4129\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 229 Step: 20381 Index:-0.1437 R2:0.7442 0.6090 0.5503 RMSE:0.6359 0.7498 0.8789 Tau:0.6824 0.6061 0.4170\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 230 Step: 20470 Index:-0.1199 R2:0.7391 0.6109 0.5359 RMSE:0.6108 0.7225 0.8558 Tau:0.6789 0.6026 0.4237\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 231 Step: 20559 Index:-0.1283 R2:0.7255 0.6049 0.5498 RMSE:0.6171 0.7280 0.8232 Tau:0.6678 0.5997 0.4239\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 232 Step: 20648 Index:-0.1232 R2:0.7329 0.6009 0.5319 RMSE:0.6139 0.7283 0.8456 Tau:0.6802 0.6050 0.4190\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 233 Step: 20737 Index:-0.1570 R2:0.7323 0.6094 0.5308 RMSE:0.6373 0.7588 0.8549 Tau:0.6762 0.6018 0.4193\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 234 Step: 20826 Index:-0.1298 R2:0.7405 0.6034 0.5551 RMSE:0.6062 0.7264 0.8244 Tau:0.6776 0.5966 0.4227\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 235 Step: 20915 Index:-0.1234 R2:0.7401 0.6146 0.5264 RMSE:0.6012 0.7259 0.8489 Tau:0.6786 0.6025 0.4103\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 236 Step: 21004 Index:-0.1189 R2:0.7479 0.6166 0.5420 RMSE:0.5943 0.7238 0.8330 Tau:0.6841 0.6049 0.4172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 237 Step: 21093 Index:-0.1025 R2:0.7462 0.6189 0.5568 RMSE:0.5932 0.7125 0.8253 Tau:0.6824 0.6100 0.4213\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 238 Step: 21182 Index:-0.1179 R2:0.7444 0.6172 0.5366 RMSE:0.6018 0.7287 0.8398 Tau:0.6851 0.6108 0.4195\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 239 Step: 21271 Index:-0.1210 R2:0.7477 0.6100 0.5530 RMSE:0.5899 0.7212 0.8245 Tau:0.6821 0.6002 0.4206\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 240 Step: 21360 Index:-0.0982 R2:0.7547 0.6253 0.5552 RMSE:0.5903 0.7073 0.8305 Tau:0.6871 0.6091 0.4222\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 241 Step: 21449 Index:-0.1117 R2:0.7483 0.6143 0.5376 RMSE:0.5933 0.7161 0.8376 Tau:0.6845 0.6043 0.4149\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 242 Step: 21538 Index:-0.1096 R2:0.7523 0.6252 0.5340 RMSE:0.6198 0.7231 0.8827 Tau:0.6894 0.6134 0.4202\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 243 Step: 21627 Index:-0.1056 R2:0.7517 0.6220 0.5547 RMSE:0.5881 0.7154 0.8218 Tau:0.6839 0.6098 0.4191\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 244 Step: 21716 Index:-0.1253 R2:0.7323 0.6062 0.5258 RMSE:0.6072 0.7304 0.8615 Tau:0.6780 0.6051 0.4144\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 245 Step: 21805 Index:-0.1089 R2:0.7537 0.6175 0.5543 RMSE:0.5835 0.7141 0.8244 Tau:0.6847 0.6053 0.4160\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 246 Step: 21894 Index:-0.1199 R2:0.7475 0.6098 0.5547 RMSE:0.6020 0.7231 0.8324 Tau:0.6853 0.6032 0.4239\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 247 Step: 21983 Index:-0.1095 R2:0.7516 0.6164 0.5376 RMSE:0.5910 0.7139 0.8397 Tau:0.6842 0.6044 0.4077\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 248 Step: 22072 Index:-0.1568 R2:0.7488 0.6059 0.5392 RMSE:0.6426 0.7589 0.9024 Tau:0.6886 0.6021 0.4142\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 249 Step: 22161 Index:-0.1082 R2:0.7490 0.6214 0.5439 RMSE:0.5896 0.7138 0.8321 Tau:0.6787 0.6056 0.4076\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 250 Step: 22250 Index:-0.1099 R2:0.7474 0.6163 0.5436 RMSE:0.5898 0.7159 0.8371 Tau:0.6793 0.6060 0.4093\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 251 Step: 22339 Index:-0.1193 R2:0.7558 0.6102 0.5492 RMSE:0.5840 0.7204 0.8247 Tau:0.6885 0.6011 0.4170\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 252 Step: 22428 Index:-0.1232 R2:0.7543 0.6233 0.5425 RMSE:0.6176 0.7298 0.8795 Tau:0.6885 0.6066 0.4176\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 253 Step: 22517 Index:-0.1112 R2:0.7531 0.6190 0.5340 RMSE:0.5848 0.7154 0.8424 Tau:0.6820 0.6042 0.3995\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 254 Step: 22606 Index:-0.1229 R2:0.7503 0.6130 0.5340 RMSE:0.6173 0.7293 0.8729 Tau:0.6884 0.6064 0.4182\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 255 Step: 22695 Index:-0.1246 R2:0.7530 0.6097 0.5409 RMSE:0.5835 0.7294 0.8434 Tau:0.6897 0.6048 0.4235\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 256 Step: 22784 Index:-0.1106 R2:0.7582 0.6201 0.5369 RMSE:0.5966 0.7212 0.8709 Tau:0.6904 0.6106 0.4157\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 258 Step: 22962 Index:-0.1295 R2:0.7510 0.6032 0.5141 RMSE:0.5970 0.7261 0.8646 Tau:0.6855 0.5965 0.4015\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 259 Step: 23051 Index:-0.0932 R2:0.7615 0.6243 0.5414 RMSE:0.5753 0.7078 0.8360 Tau:0.6933 0.6146 0.4146\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 260 Step: 23140 Index:-0.1341 R2:0.7663 0.6188 0.5426 RMSE:0.6254 0.7425 0.8898 Tau:0.6966 0.6084 0.4160\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 261 Step: 23229 Index:-0.1334 R2:0.7588 0.6027 0.5470 RMSE:0.5926 0.7306 0.8470 Tau:0.6920 0.5972 0.4175\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 262 Step: 23318 Index:-0.1541 R2:0.7669 0.6202 0.5404 RMSE:0.6181 0.7613 0.8513 Tau:0.6984 0.6072 0.4211\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 263 Step: 23407 Index:-0.1820 R2:0.7484 0.5887 0.5177 RMSE:0.6406 0.7688 0.9193 Tau:0.6863 0.5868 0.4168\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 264 Step: 23496 Index:-0.1339 R2:0.7606 0.6174 0.5531 RMSE:0.5966 0.7402 0.8317 Tau:0.6947 0.6062 0.4235\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 265 Step: 23585 Index:-0.1292 R2:0.7643 0.6087 0.5270 RMSE:0.6023 0.7307 0.8720 Tau:0.6974 0.6016 0.4130\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 266 Step: 23674 Index:-0.1101 R2:0.7394 0.6244 0.5504 RMSE:0.6027 0.7167 0.8375 Tau:0.6704 0.6066 0.4076\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 267 Step: 23763 Index:-0.1068 R2:0.7698 0.6240 0.5457 RMSE:0.5732 0.7170 0.8293 Tau:0.7001 0.6102 0.4186\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 268 Step: 23852 Index:-0.1330 R2:0.7586 0.6207 0.5363 RMSE:0.5967 0.7418 0.8529 Tau:0.6911 0.6088 0.4189\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 269 Step: 23941 Index:-0.1222 R2:0.7564 0.6066 0.5248 RMSE:0.5961 0.7237 0.8568 Tau:0.6896 0.6015 0.4003\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 270 Step: 24030 Index:-0.1165 R2:0.7639 0.6120 0.5285 RMSE:0.5721 0.7209 0.8585 Tau:0.6941 0.6044 0.4101\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 271 Step: 24119 Index:-0.1184 R2:0.7569 0.6138 0.5425 RMSE:0.5835 0.7210 0.8481 Tau:0.6918 0.6026 0.4203\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 272 Step: 24208 Index:-0.1279 R2:0.7555 0.6127 0.5433 RMSE:0.5870 0.7324 0.8409 Tau:0.6920 0.6045 0.4236\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 273 Step: 24297 Index:-0.1160 R2:0.7600 0.6221 0.5513 RMSE:0.5803 0.7240 0.8383 Tau:0.6926 0.6080 0.4261\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 274 Step: 24386 Index:-0.1414 R2:0.7718 0.6208 0.5419 RMSE:0.6221 0.7483 0.9045 Tau:0.7006 0.6070 0.4192\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 275 Step: 24475 Index:-0.1071 R2:0.7660 0.6218 0.5427 RMSE:0.5739 0.7173 0.8345 Tau:0.7006 0.6102 0.4223\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 276 Step: 24564 Index:-0.1061 R2:0.7721 0.6215 0.5519 RMSE:0.5672 0.7161 0.8458 Tau:0.7021 0.6100 0.4252\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 277 Step: 24653 Index:-0.1175 R2:0.7699 0.6111 0.5312 RMSE:0.5712 0.7194 0.8447 Tau:0.6998 0.6019 0.4174\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 278 Step: 24742 Index:-0.1074 R2:0.7673 0.6220 0.5581 RMSE:0.5668 0.7142 0.8237 Tau:0.6969 0.6068 0.4216\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 279 Step: 24831 Index:-0.1301 R2:0.7653 0.6141 0.5411 RMSE:0.5767 0.7283 0.8362 Tau:0.6959 0.5981 0.4124\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 280 Step: 24920 Index:-0.1114 R2:0.7742 0.6176 0.5405 RMSE:0.5674 0.7132 0.8436 Tau:0.7002 0.6018 0.4065\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 281 Step: 25009 Index:-0.1529 R2:0.7543 0.6060 0.5386 RMSE:0.6156 0.7480 0.8830 Tau:0.6879 0.5950 0.4262\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 282 Step: 25098 Index:-0.1099 R2:0.7685 0.6150 0.5384 RMSE:0.5719 0.7152 0.8402 Tau:0.7000 0.6054 0.4213\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 283 Step: 25187 Index:-0.1431 R2:0.7309 0.6006 0.5389 RMSE:0.6121 0.7386 0.8561 Tau:0.6721 0.5955 0.4100\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 284 Step: 25276 Index:-0.1425 R2:0.7644 0.6061 0.5363 RMSE:0.5867 0.7426 0.8406 Tau:0.6960 0.6001 0.4107\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 285 Step: 25365 Index:-0.1176 R2:0.7746 0.6142 0.5419 RMSE:0.5607 0.7212 0.8499 Tau:0.7063 0.6036 0.4196\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 286 Step: 25454 Index:-0.1100 R2:0.7725 0.6204 0.5513 RMSE:0.5709 0.7146 0.8404 Tau:0.6999 0.6046 0.4141\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 287 Step: 25543 Index:-0.1336 R2:0.7729 0.6121 0.5394 RMSE:0.6015 0.7372 0.8791 Tau:0.7029 0.6036 0.4219\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 288 Step: 25632 Index:-0.1151 R2:0.7759 0.6102 0.5406 RMSE:0.5578 0.7211 0.8415 Tau:0.7065 0.6060 0.4240\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 289 Step: 25721 Index:-0.1135 R2:0.7746 0.6181 0.5508 RMSE:0.5599 0.7170 0.8265 Tau:0.7037 0.6035 0.4273\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 290 Step: 25810 Index:-0.1321 R2:0.7682 0.6027 0.5261 RMSE:0.5734 0.7284 0.8603 Tau:0.7005 0.5963 0.4200\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 291 Step: 25899 Index:-0.1117 R2:0.7789 0.6189 0.5505 RMSE:0.5603 0.7177 0.8239 Tau:0.7063 0.6060 0.4225\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 292 Step: 25988 Index:-0.1278 R2:0.7752 0.6092 0.5417 RMSE:0.5617 0.7298 0.8590 Tau:0.7031 0.6020 0.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 293 Step: 26077 Index:-0.1475 R2:0.7738 0.6152 0.5450 RMSE:0.5778 0.7515 0.8515 Tau:0.7016 0.6041 0.4224\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 294 Step: 26166 Index:-0.1249 R2:0.7760 0.6106 0.5319 RMSE:0.5883 0.7312 0.8715 Tau:0.7034 0.6063 0.4177\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 295 Step: 26255 Index:-0.1088 R2:0.7754 0.6191 0.5444 RMSE:0.5615 0.7132 0.8415 Tau:0.6995 0.6044 0.4146\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 296 Step: 26344 Index:-0.1387 R2:0.7763 0.6093 0.5387 RMSE:0.5764 0.7395 0.8796 Tau:0.7062 0.6008 0.4198\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 297 Step: 26433 Index:-0.1462 R2:0.7709 0.6084 0.5262 RMSE:0.6088 0.7470 0.8988 Tau:0.7002 0.6008 0.4107\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 298 Step: 26522 Index:-0.1134 R2:0.7795 0.6166 0.5511 RMSE:0.5645 0.7173 0.8413 Tau:0.7061 0.6039 0.4210\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 299 Step: 26611 Index:-0.1329 R2:0.7730 0.6092 0.5455 RMSE:0.5878 0.7359 0.8684 Tau:0.7045 0.6030 0.4308\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 300 Step: 26700 Index:-0.1158 R2:0.7771 0.6132 0.5554 RMSE:0.5688 0.7221 0.8369 Tau:0.7060 0.6062 0.4310\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 301 Step: 26789 Index:-0.1550 R2:0.7760 0.6086 0.5426 RMSE:0.6131 0.7580 0.9012 Tau:0.7082 0.6030 0.4268\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 302 Step: 26878 Index:-0.1001 R2:0.7814 0.6250 0.5506 RMSE:0.5511 0.7082 0.8337 Tau:0.7111 0.6081 0.4287\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 303 Step: 26967 Index:-0.1419 R2:0.7731 0.6193 0.5597 RMSE:0.5891 0.7456 0.8704 Tau:0.7001 0.6038 0.4358\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 304 Step: 27056 Index:-0.1422 R2:0.7759 0.6103 0.5390 RMSE:0.5950 0.7460 0.8895 Tau:0.7058 0.6038 0.4219\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau \n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 304 r2:0.5473 RMSE:0.8389 WTI:0.3351 AP:0.6242 Tau:0.4153 \n",
      " \n",
      " Top-1:0.5714 Top-1-fp:0.0000 \n",
      " Top-5:0.3947 Top-5-fp:0.1579 \n",
      " Top-10:0.5584 Top-10-fp:0.1818 \n",
      " Top-15:0.6609 Top-15-fp:0.1739 \n",
      " Top-20:0.6948 Top-20-fp:0.2208 \n",
      " Top-25:0.6839 Top-25-fp:0.2642 \n",
      " Top-30:0.6883 Top-30-fp:0.2900 \n",
      " Top-40:0.6857 Top-40-fp:0.3786 \n",
      " Top-50:0.7464 Top-50-fp:0.4585 \n",
      " \n",
      " Top50:0.5000 Top50-fp:0.1400 \n",
      " Top100:0.6500 Top100-fp:0.1700 \n",
      " Top150:0.6933 Top150-fp:0.2067 \n",
      " Top200:0.6850 Top200-fp:0.2800 \n",
      " Top250:0.6800 Top250-fp:0.3160 \n",
      " Top300:0.6821 Top300-fp:0.3633 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
