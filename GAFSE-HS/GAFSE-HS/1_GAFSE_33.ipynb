{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC50_P21554_1_200\n",
      "model_file/1_GAFSE_EC50_P21554_1_200_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/EC50_P21554_1_200_train.csv\"\n",
    "test_filename = \"./data/benchmark/EC50_P21554_1_200_test.csv\"\n",
    "test_active = 200\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0       CCCCCCC(C)(C)C1=CC(=C(C=C1)C2CC(CCC2CCCO)O)O -0.690196\n",
      "1  C1=CC(=CC=C1C(C2=CC=C(C=C2)Cl)C3=CC4=C(C=C3)NC... -2.225309\n",
      "2  C1CC1N2C3=C(C=C(C=C3)C(C4=CC=C(C=C4)Cl)C5=CC=C... -1.462398\n",
      "3  CC(C1=CC=CC=N1)NC(=O)C2=NN(C3=C2CCCC3=CC4=CC=C... -1.255273\n",
      "4  C1CN(CCC1C2=NC(=NO2)C3=C(C=C(C=C3)F)Cl)C4=CN=C... -3.155336\n",
      "number of all smiles:  1226\n",
      "number of successfully processed smiles:  1226\n",
      "                                              smiles     value  \\\n",
      "0       CCCCCCC(C)(C)C1=CC(=C(C=C1)C2CC(CCC2CCCO)O)O -0.690196   \n",
      "1  C1=CC(=CC=C1C(C2=CC=C(C=C2)Cl)C3=CC4=C(C=C3)NC... -2.225309   \n",
      "2  C1CC1N2C3=C(C=C(C=C3)C(C4=CC=C(C=C4)Cl)C5=CC=C... -1.462398   \n",
      "3  CC(C1=CC=CC=N1)NC(=O)C2=NN(C3=C2CCCC3=CC4=CC=C... -1.255273   \n",
      "4  C1CN(CCC1C2=NC(=NO2)C3=C(C=C(C=C3)F)Cl)C4=CN=C... -3.155336   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0          CCCCCCC(C)(C)c1ccc(C2CC(O)CCC2CCCO)c(O)c1  \n",
      "1  O=c1cc(NCc2ccc(C(F)(F)F)cn2)c2cc(C(c3ccc(Cl)cc...  \n",
      "2  NC(=O)CCC(=O)N1CCC(c2nn(C3CC3)c3ccc(C(c4ccc(Cl...  \n",
      "3  CC(NC(=O)c1nn(-c2ccc(C(F)(F)F)cc2Cl)c2c1CCCC2=...  \n",
      "4  Fc1ccc(-c2noc(C3CCN(c4cnc5ccc(Cl)cc5c4)CC3)n2)...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1930\n",
      "number of successfully processed smiles:  1930\n",
      "(1930, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1CN(CCC1NC2=NC=NC3=C2C=C(C=C3)C(C4=CC=C(C=C4)... -1.204120   \n",
      "1  CC(C)(C1=CC=CC=C1)NC(=O)C2=NN(C3=C2CC4C3C4)C5=... -1.198657   \n",
      "2   CC(C)(C)C(C(=O)NC)NC(=O)C1=CC=CC(=N1)C2=CC=CC=C2 -2.867585   \n",
      "3  C1CC1N2C(=C3C=C(C=CC3=N2)C(C4=CC=C(C=C4)Cl)C5=... -1.230449   \n",
      "4  CC(C(CC1=CC=C(C=C1)Cl)C2=CC=CC(=C2)C#N)NC(=O)C... -0.278754   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  O=S(=O)(CCO)N1CCC(Nc2ncnc3ccc(C(c4ccc(Cl)cc4)c...  \n",
      "1  CC(C)(NC(=O)c1nn(-c2ccc(F)cc2F)c2c1CC1CC21)c1c...  \n",
      "2        CNC(=O)C(NC(=O)c1cccc(-c2ccccc2)n1)C(C)(C)C  \n",
      "3  NC(=O)c1ccc(S(=O)(=O)N2CCC(c3c4cc(C(c5ccc(Cl)c...  \n",
      "4  CC(NC(=O)C(C)(C)Nc1cc2ccccc2cn1)C(Cc1ccc(Cl)cc...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/EC50_P21554_1_200_train.pickle\n",
      "./data/benchmark/EC50_P21554_1_200_train\n",
      "3156\n",
      "feature dicts file saved as ./data/benchmark/EC50_P21554_1_200_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981, 3) (245, 3) (1930, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_EC50_P21554_1_200_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 193 Index:-0.7660 R2:0.0852 0.0676 0.0911 RMSE:0.9396 0.9547 0.9402 Tau:0.2265 0.1886 0.2415\n",
      "Epoch: 2 Step: 386 Index:-0.7039 R2:0.1387 0.1174 0.1386 RMSE:0.9146 0.9383 0.9163 Tau:0.2738 0.2344 0.2860\n",
      "Epoch: 3 Step: 579 Index:-0.6580 R2:0.1835 0.1536 0.1869 RMSE:0.8962 0.9229 0.8984 Tau:0.3078 0.2648 0.2860\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 4 Step: 772 Index:-0.6676 R2:0.1969 0.1558 0.2061 RMSE:0.8938 0.9333 0.8872 Tau:0.3192 0.2656 0.2934\n",
      "Epoch: 5 Step: 965 Index:-0.6434 R2:0.2347 0.1875 0.2499 RMSE:0.8860 0.9294 0.8756 Tau:0.3523 0.2861 0.2989\n",
      "Epoch: 6 Step: 1158 Index:-0.5955 R2:0.2457 0.1890 0.2672 RMSE:0.8537 0.8890 0.8509 Tau:0.3590 0.2935 0.3013\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 7 Step: 1351 Index:-0.6137 R2:0.2640 0.2002 0.2930 RMSE:0.8591 0.9108 0.8440 Tau:0.3715 0.2971 0.2993\n",
      "Epoch: 8 Step: 1544 Index:-0.5727 R2:0.2894 0.2159 0.3105 RMSE:0.8352 0.8768 0.8350 Tau:0.3942 0.3041 0.3000\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 1737 Index:-0.5958 R2:0.2826 0.1926 0.3025 RMSE:0.8308 0.8935 0.8185 Tau:0.3871 0.2977 0.3042\n",
      "Epoch: 10 Step: 1930 Index:-0.5483 R2:0.3162 0.2256 0.3406 RMSE:0.8161 0.8704 0.8134 Tau:0.4080 0.3221 0.2938\n",
      "Epoch: 11 Step: 2123 Index:-0.5426 R2:0.3198 0.2323 0.3462 RMSE:0.8172 0.8663 0.8168 Tau:0.4089 0.3236 0.2871\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 12 Step: 2316 Index:-0.5739 R2:0.3157 0.2074 0.3355 RMSE:0.8098 0.8813 0.8009 Tau:0.4075 0.3073 0.3050\n",
      "Epoch: 13 Step: 2509 Index:-0.5422 R2:0.3330 0.2288 0.3547 RMSE:0.8009 0.8660 0.7961 Tau:0.4169 0.3238 0.2991\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 14 Step: 2702 Index:-0.5652 R2:0.3390 0.2276 0.3629 RMSE:0.8117 0.8901 0.7989 Tau:0.4198 0.3250 0.2867\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 15 Step: 2895 Index:-0.5440 R2:0.3483 0.2280 0.3628 RMSE:0.8049 0.8695 0.8098 Tau:0.4263 0.3256 0.2962\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 16 Step: 3088 Index:-0.5657 R2:0.3470 0.2202 0.3639 RMSE:0.7969 0.8859 0.7837 Tau:0.4246 0.3202 0.3006\n",
      "Epoch: 17 Step: 3281 Index:-0.5299 R2:0.3620 0.2397 0.3819 RMSE:0.7843 0.8663 0.7744 Tau:0.4346 0.3364 0.2936\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 18 Step: 3474 Index:-0.5627 R2:0.3510 0.2234 0.3703 RMSE:0.7940 0.8851 0.7781 Tau:0.4273 0.3225 0.3014\n",
      "Epoch: 19 Step: 3667 Index:-0.5040 R2:0.3605 0.2571 0.3897 RMSE:0.7898 0.8506 0.7826 Tau:0.4349 0.3466 0.2963\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 20 Step: 3860 Index:-0.5528 R2:0.3656 0.2324 0.3826 RMSE:0.7869 0.8810 0.7727 Tau:0.4372 0.3282 0.2922\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 21 Step: 4053 Index:-0.5454 R2:0.3831 0.2350 0.3937 RMSE:0.7822 0.8840 0.7706 Tau:0.4473 0.3386 0.2895\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 22 Step: 4246 Index:-0.5311 R2:0.3784 0.2536 0.3896 RMSE:0.7896 0.8790 0.7751 Tau:0.4478 0.3479 0.2951\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 23 Step: 4439 Index:-0.5343 R2:0.3901 0.2490 0.3951 RMSE:0.7844 0.8835 0.7737 Tau:0.4536 0.3493 0.2903\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 24 Step: 4632 Index:-0.5140 R2:0.3870 0.2571 0.3991 RMSE:0.7655 0.8542 0.7602 Tau:0.4503 0.3402 0.2912\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 25 Step: 4825 Index:-0.5547 R2:0.4060 0.2496 0.4106 RMSE:0.7868 0.8995 0.7722 Tau:0.4618 0.3447 0.2841\n",
      "Epoch: 26 Step: 5018 Index:-0.4830 R2:0.4046 0.2683 0.4057 RMSE:0.7564 0.8433 0.7605 Tau:0.4650 0.3603 0.2929\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 27 Step: 5211 Index:-0.5103 R2:0.4181 0.2409 0.4117 RMSE:0.7488 0.8590 0.7576 Tau:0.4712 0.3488 0.2914\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 28 Step: 5404 Index:-0.5507 R2:0.4190 0.2521 0.4104 RMSE:0.7814 0.9005 0.7715 Tau:0.4720 0.3498 0.2991\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 29 Step: 5597 Index:-0.6414 R2:0.4331 0.2757 0.4218 RMSE:0.8885 1.0062 0.8685 Tau:0.4793 0.3648 0.2860\n",
      "Epoch: 30 Step: 5790 Index:-0.4815 R2:0.4382 0.2873 0.4365 RMSE:0.7508 0.8605 0.7442 Tau:0.4824 0.3790 0.2936\n",
      "Epoch: 31 Step: 5983 Index:-0.4668 R2:0.4435 0.2910 0.4271 RMSE:0.7390 0.8442 0.7442 Tau:0.4884 0.3774 0.2954\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 32 Step: 6176 Index:-0.5089 R2:0.4265 0.2919 0.4134 RMSE:0.7828 0.8849 0.7744 Tau:0.4835 0.3760 0.2992\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 33 Step: 6369 Index:-0.4765 R2:0.4403 0.2791 0.4134 RMSE:0.7346 0.8437 0.7500 Tau:0.4848 0.3672 0.2993\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 34 Step: 6562 Index:-0.4947 R2:0.4564 0.2930 0.4338 RMSE:0.7515 0.8721 0.7521 Tau:0.4961 0.3774 0.2978\n",
      "Epoch: 35 Step: 6755 Index:-0.4617 R2:0.4568 0.2854 0.4393 RMSE:0.7318 0.8360 0.7556 Tau:0.4955 0.3743 0.3021\n",
      "Epoch: 36 Step: 6948 Index:-0.4469 R2:0.4587 0.3031 0.4487 RMSE:0.7212 0.8322 0.7268 Tau:0.4982 0.3853 0.3029\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 37 Step: 7141 Index:-0.4505 R2:0.4755 0.3004 0.4566 RMSE:0.7133 0.8360 0.7224 Tau:0.5058 0.3854 0.2942\n",
      "Epoch: 38 Step: 7334 Index:-0.4332 R2:0.4814 0.3025 0.4599 RMSE:0.7156 0.8231 0.7386 Tau:0.5075 0.3899 0.2784\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 39 Step: 7527 Index:-0.4405 R2:0.4842 0.3242 0.4649 RMSE:0.7205 0.8400 0.7251 Tau:0.5086 0.3996 0.2831\n",
      "Epoch: 40 Step: 7720 Index:-0.4179 R2:0.4857 0.3172 0.4583 RMSE:0.7101 0.8151 0.7374 Tau:0.5152 0.3971 0.3022\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 41 Step: 7913 Index:-0.4654 R2:0.4806 0.3058 0.4512 RMSE:0.7235 0.8520 0.7328 Tau:0.5102 0.3866 0.3051\n",
      "Epoch: 42 Step: 8106 Index:-0.4112 R2:0.4975 0.3276 0.4709 RMSE:0.6949 0.8140 0.7126 Tau:0.5194 0.4028 0.2964\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 8299 Index:-0.4917 R2:0.5040 0.3112 0.4640 RMSE:0.7367 0.8806 0.7449 Tau:0.5235 0.3888 0.2945\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 44 Step: 8492 Index:-0.4211 R2:0.5037 0.3231 0.4751 RMSE:0.6909 0.8205 0.7092 Tau:0.5251 0.3994 0.3004\n",
      "Epoch: 45 Step: 8685 Index:-0.3916 R2:0.5088 0.3386 0.4857 RMSE:0.7050 0.8053 0.7319 Tau:0.5278 0.4137 0.2984\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 46 Step: 8878 Index:-0.4113 R2:0.5141 0.3302 0.4764 RMSE:0.6864 0.8183 0.7086 Tau:0.5296 0.4070 0.3026\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 47 Step: 9071 Index:-0.4502 R2:0.5019 0.3155 0.4818 RMSE:0.7080 0.8460 0.7139 Tau:0.5222 0.3957 0.3019\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 48 Step: 9264 Index:-0.4899 R2:0.5008 0.3172 0.4611 RMSE:0.7441 0.8844 0.7520 Tau:0.5221 0.3945 0.3109\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 49 Step: 9457 Index:-0.4095 R2:0.4913 0.3308 0.4734 RMSE:0.6972 0.8111 0.7117 Tau:0.5156 0.4016 0.2984\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 50 Step: 9650 Index:-0.4996 R2:0.5227 0.3231 0.4764 RMSE:0.7497 0.8984 0.7590 Tau:0.5334 0.3988 0.2973\n",
      "Epoch: 51 Step: 9843 Index:-0.3587 R2:0.5299 0.3604 0.4857 RMSE:0.6746 0.7888 0.7071 Tau:0.5383 0.4302 0.2999\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 52 Step: 10036 Index:-0.4043 R2:0.5383 0.3490 0.4872 RMSE:0.6792 0.8227 0.7069 Tau:0.5429 0.4184 0.2869\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 53 Step: 10229 Index:-0.3937 R2:0.5343 0.3748 0.4924 RMSE:0.7040 0.8325 0.7213 Tau:0.5414 0.4388 0.2998\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 54 Step: 10422 Index:-0.3824 R2:0.5341 0.3545 0.4878 RMSE:0.6694 0.7994 0.7007 Tau:0.5405 0.4171 0.2893\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 55 Step: 10615 Index:-0.3952 R2:0.5342 0.3313 0.4758 RMSE:0.6699 0.8068 0.7160 Tau:0.5432 0.4117 0.3044\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 56 Step: 10808 Index:-0.3944 R2:0.5382 0.3521 0.4827 RMSE:0.6720 0.8120 0.7078 Tau:0.5456 0.4176 0.3025\n",
      "Epoch: 57 Step: 11001 Index:-0.3406 R2:0.5296 0.3903 0.4953 RMSE:0.6724 0.7801 0.6961 Tau:0.5356 0.4394 0.2832\n",
      "Epoch: 58 Step: 11194 Index:-0.3104 R2:0.5432 0.4000 0.5120 RMSE:0.6676 0.7641 0.6920 Tau:0.5472 0.4537 0.2896\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 59 Step: 11387 Index:-0.3391 R2:0.5553 0.3907 0.5016 RMSE:0.6625 0.7883 0.6942 Tau:0.5548 0.4492 0.2984\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 60 Step: 11580 Index:-0.3497 R2:0.5518 0.3740 0.4905 RMSE:0.6580 0.7796 0.7040 Tau:0.5518 0.4299 0.3007\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 61 Step: 11773 Index:-0.5006 R2:0.5624 0.3815 0.4927 RMSE:0.7914 0.9464 0.8192 Tau:0.5569 0.4458 0.2812\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 62 Step: 11966 Index:-0.3854 R2:0.5609 0.3661 0.4879 RMSE:0.6646 0.8142 0.7092 Tau:0.5579 0.4288 0.2999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 63 Step: 12159 Index:-0.3766 R2:0.5551 0.3511 0.4950 RMSE:0.6527 0.7968 0.7005 Tau:0.5541 0.4203 0.3074\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 64 Step: 12352 Index:-0.3886 R2:0.5603 0.3748 0.4890 RMSE:0.6805 0.8288 0.7204 Tau:0.5553 0.4402 0.2898\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 65 Step: 12545 Index:-0.3580 R2:0.5632 0.3628 0.4905 RMSE:0.6498 0.7871 0.7049 Tau:0.5611 0.4291 0.2986\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 66 Step: 12738 Index:-0.3348 R2:0.5749 0.3807 0.4965 RMSE:0.6411 0.7756 0.7003 Tau:0.5656 0.4408 0.2975\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 67 Step: 12931 Index:-0.3665 R2:0.5645 0.3695 0.5021 RMSE:0.6486 0.7914 0.6910 Tau:0.5563 0.4250 0.2887\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 68 Step: 13124 Index:-0.3804 R2:0.5779 0.3577 0.4722 RMSE:0.6462 0.8104 0.7159 Tau:0.5661 0.4300 0.2861\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 69 Step: 13317 Index:-0.3446 R2:0.5723 0.3893 0.5043 RMSE:0.6492 0.7938 0.6990 Tau:0.5659 0.4492 0.3092\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 70 Step: 13510 Index:-0.3882 R2:0.5724 0.3766 0.4767 RMSE:0.6701 0.8239 0.7297 Tau:0.5636 0.4357 0.3044\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 71 Step: 13703 Index:-0.3606 R2:0.5864 0.3652 0.5089 RMSE:0.6315 0.7865 0.6911 Tau:0.5723 0.4258 0.2876\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 72 Step: 13896 Index:-0.3562 R2:0.5945 0.3924 0.5055 RMSE:0.6440 0.8065 0.7030 Tau:0.5764 0.4503 0.2973\n",
      "Epoch: 73 Step: 14089 Index:-0.3101 R2:0.5898 0.4012 0.5118 RMSE:0.6288 0.7634 0.6893 Tau:0.5747 0.4533 0.3008\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 74 Step: 14282 Index:-0.3625 R2:0.5963 0.3981 0.5118 RMSE:0.6463 0.8081 0.7021 Tau:0.5776 0.4456 0.2978\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 75 Step: 14475 Index:-0.3979 R2:0.5844 0.3520 0.4891 RMSE:0.6400 0.8167 0.7091 Tau:0.5720 0.4188 0.3071\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 76 Step: 14668 Index:-0.3746 R2:0.5990 0.3994 0.5124 RMSE:0.6602 0.8223 0.7140 Tau:0.5811 0.4478 0.3018\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 77 Step: 14861 Index:-0.3229 R2:0.6025 0.3913 0.5081 RMSE:0.6302 0.7693 0.7001 Tau:0.5821 0.4464 0.2926\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 78 Step: 15054 Index:-0.3900 R2:0.5970 0.3722 0.4952 RMSE:0.6456 0.8229 0.7159 Tau:0.5810 0.4329 0.3028\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 79 Step: 15247 Index:-0.3176 R2:0.5992 0.3962 0.5045 RMSE:0.6330 0.7657 0.6982 Tau:0.5778 0.4481 0.2760\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 80 Step: 15440 Index:-0.3261 R2:0.6120 0.3979 0.5067 RMSE:0.6133 0.7741 0.6884 Tau:0.5857 0.4480 0.2954\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 81 Step: 15633 Index:-0.3294 R2:0.6089 0.3915 0.5043 RMSE:0.6144 0.7772 0.6912 Tau:0.5858 0.4478 0.2989\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 82 Step: 15826 Index:-0.3889 R2:0.6133 0.3953 0.4938 RMSE:0.6606 0.8358 0.7391 Tau:0.5881 0.4469 0.3018\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 83 Step: 16019 Index:-0.3397 R2:0.6214 0.3857 0.4850 RMSE:0.6089 0.7814 0.7037 Tau:0.5932 0.4417 0.2932\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 84 Step: 16212 Index:-0.3478 R2:0.6168 0.3914 0.5112 RMSE:0.6162 0.7919 0.6909 Tau:0.5883 0.4441 0.2809\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 85 Step: 16405 Index:-0.3525 R2:0.6104 0.3775 0.5109 RMSE:0.6101 0.7849 0.6898 Tau:0.5879 0.4323 0.3020\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 86 Step: 16598 Index:-0.3418 R2:0.6153 0.3884 0.4957 RMSE:0.6066 0.7802 0.7039 Tau:0.5909 0.4384 0.3044\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 87 Step: 16791 Index:-0.3340 R2:0.6011 0.4049 0.5075 RMSE:0.6321 0.7897 0.6977 Tau:0.5799 0.4557 0.2833\n",
      "Epoch: 88 Step: 16984 Index:-0.3055 R2:0.6227 0.4228 0.5233 RMSE:0.6096 0.7701 0.6833 Tau:0.5944 0.4646 0.2996\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 89 Step: 17177 Index:-0.3505 R2:0.6277 0.3739 0.5018 RMSE:0.5981 0.7848 0.6965 Tau:0.5972 0.4343 0.2981\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 90 Step: 17370 Index:-0.3540 R2:0.6134 0.3698 0.5094 RMSE:0.6144 0.7858 0.7006 Tau:0.5872 0.4318 0.3085\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 91 Step: 17563 Index:-0.3751 R2:0.6134 0.3678 0.5064 RMSE:0.6132 0.8049 0.7007 Tau:0.5908 0.4299 0.3056\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 92 Step: 17756 Index:-0.3695 R2:0.6274 0.3752 0.5088 RMSE:0.6059 0.8047 0.6991 Tau:0.5972 0.4352 0.3020\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 93 Step: 17949 Index:-0.3660 R2:0.6322 0.4018 0.5052 RMSE:0.6299 0.8183 0.7248 Tau:0.6020 0.4522 0.2984\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 94 Step: 18142 Index:-0.3131 R2:0.6342 0.4062 0.5064 RMSE:0.5922 0.7669 0.6946 Tau:0.6033 0.4538 0.3025\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 95 Step: 18335 Index:-0.3106 R2:0.6359 0.3985 0.5280 RMSE:0.6037 0.7646 0.6833 Tau:0.6023 0.4541 0.2974\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 96 Step: 18528 Index:-0.3173 R2:0.6431 0.4184 0.5180 RMSE:0.6013 0.7801 0.6931 Tau:0.6072 0.4628 0.2983\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 97 Step: 18721 Index:-0.3314 R2:0.6400 0.3943 0.5061 RMSE:0.5906 0.7758 0.6929 Tau:0.6065 0.4444 0.3014\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 98 Step: 18914 Index:-0.3117 R2:0.6431 0.4035 0.5011 RMSE:0.5873 0.7623 0.7047 Tau:0.6086 0.4506 0.2927\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 99 Step: 19107 Index:-0.3088 R2:0.6354 0.4130 0.5235 RMSE:0.5930 0.7697 0.6845 Tau:0.6054 0.4609 0.3082\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 100 Step: 19300 Index:-0.3682 R2:0.6496 0.3943 0.5136 RMSE:0.6175 0.8177 0.7110 Tau:0.6110 0.4495 0.2988\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 101 Step: 19493 Index:-0.4020 R2:0.6296 0.3739 0.4867 RMSE:0.6327 0.8366 0.7453 Tau:0.5975 0.4346 0.3081\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 102 Step: 19686 Index:-0.3686 R2:0.6469 0.4021 0.5197 RMSE:0.6215 0.8244 0.7244 Tau:0.6107 0.4558 0.3044\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 103 Step: 19879 Index:-0.3331 R2:0.6535 0.4047 0.5222 RMSE:0.5893 0.7871 0.6918 Tau:0.6153 0.4541 0.2968\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 104 Step: 20072 Index:-0.3861 R2:0.6554 0.3945 0.5145 RMSE:0.6214 0.8345 0.7256 Tau:0.6182 0.4484 0.2970\n",
      "Epoch: 105 Step: 20265 Index:-0.2930 R2:0.6583 0.4130 0.5215 RMSE:0.5755 0.7567 0.6856 Tau:0.6181 0.4636 0.2939\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 106 Step: 20458 Index:-0.3088 R2:0.6566 0.4173 0.5338 RMSE:0.5840 0.7754 0.6813 Tau:0.6177 0.4667 0.3019\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 107 Step: 20651 Index:-0.3538 R2:0.6516 0.3887 0.5172 RMSE:0.5933 0.8076 0.7081 Tau:0.6131 0.4538 0.2929\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 108 Step: 20844 Index:-0.3831 R2:0.6363 0.3625 0.4834 RMSE:0.6000 0.8088 0.7152 Tau:0.6021 0.4258 0.2721\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 109 Step: 21037 Index:-0.3116 R2:0.6625 0.4078 0.5326 RMSE:0.5724 0.7707 0.6750 Tau:0.6210 0.4591 0.3041\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 110 Step: 21230 Index:-0.3576 R2:0.6579 0.3819 0.5302 RMSE:0.5839 0.7998 0.6808 Tau:0.6168 0.4423 0.2981\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 111 Step: 21423 Index:-0.3742 R2:0.6617 0.3701 0.5135 RMSE:0.5882 0.8155 0.7022 Tau:0.6204 0.4413 0.2955\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 112 Step: 21616 Index:-0.3824 R2:0.6642 0.4051 0.5231 RMSE:0.6338 0.8438 0.7347 Tau:0.6226 0.4614 0.2974\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 113 Step: 21809 Index:-0.3117 R2:0.6591 0.4018 0.5279 RMSE:0.5802 0.7647 0.6845 Tau:0.6182 0.4530 0.2875\n",
      "Epoch: 114 Step: 22002 Index:-0.2836 R2:0.6683 0.4256 0.5236 RMSE:0.5658 0.7498 0.6807 Tau:0.6245 0.4663 0.2938\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 115 Step: 22195 Index:-0.3336 R2:0.6452 0.3866 0.5231 RMSE:0.5923 0.7764 0.6938 Tau:0.6104 0.4428 0.2833\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 116 Step: 22388 Index:-0.3380 R2:0.6552 0.3845 0.5324 RMSE:0.5743 0.7868 0.6807 Tau:0.6176 0.4488 0.2986\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 117 Step: 22581 Index:-0.3210 R2:0.6583 0.3972 0.5100 RMSE:0.5715 0.7714 0.7009 Tau:0.6225 0.4504 0.3072\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 118 Step: 22774 Index:-0.3300 R2:0.6719 0.4002 0.5197 RMSE:0.5653 0.7834 0.6916 Tau:0.6295 0.4534 0.2993\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 119 Step: 22967 Index:-0.3073 R2:0.6802 0.4064 0.5302 RMSE:0.5544 0.7664 0.6777 Tau:0.6316 0.4591 0.2894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 120 Step: 23160 Index:-0.3275 R2:0.6515 0.4013 0.5174 RMSE:0.5835 0.7820 0.6878 Tau:0.6111 0.4545 0.2817\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 121 Step: 23353 Index:-0.3607 R2:0.6501 0.3690 0.5252 RMSE:0.5797 0.8001 0.6907 Tau:0.6143 0.4394 0.3025\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 122 Step: 23546 Index:-0.3538 R2:0.6852 0.4100 0.5293 RMSE:0.5897 0.8150 0.7106 Tau:0.6365 0.4612 0.2971\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 123 Step: 23739 Index:-0.3312 R2:0.6558 0.3866 0.5121 RMSE:0.5827 0.7779 0.7037 Tau:0.6172 0.4466 0.2987\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 124 Step: 23932 Index:-0.3935 R2:0.6732 0.3864 0.5193 RMSE:0.5976 0.8355 0.7307 Tau:0.6274 0.4420 0.3051\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 125 Step: 24125 Index:-0.2953 R2:0.6885 0.4254 0.5300 RMSE:0.5531 0.7672 0.6855 Tau:0.6374 0.4719 0.2972\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 126 Step: 24318 Index:-0.3605 R2:0.6736 0.3713 0.5098 RMSE:0.5585 0.7929 0.7002 Tau:0.6291 0.4324 0.3092\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 127 Step: 24511 Index:-0.3180 R2:0.6823 0.3998 0.5351 RMSE:0.5517 0.7739 0.6765 Tau:0.6359 0.4559 0.3006\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 128 Step: 24704 Index:-0.3077 R2:0.6884 0.4026 0.5284 RMSE:0.5485 0.7679 0.6883 Tau:0.6381 0.4602 0.2978\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 129 Step: 24897 Index:-0.3730 R2:0.6592 0.3780 0.5098 RMSE:0.5860 0.8143 0.7181 Tau:0.6161 0.4413 0.3090\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 130 Step: 25090 Index:-0.3302 R2:0.6792 0.3985 0.5313 RMSE:0.5587 0.7835 0.6803 Tau:0.6308 0.4532 0.2821\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 131 Step: 25283 Index:-0.3274 R2:0.6877 0.3976 0.5285 RMSE:0.5521 0.7789 0.6778 Tau:0.6366 0.4514 0.2907\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 132 Step: 25476 Index:-0.2851 R2:0.6787 0.4263 0.5275 RMSE:0.5546 0.7533 0.6829 Tau:0.6320 0.4682 0.3039\n",
      "Epoch: 133 Step: 25669 Index:-0.2779 R2:0.6935 0.4270 0.5316 RMSE:0.5414 0.7539 0.6826 Tau:0.6423 0.4760 0.2957\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 134 Step: 25862 Index:-0.3244 R2:0.6840 0.4106 0.5332 RMSE:0.5584 0.7829 0.6825 Tau:0.6354 0.4585 0.2982\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 135 Step: 26055 Index:-0.2902 R2:0.6810 0.4256 0.5259 RMSE:0.5533 0.7611 0.6890 Tau:0.6356 0.4709 0.3074\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 136 Step: 26248 Index:-0.2969 R2:0.7006 0.4217 0.5228 RMSE:0.5410 0.7679 0.6889 Tau:0.6475 0.4709 0.2900\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 137 Step: 26441 Index:-0.3086 R2:0.6939 0.4046 0.5206 RMSE:0.5519 0.7666 0.7028 Tau:0.6410 0.4581 0.2980\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 138 Step: 26634 Index:-0.2910 R2:0.6897 0.4191 0.5349 RMSE:0.5446 0.7586 0.6802 Tau:0.6379 0.4676 0.2982\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 139 Step: 26827 Index:-0.2982 R2:0.7006 0.4108 0.5252 RMSE:0.5574 0.7588 0.6949 Tau:0.6449 0.4607 0.2915\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 140 Step: 27020 Index:-0.3160 R2:0.7000 0.4017 0.5296 RMSE:0.5371 0.7745 0.6975 Tau:0.6489 0.4585 0.3036\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 141 Step: 27213 Index:-0.2920 R2:0.6960 0.4180 0.5465 RMSE:0.5650 0.7586 0.6882 Tau:0.6424 0.4666 0.2898\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 142 Step: 27406 Index:-0.3845 R2:0.6940 0.4004 0.5169 RMSE:0.5975 0.8372 0.7346 Tau:0.6432 0.4527 0.2933\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 143 Step: 27599 Index:-0.3239 R2:0.6757 0.4174 0.5392 RMSE:0.6299 0.7843 0.7361 Tau:0.6266 0.4604 0.2878\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 144 Step: 27792 Index:-0.2857 R2:0.7055 0.4190 0.5404 RMSE:0.5350 0.7548 0.6817 Tau:0.6506 0.4691 0.3033\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 145 Step: 27985 Index:-0.3157 R2:0.6985 0.3950 0.5335 RMSE:0.5425 0.7691 0.6842 Tau:0.6450 0.4534 0.3120\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 146 Step: 28178 Index:-0.2898 R2:0.6975 0.4125 0.5148 RMSE:0.5423 0.7613 0.6885 Tau:0.6420 0.4715 0.2843\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 147 Step: 28371 Index:-0.3040 R2:0.7059 0.4112 0.5427 RMSE:0.5302 0.7681 0.6750 Tau:0.6511 0.4641 0.3035\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 148 Step: 28564 Index:-0.3294 R2:0.7006 0.3922 0.5162 RMSE:0.5397 0.7758 0.7053 Tau:0.6439 0.4464 0.2990\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 149 Step: 28757 Index:-0.2971 R2:0.7050 0.4103 0.5327 RMSE:0.5579 0.7618 0.6989 Tau:0.6497 0.4647 0.2842\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 150 Step: 28950 Index:-0.2812 R2:0.7173 0.4307 0.5418 RMSE:0.5271 0.7610 0.6734 Tau:0.6583 0.4798 0.3024\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 151 Step: 29143 Index:-0.2954 R2:0.7037 0.4142 0.5312 RMSE:0.5513 0.7633 0.7011 Tau:0.6501 0.4679 0.3036\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 152 Step: 29336 Index:-0.3105 R2:0.7076 0.4016 0.5283 RMSE:0.5290 0.7723 0.6858 Tau:0.6518 0.4618 0.2989\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 153 Step: 29529 Index:-0.2865 R2:0.6967 0.4237 0.5235 RMSE:0.5398 0.7640 0.7000 Tau:0.6447 0.4775 0.3131\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 154 Step: 29722 Index:-0.4024 R2:0.7019 0.3876 0.4986 RMSE:0.5890 0.8464 0.7580 Tau:0.6438 0.4440 0.3037\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 155 Step: 29915 Index:-0.3000 R2:0.7202 0.4238 0.5301 RMSE:0.5276 0.7742 0.6931 Tau:0.6619 0.4742 0.3078\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 156 Step: 30108 Index:-0.2908 R2:0.7222 0.4203 0.5256 RMSE:0.5165 0.7626 0.6929 Tau:0.6620 0.4718 0.3029\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 157 Step: 30301 Index:-0.3819 R2:0.6955 0.3875 0.5300 RMSE:0.5846 0.8357 0.7164 Tau:0.6467 0.4539 0.3069\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 158 Step: 30494 Index:-0.3419 R2:0.7278 0.3923 0.5266 RMSE:0.5264 0.7964 0.6929 Tau:0.6643 0.4545 0.3004\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 159 Step: 30687 Index:-0.3450 R2:0.7290 0.4006 0.5355 RMSE:0.5421 0.8030 0.6887 Tau:0.6655 0.4580 0.2935\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 160 Step: 30880 Index:-0.3050 R2:0.7223 0.4200 0.5358 RMSE:0.5268 0.7805 0.7007 Tau:0.6627 0.4755 0.3103\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 161 Step: 31073 Index:-0.2892 R2:0.7339 0.4207 0.5336 RMSE:0.5071 0.7589 0.6881 Tau:0.6699 0.4697 0.2993\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 162 Step: 31266 Index:-0.2932 R2:0.7377 0.4201 0.5455 RMSE:0.5095 0.7658 0.6682 Tau:0.6693 0.4726 0.2936\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 163 Step: 31459 Index:-0.2978 R2:0.7224 0.4203 0.5226 RMSE:0.5223 0.7712 0.6972 Tau:0.6614 0.4734 0.3042\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 164 Step: 31652 Index:-0.3256 R2:0.7389 0.4107 0.5394 RMSE:0.5207 0.7964 0.6937 Tau:0.6726 0.4708 0.3056\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 165 Step: 31845 Index:-0.3167 R2:0.7222 0.3991 0.5284 RMSE:0.5154 0.7780 0.6915 Tau:0.6599 0.4613 0.3007\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 166 Step: 32038 Index:-0.3003 R2:0.7273 0.4127 0.5397 RMSE:0.5113 0.7655 0.6823 Tau:0.6669 0.4652 0.3101\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 167 Step: 32231 Index:-0.3188 R2:0.7184 0.3961 0.5339 RMSE:0.5219 0.7766 0.6931 Tau:0.6591 0.4578 0.3052\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 168 Step: 32424 Index:-0.2988 R2:0.7346 0.4151 0.5297 RMSE:0.5035 0.7682 0.6950 Tau:0.6729 0.4693 0.3096\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 169 Step: 32617 Index:-0.2935 R2:0.7376 0.4233 0.5366 RMSE:0.5079 0.7692 0.6871 Tau:0.6709 0.4757 0.3066\n",
      "Epoch: 170 Step: 32810 Index:-0.2595 R2:0.7345 0.4383 0.5494 RMSE:0.5052 0.7455 0.6733 Tau:0.6703 0.4860 0.3111\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 171 Step: 33003 Index:-0.2990 R2:0.7396 0.4204 0.5534 RMSE:0.5084 0.7751 0.6749 Tau:0.6731 0.4762 0.3057\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 172 Step: 33196 Index:-0.2860 R2:0.7455 0.4165 0.5542 RMSE:0.4983 0.7609 0.6768 Tau:0.6793 0.4750 0.3082\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 173 Step: 33389 Index:-0.2689 R2:0.7296 0.4283 0.5304 RMSE:0.5242 0.7514 0.6997 Tau:0.6693 0.4825 0.3122\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 174 Step: 33582 Index:-0.2789 R2:0.7368 0.4172 0.5385 RMSE:0.5054 0.7578 0.6777 Tau:0.6714 0.4790 0.3017\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 175 Step: 33775 Index:-0.2769 R2:0.7542 0.4224 0.5475 RMSE:0.5020 0.7527 0.6777 Tau:0.6835 0.4758 0.3034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 176 Step: 33968 Index:-0.2735 R2:0.7441 0.4333 0.5489 RMSE:0.4953 0.7538 0.6774 Tau:0.6774 0.4803 0.3035\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 177 Step: 34161 Index:-0.3422 R2:0.7393 0.3936 0.5390 RMSE:0.5157 0.7955 0.6826 Tau:0.6724 0.4533 0.3105\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 178 Step: 34354 Index:-0.3599 R2:0.7493 0.4214 0.5511 RMSE:0.5642 0.8340 0.7267 Tau:0.6815 0.4741 0.3137\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 179 Step: 34547 Index:-0.3491 R2:0.7491 0.4070 0.5326 RMSE:0.5284 0.8112 0.7072 Tau:0.6798 0.4621 0.3082\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 180 Step: 34740 Index:-0.2703 R2:0.7429 0.4426 0.5443 RMSE:0.5017 0.7577 0.6800 Tau:0.6743 0.4874 0.2981\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 181 Step: 34933 Index:-0.2955 R2:0.7454 0.4116 0.5420 RMSE:0.4961 0.7660 0.6757 Tau:0.6767 0.4705 0.3016\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 182 Step: 35126 Index:-0.3043 R2:0.7504 0.4053 0.5391 RMSE:0.4912 0.7696 0.6843 Tau:0.6809 0.4653 0.3027\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 183 Step: 35319 Index:-0.3129 R2:0.7478 0.4024 0.5387 RMSE:0.4937 0.7817 0.6907 Tau:0.6789 0.4689 0.3117\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 184 Step: 35512 Index:-0.3066 R2:0.7422 0.4119 0.5463 RMSE:0.4998 0.7789 0.6971 Tau:0.6755 0.4723 0.3133\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 185 Step: 35705 Index:-0.2712 R2:0.7571 0.4377 0.5630 RMSE:0.4886 0.7569 0.6602 Tau:0.6856 0.4856 0.3094\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 186 Step: 35898 Index:-0.3442 R2:0.7198 0.3935 0.5208 RMSE:0.5222 0.7975 0.7055 Tau:0.6613 0.4532 0.3137\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 187 Step: 36091 Index:-0.3500 R2:0.7435 0.4084 0.5426 RMSE:0.5310 0.8182 0.7163 Tau:0.6784 0.4682 0.3205\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 188 Step: 36284 Index:-0.3079 R2:0.7451 0.4017 0.5472 RMSE:0.4963 0.7734 0.6694 Tau:0.6761 0.4654 0.2989\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 189 Step: 36477 Index:-0.3095 R2:0.7502 0.4105 0.5386 RMSE:0.4886 0.7730 0.6920 Tau:0.6821 0.4636 0.3168\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 190 Step: 36670 Index:-0.2941 R2:0.7399 0.4086 0.5383 RMSE:0.5059 0.7635 0.6775 Tau:0.6731 0.4694 0.3017\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 191 Step: 36863 Index:-0.3530 R2:0.7570 0.4030 0.5530 RMSE:0.5211 0.8207 0.6987 Tau:0.6827 0.4678 0.3047\n",
      "Epoch: 192 Step: 37056 Index:-0.2510 R2:0.7559 0.4535 0.5549 RMSE:0.4835 0.7434 0.6755 Tau:0.6857 0.4923 0.3143\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 193 Step: 37249 Index:-0.2981 R2:0.7629 0.4091 0.5407 RMSE:0.4834 0.7701 0.6732 Tau:0.6903 0.4719 0.3045\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 194 Step: 37442 Index:-0.2926 R2:0.7737 0.4168 0.5459 RMSE:0.4717 0.7637 0.6872 Tau:0.6985 0.4711 0.3122\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 195 Step: 37635 Index:-0.3031 R2:0.7706 0.4225 0.5453 RMSE:0.4858 0.7790 0.6817 Tau:0.6970 0.4759 0.3122\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 196 Step: 37828 Index:-0.2782 R2:0.7757 0.4215 0.5652 RMSE:0.4955 0.7558 0.6706 Tau:0.6981 0.4776 0.2995\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 197 Step: 38021 Index:-0.2822 R2:0.7742 0.4212 0.5445 RMSE:0.4827 0.7583 0.6853 Tau:0.6985 0.4761 0.3040\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 198 Step: 38214 Index:-0.2892 R2:0.7629 0.4190 0.5425 RMSE:0.4770 0.7663 0.6899 Tau:0.6895 0.4771 0.3169\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 199 Step: 38407 Index:-0.3069 R2:0.7700 0.4160 0.5419 RMSE:0.5352 0.7833 0.7358 Tau:0.6935 0.4764 0.3085\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 200 Step: 38600 Index:-0.3064 R2:0.7779 0.4120 0.5452 RMSE:0.4641 0.7740 0.6827 Tau:0.7020 0.4676 0.3121\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 201 Step: 38793 Index:-0.3004 R2:0.7803 0.4286 0.5661 RMSE:0.4798 0.7812 0.6672 Tau:0.7019 0.4808 0.3035\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 202 Step: 38986 Index:-0.2687 R2:0.7689 0.4432 0.5539 RMSE:0.4828 0.7605 0.6764 Tau:0.6954 0.4917 0.3224\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 203 Step: 39179 Index:-0.3744 R2:0.7709 0.4268 0.5531 RMSE:0.5880 0.8569 0.7478 Tau:0.6967 0.4825 0.3087\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 204 Step: 39372 Index:-0.3072 R2:0.7684 0.4228 0.5552 RMSE:0.4884 0.7892 0.6951 Tau:0.6942 0.4820 0.3141\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 205 Step: 39565 Index:-0.2879 R2:0.7790 0.4151 0.5660 RMSE:0.4647 0.7644 0.6583 Tau:0.6999 0.4764 0.2994\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 206 Step: 39758 Index:-0.3400 R2:0.7522 0.4085 0.5471 RMSE:0.6099 0.8145 0.7700 Tau:0.6791 0.4745 0.2823\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 207 Step: 39951 Index:-0.2840 R2:0.7708 0.4236 0.5513 RMSE:0.4682 0.7631 0.6820 Tau:0.6984 0.4791 0.3212\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 208 Step: 40144 Index:-0.2532 R2:0.7852 0.4450 0.5600 RMSE:0.4563 0.7454 0.6760 Tau:0.7077 0.4922 0.3089\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 209 Step: 40337 Index:-0.2840 R2:0.7852 0.4386 0.5581 RMSE:0.4748 0.7730 0.6811 Tau:0.7080 0.4890 0.3157\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 210 Step: 40530 Index:-0.2668 R2:0.7829 0.4362 0.5663 RMSE:0.4661 0.7508 0.6711 Tau:0.7049 0.4839 0.3031\n",
      "Epoch: 211 Step: 40723 Index:-0.2492 R2:0.7939 0.4450 0.5688 RMSE:0.4500 0.7434 0.6574 Tau:0.7121 0.4942 0.3050\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 212 Step: 40916 Index:-0.2644 R2:0.7876 0.4375 0.5521 RMSE:0.4555 0.7545 0.6719 Tau:0.7067 0.4900 0.3024\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 213 Step: 41109 Index:-0.3003 R2:0.7812 0.4329 0.5680 RMSE:0.4875 0.7849 0.6685 Tau:0.7033 0.4847 0.3041\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 214 Step: 41302 Index:-0.2826 R2:0.7795 0.4310 0.5676 RMSE:0.4826 0.7634 0.6849 Tau:0.7018 0.4808 0.3009\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 215 Step: 41495 Index:-0.3271 R2:0.7842 0.4110 0.5540 RMSE:0.4657 0.7940 0.6810 Tau:0.7069 0.4669 0.3024\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 216 Step: 41688 Index:-0.2986 R2:0.7902 0.4089 0.5548 RMSE:0.4528 0.7719 0.6692 Tau:0.7103 0.4732 0.3066\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 217 Step: 41881 Index:-0.2827 R2:0.7969 0.4255 0.5563 RMSE:0.4435 0.7607 0.6757 Tau:0.7147 0.4779 0.3101\n",
      "Epoch: 218 Step: 42074 Index:-0.2457 R2:0.7937 0.4516 0.5661 RMSE:0.4475 0.7427 0.6594 Tau:0.7131 0.4970 0.3100\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 219 Step: 42267 Index:-0.3018 R2:0.7931 0.4096 0.5488 RMSE:0.4535 0.7736 0.6857 Tau:0.7141 0.4718 0.3132\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 220 Step: 42460 Index:-0.2917 R2:0.7976 0.4253 0.5495 RMSE:0.4402 0.7721 0.6909 Tau:0.7165 0.4804 0.3170\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 221 Step: 42653 Index:-0.2861 R2:0.7941 0.4217 0.5743 RMSE:0.4534 0.7675 0.6495 Tau:0.7125 0.4814 0.3042\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 222 Step: 42846 Index:-0.2998 R2:0.8032 0.4379 0.5793 RMSE:0.4624 0.7901 0.6827 Tau:0.7210 0.4904 0.3151\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 223 Step: 43039 Index:-0.2608 R2:0.8026 0.4388 0.5639 RMSE:0.4547 0.7512 0.6807 Tau:0.7207 0.4903 0.3089\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 224 Step: 43232 Index:-0.2882 R2:0.7934 0.4344 0.5745 RMSE:0.4552 0.7732 0.6636 Tau:0.7123 0.4850 0.3077\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 225 Step: 43425 Index:-0.3171 R2:0.8108 0.4345 0.5738 RMSE:0.4700 0.8040 0.6882 Tau:0.7267 0.4870 0.3087\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 226 Step: 43618 Index:-0.2835 R2:0.7942 0.4168 0.5507 RMSE:0.4487 0.7667 0.6796 Tau:0.7151 0.4831 0.3194\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 227 Step: 43811 Index:-0.2809 R2:0.8081 0.4320 0.5578 RMSE:0.4395 0.7682 0.6761 Tau:0.7232 0.4873 0.3057\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 228 Step: 44004 Index:-0.2904 R2:0.8051 0.4195 0.5548 RMSE:0.4339 0.7700 0.6756 Tau:0.7222 0.4796 0.3067\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 229 Step: 44197 Index:-0.2680 R2:0.7994 0.4322 0.5619 RMSE:0.4431 0.7569 0.6668 Tau:0.7165 0.4889 0.3131\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 230 Step: 44390 Index:-0.3214 R2:0.7960 0.4068 0.5537 RMSE:0.4487 0.7938 0.6840 Tau:0.7173 0.4724 0.3183\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 231 Step: 44583 Index:-0.2931 R2:0.8042 0.4195 0.5705 RMSE:0.4922 0.7755 0.6967 Tau:0.7210 0.4824 0.3071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 232 Step: 44776 Index:-0.3716 R2:0.8006 0.4254 0.5549 RMSE:0.5369 0.8548 0.7557 Tau:0.7188 0.4832 0.3141\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 233 Step: 44969 Index:-0.2951 R2:0.8110 0.4228 0.5678 RMSE:0.4284 0.7777 0.6751 Tau:0.7264 0.4827 0.3165\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 234 Step: 45162 Index:-0.2587 R2:0.8194 0.4367 0.5807 RMSE:0.4306 0.7476 0.6482 Tau:0.7324 0.4889 0.3085\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 235 Step: 45355 Index:-0.2546 R2:0.8131 0.4435 0.5752 RMSE:0.4276 0.7480 0.6585 Tau:0.7272 0.4933 0.3155\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 236 Step: 45548 Index:-0.2918 R2:0.8128 0.4214 0.5884 RMSE:0.4261 0.7738 0.6513 Tau:0.7285 0.4820 0.3117\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 237 Step: 45741 Index:-0.3444 R2:0.7995 0.4019 0.5524 RMSE:0.4439 0.8071 0.7015 Tau:0.7193 0.4627 0.3126\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 238 Step: 45934 Index:-0.2642 R2:0.8112 0.4431 0.5798 RMSE:0.4282 0.7574 0.6613 Tau:0.7279 0.4932 0.3120\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 239 Step: 46127 Index:-0.2866 R2:0.8063 0.4338 0.5748 RMSE:0.4353 0.7707 0.6679 Tau:0.7227 0.4841 0.3176\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 240 Step: 46320 Index:-0.2848 R2:0.7996 0.4338 0.5598 RMSE:0.4378 0.7719 0.6915 Tau:0.7180 0.4870 0.3165\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 241 Step: 46513 Index:-0.3025 R2:0.8144 0.4267 0.5655 RMSE:0.4555 0.7800 0.7090 Tau:0.7295 0.4774 0.3165\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 242 Step: 46706 Index:-0.3205 R2:0.8097 0.4156 0.5659 RMSE:0.4449 0.7979 0.6893 Tau:0.7248 0.4774 0.3100\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 243 Step: 46899 Index:-0.2948 R2:0.8112 0.4160 0.5614 RMSE:0.4267 0.7771 0.6790 Tau:0.7293 0.4823 0.3052\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 244 Step: 47092 Index:-0.3131 R2:0.8228 0.4109 0.5594 RMSE:0.4148 0.7864 0.6831 Tau:0.7357 0.4734 0.3162\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 245 Step: 47285 Index:-0.2932 R2:0.8213 0.4275 0.5630 RMSE:0.4197 0.7778 0.6814 Tau:0.7374 0.4846 0.3121\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 246 Step: 47478 Index:-0.2796 R2:0.7992 0.4285 0.5521 RMSE:0.4483 0.7649 0.6852 Tau:0.7218 0.4854 0.3141\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 247 Step: 47671 Index:-0.3048 R2:0.8186 0.4470 0.5791 RMSE:0.4698 0.8033 0.7001 Tau:0.7345 0.4985 0.3128\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 248 Step: 47864 Index:-0.2965 R2:0.8197 0.4187 0.5551 RMSE:0.4221 0.7717 0.6846 Tau:0.7353 0.4752 0.3130\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 249 Step: 48057 Index:-0.3308 R2:0.8018 0.4153 0.5545 RMSE:0.4578 0.8002 0.6884 Tau:0.7235 0.4694 0.3046\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 250 Step: 48250 Index:-0.2717 R2:0.8188 0.4464 0.5701 RMSE:0.4202 0.7693 0.6857 Tau:0.7341 0.4976 0.3238\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 251 Step: 48443 Index:-0.3040 R2:0.8252 0.4146 0.5809 RMSE:0.4224 0.7813 0.6701 Tau:0.7371 0.4772 0.3059\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 252 Step: 48636 Index:-0.3061 R2:0.8068 0.4291 0.5771 RMSE:0.5050 0.7937 0.7143 Tau:0.7223 0.4876 0.3068\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 253 Step: 48829 Index:-0.2541 R2:0.8211 0.4473 0.5797 RMSE:0.4176 0.7524 0.6537 Tau:0.7361 0.4983 0.3125\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 254 Step: 49022 Index:-0.2939 R2:0.8357 0.4270 0.5687 RMSE:0.4073 0.7774 0.6717 Tau:0.7477 0.4835 0.3111\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 255 Step: 49215 Index:-0.2525 R2:0.8296 0.4460 0.5755 RMSE:0.4064 0.7516 0.6630 Tau:0.7419 0.4992 0.3141\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 256 Step: 49408 Index:-0.2976 R2:0.8191 0.4228 0.5624 RMSE:0.4270 0.7817 0.6807 Tau:0.7324 0.4841 0.3097\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 257 Step: 49601 Index:-0.2959 R2:0.8167 0.4365 0.5688 RMSE:0.4312 0.7878 0.6915 Tau:0.7291 0.4919 0.3146\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 258 Step: 49794 Index:-0.3049 R2:0.8230 0.4385 0.5537 RMSE:0.4257 0.7896 0.7110 Tau:0.7389 0.4847 0.3192\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 259 Step: 49987 Index:-0.3099 R2:0.8271 0.4143 0.5542 RMSE:0.4225 0.7907 0.6855 Tau:0.7397 0.4808 0.3100\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 260 Step: 50180 Index:-0.3266 R2:0.8069 0.4079 0.5623 RMSE:0.4335 0.8008 0.6910 Tau:0.7205 0.4742 0.3055\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 261 Step: 50373 Index:-0.2938 R2:0.8314 0.4261 0.5519 RMSE:0.4047 0.7755 0.6945 Tau:0.7412 0.4817 0.3104\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 262 Step: 50566 Index:-0.2845 R2:0.8427 0.4348 0.5704 RMSE:0.3901 0.7697 0.6766 Tau:0.7524 0.4852 0.3144\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 263 Step: 50759 Index:-0.2691 R2:0.8367 0.4513 0.5739 RMSE:0.3967 0.7667 0.6826 Tau:0.7497 0.4976 0.3160\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 264 Step: 50952 Index:-0.2616 R2:0.8377 0.4413 0.5748 RMSE:0.4006 0.7567 0.6647 Tau:0.7481 0.4951 0.3068\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 265 Step: 51145 Index:-0.2837 R2:0.8339 0.4398 0.5583 RMSE:0.4005 0.7787 0.7053 Tau:0.7471 0.4950 0.3186\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 266 Step: 51338 Index:-0.2985 R2:0.8421 0.4349 0.5633 RMSE:0.4049 0.7867 0.6987 Tau:0.7518 0.4882 0.3147\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 267 Step: 51531 Index:-0.2943 R2:0.8367 0.4282 0.5658 RMSE:0.3954 0.7850 0.7014 Tau:0.7468 0.4907 0.3252\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 268 Step: 51724 Index:-0.3179 R2:0.8297 0.4194 0.5690 RMSE:0.4142 0.8010 0.6921 Tau:0.7441 0.4831 0.3165\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 269 Step: 51917 Index:-0.2937 R2:0.8425 0.4257 0.5582 RMSE:0.3960 0.7759 0.6922 Tau:0.7535 0.4821 0.3197\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 270 Step: 52110 Index:-0.2911 R2:0.8400 0.4235 0.5677 RMSE:0.4202 0.7763 0.6896 Tau:0.7527 0.4852 0.3089\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 271 Step: 52303 Index:-0.3421 R2:0.8362 0.4135 0.5568 RMSE:0.4074 0.8173 0.7203 Tau:0.7468 0.4752 0.3163\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 272 Step: 52496 Index:-0.3074 R2:0.8446 0.4146 0.5643 RMSE:0.4076 0.7858 0.6951 Tau:0.7525 0.4783 0.3057\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 273 Step: 52689 Index:-0.3314 R2:0.8310 0.4117 0.5653 RMSE:0.4046 0.8081 0.7023 Tau:0.7425 0.4766 0.3096\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 274 Step: 52882 Index:-0.3540 R2:0.8315 0.4073 0.5491 RMSE:0.4323 0.8295 0.7375 Tau:0.7411 0.4756 0.3138\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 275 Step: 53075 Index:-0.2925 R2:0.8458 0.4480 0.5693 RMSE:0.4164 0.7888 0.6978 Tau:0.7564 0.4963 0.3106\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 276 Step: 53268 Index:-0.3253 R2:0.8295 0.4347 0.5409 RMSE:0.4543 0.8132 0.7369 Tau:0.7421 0.4878 0.3197\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 277 Step: 53461 Index:-0.3169 R2:0.8427 0.4249 0.5675 RMSE:0.3993 0.8017 0.6984 Tau:0.7527 0.4848 0.3159\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 278 Step: 53654 Index:-0.2889 R2:0.8436 0.4307 0.5600 RMSE:0.3997 0.7754 0.6897 Tau:0.7568 0.4866 0.3174\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 279 Step: 53847 Index:-0.3367 R2:0.8378 0.4050 0.5450 RMSE:0.3944 0.8033 0.7112 Tau:0.7493 0.4667 0.3131\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 280 Step: 54040 Index:-0.3197 R2:0.8342 0.4026 0.5502 RMSE:0.4018 0.7943 0.6955 Tau:0.7469 0.4746 0.3165\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 281 Step: 54233 Index:-0.2802 R2:0.8358 0.4388 0.5827 RMSE:0.3978 0.7713 0.6634 Tau:0.7483 0.4911 0.3066\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 282 Step: 54426 Index:-0.3014 R2:0.8469 0.4240 0.5819 RMSE:0.4153 0.7869 0.6899 Tau:0.7566 0.4855 0.3146\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 283 Step: 54619 Index:-0.3092 R2:0.8400 0.4154 0.5572 RMSE:0.4066 0.7884 0.7024 Tau:0.7494 0.4793 0.3144\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 284 Step: 54812 Index:-0.2587 R2:0.8494 0.4433 0.5619 RMSE:0.3874 0.7581 0.6814 Tau:0.7587 0.4994 0.3181\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 285 Step: 55005 Index:-0.3146 R2:0.8337 0.4346 0.5522 RMSE:0.4366 0.8102 0.7337 Tau:0.7458 0.4957 0.3225\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 286 Step: 55198 Index:-0.2839 R2:0.8537 0.4385 0.5714 RMSE:0.3764 0.7765 0.6785 Tau:0.7634 0.4926 0.3092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 287 Step: 55391 Index:-0.2640 R2:0.8468 0.4490 0.5760 RMSE:0.3866 0.7631 0.6708 Tau:0.7581 0.4992 0.3080\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 288 Step: 55584 Index:-0.2889 R2:0.8515 0.4345 0.5837 RMSE:0.3791 0.7839 0.6791 Tau:0.7619 0.4949 0.3148\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 289 Step: 55777 Index:-0.3145 R2:0.8427 0.4202 0.5645 RMSE:0.3891 0.7980 0.7000 Tau:0.7535 0.4835 0.3261\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 290 Step: 55970 Index:-0.3196 R2:0.8440 0.4392 0.5541 RMSE:0.4396 0.8104 0.7302 Tau:0.7552 0.4909 0.3166\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 291 Step: 56163 Index:-0.3006 R2:0.8433 0.4346 0.5759 RMSE:0.4404 0.7920 0.7060 Tau:0.7531 0.4913 0.3188\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 292 Step: 56356 Index:-0.3094 R2:0.8423 0.4265 0.5542 RMSE:0.3954 0.7968 0.7127 Tau:0.7535 0.4874 0.3193\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 293 Step: 56549 Index:-0.2951 R2:0.8539 0.4348 0.5768 RMSE:0.3852 0.7826 0.6904 Tau:0.7649 0.4876 0.3152\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 294 Step: 56742 Index:-0.3282 R2:0.8394 0.4254 0.5640 RMSE:0.4059 0.8169 0.7276 Tau:0.7542 0.4887 0.3179\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 295 Step: 56935 Index:-0.3189 R2:0.8536 0.4200 0.5566 RMSE:0.3792 0.7973 0.7031 Tau:0.7640 0.4784 0.3057\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 296 Step: 57128 Index:-0.2739 R2:0.8483 0.4504 0.5818 RMSE:0.3982 0.7712 0.6880 Tau:0.7600 0.4974 0.3179\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 297 Step: 57321 Index:-0.3357 R2:0.8542 0.4225 0.5518 RMSE:0.3983 0.8185 0.7334 Tau:0.7633 0.4829 0.3160\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 298 Step: 57514 Index:-0.2983 R2:0.8611 0.4275 0.5678 RMSE:0.3716 0.7886 0.6961 Tau:0.7702 0.4902 0.3116\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 299 Step: 57707 Index:-0.3315 R2:0.8385 0.4151 0.5519 RMSE:0.3933 0.8087 0.7219 Tau:0.7498 0.4772 0.3227\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 300 Step: 57900 Index:-0.3242 R2:0.8523 0.4119 0.5565 RMSE:0.3880 0.8006 0.7117 Tau:0.7607 0.4764 0.3116\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 301 Step: 58093 Index:-0.2988 R2:0.8566 0.4295 0.5810 RMSE:0.3939 0.7852 0.6841 Tau:0.7649 0.4864 0.3124\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 302 Step: 58286 Index:-0.3114 R2:0.8627 0.4358 0.5762 RMSE:0.3883 0.8088 0.7104 Tau:0.7716 0.4974 0.3160\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 303 Step: 58479 Index:-0.3374 R2:0.8451 0.4169 0.5625 RMSE:0.3853 0.8117 0.7122 Tau:0.7586 0.4742 0.3130\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 304 Step: 58672 Index:-0.3332 R2:0.8508 0.4008 0.5603 RMSE:0.3796 0.8084 0.7031 Tau:0.7571 0.4752 0.3122\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 305 Step: 58865 Index:-0.2996 R2:0.8488 0.4276 0.5669 RMSE:0.3841 0.7864 0.6921 Tau:0.7581 0.4868 0.3157\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 306 Step: 59058 Index:-0.3089 R2:0.8696 0.4229 0.5707 RMSE:0.3551 0.7963 0.7023 Tau:0.7772 0.4874 0.3139\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 307 Step: 59251 Index:-0.3296 R2:0.8433 0.4109 0.5474 RMSE:0.3871 0.8111 0.7266 Tau:0.7546 0.4815 0.3231\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 308 Step: 59444 Index:-0.4212 R2:0.7897 0.3901 0.5104 RMSE:0.4960 0.8885 0.8032 Tau:0.7182 0.4673 0.2952\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 309 Step: 59637 Index:-0.3118 R2:0.8617 0.4205 0.5684 RMSE:0.3686 0.7986 0.7033 Tau:0.7714 0.4868 0.3180\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 310 Step: 59830 Index:-0.3067 R2:0.8592 0.4285 0.5629 RMSE:0.3669 0.7978 0.7194 Tau:0.7676 0.4911 0.3221\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 311 Step: 60023 Index:-0.3185 R2:0.8599 0.4202 0.5740 RMSE:0.3705 0.8046 0.7026 Tau:0.7678 0.4861 0.3128\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 312 Step: 60216 Index:-0.3456 R2:0.8517 0.4084 0.5628 RMSE:0.3795 0.8205 0.7105 Tau:0.7591 0.4750 0.3075\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 313 Step: 60409 Index:-0.3238 R2:0.8654 0.4112 0.5732 RMSE:0.3677 0.8107 0.7042 Tau:0.7734 0.4868 0.3169\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 314 Step: 60602 Index:-0.3410 R2:0.8692 0.4086 0.5668 RMSE:0.3763 0.8232 0.7234 Tau:0.7757 0.4822 0.3152\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 315 Step: 60795 Index:-0.3231 R2:0.8638 0.4170 0.5798 RMSE:0.3612 0.8124 0.7039 Tau:0.7711 0.4893 0.3161\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 316 Step: 60988 Index:-0.3094 R2:0.8661 0.4231 0.5559 RMSE:0.3654 0.7989 0.7077 Tau:0.7754 0.4895 0.3161\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 317 Step: 61181 Index:-0.3637 R2:0.8511 0.3993 0.5436 RMSE:0.4263 0.8452 0.7544 Tau:0.7617 0.4815 0.3184\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 318 Step: 61374 Index:-0.2883 R2:0.8615 0.4336 0.5776 RMSE:0.3691 0.7796 0.6782 Tau:0.7714 0.4913 0.3153\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 318 r2:0.5661 RMSE:0.6594 WTI:0.3829 AP:0.4994 Tau:0.3100 \n",
      " \n",
      " Top-1:0.6316 Top-1-fp:0.1579 \n",
      " Top-5:0.6875 Top-5-fp:0.1979 \n",
      " Top-10:0.5440 Top-10-fp:0.4508 \n",
      " Top-15:0.6150 Top-15-fp:0.5744 \n",
      " Top-20:0.6800 Top-20-fp:0.6477 \n",
      " Top-25:0.7300 Top-25-fp:0.6971 \n",
      " Top-30:0.7600 Top-30-fp:0.7375 \n",
      " Top-40:0.8250 Top-40-fp:0.7863 \n",
      " Top-50:0.9000 Top-50-fp:0.8135 \n",
      " \n",
      " Top50:0.6400 Top50-fp:0.1200 \n",
      " Top100:0.6800 Top100-fp:0.2200 \n",
      " Top150:0.6267 Top150-fp:0.3600 \n",
      " Top200:0.5450 Top200-fp:0.4550 \n",
      " Top250:0.5750 Top250-fp:0.5400 \n",
      " Top300:0.6300 Top300-fp:0.5800 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
