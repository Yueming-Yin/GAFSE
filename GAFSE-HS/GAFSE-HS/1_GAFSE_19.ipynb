{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IC50_O43614_1_420\n",
      "model_file/1_GAFSE_IC50_O43614_1_420yjt_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/IC50_O43614_1_420_train.csv\"\n",
    "test_filename = \"./data/benchmark/IC50_O43614_1_420_test.csv\"\n",
    "test_active = 420\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CC1=CC(=C(C=C1)N2N=CC=N2)C(=O)N3CCCC3C4=NC(=NO... -1.602060\n",
      "1  COC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C=... -0.954243\n",
      "2  CC1=CC=CC(=C1)C2=C(N=CO2)C(=O)NC3=CN(N=C3)CCN4... -2.705008\n",
      "3  CC1CC(N(C1=O)CC2=CC3=C(C=C2)OC4=CC=CC=C43)C5=C... -0.778151\n",
      "4  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.982271\n",
      "number of all smiles:  1879\n",
      "number of successfully processed smiles:  1879\n",
      "                                              smiles     value  \\\n",
      "0  CC1=CC(=C(C=C1)N2N=CC=N2)C(=O)N3CCCC3C4=NC(=NO... -1.602060   \n",
      "1  COC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C=... -0.954243   \n",
      "2  CC1=CC=CC(=C1)C2=C(N=CO2)C(=O)NC3=CN(N=C3)CCN4... -2.705008   \n",
      "3  CC1CC(N(C1=O)CC2=CC3=C(C=C2)OC4=CC=CC=C43)C5=C... -0.778151   \n",
      "4  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.982271   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Cc1ccc(-n2nccn2)c(C(=O)N2CCCC2c2nc(-c3c(C)cccc...  \n",
      "1  COc1c(F)cccc1-c1noc(C2CCCN2C(=O)c2cc(Cl)ccc2-n...  \n",
      "2  Cc1cccc(-c2ocnc2C(=O)Nc2cnn(CCn3ccc4cc(Cl)ccc4...  \n",
      "3    COc1cccc(F)c1C1CC(C)C(=O)N1Cc1ccc2oc3ccccc3c2c1  \n",
      "4  CC1CN(C(=O)c2cc(Cl)ccc2-n2nccn2)C(Cc2cccc(-n3n...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  821\n",
      "number of successfully processed smiles:  821\n",
      "(821, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1COCC(N1C(=O)C2=CC=CC=C2N3N=CC=N3)CC4=CC=CC(=... -3.276921   \n",
      "1  CCOC1=C(C=CC=C1F)C2=NOC(=N2)C3CCCN3C(=O)C4=C(C... -0.845098   \n",
      "2  CC1=C(C=CC=C1OC)C2=NC(=NO2)C3CCCN3C(=O)C4=C(C=... -2.000000   \n",
      "3  CC1CN(C(CO1)CC2=CC(=CC=C2)N3N=CC=N3)C(=O)C4=C(... -1.968483   \n",
      "4  C1CC(C(C1)NC(=O)C2=CC=CC=C2N3C=CC=N3)NC4=NC5=C... -3.633468   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  O=C(c1ccccc1-n1nccn1)N1CCOCC1Cc1cccc(-c2ncccn2)c1  \n",
      "1  CCOc1c(F)cccc1-c1noc(C2CCCN2C(=O)c2cc(C)ccc2-n...  \n",
      "2  COc1cccc(-c2nc(C3CCCN3C(=O)c3ccc(Cl)cc3-n3nccn...  \n",
      "3  CC1CN(C(=O)c2cccc(Cl)c2-n2nccn2)C(Cc2cccc(-n3n...  \n",
      "4     O=C(NC1CCCC1Nc1nc2ccc(F)cc2s1)c1ccccc1-n1cccn1  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/IC50_O43614_1_420_train.pickle\n",
      "./data/benchmark/IC50_O43614_1_420_train\n",
      "2700\n",
      "feature dicts file saved as ./data/benchmark/IC50_O43614_1_420_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503, 3) (376, 3) (821, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_IC50_O43614_1_420yjt_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 150 Index:-0.8994 R2:0.0173 0.0388 0.0239 RMSE:1.0587 1.0685 1.0433 Tau:0.1201 0.1691 0.0153\n",
      "Epoch: 2 Step: 300 Index:-0.6737 R2:0.1661 0.1830 0.0955 RMSE:0.9182 0.9589 0.9189 Tau:0.2731 0.2851 0.3977\n",
      "Epoch: 3 Step: 450 Index:-0.5878 R2:0.1928 0.2086 0.1181 RMSE:0.8689 0.8895 0.8791 Tau:0.2936 0.3017 0.4489\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 4 Step: 600 Index:-0.6281 R2:0.2205 0.2246 0.1428 RMSE:0.9345 0.9499 0.9515 Tau:0.3127 0.3218 0.4906\n",
      "Epoch: 5 Step: 750 Index:-0.5280 R2:0.2351 0.2406 0.1580 RMSE:0.8313 0.8563 0.8505 Tau:0.3205 0.3283 0.5118\n",
      "Epoch: 6 Step: 900 Index:-0.5251 R2:0.2470 0.2541 0.1729 RMSE:0.8225 0.8557 0.8391 Tau:0.3280 0.3306 0.5281\n",
      "Epoch: 7 Step: 1050 Index:-0.5100 R2:0.2652 0.2669 0.1906 RMSE:0.8176 0.8532 0.8343 Tau:0.3421 0.3432 0.5364\n",
      "Epoch: 8 Step: 1200 Index:-0.4630 R2:0.2859 0.2830 0.2183 RMSE:0.7880 0.8225 0.8049 Tau:0.3608 0.3595 0.5426\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 1350 Index:-0.4894 R2:0.2989 0.3013 0.2390 RMSE:0.8223 0.8589 0.8318 Tau:0.3688 0.3695 0.5493\n",
      "Epoch: 10 Step: 1500 Index:-0.4346 R2:0.3132 0.3087 0.2589 RMSE:0.7936 0.8212 0.8022 Tau:0.3833 0.3865 0.5446\n",
      "Epoch: 11 Step: 1650 Index:-0.4135 R2:0.3221 0.3253 0.2714 RMSE:0.7718 0.8037 0.7783 Tau:0.3861 0.3901 0.5510\n",
      "Epoch: 12 Step: 1800 Index:-0.4095 R2:0.3308 0.3282 0.2750 RMSE:0.7755 0.8106 0.7854 Tau:0.3937 0.4011 0.5608\n",
      "Epoch: 13 Step: 1950 Index:-0.3926 R2:0.3378 0.3314 0.2850 RMSE:0.7657 0.7964 0.7748 Tau:0.3981 0.4038 0.5632\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 14 Step: 2100 Index:-0.4364 R2:0.3466 0.3472 0.3068 RMSE:0.8261 0.8436 0.8309 Tau:0.4032 0.4072 0.5595\n",
      "Epoch: 15 Step: 2250 Index:-0.3727 R2:0.3547 0.3545 0.3111 RMSE:0.7515 0.7843 0.7576 Tau:0.4085 0.4116 0.5757\n",
      "Epoch: 16 Step: 2400 Index:-0.3586 R2:0.3623 0.3600 0.3243 RMSE:0.7419 0.7728 0.7462 Tau:0.4163 0.4142 0.5786\n",
      "Epoch: 17 Step: 2550 Index:-0.3525 R2:0.3673 0.3722 0.3266 RMSE:0.7513 0.7740 0.7569 Tau:0.4162 0.4216 0.5807\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 18 Step: 2700 Index:-0.3711 R2:0.3692 0.3712 0.3322 RMSE:0.7690 0.7901 0.7744 Tau:0.4175 0.4190 0.5810\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 19 Step: 2850 Index:-0.3545 R2:0.3767 0.3720 0.3382 RMSE:0.7448 0.7732 0.7488 Tau:0.4231 0.4187 0.5852\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 20 Step: 3000 Index:-0.3692 R2:0.3780 0.3736 0.3359 RMSE:0.7690 0.7932 0.7764 Tau:0.4258 0.4239 0.5838\n",
      "Epoch: 21 Step: 3150 Index:-0.3453 R2:0.3842 0.3765 0.3447 RMSE:0.7312 0.7668 0.7349 Tau:0.4288 0.4214 0.5915\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 22 Step: 3300 Index:-0.3488 R2:0.3848 0.3833 0.3522 RMSE:0.7472 0.7721 0.7478 Tau:0.4280 0.4233 0.5867\n",
      "Epoch: 23 Step: 3450 Index:-0.3369 R2:0.3877 0.3841 0.3474 RMSE:0.7351 0.7634 0.7406 Tau:0.4299 0.4265 0.5902\n",
      "Epoch: 24 Step: 3600 Index:-0.3272 R2:0.3916 0.3904 0.3567 RMSE:0.7259 0.7546 0.7292 Tau:0.4315 0.4274 0.5932\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 25 Step: 3750 Index:-0.3387 R2:0.3915 0.3839 0.3638 RMSE:0.7246 0.7590 0.7241 Tau:0.4306 0.4203 0.5935\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 26 Step: 3900 Index:-0.3302 R2:0.3932 0.3836 0.3507 RMSE:0.7244 0.7591 0.7313 Tau:0.4376 0.4289 0.5909\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 27 Step: 4050 Index:-0.3297 R2:0.4021 0.3874 0.3677 RMSE:0.7204 0.7565 0.7241 Tau:0.4420 0.4268 0.6003\n",
      "Epoch: 28 Step: 4200 Index:-0.3265 R2:0.4030 0.3949 0.3686 RMSE:0.7203 0.7563 0.7236 Tau:0.4402 0.4298 0.6009\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 29 Step: 4350 Index:-0.3685 R2:0.4046 0.3842 0.3701 RMSE:0.7494 0.7958 0.7484 Tau:0.4464 0.4273 0.6021\n",
      "Epoch: 30 Step: 4500 Index:-0.3167 R2:0.4122 0.4019 0.3779 RMSE:0.7133 0.7488 0.7155 Tau:0.4462 0.4321 0.6050\n",
      "Epoch: 31 Step: 4650 Index:-0.3024 R2:0.4165 0.4092 0.3800 RMSE:0.7106 0.7424 0.7163 Tau:0.4502 0.4401 0.6067\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 32 Step: 4800 Index:-0.3749 R2:0.4121 0.4018 0.3743 RMSE:0.7879 0.8097 0.7952 Tau:0.4482 0.4348 0.5976\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 33 Step: 4950 Index:-0.3041 R2:0.4238 0.4142 0.3860 RMSE:0.7151 0.7458 0.7212 Tau:0.4556 0.4417 0.6072\n",
      "Epoch: 34 Step: 5100 Index:-0.2985 R2:0.4264 0.4131 0.3851 RMSE:0.7058 0.7415 0.7129 Tau:0.4581 0.4429 0.6116\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 35 Step: 5250 Index:-0.2996 R2:0.4220 0.4248 0.3859 RMSE:0.7248 0.7455 0.7322 Tau:0.4501 0.4460 0.6061\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 36 Step: 5400 Index:-0.3508 R2:0.4303 0.4199 0.3983 RMSE:0.7678 0.7903 0.7734 Tau:0.4604 0.4395 0.6124\n",
      "Epoch: 37 Step: 5550 Index:-0.2838 R2:0.4320 0.4236 0.3827 RMSE:0.7013 0.7350 0.7131 Tau:0.4629 0.4512 0.6149\n",
      "Epoch: 38 Step: 5700 Index:-0.2746 R2:0.4385 0.4344 0.4044 RMSE:0.6970 0.7289 0.7005 Tau:0.4662 0.4543 0.6139\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 39 Step: 5850 Index:-0.2978 R2:0.4385 0.4267 0.4025 RMSE:0.7080 0.7475 0.7109 Tau:0.4658 0.4497 0.6139\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 40 Step: 6000 Index:-0.3039 R2:0.4391 0.4166 0.4096 RMSE:0.7173 0.7528 0.7221 Tau:0.4755 0.4489 0.6148\n",
      "Epoch: 41 Step: 6150 Index:-0.2674 R2:0.4485 0.4364 0.4144 RMSE:0.6915 0.7272 0.6945 Tau:0.4776 0.4597 0.6151\n",
      "Epoch: 42 Step: 6300 Index:-0.2635 R2:0.4498 0.4400 0.4098 RMSE:0.6903 0.7251 0.6969 Tau:0.4752 0.4616 0.6188\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 6450 Index:-0.2865 R2:0.4550 0.4369 0.4103 RMSE:0.7124 0.7451 0.7238 Tau:0.4782 0.4586 0.6229\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 44 Step: 6600 Index:-0.2650 R2:0.4560 0.4472 0.4107 RMSE:0.6989 0.7284 0.7105 Tau:0.4782 0.4635 0.6207\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 45 Step: 6750 Index:-0.2793 R2:0.4601 0.4494 0.4126 RMSE:0.7162 0.7432 0.7300 Tau:0.4821 0.4639 0.6215\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 46 Step: 6900 Index:-0.2663 R2:0.4605 0.4516 0.4137 RMSE:0.6946 0.7311 0.7054 Tau:0.4798 0.4649 0.6226\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 47 Step: 7050 Index:-0.2885 R2:0.4714 0.4478 0.4318 RMSE:0.7195 0.7512 0.7325 Tau:0.4902 0.4627 0.6255\n",
      "Epoch: 48 Step: 7200 Index:-0.2588 R2:0.4714 0.4558 0.4290 RMSE:0.6861 0.7199 0.6962 Tau:0.4862 0.4611 0.6246\n",
      "Epoch: 49 Step: 7350 Index:-0.2549 R2:0.4775 0.4620 0.4253 RMSE:0.6853 0.7253 0.6966 Tau:0.4951 0.4704 0.6303\n",
      "Epoch: 50 Step: 7500 Index:-0.2542 R2:0.4822 0.4619 0.4275 RMSE:0.7017 0.7334 0.7215 Tau:0.5011 0.4792 0.6299\n",
      "Epoch: 51 Step: 7650 Index:-0.2221 R2:0.4880 0.4831 0.4353 RMSE:0.6710 0.7041 0.6849 Tau:0.4966 0.4821 0.6272\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 52 Step: 7800 Index:-0.2366 R2:0.4885 0.4711 0.4308 RMSE:0.6765 0.7186 0.6929 Tau:0.5013 0.4820 0.6265\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 53 Step: 7950 Index:-0.2340 R2:0.4895 0.4710 0.4347 RMSE:0.6691 0.7102 0.6842 Tau:0.5010 0.4762 0.6262\n",
      "Epoch: 54 Step: 8100 Index:-0.2185 R2:0.4988 0.4783 0.4483 RMSE:0.6604 0.7009 0.6740 Tau:0.5083 0.4824 0.6286\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 55 Step: 8250 Index:-0.2614 R2:0.5045 0.4750 0.4475 RMSE:0.7064 0.7402 0.7272 Tau:0.5102 0.4788 0.6333\n",
      "Epoch: 56 Step: 8400 Index:-0.2144 R2:0.4985 0.4846 0.4498 RMSE:0.6585 0.6954 0.6741 Tau:0.5007 0.4810 0.6264\n",
      "Epoch: 57 Step: 8550 Index:-0.2121 R2:0.5000 0.4796 0.4322 RMSE:0.6637 0.7019 0.6884 Tau:0.5103 0.4899 0.6297\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 58 Step: 8700 Index:-0.2154 R2:0.5115 0.4884 0.4512 RMSE:0.6738 0.7081 0.6959 Tau:0.5146 0.4927 0.6263\n",
      "Epoch: 59 Step: 8850 Index:-0.1915 R2:0.5117 0.4945 0.4531 RMSE:0.6511 0.6871 0.6751 Tau:0.5161 0.4956 0.6272\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 60 Step: 9000 Index:-0.2294 R2:0.5141 0.4981 0.4584 RMSE:0.7005 0.7267 0.7228 Tau:0.5155 0.4974 0.6257\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 61 Step: 9150 Index:-0.2026 R2:0.5195 0.4874 0.4581 RMSE:0.6466 0.6950 0.6678 Tau:0.5239 0.4924 0.6316\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 62 Step: 9300 Index:-0.2011 R2:0.5180 0.4968 0.4608 RMSE:0.6542 0.6910 0.6741 Tau:0.5169 0.4899 0.6256\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 63 Step: 9450 Index:-0.2015 R2:0.5241 0.4978 0.4676 RMSE:0.6585 0.6966 0.6806 Tau:0.5262 0.4951 0.6302\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 64 Step: 9600 Index:-0.1925 R2:0.5251 0.5070 0.4513 RMSE:0.6622 0.6951 0.6926 Tau:0.5226 0.5027 0.6318\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 65 Step: 9750 Index:-0.2259 R2:0.5293 0.4966 0.4584 RMSE:0.6928 0.7290 0.7235 Tau:0.5322 0.5031 0.6346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 66 Step: 9900 Index:-0.1950 R2:0.5306 0.5012 0.4678 RMSE:0.6436 0.6927 0.6660 Tau:0.5304 0.4978 0.6277\n",
      "Epoch: 67 Step: 10050 Index:-0.1742 R2:0.5368 0.5071 0.4640 RMSE:0.6344 0.6816 0.6655 Tau:0.5340 0.5074 0.6313\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 68 Step: 10200 Index:-0.2102 R2:0.5434 0.5063 0.4768 RMSE:0.6733 0.7129 0.7040 Tau:0.5389 0.5028 0.6353\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 69 Step: 10350 Index:-0.2593 R2:0.5284 0.5080 0.4691 RMSE:0.7335 0.7546 0.7590 Tau:0.5204 0.4953 0.6197\n",
      "Epoch: 70 Step: 10500 Index:-0.1701 R2:0.5415 0.5092 0.4639 RMSE:0.6336 0.6789 0.6702 Tau:0.5383 0.5088 0.6307\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 71 Step: 10650 Index:-0.1917 R2:0.5494 0.5152 0.4745 RMSE:0.6643 0.7035 0.7014 Tau:0.5434 0.5118 0.6309\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 72 Step: 10800 Index:-0.1742 R2:0.5503 0.5111 0.4770 RMSE:0.6306 0.6827 0.6569 Tau:0.5434 0.5085 0.6329\n",
      "Epoch: 73 Step: 10950 Index:-0.1673 R2:0.5455 0.5158 0.4757 RMSE:0.6288 0.6741 0.6578 Tau:0.5341 0.5068 0.6321\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 74 Step: 11100 Index:-0.1940 R2:0.5503 0.4995 0.4888 RMSE:0.6344 0.6892 0.6585 Tau:0.5432 0.4952 0.6318\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 75 Step: 11250 Index:-0.1712 R2:0.5510 0.5109 0.4766 RMSE:0.6272 0.6773 0.6624 Tau:0.5422 0.5061 0.6339\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 76 Step: 11400 Index:-0.1912 R2:0.5490 0.5038 0.4790 RMSE:0.6356 0.6866 0.6696 Tau:0.5378 0.4954 0.6340\n",
      "Epoch: 77 Step: 11550 Index:-0.1590 R2:0.5697 0.5212 0.4798 RMSE:0.6170 0.6773 0.6553 Tau:0.5568 0.5183 0.6439\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 78 Step: 11700 Index:-0.1826 R2:0.5660 0.5142 0.4951 RMSE:0.6418 0.6940 0.6734 Tau:0.5559 0.5114 0.6327\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 79 Step: 11850 Index:-0.1654 R2:0.5673 0.5116 0.4883 RMSE:0.6172 0.6780 0.6526 Tau:0.5572 0.5126 0.6408\n",
      "Epoch: 80 Step: 12000 Index:-0.1431 R2:0.5680 0.5269 0.4789 RMSE:0.6153 0.6672 0.6592 Tau:0.5547 0.5241 0.6401\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 81 Step: 12150 Index:-0.1777 R2:0.5753 0.5213 0.4887 RMSE:0.6454 0.6955 0.6852 Tau:0.5609 0.5178 0.6427\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 82 Step: 12300 Index:-0.2129 R2:0.5693 0.5103 0.4739 RMSE:0.6786 0.7267 0.7216 Tau:0.5590 0.5139 0.6381\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 83 Step: 12450 Index:-0.1528 R2:0.5726 0.5239 0.4890 RMSE:0.6112 0.6700 0.6486 Tau:0.5556 0.5172 0.6401\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 84 Step: 12600 Index:-0.1602 R2:0.5736 0.5166 0.4827 RMSE:0.6120 0.6774 0.6533 Tau:0.5613 0.5173 0.6417\n",
      "Epoch: 85 Step: 12750 Index:-0.1196 R2:0.5856 0.5469 0.4934 RMSE:0.6027 0.6534 0.6487 Tau:0.5654 0.5338 0.6370\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 86 Step: 12900 Index:-0.1485 R2:0.5804 0.5256 0.4922 RMSE:0.6038 0.6662 0.6473 Tau:0.5632 0.5178 0.6388\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 87 Step: 13050 Index:-0.1400 R2:0.5790 0.5382 0.4900 RMSE:0.6109 0.6664 0.6548 Tau:0.5586 0.5263 0.6390\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 88 Step: 13200 Index:-0.2233 R2:0.5322 0.4875 0.4520 RMSE:0.6550 0.7121 0.6861 Tau:0.5291 0.4888 0.6272\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 89 Step: 13350 Index:-0.1328 R2:0.5694 0.5424 0.4991 RMSE:0.6118 0.6575 0.6451 Tau:0.5500 0.5247 0.6308\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 90 Step: 13500 Index:-0.1850 R2:0.5841 0.5479 0.5000 RMSE:0.6665 0.7212 0.6951 Tau:0.5639 0.5361 0.6450\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 91 Step: 13650 Index:-0.1532 R2:0.5772 0.5298 0.4995 RMSE:0.6145 0.6674 0.6560 Tau:0.5563 0.5142 0.6320\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 92 Step: 13800 Index:-0.1242 R2:0.5935 0.5425 0.5014 RMSE:0.5941 0.6540 0.6432 Tau:0.5713 0.5298 0.6458\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 93 Step: 13950 Index:-0.1270 R2:0.5914 0.5399 0.4950 RMSE:0.5967 0.6570 0.6465 Tau:0.5696 0.5300 0.6427\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 94 Step: 14100 Index:-0.1466 R2:0.5802 0.5320 0.4757 RMSE:0.6166 0.6709 0.6747 Tau:0.5607 0.5244 0.6405\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 95 Step: 14250 Index:-0.1211 R2:0.5903 0.5390 0.4972 RMSE:0.5959 0.6562 0.6460 Tau:0.5725 0.5351 0.6427\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 96 Step: 14400 Index:-0.1365 R2:0.5896 0.5352 0.4961 RMSE:0.5972 0.6604 0.6446 Tau:0.5661 0.5238 0.6434\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 97 Step: 14550 Index:-0.1498 R2:0.5877 0.5361 0.4889 RMSE:0.6212 0.6742 0.6778 Tau:0.5653 0.5244 0.6363\n",
      "Epoch: 98 Step: 14700 Index:-0.1134 R2:0.6017 0.5567 0.5003 RMSE:0.5954 0.6545 0.6465 Tau:0.5767 0.5410 0.6446\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 99 Step: 14850 Index:-0.1141 R2:0.6028 0.5491 0.5009 RMSE:0.5921 0.6539 0.6422 Tau:0.5800 0.5398 0.6429\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 100 Step: 15000 Index:-0.1259 R2:0.6088 0.5513 0.5142 RMSE:0.5888 0.6579 0.6360 Tau:0.5802 0.5321 0.6489\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 101 Step: 15150 Index:-0.1265 R2:0.6021 0.5534 0.5051 RMSE:0.6194 0.6701 0.6736 Tau:0.5772 0.5436 0.6493\n",
      "Epoch: 102 Step: 15300 Index:-0.1064 R2:0.6072 0.5664 0.5207 RMSE:0.5962 0.6442 0.6460 Tau:0.5775 0.5379 0.6383\n",
      "Epoch: 103 Step: 15450 Index:-0.0992 R2:0.6088 0.5646 0.5180 RMSE:0.5863 0.6401 0.6355 Tau:0.5787 0.5409 0.6434\n",
      "Epoch: 104 Step: 15600 Index:-0.0938 R2:0.6130 0.5657 0.5060 RMSE:0.5814 0.6394 0.6399 Tau:0.5841 0.5456 0.6444\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 105 Step: 15750 Index:-0.1066 R2:0.6092 0.5520 0.4995 RMSE:0.5846 0.6499 0.6432 Tau:0.5839 0.5433 0.6449\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 106 Step: 15900 Index:-0.1329 R2:0.6187 0.5507 0.5140 RMSE:0.6112 0.6712 0.6700 Tau:0.5915 0.5383 0.6453\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 107 Step: 16050 Index:-0.1216 R2:0.6119 0.5426 0.4998 RMSE:0.5826 0.6564 0.6423 Tau:0.5873 0.5348 0.6467\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 108 Step: 16200 Index:-0.1052 R2:0.6087 0.5591 0.5090 RMSE:0.5834 0.6448 0.6373 Tau:0.5782 0.5397 0.6489\n",
      "Epoch: 109 Step: 16350 Index:-0.0915 R2:0.6244 0.5709 0.5244 RMSE:0.5710 0.6348 0.6275 Tau:0.5910 0.5433 0.6455\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 110 Step: 16500 Index:-0.1145 R2:0.6171 0.5611 0.5069 RMSE:0.5894 0.6590 0.6467 Tau:0.5859 0.5445 0.6491\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 111 Step: 16650 Index:-0.1046 R2:0.6167 0.5569 0.5073 RMSE:0.5796 0.6453 0.6408 Tau:0.5861 0.5407 0.6529\n",
      "Epoch: 112 Step: 16800 Index:-0.0818 R2:0.6287 0.5731 0.5135 RMSE:0.5697 0.6336 0.6354 Tau:0.5959 0.5518 0.6454\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 113 Step: 16950 Index:-0.0954 R2:0.6260 0.5675 0.5258 RMSE:0.5745 0.6377 0.6353 Tau:0.5927 0.5423 0.6501\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 114 Step: 17100 Index:-0.0903 R2:0.6344 0.5747 0.5187 RMSE:0.5828 0.6438 0.6528 Tau:0.6013 0.5535 0.6496\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 115 Step: 17250 Index:-0.0852 R2:0.6277 0.5774 0.5157 RMSE:0.5702 0.6335 0.6390 Tau:0.5912 0.5482 0.6486\n",
      "Epoch: 116 Step: 17400 Index:-0.0679 R2:0.6244 0.5885 0.5155 RMSE:0.5704 0.6208 0.6357 Tau:0.5859 0.5529 0.6436\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 117 Step: 17550 Index:-0.0941 R2:0.6236 0.5627 0.5148 RMSE:0.5713 0.6405 0.6353 Tau:0.5946 0.5464 0.6468\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 118 Step: 17700 Index:-0.0788 R2:0.6304 0.5786 0.5029 RMSE:0.5749 0.6337 0.6562 Tau:0.5965 0.5549 0.6464\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 119 Step: 17850 Index:-0.0908 R2:0.6375 0.5717 0.5181 RMSE:0.5692 0.6434 0.6338 Tau:0.6045 0.5526 0.6542\n",
      "Epoch: 120 Step: 18000 Index:-0.0673 R2:0.6279 0.5833 0.5227 RMSE:0.5672 0.6231 0.6359 Tau:0.5951 0.5558 0.6462\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 121 Step: 18150 Index:-0.0780 R2:0.6410 0.5839 0.5217 RMSE:0.5799 0.6398 0.6492 Tau:0.6049 0.5618 0.6532\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 122 Step: 18300 Index:-0.0772 R2:0.6304 0.5766 0.5060 RMSE:0.5695 0.6311 0.6438 Tau:0.5945 0.5539 0.6484\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 123 Step: 18450 Index:-0.0828 R2:0.6346 0.5916 0.5252 RMSE:0.5959 0.6413 0.6656 Tau:0.5936 0.5585 0.6480\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 124 Step: 18600 Index:-0.0882 R2:0.6450 0.5792 0.5332 RMSE:0.5648 0.6391 0.6244 Tau:0.6057 0.5509 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 125 Step: 18750 Index:-0.0736 R2:0.6422 0.5869 0.5240 RMSE:0.5643 0.6317 0.6377 Tau:0.6016 0.5581 0.6569\n",
      "Epoch: 126 Step: 18900 Index:-0.0644 R2:0.6473 0.5906 0.5179 RMSE:0.5662 0.6263 0.6465 Tau:0.6070 0.5619 0.6535\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 127 Step: 19050 Index:-0.0837 R2:0.6375 0.5894 0.5148 RMSE:0.5919 0.6445 0.6804 Tau:0.6017 0.5608 0.6460\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 128 Step: 19200 Index:-0.0998 R2:0.6380 0.5612 0.5205 RMSE:0.5736 0.6477 0.6433 Tau:0.6036 0.5479 0.6496\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 129 Step: 19350 Index:-0.1203 R2:0.6356 0.5712 0.5095 RMSE:0.6166 0.6707 0.6915 Tau:0.6049 0.5504 0.6432\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 130 Step: 19500 Index:-0.1084 R2:0.6315 0.5627 0.5235 RMSE:0.5811 0.6496 0.6493 Tau:0.5971 0.5413 0.6482\n",
      "Epoch: 131 Step: 19650 Index:-0.0579 R2:0.6534 0.5926 0.5272 RMSE:0.5518 0.6202 0.6290 Tau:0.6110 0.5623 0.6527\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 132 Step: 19800 Index:-0.0691 R2:0.6495 0.5909 0.5213 RMSE:0.5727 0.6338 0.6588 Tau:0.6100 0.5648 0.6531\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 133 Step: 19950 Index:-0.1214 R2:0.6415 0.5627 0.5101 RMSE:0.5990 0.6699 0.6774 Tau:0.6051 0.5484 0.6500\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 134 Step: 20100 Index:-0.0899 R2:0.6491 0.5997 0.5198 RMSE:0.6099 0.6585 0.6888 Tau:0.6075 0.5686 0.6483\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 135 Step: 20250 Index:-0.0791 R2:0.6600 0.5898 0.5269 RMSE:0.5733 0.6401 0.6563 Tau:0.6163 0.5610 0.6521\n",
      "Epoch: 136 Step: 20400 Index:-0.0456 R2:0.6587 0.6002 0.5259 RMSE:0.5474 0.6141 0.6286 Tau:0.6141 0.5685 0.6550\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 137 Step: 20550 Index:-0.0758 R2:0.6541 0.5822 0.5295 RMSE:0.5655 0.6346 0.6505 Tau:0.6133 0.5588 0.6560\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 138 Step: 20700 Index:-0.0708 R2:0.6601 0.6004 0.5235 RMSE:0.5692 0.6400 0.6489 Tau:0.6150 0.5692 0.6604\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 139 Step: 20850 Index:-0.0656 R2:0.6592 0.5862 0.5181 RMSE:0.5524 0.6266 0.6421 Tau:0.6143 0.5610 0.6534\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 140 Step: 21000 Index:-0.0593 R2:0.6655 0.6016 0.5252 RMSE:0.5658 0.6291 0.6589 Tau:0.6175 0.5698 0.6493\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 141 Step: 21150 Index:-0.0535 R2:0.6536 0.6012 0.5215 RMSE:0.5553 0.6197 0.6374 Tau:0.6080 0.5661 0.6504\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 142 Step: 21300 Index:-0.0580 R2:0.6657 0.5920 0.5196 RMSE:0.5516 0.6258 0.6443 Tau:0.6215 0.5678 0.6548\n",
      "Epoch: 143 Step: 21450 Index:-0.0375 R2:0.6626 0.6076 0.5236 RMSE:0.5409 0.6062 0.6331 Tau:0.6134 0.5687 0.6515\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 144 Step: 21600 Index:-0.0635 R2:0.6580 0.5903 0.5316 RMSE:0.5462 0.6189 0.6277 Tau:0.6101 0.5555 0.6526\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 145 Step: 21750 Index:-0.0425 R2:0.6706 0.6106 0.5334 RMSE:0.5590 0.6191 0.6438 Tau:0.6229 0.5765 0.6541\n",
      "Epoch: 146 Step: 21900 Index:-0.0271 R2:0.6745 0.6131 0.5288 RMSE:0.5398 0.6066 0.6398 Tau:0.6261 0.5796 0.6584\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 147 Step: 22050 Index:-0.0502 R2:0.6560 0.6041 0.5041 RMSE:0.5579 0.6226 0.6475 Tau:0.6121 0.5725 0.6446\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 148 Step: 22200 Index:-0.0525 R2:0.6695 0.6088 0.5308 RMSE:0.5659 0.6254 0.6613 Tau:0.6206 0.5729 0.6522\n",
      "Epoch: 149 Step: 22350 Index:-0.0248 R2:0.6706 0.6115 0.5194 RMSE:0.5344 0.6021 0.6398 Tau:0.6199 0.5773 0.6530\n",
      "Epoch: 150 Step: 22500 Index:-0.0200 R2:0.6756 0.6149 0.5215 RMSE:0.5304 0.5999 0.6374 Tau:0.6274 0.5800 0.6589\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 151 Step: 22650 Index:-0.0743 R2:0.6667 0.6009 0.5226 RMSE:0.5676 0.6446 0.6535 Tau:0.6203 0.5703 0.6488\n",
      "Epoch: 152 Step: 22800 Index:-0.0168 R2:0.6760 0.6201 0.5188 RMSE:0.5351 0.5994 0.6398 Tau:0.6229 0.5826 0.6569\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 153 Step: 22950 Index:-0.0528 R2:0.6635 0.6048 0.5299 RMSE:0.5504 0.6218 0.6345 Tau:0.6149 0.5690 0.6507\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 154 Step: 23100 Index:-0.0392 R2:0.6759 0.6089 0.5383 RMSE:0.5377 0.6129 0.6209 Tau:0.6287 0.5737 0.6586\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 155 Step: 23250 Index:-0.0340 R2:0.6767 0.6107 0.5261 RMSE:0.5332 0.6090 0.6350 Tau:0.6252 0.5751 0.6585\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 156 Step: 23400 Index:-0.0297 R2:0.6785 0.6113 0.5282 RMSE:0.5291 0.6040 0.6310 Tau:0.6275 0.5743 0.6530\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 157 Step: 23550 Index:-0.0298 R2:0.6785 0.6146 0.5273 RMSE:0.5348 0.6070 0.6316 Tau:0.6293 0.5773 0.6559\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 158 Step: 23700 Index:-0.0944 R2:0.6847 0.6111 0.5371 RMSE:0.6160 0.6718 0.7114 Tau:0.6334 0.5773 0.6498\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 159 Step: 23850 Index:-0.0365 R2:0.6849 0.6158 0.5277 RMSE:0.5495 0.6173 0.6641 Tau:0.6333 0.5808 0.6554\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 160 Step: 24000 Index:-0.0616 R2:0.6703 0.5818 0.5116 RMSE:0.5368 0.6256 0.6401 Tau:0.6274 0.5640 0.6612\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 161 Step: 24150 Index:-0.0296 R2:0.6815 0.6105 0.5355 RMSE:0.5276 0.6032 0.6280 Tau:0.6273 0.5736 0.6589\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 162 Step: 24300 Index:-0.0437 R2:0.6764 0.6005 0.5262 RMSE:0.5351 0.6164 0.6325 Tau:0.6277 0.5727 0.6580\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 163 Step: 24450 Index:-0.0505 R2:0.6760 0.6065 0.5305 RMSE:0.5423 0.6231 0.6385 Tau:0.6236 0.5726 0.6635\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 164 Step: 24600 Index:-0.0375 R2:0.6870 0.6034 0.5340 RMSE:0.5262 0.6099 0.6371 Tau:0.6329 0.5724 0.6575\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 165 Step: 24750 Index:-0.0749 R2:0.6828 0.6211 0.5353 RMSE:0.6013 0.6541 0.7101 Tau:0.6302 0.5792 0.6504\n",
      "Epoch: 166 Step: 24900 Index:-0.0120 R2:0.6867 0.6192 0.5223 RMSE:0.5207 0.5968 0.6401 Tau:0.6336 0.5849 0.6614\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 167 Step: 25050 Index:-0.0692 R2:0.6674 0.5810 0.5069 RMSE:0.5460 0.6346 0.6475 Tau:0.6231 0.5654 0.6592\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 168 Step: 25200 Index:-0.0122 R2:0.6889 0.6218 0.5325 RMSE:0.5235 0.5959 0.6347 Tau:0.6335 0.5836 0.6550\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 169 Step: 25350 Index:-0.0204 R2:0.6828 0.6234 0.5353 RMSE:0.5324 0.6038 0.6327 Tau:0.6268 0.5834 0.6553\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 170 Step: 25500 Index:-0.0292 R2:0.6871 0.6123 0.5237 RMSE:0.5323 0.6085 0.6556 Tau:0.6318 0.5793 0.6585\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 171 Step: 25650 Index:-0.0589 R2:0.6969 0.6162 0.5430 RMSE:0.5687 0.6384 0.6787 Tau:0.6403 0.5795 0.6550\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 172 Step: 25800 Index:-0.0267 R2:0.6934 0.6146 0.5261 RMSE:0.5218 0.6070 0.6358 Tau:0.6390 0.5803 0.6616\n",
      "Epoch: 173 Step: 25950 Index:-0.0096 R2:0.6940 0.6285 0.5230 RMSE:0.5203 0.5964 0.6378 Tau:0.6360 0.5868 0.6608\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 174 Step: 26100 Index:-0.0120 R2:0.6973 0.6199 0.5216 RMSE:0.5123 0.5951 0.6413 Tau:0.6433 0.5832 0.6613\n",
      "Epoch: 175 Step: 26250 Index:-0.0079 R2:0.6985 0.6259 0.5324 RMSE:0.5156 0.5934 0.6284 Tau:0.6422 0.5854 0.6541\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 176 Step: 26400 Index:-0.0380 R2:0.6924 0.6041 0.5256 RMSE:0.5290 0.6133 0.6430 Tau:0.6394 0.5753 0.6541\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 177 Step: 26550 Index:-0.0448 R2:0.6963 0.6063 0.5140 RMSE:0.5300 0.6219 0.6402 Tau:0.6405 0.5771 0.6637\n",
      "Epoch: 178 Step: 26700 Index:-0.0006 R2:0.7009 0.6298 0.5295 RMSE:0.5114 0.5896 0.6315 Tau:0.6423 0.5891 0.6643\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 179 Step: 26850 Index:-0.0038 R2:0.6972 0.6290 0.5327 RMSE:0.5143 0.5887 0.6322 Tau:0.6370 0.5849 0.6558\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 180 Step: 27000 Index:-0.0313 R2:0.7022 0.6063 0.5212 RMSE:0.5145 0.6088 0.6338 Tau:0.6453 0.5776 0.6643\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 181 Step: 27150 Index:-0.0387 R2:0.6974 0.6092 0.5296 RMSE:0.5335 0.6160 0.6513 Tau:0.6366 0.5772 0.6498\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 182 Step: 27300 Index:-0.0121 R2:0.7034 0.6236 0.5182 RMSE:0.5229 0.6026 0.6556 Tau:0.6438 0.5905 0.6578\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 183 Step: 27450 Index:-0.0184 R2:0.7047 0.6162 0.5304 RMSE:0.5093 0.5999 0.6297 Tau:0.6464 0.5815 0.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 184 Step: 27600 Index:-0.0156 R2:0.7006 0.6266 0.5396 RMSE:0.5243 0.5987 0.6443 Tau:0.6414 0.5831 0.6493\n",
      "Epoch: 185 Step: 27750 Index:0.0069 R2:0.7001 0.6414 0.5292 RMSE:0.5228 0.5881 0.6560 Tau:0.6411 0.5950 0.6534\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 186 Step: 27900 Index:-0.0063 R2:0.6811 0.6261 0.5194 RMSE:0.5269 0.5905 0.6494 Tau:0.6246 0.5841 0.6496\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 187 Step: 28050 Index:-0.0098 R2:0.7090 0.6265 0.5294 RMSE:0.5102 0.5985 0.6342 Tau:0.6478 0.5887 0.6648\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 188 Step: 28200 Index:-0.0137 R2:0.7083 0.6302 0.5358 RMSE:0.5172 0.6017 0.6283 Tau:0.6464 0.5880 0.6620\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 189 Step: 28350 Index:-0.0101 R2:0.7023 0.6234 0.5370 RMSE:0.5083 0.5922 0.6344 Tau:0.6427 0.5821 0.6524\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 190 Step: 28500 Index:-0.0363 R2:0.7061 0.6130 0.5319 RMSE:0.5258 0.6149 0.6629 Tau:0.6451 0.5786 0.6603\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 191 Step: 28650 Index:-0.0038 R2:0.7172 0.6293 0.5340 RMSE:0.5037 0.5920 0.6429 Tau:0.6527 0.5883 0.6630\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 192 Step: 28800 Index:-0.0934 R2:0.7133 0.6217 0.5207 RMSE:0.6188 0.6840 0.7376 Tau:0.6520 0.5906 0.6538\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 193 Step: 28950 Index:-0.0035 R2:0.7167 0.6245 0.5296 RMSE:0.4983 0.5924 0.6405 Tau:0.6542 0.5889 0.6601\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 194 Step: 29100 Index:-0.0301 R2:0.7079 0.6057 0.5265 RMSE:0.5049 0.6069 0.6350 Tau:0.6479 0.5768 0.6625\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 195 Step: 29250 Index:-0.0044 R2:0.7097 0.6247 0.5252 RMSE:0.5041 0.5922 0.6442 Tau:0.6460 0.5878 0.6649\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 196 Step: 29400 Index:-0.0253 R2:0.7154 0.6093 0.5323 RMSE:0.5070 0.6070 0.6366 Tau:0.6553 0.5817 0.6545\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 197 Step: 29550 Index:-0.0581 R2:0.7093 0.6011 0.5372 RMSE:0.5292 0.6335 0.6345 Tau:0.6502 0.5753 0.6572\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 198 Step: 29700 Index:0.0054 R2:0.7184 0.6329 0.5349 RMSE:0.4954 0.5854 0.6373 Tau:0.6547 0.5907 0.6592\n",
      "Epoch: 199 Step: 29850 Index:0.0099 R2:0.7179 0.6341 0.5287 RMSE:0.4999 0.5871 0.6311 Tau:0.6552 0.5969 0.6581\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 200 Step: 30000 Index:-0.0063 R2:0.7124 0.6285 0.5268 RMSE:0.5042 0.5942 0.6422 Tau:0.6498 0.5879 0.6625\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 201 Step: 30150 Index:-0.0425 R2:0.7149 0.6057 0.5235 RMSE:0.5113 0.6142 0.6584 Tau:0.6507 0.5717 0.6577\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 202 Step: 30300 Index:-0.0169 R2:0.7224 0.6218 0.5164 RMSE:0.4986 0.6015 0.6495 Tau:0.6558 0.5847 0.6577\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 203 Step: 30450 Index:-0.0296 R2:0.7278 0.6317 0.5263 RMSE:0.5393 0.6235 0.6941 Tau:0.6609 0.5938 0.6571\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 204 Step: 30600 Index:-0.0409 R2:0.7182 0.6402 0.5240 RMSE:0.5847 0.6438 0.7092 Tau:0.6531 0.6029 0.6591\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 205 Step: 30750 Index:-0.0005 R2:0.7111 0.6236 0.5214 RMSE:0.5021 0.5939 0.6393 Tau:0.6509 0.5934 0.6532\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 206 Step: 30900 Index:-0.0160 R2:0.7095 0.6174 0.5240 RMSE:0.5099 0.6069 0.6407 Tau:0.6501 0.5909 0.6581\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 207 Step: 31050 Index:-0.0268 R2:0.7229 0.6095 0.5267 RMSE:0.4992 0.6071 0.6417 Tau:0.6605 0.5803 0.6568\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 208 Step: 31200 Index:0.0008 R2:0.7215 0.6267 0.5279 RMSE:0.4939 0.5911 0.6490 Tau:0.6566 0.5919 0.6633\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 209 Step: 31350 Index:-0.0315 R2:0.7202 0.6146 0.5220 RMSE:0.5158 0.6128 0.6665 Tau:0.6569 0.5813 0.6566\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 210 Step: 31500 Index:-0.0090 R2:0.7288 0.6284 0.5374 RMSE:0.5123 0.6060 0.6591 Tau:0.6641 0.5970 0.6621\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 211 Step: 31650 Index:0.0039 R2:0.7305 0.6331 0.5258 RMSE:0.4950 0.5918 0.6518 Tau:0.6605 0.5957 0.6593\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 212 Step: 31800 Index:-0.0157 R2:0.7292 0.6271 0.5309 RMSE:0.5156 0.6116 0.6692 Tau:0.6632 0.5959 0.6606\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 213 Step: 31950 Index:-0.0510 R2:0.7242 0.6266 0.5306 RMSE:0.5636 0.6462 0.7151 Tau:0.6596 0.5953 0.6621\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 214 Step: 32100 Index:-0.0134 R2:0.7321 0.6387 0.5299 RMSE:0.5182 0.6134 0.6618 Tau:0.6627 0.6000 0.6629\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 215 Step: 32250 Index:0.0020 R2:0.7346 0.6310 0.5195 RMSE:0.4967 0.5954 0.6565 Tau:0.6662 0.5975 0.6635\n",
      "Epoch: 216 Step: 32400 Index:0.0143 R2:0.7264 0.6367 0.5297 RMSE:0.4942 0.5850 0.6492 Tau:0.6578 0.5993 0.6632\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 217 Step: 32550 Index:-0.0386 R2:0.7306 0.5997 0.5177 RMSE:0.4936 0.6142 0.6543 Tau:0.6623 0.5756 0.6604\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 218 Step: 32700 Index:-0.0056 R2:0.7374 0.6221 0.5147 RMSE:0.4885 0.5988 0.6580 Tau:0.6691 0.5932 0.6610\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 219 Step: 32850 Index:-0.0275 R2:0.7343 0.6140 0.5231 RMSE:0.5043 0.6162 0.6733 Tau:0.6692 0.5887 0.6649\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 220 Step: 33000 Index:-0.0164 R2:0.7232 0.6284 0.5211 RMSE:0.5217 0.6133 0.6900 Tau:0.6566 0.5970 0.6629\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 221 Step: 33150 Index:0.0013 R2:0.7341 0.6257 0.5226 RMSE:0.4842 0.5926 0.6549 Tau:0.6637 0.5939 0.6595\n",
      "Epoch: 222 Step: 33300 Index:0.0231 R2:0.7402 0.6371 0.5194 RMSE:0.4763 0.5820 0.6525 Tau:0.6697 0.6050 0.6594\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 223 Step: 33450 Index:0.0030 R2:0.7309 0.6221 0.5055 RMSE:0.4893 0.5944 0.6561 Tau:0.6642 0.5975 0.6536\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 224 Step: 33600 Index:0.0092 R2:0.7437 0.6262 0.5242 RMSE:0.4730 0.5901 0.6465 Tau:0.6736 0.5993 0.6634\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 225 Step: 33750 Index:-0.0015 R2:0.7456 0.6293 0.5222 RMSE:0.4950 0.6019 0.6640 Tau:0.6738 0.6004 0.6644\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 226 Step: 33900 Index:-0.0212 R2:0.7419 0.6172 0.5148 RMSE:0.5040 0.6144 0.6694 Tau:0.6715 0.5932 0.6577\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 227 Step: 34050 Index:-0.0057 R2:0.7414 0.6232 0.5123 RMSE:0.4851 0.6019 0.6538 Tau:0.6706 0.5962 0.6625\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 228 Step: 34200 Index:0.0029 R2:0.7437 0.6223 0.5244 RMSE:0.4744 0.5930 0.6412 Tau:0.6712 0.5959 0.6670\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 229 Step: 34350 Index:-0.0013 R2:0.7399 0.6320 0.5316 RMSE:0.4989 0.6038 0.6680 Tau:0.6708 0.6025 0.6641\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 230 Step: 34500 Index:0.0163 R2:0.7426 0.6354 0.5257 RMSE:0.4725 0.5834 0.6515 Tau:0.6706 0.5997 0.6610\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 231 Step: 34650 Index:0.0013 R2:0.7507 0.6330 0.5341 RMSE:0.4897 0.6013 0.6611 Tau:0.6784 0.6026 0.6608\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 232 Step: 34800 Index:-0.0028 R2:0.7453 0.6385 0.5349 RMSE:0.5059 0.6093 0.6442 Tau:0.6731 0.6065 0.6615\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 233 Step: 34950 Index:-0.0077 R2:0.7450 0.6193 0.5254 RMSE:0.4908 0.6057 0.6567 Tau:0.6748 0.5980 0.6593\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 234 Step: 35100 Index:0.0019 R2:0.7439 0.6300 0.5308 RMSE:0.4876 0.6012 0.6516 Tau:0.6737 0.6032 0.6665\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 235 Step: 35250 Index:-0.0037 R2:0.7445 0.6272 0.5264 RMSE:0.4880 0.6032 0.6690 Tau:0.6738 0.5995 0.6612\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 236 Step: 35400 Index:0.0108 R2:0.7464 0.6366 0.5233 RMSE:0.4865 0.5943 0.6476 Tau:0.6748 0.6052 0.6604\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 237 Step: 35550 Index:0.0055 R2:0.7498 0.6258 0.5378 RMSE:0.4680 0.5908 0.6329 Tau:0.6752 0.5963 0.6680\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 238 Step: 35700 Index:-0.0037 R2:0.7476 0.6291 0.5404 RMSE:0.4936 0.6078 0.6648 Tau:0.6768 0.6041 0.6689\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 239 Step: 35850 Index:0.0023 R2:0.7423 0.6198 0.5176 RMSE:0.4732 0.5961 0.6530 Tau:0.6715 0.5984 0.6665\n",
      "Epoch: 240 Step: 36000 Index:0.0233 R2:0.7467 0.6359 0.5288 RMSE:0.4690 0.5827 0.6465 Tau:0.6730 0.6060 0.6659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 241 Step: 36150 Index:-0.0141 R2:0.7399 0.6066 0.5178 RMSE:0.4793 0.6079 0.6558 Tau:0.6744 0.5938 0.6680\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 242 Step: 36300 Index:0.0033 R2:0.7469 0.6390 0.5149 RMSE:0.5004 0.6036 0.6876 Tau:0.6730 0.6070 0.6597\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 243 Step: 36450 Index:-0.0187 R2:0.7434 0.6023 0.5159 RMSE:0.4803 0.6086 0.6414 Tau:0.6746 0.5900 0.6537\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 244 Step: 36600 Index:0.0037 R2:0.7490 0.6226 0.5230 RMSE:0.4713 0.5965 0.6582 Tau:0.6756 0.6002 0.6679\n",
      "Epoch: 245 Step: 36750 Index:0.0404 R2:0.7539 0.6483 0.5318 RMSE:0.4648 0.5737 0.6503 Tau:0.6774 0.6142 0.6677\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 246 Step: 36900 Index:-0.0049 R2:0.7570 0.6363 0.5233 RMSE:0.5108 0.6171 0.6923 Tau:0.6805 0.6122 0.6627\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 247 Step: 37050 Index:0.0002 R2:0.7482 0.6287 0.5397 RMSE:0.4876 0.6037 0.6634 Tau:0.6751 0.6040 0.6621\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 248 Step: 37200 Index:0.0030 R2:0.7535 0.6207 0.5260 RMSE:0.4653 0.5946 0.6402 Tau:0.6796 0.5976 0.6629\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 249 Step: 37350 Index:0.0101 R2:0.7524 0.6251 0.5333 RMSE:0.4634 0.5921 0.6431 Tau:0.6803 0.6022 0.6673\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 250 Step: 37500 Index:-0.0032 R2:0.7527 0.6147 0.5289 RMSE:0.4643 0.6007 0.6516 Tau:0.6798 0.5975 0.6637\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 251 Step: 37650 Index:-0.0129 R2:0.7467 0.6175 0.5224 RMSE:0.4748 0.6047 0.6549 Tau:0.6712 0.5918 0.6649\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 252 Step: 37800 Index:0.0082 R2:0.7533 0.6236 0.5082 RMSE:0.4662 0.5951 0.6564 Tau:0.6793 0.6033 0.6585\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 253 Step: 37950 Index:0.0220 R2:0.7520 0.6354 0.5402 RMSE:0.4667 0.5874 0.6532 Tau:0.6782 0.6094 0.6582\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 254 Step: 38100 Index:-0.0039 R2:0.7420 0.6166 0.5317 RMSE:0.4732 0.5992 0.6496 Tau:0.6720 0.5953 0.6581\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 255 Step: 38250 Index:-0.0093 R2:0.7529 0.6233 0.5392 RMSE:0.5031 0.6172 0.6709 Tau:0.6810 0.6079 0.6571\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 256 Step: 38400 Index:0.0323 R2:0.7578 0.6384 0.5386 RMSE:0.4608 0.5821 0.6463 Tau:0.6834 0.6144 0.6620\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 257 Step: 38550 Index:-0.0029 R2:0.7611 0.6185 0.5338 RMSE:0.4678 0.6051 0.6575 Tau:0.6854 0.6022 0.6672\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 258 Step: 38700 Index:0.0152 R2:0.7610 0.6266 0.5377 RMSE:0.4597 0.5902 0.6385 Tau:0.6878 0.6054 0.6657\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 259 Step: 38850 Index:0.0217 R2:0.7522 0.6380 0.5309 RMSE:0.4738 0.5904 0.6471 Tau:0.6768 0.6122 0.6686\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 260 Step: 39000 Index:0.0133 R2:0.7574 0.6244 0.5139 RMSE:0.4659 0.5957 0.6614 Tau:0.6822 0.6089 0.6595\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 261 Step: 39150 Index:-0.0403 R2:0.7600 0.6189 0.5401 RMSE:0.5212 0.6447 0.7015 Tau:0.6887 0.6044 0.6677\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 262 Step: 39300 Index:0.0014 R2:0.7603 0.6171 0.5223 RMSE:0.4567 0.5990 0.6499 Tau:0.6848 0.6004 0.6604\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 263 Step: 39450 Index:0.0224 R2:0.7685 0.6299 0.5357 RMSE:0.4481 0.5893 0.6451 Tau:0.6902 0.6117 0.6706\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 264 Step: 39600 Index:0.0240 R2:0.7641 0.6283 0.5221 RMSE:0.4584 0.5901 0.6518 Tau:0.6885 0.6141 0.6600\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 265 Step: 39750 Index:0.0203 R2:0.7645 0.6273 0.5214 RMSE:0.4551 0.5900 0.6515 Tau:0.6866 0.6102 0.6550\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 266 Step: 39900 Index:-0.0238 R2:0.7566 0.6054 0.5228 RMSE:0.4674 0.6148 0.6491 Tau:0.6826 0.5910 0.6583\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 267 Step: 40050 Index:0.0153 R2:0.7644 0.6226 0.5191 RMSE:0.4565 0.5953 0.6565 Tau:0.6891 0.6107 0.6672\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 268 Step: 40200 Index:-0.0066 R2:0.7671 0.6160 0.5367 RMSE:0.4735 0.6101 0.6520 Tau:0.6909 0.6035 0.6686\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 269 Step: 40350 Index:0.0105 R2:0.7509 0.6274 0.5271 RMSE:0.4636 0.5948 0.6576 Tau:0.6739 0.6054 0.6625\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 270 Step: 40500 Index:-0.0070 R2:0.7642 0.6273 0.5321 RMSE:0.4988 0.6195 0.6801 Tau:0.6889 0.6125 0.6614\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 271 Step: 40650 Index:0.0343 R2:0.7665 0.6385 0.5410 RMSE:0.4564 0.5876 0.6523 Tau:0.6904 0.6219 0.6717\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 272 Step: 40800 Index:-0.0069 R2:0.7579 0.6076 0.5185 RMSE:0.4668 0.6046 0.6435 Tau:0.6820 0.5977 0.6651\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 273 Step: 40950 Index:0.0132 R2:0.7608 0.6265 0.5174 RMSE:0.4546 0.5943 0.6660 Tau:0.6840 0.6074 0.6672\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 274 Step: 41100 Index:-0.0092 R2:0.7612 0.6149 0.5263 RMSE:0.4538 0.6072 0.6645 Tau:0.6842 0.5980 0.6718\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 275 Step: 41250 Index:0.0053 R2:0.7670 0.6210 0.5246 RMSE:0.4547 0.5988 0.6493 Tau:0.6882 0.6041 0.6627\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 276 Step: 41400 Index:0.0231 R2:0.7754 0.6319 0.5239 RMSE:0.4568 0.5932 0.6601 Tau:0.6956 0.6163 0.6640\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 277 Step: 41550 Index:0.0039 R2:0.7571 0.6193 0.5199 RMSE:0.4630 0.6043 0.6715 Tau:0.6844 0.6081 0.6731\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 278 Step: 41700 Index:0.0118 R2:0.7714 0.6300 0.5336 RMSE:0.4651 0.6031 0.6683 Tau:0.6927 0.6150 0.6614\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 279 Step: 41850 Index:-0.0326 R2:0.7652 0.6109 0.5175 RMSE:0.4858 0.6315 0.6924 Tau:0.6865 0.5989 0.6664\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 280 Step: 42000 Index:-0.0294 R2:0.7695 0.6220 0.5360 RMSE:0.4955 0.6374 0.7028 Tau:0.6949 0.6080 0.6694\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 281 Step: 42150 Index:0.0195 R2:0.7757 0.6246 0.5244 RMSE:0.4421 0.5946 0.6565 Tau:0.6967 0.6142 0.6704\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 282 Step: 42300 Index:0.0071 R2:0.7712 0.6320 0.5384 RMSE:0.4692 0.6056 0.6740 Tau:0.6942 0.6127 0.6637\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 283 Step: 42450 Index:0.0106 R2:0.7746 0.6267 0.5082 RMSE:0.4550 0.6043 0.6882 Tau:0.6952 0.6148 0.6662\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 284 Step: 42600 Index:0.0012 R2:0.7734 0.6210 0.5307 RMSE:0.4637 0.6082 0.6651 Tau:0.6951 0.6094 0.6663\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 285 Step: 42750 Index:0.0073 R2:0.7734 0.6346 0.5346 RMSE:0.4798 0.6095 0.6764 Tau:0.6927 0.6168 0.6654\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 286 Step: 42900 Index:-0.0373 R2:0.7695 0.6066 0.5323 RMSE:0.4772 0.6346 0.6834 Tau:0.6907 0.5973 0.6677\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 287 Step: 43050 Index:0.0115 R2:0.7785 0.6333 0.5349 RMSE:0.4606 0.6063 0.6749 Tau:0.6982 0.6178 0.6627\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 288 Step: 43200 Index:-0.0249 R2:0.7769 0.6120 0.5254 RMSE:0.4786 0.6326 0.6664 Tau:0.6973 0.6077 0.6736\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 289 Step: 43350 Index:-0.0109 R2:0.7687 0.6126 0.5233 RMSE:0.4836 0.6235 0.6794 Tau:0.6928 0.6126 0.6655\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 290 Step: 43500 Index:-0.0116 R2:0.7686 0.6096 0.5194 RMSE:0.4681 0.6158 0.6497 Tau:0.6928 0.6042 0.6671\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 291 Step: 43650 Index:-0.0009 R2:0.7762 0.6201 0.5146 RMSE:0.4561 0.6119 0.6848 Tau:0.6959 0.6109 0.6688\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 292 Step: 43800 Index:0.0266 R2:0.7779 0.6327 0.5369 RMSE:0.4413 0.5899 0.6478 Tau:0.6974 0.6165 0.6670\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 293 Step: 43950 Index:0.0275 R2:0.7778 0.6321 0.5362 RMSE:0.4399 0.5895 0.6472 Tau:0.6959 0.6169 0.6694\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 294 Step: 44100 Index:0.0101 R2:0.7725 0.6204 0.5263 RMSE:0.4523 0.6011 0.6497 Tau:0.6944 0.6112 0.6702\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 295 Step: 44250 Index:-0.0197 R2:0.7688 0.6145 0.5244 RMSE:0.4982 0.6315 0.6612 Tau:0.6931 0.6118 0.6749\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 296 Step: 44400 Index:-0.0372 R2:0.7808 0.6096 0.5279 RMSE:0.4888 0.6449 0.7013 Tau:0.7014 0.6078 0.6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 297 Step: 44550 Index:-0.0179 R2:0.7735 0.6203 0.5350 RMSE:0.4801 0.6282 0.6835 Tau:0.6941 0.6102 0.6698\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 298 Step: 44700 Index:-0.0157 R2:0.7759 0.6166 0.5276 RMSE:0.4723 0.6208 0.6554 Tau:0.6934 0.6051 0.6644\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 299 Step: 44850 Index:0.0061 R2:0.7807 0.6120 0.5285 RMSE:0.4412 0.6021 0.6421 Tau:0.6999 0.6082 0.6732\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 300 Step: 45000 Index:0.0127 R2:0.7778 0.6304 0.5258 RMSE:0.4547 0.6053 0.6768 Tau:0.6993 0.6180 0.6685\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 301 Step: 45150 Index:0.0041 R2:0.7857 0.6235 0.5273 RMSE:0.4548 0.6120 0.6777 Tau:0.7042 0.6161 0.6675\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 302 Step: 45300 Index:0.0279 R2:0.7878 0.6347 0.5343 RMSE:0.4454 0.5975 0.6642 Tau:0.7039 0.6254 0.6728\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 303 Step: 45450 Index:0.0146 R2:0.7806 0.6289 0.5384 RMSE:0.4432 0.6035 0.6647 Tau:0.7017 0.6181 0.6626\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 304 Step: 45600 Index:0.0079 R2:0.7805 0.6176 0.5362 RMSE:0.4385 0.5994 0.6410 Tau:0.6986 0.6073 0.6622\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 305 Step: 45750 Index:-0.0010 R2:0.7710 0.6133 0.5331 RMSE:0.4535 0.6122 0.6666 Tau:0.6953 0.6112 0.6652\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 306 Step: 45900 Index:0.0064 R2:0.7792 0.6185 0.5341 RMSE:0.4436 0.6049 0.6559 Tau:0.7010 0.6114 0.6733\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 307 Step: 46050 Index:-0.0060 R2:0.7758 0.6384 0.5311 RMSE:0.5106 0.6387 0.7181 Tau:0.6977 0.6327 0.6721\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 308 Step: 46200 Index:0.0134 R2:0.7825 0.6151 0.5278 RMSE:0.4426 0.6007 0.6443 Tau:0.7016 0.6141 0.6669\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 309 Step: 46350 Index:0.0278 R2:0.7814 0.6264 0.5225 RMSE:0.4408 0.5938 0.6573 Tau:0.6987 0.6215 0.6666\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 310 Step: 46500 Index:0.0293 R2:0.7750 0.6296 0.5238 RMSE:0.4419 0.5911 0.6585 Tau:0.6928 0.6204 0.6657\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 311 Step: 46650 Index:0.0231 R2:0.7843 0.6260 0.5246 RMSE:0.4476 0.5977 0.6584 Tau:0.6998 0.6208 0.6726\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 312 Step: 46800 Index:0.0294 R2:0.7901 0.6272 0.5320 RMSE:0.4301 0.5924 0.6499 Tau:0.7080 0.6217 0.6651\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 313 Step: 46950 Index:0.0314 R2:0.7781 0.6333 0.5432 RMSE:0.4427 0.5922 0.6504 Tau:0.6945 0.6236 0.6700\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 314 Step: 47100 Index:0.0131 R2:0.7755 0.6255 0.5362 RMSE:0.4415 0.6019 0.6558 Tau:0.6926 0.6151 0.6684\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 315 Step: 47250 Index:0.0206 R2:0.7870 0.6265 0.5397 RMSE:0.4317 0.5973 0.6465 Tau:0.7052 0.6179 0.6678\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 316 Step: 47400 Index:0.0001 R2:0.7844 0.6302 0.5315 RMSE:0.4682 0.6234 0.6925 Tau:0.7026 0.6235 0.6654\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 317 Step: 47550 Index:0.0081 R2:0.7855 0.6235 0.5276 RMSE:0.4448 0.6099 0.6609 Tau:0.7036 0.6179 0.6735\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 318 Step: 47700 Index:0.0113 R2:0.7794 0.6171 0.5124 RMSE:0.4467 0.6051 0.6701 Tau:0.6990 0.6165 0.6756\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 319 Step: 47850 Index:0.0273 R2:0.7832 0.6307 0.5281 RMSE:0.4489 0.5997 0.6521 Tau:0.6990 0.6270 0.6652\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 320 Step: 48000 Index:0.0037 R2:0.7865 0.6208 0.5351 RMSE:0.4553 0.6122 0.6436 Tau:0.7039 0.6158 0.6720\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 321 Step: 48150 Index:0.0227 R2:0.7876 0.6295 0.5385 RMSE:0.4313 0.5990 0.6528 Tau:0.7040 0.6217 0.6696\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 322 Step: 48300 Index:0.0080 R2:0.7857 0.6209 0.5318 RMSE:0.4310 0.6070 0.6656 Tau:0.7038 0.6149 0.6711\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 323 Step: 48450 Index:0.0081 R2:0.7938 0.6108 0.5269 RMSE:0.4288 0.6087 0.6553 Tau:0.7120 0.6168 0.6674\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 324 Step: 48600 Index:0.0183 R2:0.7781 0.6192 0.5213 RMSE:0.4400 0.5997 0.6541 Tau:0.6980 0.6181 0.6655\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 325 Step: 48750 Index:-0.0108 R2:0.7832 0.6111 0.5193 RMSE:0.4522 0.6236 0.6830 Tau:0.6993 0.6128 0.6764\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 326 Step: 48900 Index:-0.0234 R2:0.7899 0.6015 0.5221 RMSE:0.4442 0.6265 0.6788 Tau:0.7062 0.6031 0.6678\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 327 Step: 49050 Index:-0.0232 R2:0.7753 0.6073 0.5180 RMSE:0.4522 0.6206 0.6653 Tau:0.6917 0.5974 0.6692\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 328 Step: 49200 Index:0.0033 R2:0.7886 0.6059 0.5205 RMSE:0.4313 0.6119 0.6560 Tau:0.7104 0.6152 0.6700\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 329 Step: 49350 Index:0.0262 R2:0.7975 0.6233 0.5340 RMSE:0.4249 0.6001 0.6560 Tau:0.7158 0.6264 0.6741\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 330 Step: 49500 Index:-0.0211 R2:0.7906 0.6162 0.5379 RMSE:0.4619 0.6334 0.6878 Tau:0.7077 0.6123 0.6747\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 331 Step: 49650 Index:-0.0021 R2:0.7819 0.6185 0.5216 RMSE:0.4351 0.6102 0.6768 Tau:0.6970 0.6081 0.6711\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 332 Step: 49800 Index:-0.0301 R2:0.7836 0.6060 0.5306 RMSE:0.4662 0.6342 0.6850 Tau:0.7024 0.6041 0.6689\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 333 Step: 49950 Index:0.0118 R2:0.7933 0.6356 0.5413 RMSE:0.4512 0.6169 0.6871 Tau:0.7087 0.6287 0.6694\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 334 Step: 50100 Index:0.0062 R2:0.7937 0.6137 0.5266 RMSE:0.4267 0.6082 0.6650 Tau:0.7083 0.6144 0.6725\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 335 Step: 50250 Index:0.0226 R2:0.7897 0.6406 0.5270 RMSE:0.4473 0.6038 0.6880 Tau:0.7039 0.6264 0.6655\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 336 Step: 50400 Index:-0.0082 R2:0.7990 0.6089 0.5360 RMSE:0.4429 0.6259 0.6691 Tau:0.7150 0.6177 0.6736\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 337 Step: 50550 Index:-0.0138 R2:0.7941 0.6023 0.5326 RMSE:0.4250 0.6202 0.6577 Tau:0.7104 0.6063 0.6698\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 338 Step: 50700 Index:0.0238 R2:0.7987 0.6325 0.5400 RMSE:0.4372 0.6068 0.6680 Tau:0.7139 0.6305 0.6682\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 339 Step: 50850 Index:0.0041 R2:0.7981 0.6148 0.5343 RMSE:0.4254 0.6115 0.6608 Tau:0.7118 0.6156 0.6759\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 340 Step: 51000 Index:0.0083 R2:0.8014 0.6241 0.5352 RMSE:0.4311 0.6129 0.6592 Tau:0.7144 0.6211 0.6710\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 341 Step: 51150 Index:-0.0167 R2:0.8022 0.6112 0.5256 RMSE:0.4561 0.6418 0.6987 Tau:0.7167 0.6251 0.6777\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 342 Step: 51300 Index:0.0318 R2:0.7990 0.6265 0.5308 RMSE:0.4224 0.5967 0.6585 Tau:0.7115 0.6285 0.6725\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 343 Step: 51450 Index:0.0214 R2:0.8054 0.6221 0.5297 RMSE:0.4132 0.6055 0.6634 Tau:0.7202 0.6269 0.6722\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 344 Step: 51600 Index:0.0145 R2:0.8022 0.6162 0.5316 RMSE:0.4303 0.6112 0.6632 Tau:0.7191 0.6257 0.6701\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 345 Step: 51750 Index:-0.0016 R2:0.7913 0.6128 0.5153 RMSE:0.4269 0.6149 0.6772 Tau:0.7097 0.6132 0.6665\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 345 r2:0.5318 RMSE:0.6503 WTI:0.3923 AP:0.8657 Tau:0.6677 \n",
      " \n",
      " Top-1:0.5000 Top-1-fp:0.0000 \n",
      " Top-5:0.6585 Top-5-fp:0.0000 \n",
      " Top-10:0.6585 Top-10-fp:0.0122 \n",
      " Top-15:0.7073 Top-15-fp:0.0081 \n",
      " Top-20:0.7195 Top-20-fp:0.0244 \n",
      " Top-25:0.7610 Top-25-fp:0.0293 \n",
      " Top-30:0.8130 Top-30-fp:0.0325 \n",
      " Top-40:0.8537 Top-40-fp:0.0579 \n",
      " Top-50:0.8683 Top-50-fp:0.1268 \n",
      " \n",
      " Top50:0.6400 Top50-fp:0.0200 \n",
      " Top100:0.6600 Top100-fp:0.0100 \n",
      " Top150:0.7133 Top150-fp:0.0133 \n",
      " Top200:0.7500 Top200-fp:0.0300 \n",
      " Top250:0.8160 Top250-fp:0.0320 \n",
      " Top300:0.8233 Top300-fp:0.0467 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
