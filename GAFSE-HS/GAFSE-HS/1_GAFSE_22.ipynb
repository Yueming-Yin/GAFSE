{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P30543_1_250\n",
      "model_file/1_GAFSE_Ki_P30543_1_250yjt_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P30543_1_250_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P30543_1_250_test.csv\"\n",
    "test_active = 100\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  C1=CC=C(C(=C1)C=CC=NNC2=NC3=C(C(=N2)N)N=CN3C4C... -1.732394\n",
      "1  C1=CC=C(C=C1)C(CNC2=NC=NC3=C2N=CN3C4C(C(C(O4)C... -1.875061\n",
      "2  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CC4=C... -2.113943\n",
      "3  C1=CN(C(=O)N=C1N)C2C(C(C(O2)COP(=O)(O)OP(=O)(O... -1.204120\n",
      "4                C1C(C(C(C1N2C=NC3=C2N=CN=C3N)O)O)CO -3.332438\n",
      "number of all smiles:  1286\n",
      "number of successfully processed smiles:  1286\n",
      "                                              smiles     value  \\\n",
      "0  C1=CC=C(C(=C1)C=CC=NNC2=NC3=C(C(=N2)N)N=CN3C4C... -1.732394   \n",
      "1  C1=CC=C(C=C1)C(CNC2=NC=NC3=C2N=CN3C4C(C(C(O4)C... -1.875061   \n",
      "2  CCNC(=O)C1C(C(C(O1)N2C=NC3=C2N=C(N=C3N)C#CC4=C... -2.113943   \n",
      "3  C1=CN(C(=O)N=C1N)C2C(C(C(O2)COP(=O)(O)OP(=O)(O... -1.204120   \n",
      "4                C1C(C(C(C1N2C=NC3=C2N=CN=C3N)O)O)CO -3.332438   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Nc1nc(NN=CC=Cc2ccccc2[N+](=O)[O-])nc2c1ncn2C1O...  \n",
      "1  OCC1OC(n2cnc3c(NCC(c4ccccc4)c4ccccc4)ncnc32)C(...  \n",
      "2  CCNC(=O)C1OC(n2cnc3c(N)nc(C#Cc4ccco4)nc32)C(O)C1O  \n",
      "3   Nc1ccn(C2OC(COP(=O)(O)OP(=O)(O)O)C(O)C2O)c(=O)n1  \n",
      "4                      Nc1ncnc2c1ncn2C1CC(CO)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  684\n",
      "number of successfully processed smiles:  684\n",
      "(684, 3)\n",
      "                                              smiles     value  \\\n",
      "0    C1=CC(=CC(=C1)N)C2=CC3=NC(=NN3C(=N2)N)C4=CC=CO4 -0.698970   \n",
      "1  CNC(=O)C1CC(C(O1)N2C=NC3=C2N=C(N=C3NCC4=CC(=CC... -3.668386   \n",
      "2  C1=CC=C(C=C1)CNC(=O)C2=CN3C(=NC(=N3)C4=CC=CO4)... -0.301030   \n",
      "3   CCN1C2=C(C(=O)N(C1=O)CC)N(C(=N2)CCCC3=CC=CC=C3)C -3.594393   \n",
      "4  COCC1C(C(C(O1)N2C=NC3=C2N=CN=C3NCC4=CC(=CC=C4)... -2.571709   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0             Nc1cccc(-c2cc3nc(-c4ccco4)nn3c(N)n2)c1  \n",
      "1  CNC(=O)C1CC(O)C(n2cnc3c(NCc4cccc(I)c4)nc(Cl)nc...  \n",
      "2          Nc1nc(C(=O)NCc2ccccc2)cn2nc(-c3ccco3)nc12  \n",
      "3          CCn1c(=O)c2c(nc(CCCc3ccccc3)n2C)n(CC)c1=O  \n",
      "4       COCC1OC(n2cnc3c(NCc4cccc(I)c4)ncnc32)C(O)C1O  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P30543_1_250_train.pickle\n",
      "./data/benchmark/Ki_P30543_1_250_train\n",
      "1970\n",
      "feature dicts file saved as ./data/benchmark/Ki_P30543_1_250_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1029, 3) (257, 3) (684, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_Ki_P30543_1_250yjt_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 102 Index:-0.9021 R2:0.0425 0.0497 0.0142 RMSE:1.0300 1.0385 1.0463 Tau:0.1309 0.1364 0.0481\n",
      "Epoch: 2 Step: 204 Index:-0.7110 R2:0.1572 0.1538 0.1778 RMSE:0.9832 0.9928 0.9682 Tau:0.2670 0.2818 0.2308\n",
      "Epoch: 3 Step: 306 Index:-0.6636 R2:0.2054 0.1936 0.2240 RMSE:0.9514 0.9658 0.9410 Tau:0.3063 0.3022 0.2678\n",
      "Epoch: 4 Step: 408 Index:-0.6172 R2:0.2402 0.2177 0.2393 RMSE:0.9237 0.9450 0.9473 Tau:0.3325 0.3278 0.2837\n",
      "Epoch: 5 Step: 510 Index:-0.5694 R2:0.2730 0.2452 0.2626 RMSE:0.9049 0.9271 0.9186 Tau:0.3615 0.3577 0.3185\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 6 Step: 612 Index:-0.5918 R2:0.2989 0.2541 0.2543 RMSE:0.9204 0.9614 0.9899 Tau:0.3791 0.3696 0.3277\n",
      "Epoch: 7 Step: 714 Index:-0.5241 R2:0.3144 0.2741 0.2690 RMSE:0.8729 0.9056 0.9140 Tau:0.3928 0.3815 0.3410\n",
      "Epoch: 8 Step: 816 Index:-0.5036 R2:0.3363 0.2893 0.2693 RMSE:0.8588 0.8967 0.9141 Tau:0.4100 0.3931 0.3505\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 918 Index:-0.5309 R2:0.3404 0.2786 0.2673 RMSE:0.8703 0.9182 0.9353 Tau:0.4075 0.3873 0.3278\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 10 Step: 1020 Index:-0.5142 R2:0.3573 0.3011 0.2939 RMSE:0.8663 0.9172 0.9425 Tau:0.4191 0.4030 0.3398\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 11 Step: 1122 Index:-0.5279 R2:0.3680 0.3072 0.2998 RMSE:0.8765 0.9358 0.9705 Tau:0.4295 0.4079 0.3533\n",
      "Epoch: 12 Step: 1224 Index:-0.4614 R2:0.3804 0.3227 0.3093 RMSE:0.8324 0.8746 0.8816 Tau:0.4370 0.4131 0.3542\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 13 Step: 1326 Index:-0.4660 R2:0.3900 0.3235 0.3199 RMSE:0.8272 0.8834 0.8997 Tau:0.4433 0.4174 0.3545\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 14 Step: 1428 Index:-0.4684 R2:0.3996 0.3218 0.3252 RMSE:0.8243 0.8880 0.9023 Tau:0.4489 0.4196 0.3547\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 15 Step: 1530 Index:-0.4708 R2:0.3982 0.3219 0.3340 RMSE:0.8465 0.8894 0.8668 Tau:0.4488 0.4186 0.3586\n",
      "Epoch: 16 Step: 1632 Index:-0.4490 R2:0.4109 0.3322 0.3274 RMSE:0.8137 0.8707 0.8786 Tau:0.4563 0.4217 0.3558\n",
      "Epoch: 17 Step: 1734 Index:-0.4438 R2:0.4158 0.3311 0.3420 RMSE:0.8097 0.8687 0.8611 Tau:0.4589 0.4249 0.3562\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 18 Step: 1836 Index:-0.4718 R2:0.4202 0.3291 0.3529 RMSE:0.8167 0.8952 0.9007 Tau:0.4604 0.4234 0.3529\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 19 Step: 1938 Index:-0.4593 R2:0.4204 0.3306 0.3608 RMSE:0.8081 0.8838 0.8807 Tau:0.4621 0.4245 0.3585\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 20 Step: 2040 Index:-0.4620 R2:0.4342 0.3336 0.3604 RMSE:0.8049 0.8890 0.8925 Tau:0.4699 0.4270 0.3581\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 21 Step: 2142 Index:-0.4475 R2:0.4349 0.3320 0.3710 RMSE:0.7938 0.8748 0.8618 Tau:0.4705 0.4273 0.3595\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 22 Step: 2244 Index:-0.4561 R2:0.4403 0.3390 0.3759 RMSE:0.8310 0.8867 0.8413 Tau:0.4753 0.4306 0.3633\n",
      "Epoch: 23 Step: 2346 Index:-0.4340 R2:0.4410 0.3439 0.3718 RMSE:0.8032 0.8670 0.8348 Tau:0.4746 0.4330 0.3607\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 24 Step: 2448 Index:-0.4361 R2:0.4486 0.3381 0.3890 RMSE:0.7864 0.8655 0.8275 Tau:0.4796 0.4293 0.3651\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 25 Step: 2550 Index:-0.5308 R2:0.4496 0.3190 0.3763 RMSE:0.8384 0.9517 0.9461 Tau:0.4760 0.4209 0.3500\n",
      "Epoch: 26 Step: 2652 Index:-0.4297 R2:0.4595 0.3450 0.3857 RMSE:0.7768 0.8597 0.8372 Tau:0.4864 0.4300 0.3599\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 27 Step: 2754 Index:-0.4380 R2:0.4580 0.3394 0.3962 RMSE:0.7913 0.8687 0.8209 Tau:0.4883 0.4307 0.3651\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 28 Step: 2856 Index:-0.4396 R2:0.4680 0.3430 0.4078 RMSE:0.7732 0.8728 0.8475 Tau:0.4898 0.4332 0.3618\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 29 Step: 2958 Index:-0.4311 R2:0.4705 0.3448 0.4021 RMSE:0.7836 0.8661 0.8159 Tau:0.4913 0.4350 0.3636\n",
      "Epoch: 30 Step: 3060 Index:-0.4246 R2:0.4649 0.3494 0.4232 RMSE:0.7693 0.8593 0.8120 Tau:0.4919 0.4348 0.3691\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 31 Step: 3162 Index:-0.5600 R2:0.4785 0.3331 0.4070 RMSE:0.8655 0.9865 0.9886 Tau:0.4946 0.4265 0.3621\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 32 Step: 3264 Index:-0.4676 R2:0.4745 0.3345 0.4031 RMSE:0.7865 0.8992 0.8847 Tau:0.4948 0.4316 0.3721\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 33 Step: 3366 Index:-0.4316 R2:0.4786 0.3453 0.3842 RMSE:0.7745 0.8611 0.8296 Tau:0.4989 0.4295 0.3594\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 34 Step: 3468 Index:-0.4309 R2:0.4774 0.3526 0.4287 RMSE:0.7825 0.8698 0.7961 Tau:0.4982 0.4389 0.3697\n",
      "Epoch: 35 Step: 3570 Index:-0.4101 R2:0.4883 0.3575 0.4314 RMSE:0.7565 0.8514 0.8072 Tau:0.5013 0.4413 0.3624\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 36 Step: 3672 Index:-0.4403 R2:0.4858 0.3509 0.4273 RMSE:0.7691 0.8817 0.8510 Tau:0.4971 0.4414 0.3605\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 37 Step: 3774 Index:-0.4675 R2:0.4947 0.3415 0.4203 RMSE:0.7786 0.9033 0.8794 Tau:0.5036 0.4358 0.3656\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 38 Step: 3876 Index:-0.4141 R2:0.4982 0.3622 0.4299 RMSE:0.7504 0.8557 0.8269 Tau:0.5086 0.4416 0.3637\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 39 Step: 3978 Index:-0.4372 R2:0.4975 0.3605 0.4414 RMSE:0.7944 0.8811 0.7965 Tau:0.5066 0.4439 0.3705\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 40 Step: 4080 Index:-0.4266 R2:0.5057 0.3515 0.4338 RMSE:0.7466 0.8676 0.8290 Tau:0.5117 0.4411 0.3735\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 41 Step: 4182 Index:-0.4224 R2:0.5093 0.3475 0.4230 RMSE:0.7463 0.8591 0.8047 Tau:0.5143 0.4367 0.3724\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 42 Step: 4284 Index:-0.4581 R2:0.5116 0.3527 0.4408 RMSE:0.7636 0.8954 0.8683 Tau:0.5166 0.4373 0.3758\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 43 Step: 4386 Index:-0.4452 R2:0.5164 0.3500 0.4357 RMSE:0.7526 0.8845 0.8533 Tau:0.5173 0.4392 0.3751\n",
      "Epoch: 44 Step: 4488 Index:-0.3973 R2:0.5170 0.3706 0.4426 RMSE:0.7348 0.8439 0.8022 Tau:0.5186 0.4465 0.3664\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 45 Step: 4590 Index:-0.4310 R2:0.5208 0.3579 0.4282 RMSE:0.7450 0.8713 0.8492 Tau:0.5222 0.4403 0.3692\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 46 Step: 4692 Index:-0.4428 R2:0.5206 0.3465 0.4274 RMSE:0.7403 0.8761 0.8421 Tau:0.5225 0.4333 0.3789\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 47 Step: 4794 Index:-0.4255 R2:0.5270 0.3511 0.4375 RMSE:0.7279 0.8645 0.8169 Tau:0.5257 0.4390 0.3784\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 48 Step: 4896 Index:-0.4544 R2:0.5287 0.3582 0.4522 RMSE:0.7632 0.9006 0.8727 Tau:0.5253 0.4462 0.3860\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 49 Step: 4998 Index:-0.4073 R2:0.5322 0.3583 0.4473 RMSE:0.7248 0.8522 0.7891 Tau:0.5275 0.4450 0.3788\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 50 Step: 5100 Index:-0.4251 R2:0.5349 0.3662 0.4573 RMSE:0.7372 0.8724 0.8356 Tau:0.5299 0.4473 0.3812\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 51 Step: 5202 Index:-0.3987 R2:0.5360 0.3693 0.4508 RMSE:0.7207 0.8454 0.7855 Tau:0.5307 0.4467 0.3798\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 52 Step: 5304 Index:-0.3975 R2:0.5374 0.3745 0.4623 RMSE:0.7187 0.8490 0.7995 Tau:0.5298 0.4515 0.3793\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 53 Step: 5406 Index:-0.4177 R2:0.5392 0.3612 0.4530 RMSE:0.7215 0.8606 0.8128 Tau:0.5334 0.4429 0.3889\n",
      "Epoch: 54 Step: 5508 Index:-0.3910 R2:0.5472 0.3741 0.4550 RMSE:0.7161 0.8417 0.7793 Tau:0.5360 0.4506 0.3780\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 55 Step: 5610 Index:-0.4621 R2:0.5497 0.3621 0.4501 RMSE:0.7613 0.9115 0.8845 Tau:0.5369 0.4495 0.3785\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 56 Step: 5712 Index:-0.4146 R2:0.5393 0.3532 0.4596 RMSE:0.7219 0.8588 0.7778 Tau:0.5365 0.4442 0.3984\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 57 Step: 5814 Index:-0.4079 R2:0.5550 0.3789 0.4613 RMSE:0.7215 0.8619 0.8312 Tau:0.5445 0.4541 0.3816\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 58 Step: 5916 Index:-0.4358 R2:0.5490 0.3620 0.4838 RMSE:0.7330 0.8892 0.8231 Tau:0.5364 0.4534 0.3922\n",
      "Epoch: 59 Step: 6018 Index:-0.3830 R2:0.5526 0.3783 0.4785 RMSE:0.7128 0.8409 0.7612 Tau:0.5383 0.4579 0.3805\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 60 Step: 6120 Index:-0.3891 R2:0.5540 0.3777 0.4692 RMSE:0.7050 0.8436 0.7898 Tau:0.5448 0.4545 0.3908\n",
      "Epoch: 61 Step: 6222 Index:-0.3795 R2:0.5614 0.3844 0.4606 RMSE:0.7080 0.8361 0.7741 Tau:0.5471 0.4566 0.3834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 62 Step: 6324 Index:-0.3959 R2:0.5594 0.3730 0.4827 RMSE:0.6982 0.8499 0.7732 Tau:0.5472 0.4540 0.3961\n",
      "Epoch: 63 Step: 6426 Index:-0.3695 R2:0.5697 0.3884 0.4801 RMSE:0.6943 0.8321 0.7657 Tau:0.5498 0.4625 0.3827\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 64 Step: 6528 Index:-0.3972 R2:0.5717 0.3837 0.4973 RMSE:0.7052 0.8611 0.7987 Tau:0.5524 0.4639 0.3874\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 65 Step: 6630 Index:-0.3763 R2:0.5749 0.3942 0.4747 RMSE:0.6966 0.8433 0.8039 Tau:0.5557 0.4670 0.3827\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 66 Step: 6732 Index:-0.3784 R2:0.5780 0.3810 0.4913 RMSE:0.6854 0.8392 0.7587 Tau:0.5583 0.4608 0.3946\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 67 Step: 6834 Index:-0.3979 R2:0.5744 0.3798 0.4556 RMSE:0.6963 0.8531 0.8140 Tau:0.5550 0.4552 0.3867\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 68 Step: 6936 Index:-0.4057 R2:0.5729 0.3944 0.4863 RMSE:0.7437 0.8699 0.7668 Tau:0.5553 0.4641 0.3940\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 69 Step: 7038 Index:-0.3791 R2:0.5862 0.3830 0.5079 RMSE:0.6793 0.8428 0.7598 Tau:0.5640 0.4636 0.4010\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 70 Step: 7140 Index:-0.3757 R2:0.5875 0.3916 0.4975 RMSE:0.6794 0.8415 0.7742 Tau:0.5646 0.4658 0.3942\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 71 Step: 7242 Index:-0.4497 R2:0.5844 0.3819 0.5143 RMSE:0.7422 0.9117 0.8552 Tau:0.5649 0.4620 0.4004\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 72 Step: 7344 Index:-0.4278 R2:0.5868 0.3854 0.5015 RMSE:0.7618 0.8925 0.7757 Tau:0.5638 0.4647 0.3927\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 73 Step: 7446 Index:-0.3807 R2:0.5925 0.3979 0.5033 RMSE:0.6936 0.8533 0.7978 Tau:0.5634 0.4726 0.3860\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 74 Step: 7548 Index:-0.4094 R2:0.5930 0.3846 0.5040 RMSE:0.6961 0.8705 0.8060 Tau:0.5671 0.4611 0.3900\n",
      "Epoch: 75 Step: 7650 Index:-0.3567 R2:0.6000 0.3959 0.5018 RMSE:0.6708 0.8274 0.7527 Tau:0.5693 0.4708 0.3851\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 76 Step: 7752 Index:-0.3952 R2:0.5993 0.3865 0.5200 RMSE:0.6857 0.8627 0.7872 Tau:0.5731 0.4675 0.3979\n",
      "Epoch: 77 Step: 7854 Index:-0.3476 R2:0.6030 0.4022 0.5076 RMSE:0.6665 0.8241 0.7523 Tau:0.5774 0.4765 0.3883\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 78 Step: 7956 Index:-0.3500 R2:0.6053 0.4059 0.4986 RMSE:0.6820 0.8283 0.7452 Tau:0.5754 0.4784 0.3913\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 79 Step: 8058 Index:-0.3634 R2:0.6085 0.3971 0.5155 RMSE:0.6634 0.8367 0.7600 Tau:0.5788 0.4733 0.3986\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 80 Step: 8160 Index:-0.4046 R2:0.5894 0.3697 0.5205 RMSE:0.6813 0.8676 0.7621 Tau:0.5659 0.4630 0.4039\n",
      "Epoch: 81 Step: 8262 Index:-0.3433 R2:0.6059 0.4118 0.5134 RMSE:0.6678 0.8225 0.7346 Tau:0.5763 0.4791 0.3909\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 82 Step: 8364 Index:-0.3785 R2:0.6093 0.4068 0.5188 RMSE:0.6847 0.8572 0.8007 Tau:0.5793 0.4787 0.3930\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 83 Step: 8466 Index:-0.3458 R2:0.6111 0.4097 0.4953 RMSE:0.6772 0.8227 0.7472 Tau:0.5801 0.4770 0.3822\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 84 Step: 8568 Index:-0.3644 R2:0.6175 0.4041 0.5189 RMSE:0.6647 0.8405 0.7707 Tau:0.5832 0.4761 0.3888\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 85 Step: 8670 Index:-0.3487 R2:0.6171 0.4059 0.4902 RMSE:0.6617 0.8223 0.7516 Tau:0.5822 0.4735 0.3893\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 86 Step: 8772 Index:-0.3437 R2:0.6116 0.4055 0.5328 RMSE:0.6587 0.8272 0.7209 Tau:0.5806 0.4835 0.3967\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 87 Step: 8874 Index:-0.3989 R2:0.6234 0.4044 0.5177 RMSE:0.6971 0.8775 0.8254 Tau:0.5869 0.4787 0.3969\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 88 Step: 8976 Index:-0.3720 R2:0.6209 0.4040 0.5329 RMSE:0.6665 0.8508 0.7699 Tau:0.5860 0.4788 0.3981\n",
      "Epoch: 89 Step: 9078 Index:-0.3404 R2:0.6197 0.4126 0.4919 RMSE:0.6555 0.8167 0.7641 Tau:0.5871 0.4762 0.3844\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 90 Step: 9180 Index:-0.3701 R2:0.6225 0.4125 0.5302 RMSE:0.6777 0.8524 0.7888 Tau:0.5851 0.4823 0.3924\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 91 Step: 9282 Index:-0.3465 R2:0.6241 0.4228 0.5274 RMSE:0.6822 0.8314 0.7279 Tau:0.5902 0.4849 0.3924\n",
      "Epoch: 92 Step: 9384 Index:-0.3316 R2:0.6246 0.4175 0.5406 RMSE:0.6481 0.8192 0.7144 Tau:0.5887 0.4877 0.3964\n",
      "Epoch: 93 Step: 9486 Index:-0.3179 R2:0.6316 0.4277 0.5215 RMSE:0.6442 0.8087 0.7293 Tau:0.5938 0.4908 0.3945\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 94 Step: 9588 Index:-0.3342 R2:0.6330 0.4277 0.5190 RMSE:0.6541 0.8264 0.7794 Tau:0.5965 0.4922 0.3870\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 95 Step: 9690 Index:-0.3389 R2:0.6262 0.4258 0.4944 RMSE:0.6786 0.8256 0.7514 Tau:0.5896 0.4867 0.3854\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 96 Step: 9792 Index:-0.3346 R2:0.6338 0.4125 0.5319 RMSE:0.6434 0.8206 0.7205 Tau:0.5950 0.4860 0.3946\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 97 Step: 9894 Index:-0.3874 R2:0.6284 0.3988 0.5448 RMSE:0.6710 0.8676 0.7789 Tau:0.5952 0.4802 0.4066\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 98 Step: 9996 Index:-0.3194 R2:0.6422 0.4291 0.5160 RMSE:0.6332 0.8127 0.7561 Tau:0.6028 0.4933 0.3946\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 99 Step: 10098 Index:-0.3359 R2:0.6437 0.4188 0.5106 RMSE:0.6354 0.8220 0.7613 Tau:0.6027 0.4861 0.3937\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 100 Step: 10200 Index:-0.3722 R2:0.6458 0.4268 0.5215 RMSE:0.6763 0.8580 0.8201 Tau:0.6020 0.4858 0.3881\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 101 Step: 10302 Index:-0.3214 R2:0.6491 0.4291 0.5243 RMSE:0.6278 0.8141 0.7512 Tau:0.6073 0.4928 0.3938\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 102 Step: 10404 Index:-0.3970 R2:0.6492 0.4277 0.5340 RMSE:0.7050 0.8883 0.8456 Tau:0.6052 0.4913 0.3926\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 103 Step: 10506 Index:-0.3533 R2:0.6397 0.4002 0.5237 RMSE:0.6371 0.8347 0.7474 Tau:0.6003 0.4815 0.4063\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 104 Step: 10608 Index:-0.3271 R2:0.6497 0.4178 0.5240 RMSE:0.6272 0.8184 0.7419 Tau:0.6061 0.4913 0.3930\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 105 Step: 10710 Index:-0.3207 R2:0.6422 0.4229 0.5281 RMSE:0.6310 0.8178 0.7379 Tau:0.6016 0.4970 0.3886\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 106 Step: 10812 Index:-0.3300 R2:0.6579 0.4244 0.5216 RMSE:0.6317 0.8213 0.7626 Tau:0.6147 0.4913 0.3922\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 107 Step: 10914 Index:-0.3292 R2:0.6551 0.4226 0.5179 RMSE:0.6327 0.8254 0.7653 Tau:0.6098 0.4962 0.3906\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 108 Step: 11016 Index:-0.3467 R2:0.6517 0.4301 0.5287 RMSE:0.6485 0.8432 0.7822 Tau:0.6063 0.4965 0.3992\n",
      "Epoch: 109 Step: 11118 Index:-0.3128 R2:0.6570 0.4331 0.5281 RMSE:0.6157 0.8116 0.7325 Tau:0.6131 0.4989 0.3983\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 110 Step: 11220 Index:-0.3336 R2:0.6546 0.4156 0.5122 RMSE:0.6235 0.8206 0.7543 Tau:0.6151 0.4870 0.3965\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 111 Step: 11322 Index:-0.3375 R2:0.6572 0.4147 0.5405 RMSE:0.6263 0.8348 0.7432 Tau:0.6114 0.4973 0.3997\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 112 Step: 11424 Index:-0.3323 R2:0.6648 0.4282 0.5287 RMSE:0.6213 0.8248 0.7619 Tau:0.6194 0.4925 0.4035\n",
      "Epoch: 113 Step: 11526 Index:-0.3119 R2:0.6586 0.4304 0.5537 RMSE:0.6207 0.8134 0.7030 Tau:0.6141 0.5015 0.4052\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 114 Step: 11628 Index:-0.3706 R2:0.6662 0.4270 0.5477 RMSE:0.6601 0.8646 0.7969 Tau:0.6203 0.4939 0.3929\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 115 Step: 11730 Index:-0.3147 R2:0.6598 0.4293 0.5289 RMSE:0.6136 0.8150 0.7345 Tau:0.6134 0.5003 0.4025\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 116 Step: 11832 Index:-0.3339 R2:0.6664 0.4266 0.5263 RMSE:0.6166 0.8276 0.7556 Tau:0.6184 0.4937 0.4018\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 117 Step: 11934 Index:-0.3173 R2:0.6651 0.4400 0.5378 RMSE:0.6271 0.8233 0.7634 Tau:0.6166 0.5061 0.3925\n",
      "Epoch: 118 Step: 12036 Index:-0.3093 R2:0.6629 0.4424 0.5306 RMSE:0.6105 0.8043 0.7404 Tau:0.6175 0.4950 0.3890\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 119 Step: 12138 Index:-0.3431 R2:0.6610 0.4346 0.5438 RMSE:0.6451 0.8447 0.7816 Tau:0.6145 0.5015 0.3876\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 120 Step: 12240 Index:-0.3301 R2:0.6731 0.4165 0.5232 RMSE:0.6074 0.8238 0.7457 Tau:0.6245 0.4937 0.4018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 121 Step: 12342 Index:-0.3192 R2:0.6756 0.4297 0.5172 RMSE:0.6032 0.8076 0.7378 Tau:0.6261 0.4884 0.3923\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 122 Step: 12444 Index:-0.3243 R2:0.6790 0.4449 0.5239 RMSE:0.6252 0.8260 0.7837 Tau:0.6268 0.5017 0.3996\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 123 Step: 12546 Index:-0.3375 R2:0.6808 0.4282 0.5418 RMSE:0.6215 0.8379 0.7686 Tau:0.6307 0.5004 0.4071\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 124 Step: 12648 Index:-0.4825 R2:0.6524 0.4013 0.5647 RMSE:0.7560 0.9651 0.8833 Tau:0.6139 0.4827 0.4033\n",
      "Epoch: 125 Step: 12750 Index:-0.3089 R2:0.6786 0.4415 0.5247 RMSE:0.6035 0.8091 0.7592 Tau:0.6300 0.5003 0.3976\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 126 Step: 12852 Index:-0.3760 R2:0.6790 0.4368 0.5393 RMSE:0.6749 0.8743 0.8346 Tau:0.6302 0.4983 0.3903\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 127 Step: 12954 Index:-0.3163 R2:0.6756 0.4389 0.5194 RMSE:0.6246 0.8170 0.7710 Tau:0.6248 0.5007 0.3767\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 128 Step: 13056 Index:-0.3256 R2:0.6843 0.4392 0.5412 RMSE:0.6111 0.8260 0.7613 Tau:0.6321 0.5004 0.3979\n",
      "Epoch: 129 Step: 13158 Index:-0.3041 R2:0.6745 0.4435 0.5024 RMSE:0.6039 0.7983 0.7493 Tau:0.6254 0.4942 0.3930\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 130 Step: 13260 Index:-0.3064 R2:0.6851 0.4376 0.5101 RMSE:0.5981 0.8048 0.7565 Tau:0.6313 0.4984 0.3928\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 131 Step: 13362 Index:-0.3519 R2:0.6845 0.4496 0.5431 RMSE:0.6540 0.8591 0.8180 Tau:0.6303 0.5071 0.3970\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 132 Step: 13464 Index:-0.3458 R2:0.6773 0.4340 0.5553 RMSE:0.6304 0.8455 0.7602 Tau:0.6243 0.4997 0.3986\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 133 Step: 13566 Index:-0.3205 R2:0.6865 0.4320 0.5529 RMSE:0.5901 0.8210 0.7221 Tau:0.6332 0.5004 0.4078\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 134 Step: 13668 Index:-0.3525 R2:0.6936 0.4389 0.5518 RMSE:0.6424 0.8552 0.7966 Tau:0.6400 0.5026 0.4002\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 135 Step: 13770 Index:-0.3113 R2:0.6848 0.4329 0.5337 RMSE:0.5936 0.8083 0.7335 Tau:0.6340 0.4970 0.4037\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 136 Step: 13872 Index:-0.3179 R2:0.6966 0.4367 0.5427 RMSE:0.5974 0.8221 0.7514 Tau:0.6416 0.5043 0.3978\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 137 Step: 13974 Index:-0.3460 R2:0.6877 0.4554 0.5277 RMSE:0.6563 0.8554 0.8323 Tau:0.6332 0.5094 0.3921\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 138 Step: 14076 Index:-0.3081 R2:0.6889 0.4447 0.5318 RMSE:0.5889 0.8079 0.7238 Tau:0.6341 0.4998 0.4094\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 139 Step: 14178 Index:-0.3074 R2:0.6931 0.4389 0.5496 RMSE:0.5938 0.8131 0.7069 Tau:0.6375 0.5057 0.4092\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 140 Step: 14280 Index:-0.3484 R2:0.6979 0.4355 0.5306 RMSE:0.6220 0.8467 0.7890 Tau:0.6416 0.4983 0.4011\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 141 Step: 14382 Index:-0.3209 R2:0.6918 0.4247 0.5283 RMSE:0.5851 0.8196 0.7303 Tau:0.6370 0.4987 0.4065\n",
      "Epoch: 142 Step: 14484 Index:-0.3015 R2:0.6991 0.4403 0.5197 RMSE:0.5800 0.8020 0.7373 Tau:0.6437 0.5004 0.4000\n",
      "Epoch: 143 Step: 14586 Index:-0.2857 R2:0.6972 0.4537 0.5460 RMSE:0.5784 0.7982 0.7244 Tau:0.6406 0.5125 0.3935\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 144 Step: 14688 Index:-0.3258 R2:0.6865 0.4290 0.5436 RMSE:0.5884 0.8231 0.7201 Tau:0.6344 0.4973 0.4087\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 145 Step: 14790 Index:-0.3077 R2:0.7001 0.4446 0.5381 RMSE:0.5897 0.8160 0.7494 Tau:0.6429 0.5084 0.4042\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 146 Step: 14892 Index:-0.3251 R2:0.6983 0.4339 0.5337 RMSE:0.6039 0.8245 0.7220 Tau:0.6426 0.4994 0.4113\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 147 Step: 14994 Index:-0.3187 R2:0.7010 0.4467 0.5390 RMSE:0.5968 0.8247 0.7671 Tau:0.6424 0.5060 0.3911\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 148 Step: 15096 Index:-0.3884 R2:0.7060 0.4300 0.5570 RMSE:0.6565 0.8875 0.8248 Tau:0.6497 0.4991 0.4045\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 149 Step: 15198 Index:-0.2976 R2:0.7057 0.4467 0.5537 RMSE:0.5868 0.8050 0.7035 Tau:0.6480 0.5074 0.4075\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 150 Step: 15300 Index:-0.3125 R2:0.7067 0.4456 0.5312 RMSE:0.5857 0.8180 0.7608 Tau:0.6479 0.5055 0.3986\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 151 Step: 15402 Index:-0.3089 R2:0.7061 0.4443 0.5443 RMSE:0.5770 0.8194 0.7415 Tau:0.6462 0.5105 0.4032\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 152 Step: 15504 Index:-0.3099 R2:0.7063 0.4331 0.5264 RMSE:0.5888 0.8113 0.7250 Tau:0.6476 0.5014 0.4002\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 153 Step: 15606 Index:-0.2943 R2:0.7102 0.4487 0.5465 RMSE:0.5744 0.8040 0.7333 Tau:0.6491 0.5097 0.3977\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 154 Step: 15708 Index:-0.2945 R2:0.7148 0.4454 0.5424 RMSE:0.5648 0.8003 0.7272 Tau:0.6562 0.5058 0.4002\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 155 Step: 15810 Index:-0.2920 R2:0.7108 0.4500 0.5406 RMSE:0.5669 0.8021 0.7214 Tau:0.6499 0.5101 0.4059\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 156 Step: 15912 Index:-0.3299 R2:0.7063 0.4476 0.5391 RMSE:0.6323 0.8375 0.7349 Tau:0.6489 0.5076 0.4075\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 157 Step: 16014 Index:-0.2899 R2:0.7193 0.4482 0.5318 RMSE:0.5664 0.7949 0.7332 Tau:0.6585 0.5050 0.3984\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 158 Step: 16116 Index:-0.3507 R2:0.7068 0.4430 0.5233 RMSE:0.6325 0.8538 0.8112 Tau:0.6447 0.5031 0.3923\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 159 Step: 16218 Index:-0.3171 R2:0.7115 0.4462 0.5602 RMSE:0.5827 0.8233 0.7528 Tau:0.6520 0.5062 0.3996\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 160 Step: 16320 Index:-0.3803 R2:0.7105 0.4274 0.5536 RMSE:0.6495 0.8816 0.8158 Tau:0.6536 0.5013 0.4100\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 161 Step: 16422 Index:-0.2993 R2:0.7100 0.4562 0.5546 RMSE:0.5754 0.8077 0.7417 Tau:0.6505 0.5084 0.4017\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 162 Step: 16524 Index:-0.3155 R2:0.7094 0.4419 0.5491 RMSE:0.5871 0.8169 0.7100 Tau:0.6516 0.5014 0.4140\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 163 Step: 16626 Index:-0.3141 R2:0.7084 0.4433 0.5489 RMSE:0.5834 0.8187 0.7126 Tau:0.6476 0.5046 0.4136\n",
      "Epoch: 164 Step: 16728 Index:-0.2845 R2:0.7195 0.4585 0.5355 RMSE:0.5606 0.7982 0.7432 Tau:0.6555 0.5136 0.4039\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 165 Step: 16830 Index:-0.2847 R2:0.7193 0.4572 0.5171 RMSE:0.5593 0.7940 0.7498 Tau:0.6555 0.5093 0.4073\n",
      "Epoch: 166 Step: 16932 Index:-0.2810 R2:0.7240 0.4561 0.5346 RMSE:0.5586 0.7940 0.7226 Tau:0.6598 0.5130 0.4041\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 167 Step: 17034 Index:-0.2952 R2:0.7168 0.4540 0.5408 RMSE:0.5625 0.8089 0.7424 Tau:0.6535 0.5137 0.4108\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 168 Step: 17136 Index:-0.3243 R2:0.7101 0.4398 0.5340 RMSE:0.5858 0.8336 0.7721 Tau:0.6493 0.5093 0.4069\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 169 Step: 17238 Index:-0.3086 R2:0.7264 0.4404 0.5373 RMSE:0.5655 0.8177 0.7522 Tau:0.6616 0.5090 0.3996\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 170 Step: 17340 Index:-0.3013 R2:0.7215 0.4462 0.5424 RMSE:0.5675 0.8109 0.7164 Tau:0.6592 0.5096 0.4107\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 171 Step: 17442 Index:-0.3259 R2:0.7283 0.4388 0.5511 RMSE:0.5681 0.8262 0.7539 Tau:0.6649 0.5003 0.4120\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 172 Step: 17544 Index:-0.3624 R2:0.7064 0.4311 0.5494 RMSE:0.6213 0.8686 0.7900 Tau:0.6464 0.5062 0.4048\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 173 Step: 17646 Index:-0.3031 R2:0.7218 0.4428 0.5351 RMSE:0.5696 0.8048 0.7225 Tau:0.6606 0.5017 0.3988\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 174 Step: 17748 Index:-0.3242 R2:0.7269 0.4468 0.5158 RMSE:0.5896 0.8295 0.8015 Tau:0.6621 0.5053 0.3997\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 175 Step: 17850 Index:-0.2832 R2:0.7212 0.4631 0.5367 RMSE:0.5567 0.7958 0.7441 Tau:0.6583 0.5126 0.4092\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 176 Step: 17952 Index:-0.2855 R2:0.7246 0.4590 0.5265 RMSE:0.5551 0.7968 0.7474 Tau:0.6604 0.5114 0.4047\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 177 Step: 18054 Index:-0.3526 R2:0.7229 0.4278 0.5050 RMSE:0.5986 0.8466 0.8043 Tau:0.6585 0.4941 0.3935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 178 Step: 18156 Index:-0.3062 R2:0.7102 0.4452 0.5542 RMSE:0.5705 0.8039 0.7112 Tau:0.6514 0.4977 0.3989\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 179 Step: 18258 Index:-0.3440 R2:0.7278 0.4234 0.5557 RMSE:0.5789 0.8482 0.7597 Tau:0.6644 0.5042 0.4171\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 180 Step: 18360 Index:-0.3147 R2:0.7207 0.4377 0.5543 RMSE:0.5559 0.8159 0.7143 Tau:0.6601 0.5013 0.4117\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 181 Step: 18462 Index:-0.2852 R2:0.7292 0.4569 0.5150 RMSE:0.5496 0.7929 0.7509 Tau:0.6618 0.5077 0.3972\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 182 Step: 18564 Index:-0.3192 R2:0.7328 0.4434 0.5339 RMSE:0.5807 0.8257 0.7276 Tau:0.6682 0.5065 0.4134\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 183 Step: 18666 Index:-0.3127 R2:0.7214 0.4435 0.5615 RMSE:0.5556 0.8175 0.7199 Tau:0.6588 0.5048 0.4089\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 184 Step: 18768 Index:-0.2892 R2:0.7368 0.4475 0.5300 RMSE:0.5505 0.7974 0.7258 Tau:0.6696 0.5082 0.4035\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 185 Step: 18870 Index:-0.2974 R2:0.7316 0.4435 0.5346 RMSE:0.5492 0.8026 0.7268 Tau:0.6643 0.5051 0.4032\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 186 Step: 18972 Index:-0.3216 R2:0.7377 0.4336 0.5266 RMSE:0.5542 0.8139 0.7521 Tau:0.6701 0.4923 0.4077\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 187 Step: 19074 Index:-0.3076 R2:0.7412 0.4365 0.5524 RMSE:0.5513 0.8154 0.7383 Tau:0.6742 0.5078 0.4096\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 188 Step: 19176 Index:-0.3165 R2:0.7365 0.4471 0.5348 RMSE:0.5577 0.8205 0.7732 Tau:0.6698 0.5040 0.4093\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 189 Step: 19278 Index:-0.2842 R2:0.7405 0.4561 0.5307 RMSE:0.5363 0.8001 0.7404 Tau:0.6714 0.5159 0.4051\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 190 Step: 19380 Index:-0.3109 R2:0.7356 0.4381 0.5348 RMSE:0.5490 0.8092 0.7468 Tau:0.6705 0.4983 0.4093\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 191 Step: 19482 Index:-0.3411 R2:0.7267 0.4212 0.5261 RMSE:0.5617 0.8379 0.7618 Tau:0.6621 0.4967 0.4067\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 192 Step: 19584 Index:-0.2877 R2:0.7415 0.4568 0.5363 RMSE:0.5381 0.8009 0.7452 Tau:0.6722 0.5133 0.4051\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 193 Step: 19686 Index:-0.2926 R2:0.7359 0.4488 0.5587 RMSE:0.5406 0.8087 0.7107 Tau:0.6692 0.5161 0.4112\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 194 Step: 19788 Index:-0.3139 R2:0.7460 0.4474 0.5423 RMSE:0.5528 0.8251 0.7644 Tau:0.6761 0.5111 0.4102\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 195 Step: 19890 Index:-0.2911 R2:0.7454 0.4496 0.5503 RMSE:0.5385 0.8021 0.7267 Tau:0.6766 0.5110 0.4082\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 196 Step: 19992 Index:-0.2894 R2:0.7425 0.4523 0.5428 RMSE:0.5358 0.8015 0.7312 Tau:0.6735 0.5121 0.4102\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 197 Step: 20094 Index:-0.3014 R2:0.7412 0.4451 0.5355 RMSE:0.5362 0.8072 0.7354 Tau:0.6730 0.5058 0.4128\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 198 Step: 20196 Index:-0.3130 R2:0.7392 0.4354 0.5300 RMSE:0.5387 0.8145 0.7362 Tau:0.6714 0.5014 0.4070\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 199 Step: 20298 Index:-0.3098 R2:0.7320 0.4452 0.5439 RMSE:0.5443 0.8119 0.7304 Tau:0.6660 0.5021 0.4049\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 200 Step: 20400 Index:-0.3139 R2:0.7378 0.4285 0.5046 RMSE:0.5414 0.8177 0.7557 Tau:0.6683 0.5038 0.4093\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 201 Step: 20502 Index:-0.2881 R2:0.7426 0.4661 0.5128 RMSE:0.5538 0.8036 0.7883 Tau:0.6714 0.5155 0.4001\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 202 Step: 20604 Index:-0.2944 R2:0.7434 0.4503 0.5498 RMSE:0.5487 0.8064 0.7075 Tau:0.6741 0.5119 0.4193\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 203 Step: 20706 Index:-0.2870 R2:0.7433 0.4539 0.5467 RMSE:0.5455 0.8031 0.7141 Tau:0.6733 0.5161 0.4144\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 204 Step: 20808 Index:-0.2933 R2:0.7478 0.4444 0.5198 RMSE:0.5391 0.7991 0.7349 Tau:0.6761 0.5059 0.4028\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 205 Step: 20910 Index:-0.3142 R2:0.7498 0.4294 0.5428 RMSE:0.5334 0.8174 0.7290 Tau:0.6796 0.5032 0.4090\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 206 Step: 21012 Index:-0.3114 R2:0.7503 0.4456 0.5436 RMSE:0.5321 0.8185 0.7471 Tau:0.6790 0.5071 0.4161\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 207 Step: 21114 Index:-0.3123 R2:0.7514 0.4357 0.5444 RMSE:0.5294 0.8217 0.7413 Tau:0.6812 0.5094 0.4146\n",
      "Epoch: 208 Step: 21216 Index:-0.2718 R2:0.7506 0.4627 0.5235 RMSE:0.5294 0.7899 0.7409 Tau:0.6789 0.5180 0.4065\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 209 Step: 21318 Index:-0.3255 R2:0.7500 0.4475 0.5567 RMSE:0.5632 0.8406 0.7828 Tau:0.6809 0.5151 0.4181\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 210 Step: 21420 Index:-0.2826 R2:0.7331 0.4657 0.5365 RMSE:0.5615 0.8012 0.7264 Tau:0.6666 0.5185 0.4078\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 211 Step: 21522 Index:-0.3307 R2:0.7487 0.4358 0.5462 RMSE:0.5671 0.8373 0.7231 Tau:0.6784 0.5066 0.4247\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 212 Step: 21624 Index:-0.2875 R2:0.7546 0.4564 0.5356 RMSE:0.5386 0.7988 0.7212 Tau:0.6817 0.5114 0.4138\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 213 Step: 21726 Index:-0.3286 R2:0.7434 0.4402 0.5485 RMSE:0.5649 0.8393 0.7176 Tau:0.6750 0.5107 0.4208\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 214 Step: 21828 Index:-0.3053 R2:0.7506 0.4379 0.5268 RMSE:0.5290 0.8120 0.7318 Tau:0.6793 0.5067 0.4139\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 215 Step: 21930 Index:-0.2815 R2:0.7558 0.4632 0.5347 RMSE:0.5268 0.7953 0.7289 Tau:0.6817 0.5139 0.4090\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 216 Step: 22032 Index:-0.3118 R2:0.7527 0.4547 0.5335 RMSE:0.5604 0.8214 0.7334 Tau:0.6818 0.5096 0.4208\n",
      "Epoch: 217 Step: 22134 Index:-0.2696 R2:0.7502 0.4703 0.5027 RMSE:0.5291 0.7829 0.7609 Tau:0.6766 0.5133 0.3988\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 218 Step: 22236 Index:-0.3003 R2:0.7579 0.4371 0.5268 RMSE:0.5249 0.8091 0.7391 Tau:0.6869 0.5088 0.4166\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 219 Step: 22338 Index:-0.3078 R2:0.7566 0.4379 0.5106 RMSE:0.5219 0.8141 0.7649 Tau:0.6828 0.5063 0.4103\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 220 Step: 22440 Index:-0.2797 R2:0.7556 0.4645 0.5189 RMSE:0.5300 0.7893 0.7362 Tau:0.6813 0.5095 0.4133\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 221 Step: 22542 Index:-0.2925 R2:0.7593 0.4518 0.5426 RMSE:0.5269 0.8028 0.7182 Tau:0.6882 0.5102 0.4178\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 222 Step: 22644 Index:-0.3034 R2:0.7473 0.4560 0.5305 RMSE:0.5291 0.8125 0.7504 Tau:0.6761 0.5091 0.4070\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 223 Step: 22746 Index:-0.2964 R2:0.7576 0.4659 0.5149 RMSE:0.5310 0.8064 0.7860 Tau:0.6820 0.5101 0.3974\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 224 Step: 22848 Index:-0.2987 R2:0.7496 0.4478 0.5179 RMSE:0.5316 0.8140 0.7612 Tau:0.6777 0.5153 0.4150\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 225 Step: 22950 Index:-0.3021 R2:0.7604 0.4577 0.5330 RMSE:0.5311 0.8207 0.7739 Tau:0.6864 0.5186 0.4127\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 226 Step: 23052 Index:-0.3080 R2:0.7469 0.4387 0.5546 RMSE:0.5290 0.8222 0.7261 Tau:0.6785 0.5142 0.4114\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 227 Step: 23154 Index:-0.2994 R2:0.7521 0.4597 0.5194 RMSE:0.5289 0.8072 0.7751 Tau:0.6788 0.5078 0.4033\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 228 Step: 23256 Index:-0.3021 R2:0.7621 0.4444 0.5265 RMSE:0.5169 0.8102 0.7486 Tau:0.6889 0.5080 0.4161\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 229 Step: 23358 Index:-0.2768 R2:0.7606 0.4631 0.5230 RMSE:0.5157 0.7954 0.7496 Tau:0.6874 0.5186 0.4124\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 230 Step: 23460 Index:-0.3477 R2:0.7634 0.4349 0.5294 RMSE:0.5573 0.8524 0.8042 Tau:0.6898 0.5047 0.4090\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 231 Step: 23562 Index:-0.2959 R2:0.7635 0.4468 0.5395 RMSE:0.5197 0.8080 0.7199 Tau:0.6897 0.5121 0.4192\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 232 Step: 23664 Index:-0.2743 R2:0.7679 0.4615 0.5239 RMSE:0.5119 0.7909 0.7419 Tau:0.6905 0.5166 0.4109\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 233 Step: 23766 Index:-0.3025 R2:0.7643 0.4447 0.5164 RMSE:0.5125 0.8097 0.7517 Tau:0.6892 0.5072 0.4213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 234 Step: 23868 Index:-0.2629 R2:0.7652 0.4771 0.5343 RMSE:0.5170 0.7809 0.7299 Tau:0.6897 0.5180 0.4098\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 235 Step: 23970 Index:-0.3268 R2:0.7664 0.4415 0.5483 RMSE:0.5485 0.8355 0.7711 Tau:0.6935 0.5087 0.4149\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 236 Step: 24072 Index:-0.3015 R2:0.7663 0.4459 0.5384 RMSE:0.5146 0.8074 0.7410 Tau:0.6917 0.5059 0.4074\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 237 Step: 24174 Index:-0.3143 R2:0.7644 0.4337 0.5348 RMSE:0.5157 0.8142 0.7395 Tau:0.6913 0.4999 0.4123\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 238 Step: 24276 Index:-0.3052 R2:0.7645 0.4383 0.5176 RMSE:0.5177 0.8110 0.7566 Tau:0.6909 0.5057 0.4216\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 239 Step: 24378 Index:-0.3064 R2:0.7609 0.4560 0.5480 RMSE:0.5406 0.8246 0.7704 Tau:0.6875 0.5182 0.4214\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 240 Step: 24480 Index:-0.2954 R2:0.7682 0.4568 0.5431 RMSE:0.5144 0.8076 0.7521 Tau:0.6932 0.5121 0.4196\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 241 Step: 24582 Index:-0.3145 R2:0.7551 0.4298 0.5285 RMSE:0.5232 0.8204 0.7299 Tau:0.6845 0.5059 0.4157\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 242 Step: 24684 Index:-0.2949 R2:0.7679 0.4520 0.5315 RMSE:0.5107 0.8036 0.7351 Tau:0.6941 0.5087 0.4209\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 243 Step: 24786 Index:-0.3100 R2:0.7691 0.4496 0.5441 RMSE:0.5225 0.8263 0.7667 Tau:0.6946 0.5163 0.4177\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 244 Step: 24888 Index:-0.2674 R2:0.7698 0.4680 0.5369 RMSE:0.5067 0.7883 0.7337 Tau:0.6927 0.5209 0.4054\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 245 Step: 24990 Index:-0.2870 R2:0.7708 0.4560 0.5510 RMSE:0.5050 0.8023 0.7275 Tau:0.6958 0.5152 0.4197\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 246 Step: 25092 Index:-0.2832 R2:0.7705 0.4660 0.5119 RMSE:0.5144 0.7899 0.7648 Tau:0.6931 0.5066 0.4123\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 247 Step: 25194 Index:-0.3136 R2:0.7645 0.4395 0.5388 RMSE:0.5102 0.8203 0.7387 Tau:0.6933 0.5068 0.4242\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 248 Step: 25296 Index:-0.2831 R2:0.7715 0.4566 0.5414 RMSE:0.5042 0.7988 0.7297 Tau:0.6949 0.5157 0.4121\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 249 Step: 25398 Index:-0.2738 R2:0.7777 0.4591 0.5063 RMSE:0.5027 0.7917 0.7526 Tau:0.6991 0.5179 0.4178\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 250 Step: 25500 Index:-0.3068 R2:0.7646 0.4650 0.5070 RMSE:0.5422 0.8198 0.8176 Tau:0.6880 0.5130 0.4098\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 251 Step: 25602 Index:-0.2921 R2:0.7770 0.4477 0.5193 RMSE:0.5059 0.8040 0.7547 Tau:0.6994 0.5119 0.4088\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 252 Step: 25704 Index:-0.3284 R2:0.7696 0.4381 0.5447 RMSE:0.5253 0.8398 0.7665 Tau:0.6935 0.5114 0.4289\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 253 Step: 25806 Index:-0.3043 R2:0.7774 0.4442 0.5560 RMSE:0.5038 0.8146 0.7319 Tau:0.7027 0.5103 0.4198\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 254 Step: 25908 Index:-0.2988 R2:0.7740 0.4544 0.5463 RMSE:0.5111 0.8153 0.7530 Tau:0.6971 0.5166 0.4147\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 255 Step: 26010 Index:-0.2937 R2:0.7714 0.4558 0.5037 RMSE:0.5126 0.8042 0.7729 Tau:0.6927 0.5105 0.4063\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 256 Step: 26112 Index:-0.2820 R2:0.7758 0.4613 0.5327 RMSE:0.5082 0.7989 0.7306 Tau:0.6980 0.5169 0.4078\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 257 Step: 26214 Index:-0.2762 R2:0.7763 0.4629 0.5214 RMSE:0.5057 0.7900 0.7399 Tau:0.6990 0.5138 0.4071\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 258 Step: 26316 Index:-0.2989 R2:0.7713 0.4548 0.5354 RMSE:0.5027 0.8125 0.7411 Tau:0.6940 0.5136 0.4207\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 259 Step: 26418 Index:-0.2905 R2:0.7769 0.4621 0.5550 RMSE:0.4971 0.8054 0.7340 Tau:0.7012 0.5149 0.4260\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 260 Step: 26520 Index:-0.2887 R2:0.7788 0.4623 0.5570 RMSE:0.4977 0.8008 0.7330 Tau:0.7022 0.5121 0.4148\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 261 Step: 26622 Index:-0.3197 R2:0.7829 0.4467 0.5412 RMSE:0.5221 0.8271 0.7738 Tau:0.7062 0.5074 0.4233\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 262 Step: 26724 Index:-0.2829 R2:0.7794 0.4680 0.5451 RMSE:0.5027 0.8023 0.7599 Tau:0.7016 0.5194 0.4208\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 263 Step: 26826 Index:-0.2915 R2:0.7767 0.4560 0.5345 RMSE:0.5002 0.8023 0.7431 Tau:0.6993 0.5108 0.4234\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 264 Step: 26928 Index:-0.2848 R2:0.7703 0.4597 0.5116 RMSE:0.5049 0.8012 0.7659 Tau:0.6918 0.5164 0.4158\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 265 Step: 27030 Index:-0.2775 R2:0.7699 0.4737 0.5115 RMSE:0.5221 0.7921 0.7556 Tau:0.6915 0.5146 0.4080\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 266 Step: 27132 Index:-0.2856 R2:0.7747 0.4641 0.5465 RMSE:0.4997 0.8029 0.7411 Tau:0.6985 0.5173 0.4239\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 267 Step: 27234 Index:-0.2892 R2:0.7784 0.4605 0.5251 RMSE:0.5048 0.7993 0.7395 Tau:0.6996 0.5101 0.4147\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 268 Step: 27336 Index:-0.2924 R2:0.7736 0.4492 0.5125 RMSE:0.5014 0.8070 0.7552 Tau:0.6949 0.5146 0.4185\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 269 Step: 27438 Index:-0.2862 R2:0.7833 0.4558 0.5311 RMSE:0.4966 0.7967 0.7307 Tau:0.7044 0.5105 0.4112\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 270 Step: 27540 Index:-0.2773 R2:0.7799 0.4665 0.5287 RMSE:0.4970 0.7923 0.7406 Tau:0.7018 0.5150 0.4255\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 271 Step: 27642 Index:-0.3030 R2:0.7801 0.4697 0.5335 RMSE:0.5282 0.8213 0.8001 Tau:0.7014 0.5183 0.4157\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 272 Step: 27744 Index:-0.2832 R2:0.7836 0.4623 0.5224 RMSE:0.4950 0.7965 0.7429 Tau:0.7036 0.5133 0.4144\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 273 Step: 27846 Index:-0.2736 R2:0.7718 0.4724 0.5342 RMSE:0.5154 0.7989 0.7387 Tau:0.6948 0.5253 0.4134\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 274 Step: 27948 Index:-0.3850 R2:0.7737 0.4448 0.5458 RMSE:0.6029 0.8908 0.8687 Tau:0.6993 0.5058 0.4028\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 275 Step: 28050 Index:-0.2918 R2:0.7829 0.4592 0.5194 RMSE:0.5009 0.7983 0.7650 Tau:0.7038 0.5065 0.4131\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 276 Step: 28152 Index:-0.3254 R2:0.7862 0.4574 0.5163 RMSE:0.5289 0.8322 0.8154 Tau:0.7037 0.5068 0.4094\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 277 Step: 28254 Index:-0.2972 R2:0.7846 0.4646 0.5356 RMSE:0.4937 0.8102 0.7622 Tau:0.7050 0.5130 0.4213\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 278 Step: 28356 Index:-0.2913 R2:0.7790 0.4590 0.5205 RMSE:0.4958 0.8044 0.7455 Tau:0.7003 0.5132 0.4295\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 279 Step: 28458 Index:-0.3169 R2:0.7856 0.4417 0.5471 RMSE:0.4921 0.8254 0.7436 Tau:0.7081 0.5086 0.4257\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 280 Step: 28560 Index:-0.2973 R2:0.7863 0.4587 0.5453 RMSE:0.4910 0.8138 0.7518 Tau:0.7052 0.5164 0.4109\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 281 Step: 28662 Index:-0.2970 R2:0.7903 0.4565 0.5394 RMSE:0.4998 0.8128 0.7639 Tau:0.7097 0.5158 0.4197\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 282 Step: 28764 Index:-0.3605 R2:0.7806 0.4506 0.5141 RMSE:0.6207 0.8698 0.7800 Tau:0.7022 0.5093 0.4285\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 283 Step: 28866 Index:-0.3015 R2:0.7830 0.4597 0.5198 RMSE:0.5071 0.8124 0.7804 Tau:0.7011 0.5110 0.4139\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 284 Step: 28968 Index:-0.3072 R2:0.7902 0.4510 0.5162 RMSE:0.5021 0.8181 0.7819 Tau:0.7091 0.5108 0.4299\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 285 Step: 29070 Index:-0.3035 R2:0.7869 0.4593 0.5404 RMSE:0.4873 0.8150 0.7580 Tau:0.7076 0.5115 0.4196\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 286 Step: 29172 Index:-0.2915 R2:0.7912 0.4598 0.5358 RMSE:0.4914 0.8037 0.7263 Tau:0.7116 0.5122 0.4262\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 287 Step: 29274 Index:-0.3124 R2:0.7840 0.4436 0.5414 RMSE:0.4939 0.8195 0.7232 Tau:0.7065 0.5071 0.4226\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 288 Step: 29376 Index:-0.3120 R2:0.7987 0.4528 0.5354 RMSE:0.5045 0.8243 0.7849 Tau:0.7174 0.5123 0.4244\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 289 Step: 29478 Index:-0.2960 R2:0.7842 0.4500 0.5126 RMSE:0.5053 0.8050 0.7447 Tau:0.7050 0.5090 0.4278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 290 Step: 29580 Index:-0.3177 R2:0.7907 0.4340 0.5225 RMSE:0.4856 0.8197 0.7497 Tau:0.7102 0.5020 0.4149\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 291 Step: 29682 Index:-0.3209 R2:0.7948 0.4458 0.5446 RMSE:0.5025 0.8332 0.7772 Tau:0.7147 0.5124 0.4341\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 292 Step: 29784 Index:-0.3172 R2:0.7909 0.4592 0.5516 RMSE:0.5083 0.8267 0.7783 Tau:0.7092 0.5096 0.4260\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 293 Step: 29886 Index:-0.3508 R2:0.7970 0.4392 0.5437 RMSE:0.5280 0.8578 0.8061 Tau:0.7167 0.5070 0.4260\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 294 Step: 29988 Index:-0.3478 R2:0.7966 0.4589 0.5448 RMSE:0.5462 0.8611 0.8253 Tau:0.7143 0.5133 0.4295\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 295 Step: 30090 Index:-0.3157 R2:0.7810 0.4541 0.5504 RMSE:0.5082 0.8235 0.7175 Tau:0.7027 0.5079 0.4339\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 296 Step: 30192 Index:-0.2863 R2:0.7989 0.4566 0.5249 RMSE:0.4799 0.7966 0.7360 Tau:0.7171 0.5103 0.4331\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 297 Step: 30294 Index:-0.2653 R2:0.7948 0.4722 0.5293 RMSE:0.4801 0.7839 0.7453 Tau:0.7118 0.5186 0.4191\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 298 Step: 30396 Index:-0.3253 R2:0.7949 0.4597 0.5208 RMSE:0.5261 0.8398 0.8224 Tau:0.7109 0.5145 0.4216\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 299 Step: 30498 Index:-0.2879 R2:0.7953 0.4633 0.5332 RMSE:0.4908 0.8021 0.7292 Tau:0.7143 0.5142 0.4289\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 300 Step: 30600 Index:-0.3305 R2:0.7961 0.4505 0.5321 RMSE:0.5010 0.8309 0.7880 Tau:0.7134 0.5004 0.4223\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 301 Step: 30702 Index:-0.3222 R2:0.7900 0.4416 0.5228 RMSE:0.4842 0.8208 0.7569 Tau:0.7095 0.4986 0.4289\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 302 Step: 30804 Index:-0.2999 R2:0.7958 0.4600 0.5229 RMSE:0.4795 0.8067 0.7499 Tau:0.7132 0.5068 0.4289\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 303 Step: 30906 Index:-0.2929 R2:0.8018 0.4604 0.5394 RMSE:0.4760 0.8098 0.7551 Tau:0.7178 0.5168 0.4254\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 304 Step: 31008 Index:-0.3029 R2:0.7930 0.4481 0.5212 RMSE:0.4819 0.8048 0.7481 Tau:0.7098 0.5018 0.4160\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 305 Step: 31110 Index:-0.2959 R2:0.8007 0.4526 0.5228 RMSE:0.4721 0.8025 0.7480 Tau:0.7165 0.5065 0.4226\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 306 Step: 31212 Index:-0.2860 R2:0.7987 0.4668 0.5246 RMSE:0.4769 0.7955 0.7594 Tau:0.7169 0.5095 0.4263\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 307 Step: 31314 Index:-0.2938 R2:0.7931 0.4652 0.5294 RMSE:0.5084 0.8111 0.7399 Tau:0.7108 0.5173 0.4228\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 308 Step: 31416 Index:-0.3156 R2:0.7849 0.4373 0.4933 RMSE:0.4951 0.8151 0.7619 Tau:0.7038 0.4995 0.4244\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 309 Step: 31518 Index:-0.2760 R2:0.8005 0.4772 0.5442 RMSE:0.4750 0.7961 0.7548 Tau:0.7176 0.5201 0.4239\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 310 Step: 31620 Index:-0.2894 R2:0.8019 0.4608 0.5427 RMSE:0.4682 0.8033 0.7360 Tau:0.7200 0.5139 0.4348\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 311 Step: 31722 Index:-0.2981 R2:0.8020 0.4670 0.5169 RMSE:0.5023 0.8140 0.8058 Tau:0.7190 0.5159 0.4186\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 312 Step: 31824 Index:-0.2828 R2:0.7982 0.4641 0.5415 RMSE:0.4737 0.7996 0.7377 Tau:0.7146 0.5168 0.4177\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 313 Step: 31926 Index:-0.3160 R2:0.8020 0.4478 0.5211 RMSE:0.4699 0.8190 0.7636 Tau:0.7187 0.5031 0.4292\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 314 Step: 32028 Index:-0.2821 R2:0.7998 0.4685 0.5211 RMSE:0.4712 0.7998 0.7637 Tau:0.7141 0.5177 0.4172\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 315 Step: 32130 Index:-0.3005 R2:0.8027 0.4574 0.5207 RMSE:0.4838 0.8142 0.7759 Tau:0.7178 0.5137 0.4247\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 316 Step: 32232 Index:-0.2948 R2:0.8037 0.4556 0.5226 RMSE:0.4724 0.8049 0.7671 Tau:0.7214 0.5101 0.4178\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 317 Step: 32334 Index:-0.2866 R2:0.8073 0.4566 0.5427 RMSE:0.4647 0.8009 0.7295 Tau:0.7240 0.5144 0.4250\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 318 Step: 32436 Index:-0.3233 R2:0.8004 0.4425 0.5217 RMSE:0.4911 0.8267 0.7753 Tau:0.7174 0.5034 0.4259\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 319 Step: 32538 Index:-0.2951 R2:0.8113 0.4469 0.5366 RMSE:0.4791 0.8038 0.7177 Tau:0.7267 0.5087 0.4307\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 320 Step: 32640 Index:-0.2863 R2:0.8014 0.4706 0.5219 RMSE:0.4752 0.7989 0.7722 Tau:0.7169 0.5125 0.4209\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 321 Step: 32742 Index:-0.3382 R2:0.7972 0.4365 0.5356 RMSE:0.5028 0.8434 0.7837 Tau:0.7161 0.5052 0.4264\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 322 Step: 32844 Index:-0.3209 R2:0.8005 0.4528 0.5343 RMSE:0.4839 0.8254 0.7784 Tau:0.7182 0.5045 0.4392\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 323 Step: 32946 Index:-0.2826 R2:0.8061 0.4622 0.5328 RMSE:0.4858 0.7959 0.7224 Tau:0.7219 0.5133 0.4231\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 324 Step: 33048 Index:-0.2818 R2:0.8109 0.4610 0.5308 RMSE:0.4644 0.7937 0.7331 Tau:0.7248 0.5119 0.4236\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 325 Step: 33150 Index:-0.2815 R2:0.8042 0.4615 0.5177 RMSE:0.4804 0.7912 0.7408 Tau:0.7208 0.5097 0.4144\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 326 Step: 33252 Index:-0.2830 R2:0.8117 0.4589 0.5473 RMSE:0.4616 0.7966 0.7237 Tau:0.7257 0.5136 0.4215\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 327 Step: 33354 Index:-0.2852 R2:0.8115 0.4643 0.5215 RMSE:0.4596 0.7930 0.7507 Tau:0.7250 0.5078 0.4134\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 328 Step: 33456 Index:-0.3288 R2:0.8039 0.4536 0.5373 RMSE:0.5039 0.8396 0.8062 Tau:0.7208 0.5108 0.4286\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 329 Step: 33558 Index:-0.2987 R2:0.8120 0.4494 0.5321 RMSE:0.4600 0.8080 0.7337 Tau:0.7256 0.5093 0.4268\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 330 Step: 33660 Index:-0.2922 R2:0.8125 0.4552 0.5295 RMSE:0.4622 0.8044 0.7356 Tau:0.7265 0.5122 0.4234\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 331 Step: 33762 Index:-0.3301 R2:0.8053 0.4566 0.5636 RMSE:0.5036 0.8474 0.7882 Tau:0.7215 0.5173 0.4309\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 332 Step: 33864 Index:-0.3315 R2:0.8094 0.4435 0.5120 RMSE:0.4816 0.8388 0.8031 Tau:0.7238 0.5073 0.4297\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 333 Step: 33966 Index:-0.3272 R2:0.8090 0.4506 0.5366 RMSE:0.4864 0.8392 0.7909 Tau:0.7241 0.5120 0.4263\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 334 Step: 34068 Index:-0.2871 R2:0.8131 0.4630 0.5235 RMSE:0.4837 0.7960 0.7314 Tau:0.7271 0.5089 0.4190\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 334 r2:0.5343 RMSE:0.7299 WTI:0.6521 AP:1.1686 Tau:0.4098 \n",
      " \n",
      " Top-1:0.1667 Top-1-fp:0.1667 \n",
      " Top-5:0.5000 Top-5-fp:0.1176 \n",
      " Top-10:0.6324 Top-10-fp:0.1324 \n",
      " Top-15:0.8600 Top-15-fp:0.1569 \n",
      " Top-20:1.0000 Top-20-fp:0.2647 \n",
      " Top-25:1.1600 Top-25-fp:0.3216 \n",
      " Top-30:1.3400 Top-30-fp:0.3463 \n",
      " Top-40:1.6100 Top-40-fp:0.4103 \n",
      " Top-50:1.8100 Top-50-fp:0.4708 \n",
      " \n",
      " Top50:0.5000 Top50-fp:0.1400 \n",
      " Top100:0.7000 Top100-fp:0.1600 \n",
      " Top150:1.0600 Top150-fp:0.2933 \n",
      " Top200:1.3100 Top200-fp:0.3450 \n",
      " Top250:1.5600 Top250-fp:0.3760 \n",
      " Top300:1.6900 Top300-fp:0.4367 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
