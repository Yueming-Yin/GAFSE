{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC50_P41143_1_200\n",
      "model_file/1_GAFSE_EC50_P41143_1_200_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/EC50_P41143_1_200_train.csv\"\n",
    "test_filename = \"./data/benchmark/EC50_P41143_1_200_test.csv\"\n",
    "test_active = 200\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CC1=CC(=CC(=C1CC(C(=O)NC(C)C(=O)NCC(=O)NC(CC2=... -2.230449\n",
      "1  COC1=CC(=C(C=C1)C(=O)NC2(CCN(CC2)C3=NC=CC(=C3)... -1.146128\n",
      "2  CCN(CC)C(=O)C1=CC=C(C=C1)C2CC3(CCNCC3)OC4=CC=C... -2.623249\n",
      "3  CCCCC(C(=O)N1CCCC1C(=O)NC(CC(C)C)C(=O)NC(CC2=C... -0.361728\n",
      "4  CCN(CC)C(=O)C1=CC=C(C=C1)N(C2CCN(CC2)CCC3=CC(=... -0.417472\n",
      "number of all smiles:  523\n",
      "number of successfully processed smiles:  523\n",
      "                                              smiles     value  \\\n",
      "0  CC1=CC(=CC(=C1CC(C(=O)NC(C)C(=O)NCC(=O)NC(CC2=... -2.230449   \n",
      "1  COC1=CC(=C(C=C1)C(=O)NC2(CCN(CC2)C3=NC=CC(=C3)... -1.146128   \n",
      "2  CCN(CC)C(=O)C1=CC=C(C=C1)C2CC3(CCNCC3)OC4=CC=C... -2.623249   \n",
      "3  CCCCC(C(=O)N1CCCC1C(=O)NC(CC(C)C)C(=O)NC(CC2=C... -0.361728   \n",
      "4  CCN(CC)C(=O)C1=CC=C(C=C1)N(C2CCN(CC2)CCC3=CC(=... -0.417472   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Cc1cc(O)cc(C)c1CC(N)C(=O)NC(C)C(=O)NCC(=O)NC(C...  \n",
      "1  COc1ccc(C(=O)NC2(c3ccccc3)CCN(c3cc(N)ccn3)CC2)...  \n",
      "2      CCN(CC)C(=O)c1ccc(C2CC3(CCNCC3)Oc3ccccc32)cc1  \n",
      "3  CCCCC(NC(=O)C(Cc1ccccc1)NC(=O)CNC(=O)C(C)NC(=O...  \n",
      "4  CCN(CC)C(=O)c1ccc(N(c2cccc(O)c2)C2CCN(CCc3cccc...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  893\n",
      "number of successfully processed smiles:  893\n",
      "(893, 3)\n",
      "                                              smiles     value  \\\n",
      "0            C1CN(CCC12C3=CC=CC=C3CO2)C4=NC=CC(=C4)N -2.488551   \n",
      "1  COC1=C2C3=C(CC4C56C3(CCN4CC7CC7)C(O2)C(CC5)(C(... -2.216773   \n",
      "2  CC(C(=O)NC(CC1=CC=CC=C1)C(=O)N(C)CC(=O)N)N(C)C... -2.982271   \n",
      "3  COC1=C2C3=C(CC4C5(C3(CCN4CC6CC6)C(O2)C(=O)CC5)... -1.243038   \n",
      "4  CCCCC(C(=O)NC(CC(=O)O)C(=O)NC(CC1=CC=CC=C1)C(=... -0.397940   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0                  Nc1ccnc(N2CCC3(CC2)OCc2ccccc23)c1  \n",
      "1  COc1ccc2c3c1OC1C4(OC)CCC5(CC4COCc4ccc(C(O)CO)c...  \n",
      "2  CC(C(=O)NC(Cc1ccccc1)C(=O)N(C)CC(N)=O)N(C)C(=O...  \n",
      "3  COc1ccc2c3c1OC1C(=O)CCC4(NC(=O)C=Cc5ccccc5Cl)C...  \n",
      "4  CCCCC(C(=O)NC(CC(=O)O)C(=O)NC(Cc1ccccc1)C(N)=O...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/EC50_P41143_1_200_train.pickle\n",
      "./data/benchmark/EC50_P41143_1_200_train\n",
      "1416\n",
      "feature dicts file saved as ./data/benchmark/EC50_P41143_1_200_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 3) (105, 3) (893, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_EC50_P41143_1_200_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 89 Index:-1.1559 R2:0.0132 0.0123 0.0346 RMSE:1.1954 1.1777 1.0941 Tau:0.0553 0.0218 0.0864\n",
      "Epoch: 2 Step: 178 Index:-0.9128 R2:0.0531 0.0896 0.0235 RMSE:1.1326 1.1014 1.0544 Tau:0.2063 0.1887 0.3856\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 3 Step: 267 Index:-0.9615 R2:0.1121 0.1164 0.0171 RMSE:1.1351 1.1435 1.0400 Tau:0.2323 0.1821 0.4198\n",
      "Epoch: 4 Step: 356 Index:-0.8885 R2:0.0755 0.1184 0.0247 RMSE:1.1064 1.0889 1.0282 Tau:0.2215 0.2004 0.4112\n",
      "Epoch: 5 Step: 445 Index:-0.7945 R2:0.1293 0.1813 0.0304 RMSE:1.0801 1.0623 1.0218 Tau:0.2717 0.2679 0.4235\n",
      "Epoch: 6 Step: 534 Index:-0.7724 R2:0.1421 0.1868 0.0362 RMSE:1.0705 1.0450 1.0400 Tau:0.2745 0.2726 0.4336\n",
      "Epoch: 7 Step: 623 Index:-0.7176 R2:0.2134 0.2383 0.0517 RMSE:1.0456 1.0350 1.0201 Tau:0.3123 0.3174 0.4488\n",
      "Epoch: 8 Step: 712 Index:-0.6394 R2:0.2431 0.2755 0.0669 RMSE:1.0150 0.9978 1.0034 Tau:0.3355 0.3584 0.4568\n",
      "Epoch: 9 Step: 801 Index:-0.6189 R2:0.2840 0.2909 0.0802 RMSE:0.9986 0.9901 1.0009 Tau:0.3616 0.3713 0.4577\n",
      "Epoch: 10 Step: 890 Index:-0.5861 R2:0.2837 0.3047 0.0812 RMSE:0.9886 0.9717 1.0080 Tau:0.3554 0.3856 0.4590\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 11 Step: 979 Index:-0.6290 R2:0.3004 0.3000 0.0979 RMSE:1.0120 1.0130 1.0340 Tau:0.3712 0.3841 0.4683\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 12 Step: 1068 Index:-0.5944 R2:0.3088 0.2998 0.0880 RMSE:0.9838 0.9810 1.0142 Tau:0.3772 0.3867 0.4694\n",
      "Epoch: 13 Step: 1157 Index:-0.5690 R2:0.3240 0.3145 0.0969 RMSE:0.9675 0.9695 1.0025 Tau:0.3889 0.4006 0.4665\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 14 Step: 1246 Index:-0.5701 R2:0.3300 0.3066 0.0936 RMSE:0.9530 0.9600 0.9969 Tau:0.3947 0.3900 0.4640\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 15 Step: 1335 Index:-0.5724 R2:0.3414 0.3188 0.1143 RMSE:0.9691 0.9796 1.0029 Tau:0.4053 0.4072 0.4757\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 16 Step: 1424 Index:-0.6051 R2:0.3485 0.3306 0.1025 RMSE:1.0221 1.0189 1.0728 Tau:0.4095 0.4138 0.4750\n",
      "Epoch: 17 Step: 1513 Index:-0.5293 R2:0.3550 0.3335 0.1192 RMSE:0.9328 0.9427 0.9819 Tau:0.4112 0.4134 0.4783\n",
      "Epoch: 18 Step: 1602 Index:-0.5232 R2:0.3637 0.3365 0.1246 RMSE:0.9346 0.9498 0.9850 Tau:0.4201 0.4266 0.4793\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 19 Step: 1691 Index:-0.5239 R2:0.3761 0.3359 0.1174 RMSE:0.9242 0.9384 0.9773 Tau:0.4258 0.4145 0.4797\n",
      "Epoch: 20 Step: 1780 Index:-0.4979 R2:0.3913 0.3557 0.1343 RMSE:0.9095 0.9256 0.9697 Tau:0.4391 0.4277 0.4802\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 21 Step: 1869 Index:-0.4989 R2:0.3802 0.3565 0.1228 RMSE:0.9086 0.9207 0.9824 Tau:0.4266 0.4219 0.4849\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 22 Step: 1958 Index:-0.5033 R2:0.4038 0.3630 0.1310 RMSE:0.9194 0.9369 0.9795 Tau:0.4480 0.4336 0.4821\n",
      "Epoch: 23 Step: 2047 Index:-0.4724 R2:0.4070 0.3739 0.1402 RMSE:0.8959 0.9111 0.9865 Tau:0.4495 0.4387 0.4884\n",
      "Epoch: 24 Step: 2136 Index:-0.4697 R2:0.4247 0.3759 0.1514 RMSE:0.8862 0.9073 0.9578 Tau:0.4651 0.4376 0.4921\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 25 Step: 2225 Index:-0.5234 R2:0.4355 0.3721 0.1625 RMSE:0.9231 0.9643 0.9902 Tau:0.4742 0.4409 0.4903\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 26 Step: 2314 Index:-0.4888 R2:0.4451 0.3788 0.1689 RMSE:0.8788 0.9323 0.9635 Tau:0.4832 0.4435 0.4955\n",
      "Epoch: 27 Step: 2403 Index:-0.4605 R2:0.4584 0.3942 0.1798 RMSE:0.8635 0.9084 0.9507 Tau:0.4883 0.4479 0.4936\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 28 Step: 2492 Index:-0.4773 R2:0.4645 0.3861 0.1849 RMSE:0.8743 0.9157 0.9457 Tau:0.4922 0.4384 0.4884\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 29 Step: 2581 Index:-0.4885 R2:0.4548 0.3933 0.1924 RMSE:0.8777 0.9357 0.9650 Tau:0.4786 0.4472 0.4947\n",
      "Epoch: 30 Step: 2670 Index:-0.4493 R2:0.4873 0.3943 0.2128 RMSE:0.8343 0.8983 0.9225 Tau:0.5124 0.4490 0.4977\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 31 Step: 2759 Index:-0.4649 R2:0.4750 0.3978 0.1966 RMSE:0.8669 0.9080 0.9670 Tau:0.5010 0.4431 0.5047\n",
      "Epoch: 32 Step: 2848 Index:-0.4337 R2:0.4979 0.4021 0.2064 RMSE:0.8254 0.8874 0.9284 Tau:0.5177 0.4538 0.4987\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 33 Step: 2937 Index:-0.4475 R2:0.5069 0.4059 0.2159 RMSE:0.8405 0.9031 0.9566 Tau:0.5310 0.4556 0.5062\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 34 Step: 3026 Index:-0.4393 R2:0.4797 0.4072 0.2096 RMSE:0.8286 0.8990 0.9484 Tau:0.4953 0.4596 0.4993\n",
      "Epoch: 35 Step: 3115 Index:-0.4310 R2:0.5112 0.4102 0.2267 RMSE:0.8107 0.8899 0.9189 Tau:0.5314 0.4589 0.5078\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 36 Step: 3204 Index:-0.4664 R2:0.5204 0.3925 0.2375 RMSE:0.8129 0.9114 0.9133 Tau:0.5376 0.4450 0.5037\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 37 Step: 3293 Index:-0.5005 R2:0.5179 0.3868 0.2264 RMSE:0.8561 0.9400 0.9731 Tau:0.5344 0.4395 0.5001\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 38 Step: 3382 Index:-0.4500 R2:0.5275 0.4128 0.2402 RMSE:0.8262 0.9059 0.9474 Tau:0.5470 0.4560 0.5104\n",
      "Epoch: 39 Step: 3471 Index:-0.4276 R2:0.5436 0.4135 0.2524 RMSE:0.7955 0.8869 0.9131 Tau:0.5555 0.4593 0.5088\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 40 Step: 3560 Index:-0.5318 R2:0.5487 0.4107 0.2639 RMSE:0.8721 0.9958 0.9717 Tau:0.5585 0.4640 0.5077\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 41 Step: 3649 Index:-0.4598 R2:0.5436 0.4250 0.2389 RMSE:0.8586 0.9275 0.9846 Tau:0.5574 0.4677 0.5112\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 42 Step: 3738 Index:-0.5498 R2:0.5500 0.4031 0.2496 RMSE:0.8889 1.0028 0.9937 Tau:0.5583 0.4530 0.5122\n",
      "Epoch: 43 Step: 3827 Index:-0.4072 R2:0.5483 0.4278 0.2598 RMSE:0.7810 0.8782 0.9002 Tau:0.5547 0.4710 0.5108\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 44 Step: 3916 Index:-0.4764 R2:0.5647 0.4111 0.2657 RMSE:0.8149 0.9265 0.9236 Tau:0.5604 0.4501 0.5016\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 45 Step: 4005 Index:-0.4178 R2:0.5549 0.4201 0.2618 RMSE:0.7755 0.8855 0.9121 Tau:0.5625 0.4677 0.5157\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 46 Step: 4094 Index:-0.4637 R2:0.5748 0.4191 0.2694 RMSE:0.7801 0.9263 0.9179 Tau:0.5751 0.4626 0.5126\n",
      "Epoch: 47 Step: 4183 Index:-0.4022 R2:0.5796 0.4361 0.2682 RMSE:0.7707 0.8780 0.9147 Tau:0.5786 0.4758 0.5140\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 48 Step: 4272 Index:-0.4053 R2:0.5806 0.4392 0.2725 RMSE:0.7618 0.8818 0.8990 Tau:0.5781 0.4765 0.5112\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 49 Step: 4361 Index:-0.4162 R2:0.5780 0.4224 0.2726 RMSE:0.7523 0.8901 0.9038 Tau:0.5740 0.4739 0.5106\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 50 Step: 4450 Index:-0.4183 R2:0.5763 0.4236 0.2832 RMSE:0.7521 0.8853 0.8896 Tau:0.5736 0.4670 0.4991\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 51 Step: 4539 Index:-0.5126 R2:0.5761 0.4055 0.2806 RMSE:0.8076 0.9788 0.9439 Tau:0.5719 0.4662 0.5136\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 52 Step: 4628 Index:-0.4026 R2:0.5962 0.4376 0.2814 RMSE:0.7412 0.8783 0.9083 Tau:0.5822 0.4758 0.5094\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 53 Step: 4717 Index:-0.6270 R2:0.5611 0.3989 0.2518 RMSE:0.9536 1.0580 1.1105 Tau:0.5517 0.4310 0.5047\n",
      "Epoch: 54 Step: 4806 Index:-0.4010 R2:0.5895 0.4460 0.2786 RMSE:0.7605 0.8793 0.9229 Tau:0.5775 0.4783 0.5031\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 55 Step: 4895 Index:-0.4011 R2:0.5966 0.4258 0.2779 RMSE:0.7473 0.8728 0.8918 Tau:0.5836 0.4717 0.5166\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 56 Step: 4984 Index:-0.4270 R2:0.6110 0.4333 0.2855 RMSE:0.7456 0.9027 0.9027 Tau:0.5911 0.4758 0.5091\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 57 Step: 5073 Index:-0.4658 R2:0.6057 0.4152 0.2834 RMSE:0.7501 0.9280 0.9091 Tau:0.5897 0.4622 0.5103\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 58 Step: 5162 Index:-0.4120 R2:0.6112 0.4323 0.2864 RMSE:0.7241 0.8800 0.9000 Tau:0.5896 0.4681 0.5041\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 59 Step: 5251 Index:-0.4158 R2:0.6162 0.4423 0.2865 RMSE:0.7277 0.8978 0.9066 Tau:0.5955 0.4820 0.5133\n",
      "Epoch: 60 Step: 5340 Index:-0.3984 R2:0.6215 0.4391 0.2861 RMSE:0.7200 0.8745 0.8977 Tau:0.5980 0.4761 0.5109\n",
      "Epoch: 61 Step: 5429 Index:-0.3891 R2:0.5825 0.4517 0.2710 RMSE:0.7481 0.8821 0.9309 Tau:0.5747 0.4930 0.5142\n",
      "Epoch: 62 Step: 5518 Index:-0.3787 R2:0.6163 0.4601 0.2901 RMSE:0.7151 0.8651 0.8952 Tau:0.6003 0.4864 0.5147\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 63 Step: 5607 Index:-0.4952 R2:0.6217 0.4256 0.2845 RMSE:0.7668 0.9482 0.9329 Tau:0.5949 0.4530 0.5126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 64 Step: 5696 Index:-0.4155 R2:0.6253 0.4368 0.2898 RMSE:0.7691 0.8961 0.9293 Tau:0.5997 0.4805 0.5143\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 65 Step: 5785 Index:-0.4068 R2:0.6331 0.4377 0.2875 RMSE:0.7136 0.8792 0.8928 Tau:0.6042 0.4725 0.5153\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 66 Step: 5874 Index:-0.4681 R2:0.6338 0.4442 0.2920 RMSE:0.7579 0.9461 0.9340 Tau:0.6063 0.4780 0.5181\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 67 Step: 5963 Index:-0.5224 R2:0.6418 0.4374 0.3039 RMSE:0.7996 0.9974 0.9672 Tau:0.6092 0.4750 0.5151\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 68 Step: 6052 Index:-0.4788 R2:0.6374 0.4469 0.2940 RMSE:0.7513 0.9479 0.9396 Tau:0.6051 0.4692 0.5062\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 69 Step: 6141 Index:-0.4903 R2:0.6481 0.4352 0.3030 RMSE:0.7594 0.9613 0.9367 Tau:0.6141 0.4710 0.5096\n",
      "Epoch: 70 Step: 6230 Index:-0.3725 R2:0.6493 0.4538 0.3036 RMSE:0.6936 0.8589 0.8865 Tau:0.6175 0.4864 0.5164\n",
      "Epoch: 71 Step: 6319 Index:-0.3716 R2:0.6411 0.4514 0.2947 RMSE:0.6927 0.8653 0.8923 Tau:0.6112 0.4937 0.5179\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 72 Step: 6408 Index:-0.4922 R2:0.6485 0.4362 0.2858 RMSE:0.7411 0.9551 0.9454 Tau:0.6111 0.4629 0.5065\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 73 Step: 6497 Index:-0.4276 R2:0.6455 0.4612 0.2886 RMSE:0.7774 0.9070 0.9689 Tau:0.6109 0.4794 0.5087\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 74 Step: 6586 Index:-0.4019 R2:0.6529 0.4389 0.2920 RMSE:0.6908 0.8714 0.8948 Tau:0.6139 0.4695 0.5135\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 75 Step: 6675 Index:-0.4387 R2:0.6527 0.4284 0.3033 RMSE:0.6869 0.9023 0.8948 Tau:0.6124 0.4637 0.5128\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 76 Step: 6764 Index:-0.4473 R2:0.6352 0.4703 0.2897 RMSE:0.8413 0.9466 1.0416 Tau:0.6035 0.4992 0.5148\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 77 Step: 6853 Index:-0.3773 R2:0.6625 0.4589 0.3018 RMSE:0.6854 0.8648 0.9029 Tau:0.6224 0.4875 0.5134\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 78 Step: 6942 Index:-0.4659 R2:0.6537 0.4206 0.2916 RMSE:0.6982 0.9226 0.9129 Tau:0.6129 0.4567 0.5162\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 79 Step: 7031 Index:-0.4319 R2:0.6581 0.4285 0.3007 RMSE:0.6724 0.9099 0.9062 Tau:0.6227 0.4780 0.5197\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 80 Step: 7120 Index:-0.3729 R2:0.6633 0.4563 0.2989 RMSE:0.6924 0.8714 0.9081 Tau:0.6274 0.4985 0.5241\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 81 Step: 7209 Index:-0.4083 R2:0.6702 0.4562 0.3085 RMSE:0.6947 0.8888 0.8982 Tau:0.6261 0.4805 0.5161\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 82 Step: 7298 Index:-0.3874 R2:0.6682 0.4560 0.3030 RMSE:0.6917 0.8797 0.9155 Tau:0.6301 0.4923 0.5203\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 83 Step: 7387 Index:-0.4149 R2:0.6549 0.4152 0.2964 RMSE:0.7051 0.8800 0.8765 Tau:0.6137 0.4651 0.5160\n",
      "Epoch: 84 Step: 7476 Index:-0.3508 R2:0.6736 0.4654 0.3102 RMSE:0.6948 0.8452 0.8787 Tau:0.6334 0.4945 0.5189\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 85 Step: 7565 Index:-0.4756 R2:0.6779 0.4551 0.3054 RMSE:0.7431 0.9591 0.9486 Tau:0.6320 0.4835 0.5133\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 86 Step: 7654 Index:-0.4081 R2:0.6784 0.4628 0.3021 RMSE:0.6896 0.9025 0.9129 Tau:0.6342 0.4945 0.5163\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 87 Step: 7743 Index:-0.3751 R2:0.6551 0.4563 0.2943 RMSE:0.6762 0.8718 0.9050 Tau:0.6185 0.4967 0.5217\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 88 Step: 7832 Index:-0.3789 R2:0.6801 0.4548 0.3041 RMSE:0.6534 0.8774 0.9029 Tau:0.6358 0.4985 0.5218\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 89 Step: 7921 Index:-0.4400 R2:0.6820 0.4506 0.2896 RMSE:0.6827 0.9176 0.9300 Tau:0.6314 0.4776 0.5154\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 90 Step: 8010 Index:-0.4202 R2:0.6489 0.4404 0.2839 RMSE:0.7023 0.8944 0.9349 Tau:0.6105 0.4743 0.5093\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 91 Step: 8099 Index:-0.3816 R2:0.6755 0.4501 0.2917 RMSE:0.6619 0.8732 0.9008 Tau:0.6277 0.4915 0.5214\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 92 Step: 8188 Index:-0.4061 R2:0.6753 0.4428 0.2836 RMSE:0.6759 0.8771 0.9149 Tau:0.6272 0.4710 0.5126\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 93 Step: 8277 Index:-0.3721 R2:0.6940 0.4617 0.3049 RMSE:0.6452 0.8589 0.8890 Tau:0.6396 0.4868 0.5190\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 94 Step: 8366 Index:-0.4372 R2:0.6825 0.4389 0.2891 RMSE:0.6806 0.9063 0.9163 Tau:0.6290 0.4692 0.5216\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 95 Step: 8455 Index:-0.3578 R2:0.6927 0.4725 0.3053 RMSE:0.6786 0.8589 0.9138 Tau:0.6395 0.5011 0.5201\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 96 Step: 8544 Index:-0.3606 R2:0.6858 0.4753 0.3076 RMSE:0.6449 0.8639 0.9045 Tau:0.6396 0.5033 0.5246\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 97 Step: 8633 Index:-0.3546 R2:0.6951 0.4772 0.3087 RMSE:0.6430 0.8571 0.8925 Tau:0.6431 0.5025 0.5232\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 98 Step: 8722 Index:-0.3758 R2:0.7008 0.4584 0.3089 RMSE:0.6389 0.8666 0.8872 Tau:0.6456 0.4908 0.5259\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 99 Step: 8811 Index:-0.3860 R2:0.7049 0.4597 0.3086 RMSE:0.6292 0.8676 0.8959 Tau:0.6442 0.4816 0.5185\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 100 Step: 8900 Index:-0.4116 R2:0.7080 0.4570 0.3066 RMSE:0.6353 0.8991 0.9129 Tau:0.6480 0.4875 0.5196\n",
      "Epoch: 101 Step: 8989 Index:-0.3406 R2:0.7100 0.4698 0.3068 RMSE:0.6370 0.8431 0.8792 Tau:0.6525 0.5025 0.5255\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 102 Step: 9078 Index:-0.4251 R2:0.7106 0.4528 0.3070 RMSE:0.6570 0.9126 0.9202 Tau:0.6504 0.4875 0.5227\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 103 Step: 9167 Index:-0.4102 R2:0.7107 0.4686 0.3027 RMSE:0.6584 0.9064 0.9346 Tau:0.6495 0.4963 0.5233\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 104 Step: 9256 Index:-0.3518 R2:0.7163 0.4742 0.3046 RMSE:0.6176 0.8506 0.8983 Tau:0.6529 0.4989 0.5215\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 105 Step: 9345 Index:-0.4055 R2:0.7163 0.4722 0.3016 RMSE:0.6282 0.8959 0.9213 Tau:0.6544 0.4904 0.5199\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 106 Step: 9434 Index:-0.3513 R2:0.6839 0.4720 0.2857 RMSE:0.6531 0.8597 0.9278 Tau:0.6325 0.5084 0.5244\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 107 Step: 9523 Index:-0.3587 R2:0.7160 0.4728 0.3058 RMSE:0.6381 0.8612 0.9186 Tau:0.6554 0.5025 0.5224\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 108 Step: 9612 Index:-0.4180 R2:0.7092 0.4657 0.2967 RMSE:0.7549 0.9114 0.9810 Tau:0.6510 0.4934 0.5278\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 109 Step: 9701 Index:-0.4445 R2:0.7100 0.4556 0.3034 RMSE:0.6409 0.9375 0.9345 Tau:0.6548 0.4930 0.5285\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 110 Step: 9790 Index:-0.3992 R2:0.7082 0.4418 0.2862 RMSE:0.6342 0.8775 0.9059 Tau:0.6519 0.4783 0.5256\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 111 Step: 9879 Index:-0.3825 R2:0.7196 0.4635 0.2988 RMSE:0.6202 0.8711 0.9022 Tau:0.6583 0.4886 0.5272\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 112 Step: 9968 Index:-0.3966 R2:0.7240 0.4551 0.2978 RMSE:0.6095 0.8779 0.9188 Tau:0.6599 0.4813 0.5257\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 113 Step: 10057 Index:-0.3918 R2:0.6993 0.4855 0.2915 RMSE:0.6394 0.9134 0.9508 Tau:0.6492 0.5216 0.5273\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 114 Step: 10146 Index:-0.3760 R2:0.7246 0.4683 0.2955 RMSE:0.6085 0.8635 0.9061 Tau:0.6582 0.4875 0.5202\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 115 Step: 10235 Index:-1.9851 R2:0.1007 0.0457 0.0349 RMSE:1.9483 2.1426 1.9885 Tau:0.2212 0.1575 -0.0435\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 116 Step: 10324 Index:-0.4608 R2:0.5886 0.3973 0.2314 RMSE:0.7707 0.9146 0.9349 Tau:0.5695 0.4538 0.4786\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 117 Step: 10413 Index:-0.3660 R2:0.6514 0.4517 0.2632 RMSE:0.7002 0.8659 0.9084 Tau:0.6127 0.5000 0.5134\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 118 Step: 10502 Index:-0.3808 R2:0.6607 0.4327 0.2711 RMSE:0.7004 0.8742 0.8959 Tau:0.6240 0.4934 0.5200\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 119 Step: 10591 Index:-0.4043 R2:0.6879 0.4525 0.2940 RMSE:0.6792 0.9016 0.9059 Tau:0.6407 0.4974 0.5212\n",
      "Epoch: 120 Step: 10680 Index:-0.3360 R2:0.6955 0.4790 0.2983 RMSE:0.6439 0.8502 0.9114 Tau:0.6446 0.5143 0.5220\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 121 Step: 10769 Index:-0.3796 R2:0.7114 0.4661 0.3075 RMSE:0.6415 0.8806 0.8983 Tau:0.6539 0.5011 0.5242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 122 Step: 10858 Index:-0.3915 R2:0.7131 0.4600 0.3096 RMSE:0.6226 0.8845 0.9015 Tau:0.6533 0.4930 0.5230\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 123 Step: 10947 Index:-0.3558 R2:0.7150 0.4740 0.3087 RMSE:0.6156 0.8605 0.8970 Tau:0.6567 0.5047 0.5250\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 124 Step: 11036 Index:-0.4024 R2:0.7208 0.4629 0.3037 RMSE:0.6176 0.8906 0.9165 Tau:0.6565 0.4882 0.5171\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 125 Step: 11125 Index:-0.4430 R2:0.7166 0.4450 0.2976 RMSE:0.6404 0.9140 0.9311 Tau:0.6532 0.4710 0.5161\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 126 Step: 11214 Index:-0.3623 R2:0.7243 0.4761 0.3077 RMSE:0.6529 0.8682 0.9317 Tau:0.6635 0.5058 0.5264\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 127 Step: 11303 Index:-0.4121 R2:0.7263 0.4626 0.3034 RMSE:0.6443 0.9021 0.9225 Tau:0.6639 0.4901 0.5232\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 128 Step: 11392 Index:-0.3808 R2:0.7287 0.4599 0.3048 RMSE:0.6034 0.8698 0.9060 Tau:0.6639 0.4890 0.5224\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 129 Step: 11481 Index:-0.3675 R2:0.7260 0.4686 0.3139 RMSE:0.6028 0.8693 0.9055 Tau:0.6636 0.5018 0.5270\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 130 Step: 11570 Index:-0.3828 R2:0.7360 0.4788 0.3108 RMSE:0.6192 0.8948 0.9174 Tau:0.6712 0.5121 0.5240\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 131 Step: 11659 Index:-0.4400 R2:0.7388 0.4667 0.3128 RMSE:0.6365 0.9388 0.9396 Tau:0.6728 0.4989 0.5243\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 132 Step: 11748 Index:-0.3546 R2:0.7391 0.4722 0.3022 RMSE:0.5946 0.8572 0.9009 Tau:0.6733 0.5025 0.5250\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 133 Step: 11837 Index:-0.4191 R2:0.7300 0.4768 0.3029 RMSE:0.6531 0.9360 0.9535 Tau:0.6678 0.5168 0.5283\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 134 Step: 11926 Index:-0.3769 R2:0.7287 0.4646 0.2904 RMSE:0.6475 0.8739 0.9413 Tau:0.6626 0.4970 0.5244\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 135 Step: 12015 Index:-0.3876 R2:0.7386 0.4611 0.3109 RMSE:0.5955 0.8850 0.9052 Tau:0.6715 0.4974 0.5260\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 136 Step: 12104 Index:-0.4130 R2:0.7455 0.4634 0.3104 RMSE:0.6086 0.9049 0.9208 Tau:0.6749 0.4919 0.5231\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 137 Step: 12193 Index:-0.3702 R2:0.7469 0.4754 0.3051 RMSE:0.5844 0.8694 0.9093 Tau:0.6777 0.4992 0.5240\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 138 Step: 12282 Index:-0.4040 R2:0.7473 0.4614 0.3066 RMSE:0.5957 0.8937 0.9126 Tau:0.6789 0.4897 0.5260\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 139 Step: 12371 Index:-0.3806 R2:0.7441 0.4558 0.3007 RMSE:0.5946 0.8655 0.9006 Tau:0.6708 0.4849 0.5230\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 140 Step: 12460 Index:-0.3676 R2:0.7417 0.4702 0.3006 RMSE:0.6018 0.8690 0.9306 Tau:0.6739 0.5014 0.5251\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 141 Step: 12549 Index:-0.6370 R2:0.7379 0.4721 0.3110 RMSE:0.8519 1.1520 1.1244 Tau:0.6718 0.5150 0.5260\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 142 Step: 12638 Index:-0.3660 R2:0.7492 0.4759 0.3140 RMSE:0.5806 0.8678 0.9174 Tau:0.6796 0.5018 0.5271\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 143 Step: 12727 Index:-0.3955 R2:0.7471 0.4848 0.3050 RMSE:0.6122 0.9065 0.9419 Tau:0.6788 0.5110 0.5253\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 144 Step: 12816 Index:-0.8641 R2:0.6718 0.3606 0.2591 RMSE:0.9759 1.2900 1.2363 Tau:0.6205 0.4259 0.5080\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 145 Step: 12905 Index:-0.4518 R2:0.7444 0.4457 0.2990 RMSE:0.6441 0.9319 0.9371 Tau:0.6734 0.4802 0.5203\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 146 Step: 12994 Index:-0.4300 R2:0.7214 0.4410 0.2782 RMSE:0.6173 0.9116 0.9595 Tau:0.6595 0.4816 0.5192\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 147 Step: 13083 Index:-0.4575 R2:0.7372 0.4407 0.2813 RMSE:0.5959 0.9295 0.9532 Tau:0.6700 0.4721 0.5173\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 148 Step: 13172 Index:-0.4670 R2:0.7416 0.4237 0.2872 RMSE:0.6593 0.9313 0.9666 Tau:0.6725 0.4644 0.5232\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 149 Step: 13261 Index:-0.3365 R2:0.7577 0.4901 0.2956 RMSE:0.6157 0.8431 0.9302 Tau:0.6854 0.5066 0.5234\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 150 Step: 13350 Index:-0.4031 R2:0.7588 0.4547 0.2990 RMSE:0.5698 0.8935 0.9199 Tau:0.6858 0.4904 0.5274\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 151 Step: 13439 Index:-0.4245 R2:0.7634 0.4704 0.3010 RMSE:0.5910 0.9238 0.9487 Tau:0.6904 0.4992 0.5265\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 152 Step: 13528 Index:-0.3968 R2:0.7623 0.4640 0.3058 RMSE:0.5630 0.8916 0.9322 Tau:0.6924 0.4948 0.5294\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 153 Step: 13617 Index:-0.4323 R2:0.7557 0.4509 0.2839 RMSE:0.5794 0.9103 0.9417 Tau:0.6823 0.4780 0.5179\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 154 Step: 13706 Index:-0.4546 R2:0.7503 0.4604 0.3068 RMSE:0.5967 0.9516 0.9647 Tau:0.6775 0.4970 0.5173\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 155 Step: 13795 Index:-0.3977 R2:0.7599 0.4767 0.2961 RMSE:0.5736 0.8947 0.9470 Tau:0.6849 0.4970 0.5246\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 156 Step: 13884 Index:-0.3848 R2:0.7678 0.4704 0.3017 RMSE:0.5581 0.8814 0.9266 Tau:0.6919 0.4967 0.5229\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 157 Step: 13973 Index:-0.4250 R2:0.7400 0.4714 0.2630 RMSE:0.5863 0.9070 0.9803 Tau:0.6704 0.4820 0.5139\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 158 Step: 14062 Index:-0.4047 R2:0.7668 0.4630 0.2919 RMSE:0.5849 0.8874 0.9438 Tau:0.6911 0.4827 0.5220\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 159 Step: 14151 Index:-0.3890 R2:0.7698 0.4724 0.2936 RMSE:0.5522 0.8879 0.9389 Tau:0.6957 0.4989 0.5247\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 160 Step: 14240 Index:-0.4603 R2:0.7448 0.4367 0.2769 RMSE:0.5828 0.9276 0.9619 Tau:0.6733 0.4673 0.5166\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 161 Step: 14329 Index:-0.3769 R2:0.7644 0.4755 0.2875 RMSE:0.5581 0.8809 0.9449 Tau:0.6894 0.5040 0.5252\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 162 Step: 14418 Index:-0.4294 R2:0.7705 0.4600 0.3010 RMSE:0.5717 0.9216 0.9432 Tau:0.6951 0.4923 0.5269\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 163 Step: 14507 Index:-0.4959 R2:0.7560 0.4758 0.2934 RMSE:0.6225 1.0036 1.0082 Tau:0.6792 0.5077 0.5264\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 164 Step: 14596 Index:-0.5542 R2:0.7584 0.4262 0.2883 RMSE:0.6771 1.0167 1.0058 Tau:0.6858 0.4626 0.5250\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 165 Step: 14685 Index:-0.4447 R2:0.7697 0.4714 0.3008 RMSE:0.5785 0.9505 0.9628 Tau:0.6947 0.5058 0.5292\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 166 Step: 14774 Index:-0.4159 R2:0.7711 0.4545 0.2831 RMSE:0.5563 0.9005 0.9426 Tau:0.6959 0.4846 0.5177\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 167 Step: 14863 Index:-0.4662 R2:0.7794 0.4634 0.2871 RMSE:0.6131 0.9522 0.9808 Tau:0.7018 0.4860 0.5277\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 168 Step: 14952 Index:-0.4294 R2:0.7800 0.4584 0.2959 RMSE:0.5562 0.9187 0.9465 Tau:0.7008 0.4893 0.5287\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 169 Step: 15041 Index:-0.3824 R2:0.7734 0.4619 0.2870 RMSE:0.5944 0.8692 0.9447 Tau:0.6943 0.4868 0.5298\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 170 Step: 15130 Index:-0.3741 R2:0.7735 0.4643 0.2800 RMSE:0.5535 0.8704 0.9474 Tau:0.6930 0.4963 0.5269\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 171 Step: 15219 Index:-0.3957 R2:0.7805 0.4570 0.2828 RMSE:0.5462 0.8825 0.9342 Tau:0.7018 0.4868 0.5281\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 172 Step: 15308 Index:-0.3634 R2:0.7784 0.4888 0.2796 RMSE:0.5475 0.8700 0.9403 Tau:0.7012 0.5066 0.5274\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 173 Step: 15397 Index:-0.4017 R2:0.7860 0.4686 0.2912 RMSE:0.5324 0.8980 0.9511 Tau:0.7063 0.4963 0.5291\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 174 Step: 15486 Index:-0.4169 R2:0.7894 0.4587 0.2992 RMSE:0.5430 0.9114 0.9365 Tau:0.7101 0.4945 0.5292\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 175 Step: 15575 Index:-0.4911 R2:0.7873 0.4419 0.2990 RMSE:0.5825 0.9731 0.9640 Tau:0.7071 0.4820 0.5312\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 176 Step: 15664 Index:-0.4652 R2:0.7830 0.4358 0.2863 RMSE:0.5747 0.9431 0.9508 Tau:0.7045 0.4780 0.5304\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 177 Step: 15753 Index:-0.3998 R2:0.7902 0.4559 0.2858 RMSE:0.5311 0.8928 0.9322 Tau:0.7100 0.4930 0.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 178 Step: 15842 Index:-0.3749 R2:0.7662 0.4882 0.2756 RMSE:0.5643 0.8998 0.9763 Tau:0.6932 0.5249 0.5347\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 179 Step: 15931 Index:-0.5028 R2:0.7840 0.4629 0.2817 RMSE:0.5953 0.9888 1.0062 Tau:0.7033 0.4860 0.5268\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 180 Step: 16020 Index:-0.3991 R2:0.7930 0.4695 0.2859 RMSE:0.5397 0.9031 0.9460 Tau:0.7122 0.5040 0.5309\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 181 Step: 16109 Index:-0.4294 R2:0.7955 0.4615 0.2839 RMSE:0.5203 0.9268 0.9663 Tau:0.7138 0.4974 0.5310\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 182 Step: 16198 Index:-0.4730 R2:0.7941 0.4360 0.2960 RMSE:0.5587 0.9502 0.9484 Tau:0.7128 0.4772 0.5316\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 183 Step: 16287 Index:-0.3810 R2:0.7956 0.4740 0.2845 RMSE:0.5363 0.8817 0.9356 Tau:0.7119 0.5007 0.5314\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 184 Step: 16376 Index:-0.4079 R2:0.8001 0.4654 0.2895 RMSE:0.5206 0.9052 0.9473 Tau:0.7176 0.4974 0.5327\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 185 Step: 16465 Index:-0.4861 R2:0.7849 0.4469 0.2707 RMSE:0.5345 0.9615 0.9870 Tau:0.7040 0.4754 0.5276\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 186 Step: 16554 Index:-0.3822 R2:0.7926 0.4790 0.2916 RMSE:0.5251 0.8888 0.9543 Tau:0.7116 0.5066 0.5342\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 187 Step: 16643 Index:-0.3965 R2:0.7902 0.4539 0.2752 RMSE:0.5590 0.8800 0.9546 Tau:0.7073 0.4835 0.5278\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 188 Step: 16732 Index:-0.4855 R2:0.8000 0.4507 0.2870 RMSE:0.5737 0.9664 0.9775 Tau:0.7207 0.4809 0.5325\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 189 Step: 16821 Index:-0.4173 R2:0.8037 0.4716 0.2915 RMSE:0.5184 0.9069 0.9477 Tau:0.7190 0.4897 0.5283\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 190 Step: 16910 Index:-0.4066 R2:0.7787 0.4751 0.2788 RMSE:0.5614 0.9271 0.9728 Tau:0.6984 0.5205 0.5332\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 191 Step: 16999 Index:-0.4170 R2:0.8002 0.4622 0.3024 RMSE:0.5161 0.8986 0.9381 Tau:0.7125 0.4816 0.5304\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 192 Step: 17088 Index:-0.3725 R2:0.7864 0.4970 0.2805 RMSE:0.5338 0.8981 0.9743 Tau:0.7076 0.5256 0.5340\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 193 Step: 17177 Index:-0.4662 R2:0.8028 0.4604 0.2766 RMSE:0.5752 0.9595 0.9804 Tau:0.7210 0.4934 0.5311\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 194 Step: 17266 Index:-0.4109 R2:0.7870 0.4683 0.2849 RMSE:0.5300 0.9189 0.9616 Tau:0.7066 0.5080 0.5346\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 195 Step: 17355 Index:-0.5061 R2:0.8046 0.4551 0.2853 RMSE:0.5825 0.9932 1.0073 Tau:0.7192 0.4871 0.5291\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 196 Step: 17444 Index:-0.5033 R2:0.7125 0.4138 0.2742 RMSE:0.6250 0.9589 1.0033 Tau:0.6506 0.4556 0.5190\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 197 Step: 17533 Index:-0.3921 R2:0.8047 0.4592 0.2890 RMSE:0.5171 0.8869 0.9347 Tau:0.7204 0.4948 0.5320\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 198 Step: 17622 Index:-0.3675 R2:0.8002 0.4762 0.2808 RMSE:0.5210 0.8759 0.9388 Tau:0.7195 0.5084 0.5329\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 199 Step: 17711 Index:-0.5075 R2:0.8044 0.4664 0.2974 RMSE:0.5838 1.0075 1.0116 Tau:0.7201 0.5000 0.5286\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 200 Step: 17800 Index:-0.4932 R2:0.8021 0.4440 0.2824 RMSE:0.5180 0.9745 0.9967 Tau:0.7177 0.4813 0.5270\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 201 Step: 17889 Index:-0.4095 R2:0.8107 0.4497 0.2803 RMSE:0.5083 0.8996 0.9503 Tau:0.7241 0.4901 0.5313\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 202 Step: 17978 Index:-0.4100 R2:0.8101 0.4456 0.2775 RMSE:0.5336 0.9099 0.9680 Tau:0.7238 0.5000 0.5314\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 203 Step: 18067 Index:-0.4482 R2:0.8120 0.4480 0.2894 RMSE:0.5028 0.9335 0.9590 Tau:0.7235 0.4853 0.5343\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 204 Step: 18156 Index:-0.4027 R2:0.8168 0.4656 0.2720 RMSE:0.4933 0.9048 0.9615 Tau:0.7310 0.5022 0.5346\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 205 Step: 18245 Index:-0.5130 R2:0.7950 0.4319 0.2641 RMSE:0.5507 0.9880 1.0039 Tau:0.7128 0.4750 0.5295\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 206 Step: 18334 Index:-0.4382 R2:0.8044 0.4590 0.2800 RMSE:0.5093 0.9367 0.9756 Tau:0.7216 0.4985 0.5304\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 207 Step: 18423 Index:-0.4400 R2:0.8088 0.4634 0.2673 RMSE:0.5023 0.9385 1.0052 Tau:0.7232 0.4985 0.5275\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 208 Step: 18512 Index:-0.4534 R2:0.8017 0.4531 0.2885 RMSE:0.5376 0.9574 0.9654 Tau:0.7201 0.5040 0.5363\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 209 Step: 18601 Index:-0.6448 R2:0.7586 0.4295 0.2373 RMSE:0.6566 1.1147 1.1151 Tau:0.6826 0.4699 0.5231\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 210 Step: 18690 Index:-0.3782 R2:0.7596 0.4835 0.2698 RMSE:0.6087 0.8954 1.0121 Tau:0.6818 0.5172 0.5260\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 211 Step: 18779 Index:-0.4320 R2:0.8087 0.4701 0.2632 RMSE:0.5149 0.9345 0.9943 Tau:0.7235 0.5025 0.5297\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 212 Step: 18868 Index:-0.4100 R2:0.8117 0.4667 0.2723 RMSE:0.4983 0.9199 0.9790 Tau:0.7300 0.5099 0.5337\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 213 Step: 18957 Index:-0.5346 R2:0.8059 0.4317 0.2555 RMSE:0.5633 1.0147 1.0334 Tau:0.7242 0.4802 0.5311\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 214 Step: 19046 Index:-0.4932 R2:0.8035 0.4566 0.2864 RMSE:0.5706 0.9862 0.9975 Tau:0.7183 0.4930 0.5356\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 215 Step: 19135 Index:-0.4018 R2:0.8210 0.4742 0.2916 RMSE:0.4861 0.9183 0.9620 Tau:0.7316 0.5165 0.5353\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 216 Step: 19224 Index:-0.3981 R2:0.8090 0.4736 0.2819 RMSE:0.5020 0.9138 0.9675 Tau:0.7250 0.5157 0.5359\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 217 Step: 19313 Index:-0.4406 R2:0.8177 0.4501 0.2689 RMSE:0.4933 0.9318 0.9821 Tau:0.7296 0.4912 0.5337\n",
      "Epoch: 218 Step: 19402 Index:-0.3162 R2:0.7092 0.4756 0.2124 RMSE:0.6968 0.8341 0.9273 Tau:0.6528 0.5179 0.5150\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 219 Step: 19491 Index:-0.4404 R2:0.7938 0.4540 0.2772 RMSE:0.5806 0.9305 0.9518 Tau:0.7123 0.4901 0.5265\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 220 Step: 19580 Index:-0.4091 R2:0.8025 0.4646 0.2642 RMSE:0.5124 0.9047 0.9598 Tau:0.7236 0.4956 0.5302\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 221 Step: 19669 Index:-0.5033 R2:0.8030 0.4264 0.2838 RMSE:0.5400 0.9845 0.9779 Tau:0.7172 0.4813 0.5326\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 222 Step: 19758 Index:-0.4745 R2:0.8154 0.4456 0.2872 RMSE:0.5098 0.9616 0.9707 Tau:0.7276 0.4871 0.5308\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 223 Step: 19847 Index:-0.4452 R2:0.8265 0.4454 0.2912 RMSE:0.4906 0.9415 0.9571 Tau:0.7355 0.4963 0.5319\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 224 Step: 19936 Index:-0.4978 R2:0.8201 0.4371 0.2797 RMSE:0.5054 0.9820 0.9813 Tau:0.7366 0.4842 0.5289\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 225 Step: 20025 Index:-0.4799 R2:0.8145 0.4333 0.2838 RMSE:0.5054 0.9556 0.9637 Tau:0.7267 0.4758 0.5282\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 226 Step: 20114 Index:-0.5040 R2:0.8165 0.4319 0.2768 RMSE:0.5246 0.9904 0.9889 Tau:0.7259 0.4864 0.5334\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 227 Step: 20203 Index:-0.4448 R2:0.8247 0.4535 0.2797 RMSE:0.4982 0.9411 0.9641 Tau:0.7402 0.4963 0.5309\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 228 Step: 20292 Index:-0.5078 R2:0.8302 0.4508 0.2849 RMSE:0.4962 1.0052 1.0065 Tau:0.7412 0.4974 0.5323\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 229 Step: 20381 Index:-0.3871 R2:0.8235 0.4527 0.2647 RMSE:0.5265 0.8922 0.9573 Tau:0.7376 0.5051 0.5317\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 230 Step: 20470 Index:-0.5731 R2:0.7989 0.4022 0.2749 RMSE:0.6075 1.0239 1.0138 Tau:0.7128 0.4508 0.5208\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 231 Step: 20559 Index:-0.4118 R2:0.8113 0.4733 0.2776 RMSE:0.4991 0.9319 0.9801 Tau:0.7286 0.5201 0.5347\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 232 Step: 20648 Index:-0.5134 R2:0.8306 0.4625 0.2884 RMSE:0.5379 1.0288 1.0202 Tau:0.7407 0.5154 0.5351\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 233 Step: 20737 Index:-0.4898 R2:0.8294 0.4348 0.2667 RMSE:0.4883 0.9776 0.9914 Tau:0.7416 0.4879 0.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 234 Step: 20826 Index:-0.4339 R2:0.8279 0.4612 0.2726 RMSE:0.4776 0.9442 0.9923 Tau:0.7393 0.5102 0.5350\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 235 Step: 20915 Index:-0.4284 R2:0.8354 0.4626 0.2650 RMSE:0.4671 0.9365 0.9887 Tau:0.7445 0.5080 0.5338\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 236 Step: 21004 Index:-0.4436 R2:0.8292 0.4532 0.2767 RMSE:0.4877 0.9506 0.9993 Tau:0.7382 0.5069 0.5344\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 237 Step: 21093 Index:-0.6447 R2:0.8153 0.4133 0.2553 RMSE:0.6421 1.1190 1.0957 Tau:0.7304 0.4743 0.5318\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 238 Step: 21182 Index:-0.4360 R2:0.8303 0.4359 0.2614 RMSE:0.4913 0.9140 0.9649 Tau:0.7423 0.4780 0.5328\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 239 Step: 21271 Index:-0.4441 R2:0.8306 0.4421 0.2576 RMSE:0.4775 0.9371 0.9784 Tau:0.7427 0.4930 0.5328\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 240 Step: 21360 Index:-0.5093 R2:0.8192 0.4481 0.2736 RMSE:0.5054 1.0019 1.0149 Tau:0.7282 0.4926 0.5343\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 241 Step: 21449 Index:-0.4555 R2:0.8354 0.4621 0.2756 RMSE:0.4726 0.9606 0.9914 Tau:0.7397 0.5051 0.5332\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 242 Step: 21538 Index:-0.4969 R2:0.8370 0.4536 0.2819 RMSE:0.4656 0.9902 1.0065 Tau:0.7465 0.4934 0.5322\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 243 Step: 21627 Index:-0.4297 R2:0.8310 0.4645 0.2755 RMSE:0.4769 0.9396 0.9762 Tau:0.7434 0.5099 0.5358\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 244 Step: 21716 Index:-0.5041 R2:0.8307 0.4480 0.2710 RMSE:0.4846 0.9978 1.0306 Tau:0.7394 0.4937 0.5333\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 245 Step: 21805 Index:-0.4877 R2:0.8180 0.4107 0.2532 RMSE:0.4967 0.9499 0.9883 Tau:0.7275 0.4622 0.5301\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 246 Step: 21894 Index:-0.4333 R2:0.8363 0.4557 0.2532 RMSE:0.4683 0.9274 0.9989 Tau:0.7469 0.4941 0.5316\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 247 Step: 21983 Index:-0.4949 R2:0.8271 0.4425 0.2559 RMSE:0.5112 0.9824 1.0316 Tau:0.7389 0.4875 0.5266\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 248 Step: 22072 Index:-0.5096 R2:0.8210 0.4253 0.2482 RMSE:0.6078 0.9839 1.0648 Tau:0.7304 0.4743 0.5286\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 249 Step: 22161 Index:-0.4034 R2:0.8231 0.4713 0.2488 RMSE:0.4877 0.9074 0.9880 Tau:0.7373 0.5040 0.5327\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 250 Step: 22250 Index:-0.5235 R2:0.8448 0.4450 0.2748 RMSE:0.5212 1.0227 1.0277 Tau:0.7537 0.4992 0.5312\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 251 Step: 22339 Index:-0.4701 R2:0.8260 0.4259 0.2545 RMSE:0.4926 0.9429 0.9977 Tau:0.7360 0.4728 0.5314\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 252 Step: 22428 Index:-0.4406 R2:0.8435 0.4372 0.2738 RMSE:0.4736 0.9266 0.9656 Tau:0.7506 0.4860 0.5346\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 253 Step: 22517 Index:-0.5506 R2:0.8225 0.4512 0.2726 RMSE:0.5159 1.0553 1.0438 Tau:0.7352 0.5047 0.5326\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 254 Step: 22606 Index:-0.5867 R2:0.8087 0.3743 0.2476 RMSE:0.5138 1.0236 1.0249 Tau:0.7195 0.4369 0.5258\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 255 Step: 22695 Index:-0.6218 R2:0.8087 0.4147 0.2589 RMSE:0.5638 1.0880 1.0567 Tau:0.7280 0.4662 0.5325\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 256 Step: 22784 Index:-0.4387 R2:0.8397 0.4555 0.2539 RMSE:0.4752 0.9357 1.0107 Tau:0.7442 0.4970 0.5285\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 257 Step: 22873 Index:-0.4566 R2:0.8322 0.4343 0.2569 RMSE:0.4746 0.9470 0.9897 Tau:0.7420 0.4904 0.5351\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 258 Step: 22962 Index:-0.4449 R2:0.8320 0.4574 0.2524 RMSE:0.4724 0.9519 1.0053 Tau:0.7414 0.5069 0.5345\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 259 Step: 23051 Index:-0.4694 R2:0.8433 0.4345 0.2524 RMSE:0.4624 0.9463 1.0066 Tau:0.7488 0.4769 0.5318\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 260 Step: 23140 Index:-0.5243 R2:0.8023 0.4512 0.2616 RMSE:0.5243 1.0290 1.0439 Tau:0.7174 0.5047 0.5379\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 261 Step: 23229 Index:-0.5024 R2:0.8372 0.4491 0.2763 RMSE:0.5110 1.0119 1.0030 Tau:0.7451 0.5095 0.5372\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 262 Step: 23318 Index:-0.4865 R2:0.8248 0.4711 0.2699 RMSE:0.5128 1.0040 1.0077 Tau:0.7379 0.5176 0.5355\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 263 Step: 23407 Index:-0.5007 R2:0.8305 0.4242 0.2529 RMSE:0.4850 0.9816 0.9978 Tau:0.7402 0.4809 0.5296\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 264 Step: 23496 Index:-0.5380 R2:0.8469 0.4265 0.2681 RMSE:0.4635 1.0218 1.0219 Tau:0.7552 0.4838 0.5326\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 265 Step: 23585 Index:-0.5708 R2:0.8247 0.3942 0.2567 RMSE:0.4978 1.0388 1.0220 Tau:0.7354 0.4681 0.5305\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 266 Step: 23674 Index:-0.5129 R2:0.8492 0.4380 0.2592 RMSE:0.4530 1.0077 1.0155 Tau:0.7560 0.4948 0.5340\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 267 Step: 23763 Index:-0.3797 R2:0.8271 0.4503 0.2808 RMSE:0.5279 0.8796 0.9397 Tau:0.7307 0.5000 0.5309\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 268 Step: 23852 Index:-0.4897 R2:0.8444 0.4496 0.2528 RMSE:0.4621 0.9816 1.0217 Tau:0.7518 0.4919 0.5336\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 269 Step: 23941 Index:-0.4902 R2:0.8479 0.4443 0.2564 RMSE:0.4611 0.9824 1.0150 Tau:0.7536 0.4923 0.5340\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 270 Step: 24030 Index:-0.5101 R2:0.8473 0.4314 0.2597 RMSE:0.4655 1.0071 1.0146 Tau:0.7548 0.4970 0.5367\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 271 Step: 24119 Index:-0.4867 R2:0.8484 0.4521 0.2505 RMSE:0.4477 0.9910 1.0341 Tau:0.7532 0.5044 0.5360\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 272 Step: 24208 Index:-0.5023 R2:0.8462 0.4376 0.2685 RMSE:0.4508 0.9865 1.0217 Tau:0.7530 0.4842 0.5320\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 273 Step: 24297 Index:-0.4879 R2:0.8346 0.4553 0.2536 RMSE:0.4692 0.9948 1.0285 Tau:0.7415 0.5069 0.5373\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 274 Step: 24386 Index:-0.5136 R2:0.8480 0.4423 0.2705 RMSE:0.4594 1.0040 1.0420 Tau:0.7504 0.4904 0.5345\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 275 Step: 24475 Index:-0.5299 R2:0.8535 0.4300 0.2613 RMSE:0.4695 1.0184 1.0281 Tau:0.7593 0.4886 0.5348\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 276 Step: 24564 Index:-0.5077 R2:0.8491 0.4284 0.2520 RMSE:0.4477 0.9922 1.0273 Tau:0.7550 0.4846 0.5342\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 277 Step: 24653 Index:-0.5351 R2:0.8337 0.4163 0.2552 RMSE:0.4691 1.0226 1.0166 Tau:0.7438 0.4875 0.5395\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 278 Step: 24742 Index:-0.5222 R2:0.8164 0.4368 0.2560 RMSE:0.5046 1.0236 1.0274 Tau:0.7326 0.5014 0.5359\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 279 Step: 24831 Index:-0.5037 R2:0.8503 0.4235 0.2388 RMSE:0.4473 0.9883 1.0193 Tau:0.7577 0.4846 0.5337\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 280 Step: 24920 Index:-0.6354 R2:0.8504 0.4272 0.2465 RMSE:0.5216 1.1145 1.0977 Tau:0.7575 0.4791 0.5319\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 281 Step: 25009 Index:-0.4766 R2:0.8480 0.4212 0.2463 RMSE:0.4710 0.9590 1.0217 Tau:0.7562 0.4824 0.5355\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 282 Step: 25098 Index:-0.5031 R2:0.8534 0.4331 0.2591 RMSE:0.4414 0.9906 1.0230 Tau:0.7608 0.4875 0.5360\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 283 Step: 25187 Index:-0.5368 R2:0.8544 0.4358 0.2616 RMSE:0.4394 1.0261 1.0365 Tau:0.7585 0.4893 0.5368\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 284 Step: 25276 Index:-0.4651 R2:0.8493 0.4519 0.2571 RMSE:0.4523 0.9552 1.0170 Tau:0.7569 0.4901 0.5334\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 285 Step: 25365 Index:-0.4852 R2:0.8552 0.4268 0.2564 RMSE:0.4518 0.9676 1.0221 Tau:0.7605 0.4824 0.5354\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 286 Step: 25454 Index:-0.4674 R2:0.8400 0.4441 0.2389 RMSE:0.4831 0.9611 1.0347 Tau:0.7488 0.4937 0.5307\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 287 Step: 25543 Index:-0.6097 R2:0.8430 0.3770 0.2286 RMSE:0.4885 1.0517 1.0498 Tau:0.7491 0.4420 0.5272\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 288 Step: 25632 Index:-0.5366 R2:0.8526 0.4076 0.2684 RMSE:0.4455 1.0065 1.0078 Tau:0.7583 0.4699 0.5318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 289 Step: 25721 Index:-0.5119 R2:0.8447 0.4333 0.2618 RMSE:0.4529 0.9983 1.0200 Tau:0.7507 0.4864 0.5326\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 290 Step: 25810 Index:-0.5401 R2:0.8565 0.4347 0.2619 RMSE:0.4454 1.0327 1.0350 Tau:0.7628 0.4926 0.5343\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 291 Step: 25899 Index:-0.4987 R2:0.8575 0.4287 0.2615 RMSE:0.4417 0.9873 1.0304 Tau:0.7621 0.4886 0.5352\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 292 Step: 25988 Index:-0.5217 R2:0.8379 0.4529 0.2476 RMSE:0.4688 1.0250 1.0548 Tau:0.7491 0.5033 0.5356\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 293 Step: 26077 Index:-0.5458 R2:0.8564 0.4193 0.2331 RMSE:0.4414 1.0252 1.0506 Tau:0.7609 0.4794 0.5344\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 294 Step: 26166 Index:-0.5685 R2:0.8526 0.3925 0.2400 RMSE:0.4508 1.0421 1.0263 Tau:0.7654 0.4736 0.5348\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 295 Step: 26255 Index:-0.6260 R2:0.8425 0.4320 0.2749 RMSE:0.5070 1.1234 1.0903 Tau:0.7545 0.4974 0.5356\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 296 Step: 26344 Index:-0.4925 R2:0.8374 0.4006 0.2253 RMSE:0.4954 0.9719 1.0220 Tau:0.7458 0.4794 0.5341\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 297 Step: 26433 Index:-0.7403 R2:0.8464 0.4054 0.2486 RMSE:0.5541 1.2054 1.1277 Tau:0.7528 0.4651 0.5327\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 298 Step: 26522 Index:-0.4901 R2:0.8563 0.4154 0.2498 RMSE:0.4727 0.9724 1.0052 Tau:0.7622 0.4824 0.5316\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 299 Step: 26611 Index:-0.5415 R2:0.8467 0.4092 0.2520 RMSE:0.4656 1.0176 1.0103 Tau:0.7567 0.4761 0.5351\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 302 Step: 26878 Index:-0.6042 R2:0.8465 0.3946 0.2333 RMSE:0.4626 1.0737 1.0601 Tau:0.7548 0.4695 0.5339\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 303 Step: 26967 Index:-0.6124 R2:0.8051 0.4067 0.2097 RMSE:0.5815 1.0757 1.1819 Tau:0.7212 0.4633 0.5298\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 304 Step: 27056 Index:-0.6477 R2:0.8539 0.3924 0.2500 RMSE:0.5363 1.1099 1.0725 Tau:0.7608 0.4622 0.5329\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 305 Step: 27145 Index:-0.6213 R2:0.8559 0.4079 0.2545 RMSE:0.4490 1.0912 1.0519 Tau:0.7632 0.4699 0.5352\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 306 Step: 27234 Index:-0.5725 R2:0.8586 0.4071 0.2584 RMSE:0.4368 1.0522 1.0278 Tau:0.7627 0.4798 0.5352\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 307 Step: 27323 Index:-0.6099 R2:0.8621 0.4316 0.2464 RMSE:0.4392 1.0944 1.0758 Tau:0.7680 0.4846 0.5356\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 308 Step: 27412 Index:-0.5952 R2:0.8539 0.3815 0.2441 RMSE:0.4550 1.0540 1.0323 Tau:0.7587 0.4589 0.5336\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 309 Step: 27501 Index:-0.5937 R2:0.8440 0.4001 0.2453 RMSE:0.5118 1.0460 1.0360 Tau:0.7489 0.4523 0.5325\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 310 Step: 27590 Index:-0.5567 R2:0.8628 0.4172 0.2524 RMSE:0.4394 1.0431 1.0493 Tau:0.7673 0.4864 0.5367\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 311 Step: 27679 Index:-0.6758 R2:0.8566 0.4240 0.2473 RMSE:0.4851 1.1567 1.1031 Tau:0.7631 0.4809 0.5340\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 312 Step: 27768 Index:-0.6346 R2:0.8519 0.4152 0.2520 RMSE:0.4818 1.1268 1.0822 Tau:0.7584 0.4923 0.5371\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 313 Step: 27857 Index:-0.5770 R2:0.8521 0.4247 0.2639 RMSE:0.4761 1.0697 1.0484 Tau:0.7583 0.4926 0.5373\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 314 Step: 27946 Index:-0.7316 R2:0.8267 0.4026 0.2112 RMSE:0.7148 1.2168 1.1966 Tau:0.7344 0.4853 0.5329\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 315 Step: 28035 Index:-0.4725 R2:0.8413 0.4116 0.2323 RMSE:0.4878 0.9713 0.9868 Tau:0.7508 0.4989 0.5338\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 316 Step: 28124 Index:-0.5958 R2:0.8630 0.3983 0.2497 RMSE:0.4267 1.0690 1.0440 Tau:0.7718 0.4732 0.5361\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 317 Step: 28213 Index:-0.5859 R2:0.8681 0.4129 0.2468 RMSE:0.4238 1.0782 1.0563 Tau:0.7724 0.4923 0.5365\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 318 Step: 28302 Index:-0.6284 R2:0.8545 0.3948 0.2365 RMSE:0.4570 1.0968 1.0766 Tau:0.7622 0.4684 0.5340\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau \n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 318 r2:0.2124 RMSE:0.9273 WTI:0.3890 AP:0.7561 Tau:0.5150 \n",
      " \n",
      " Top-1:0.1250 Top-1-fp:0.2500 \n",
      " Top-5:0.3864 Top-5-fp:0.2955 \n",
      " Top-10:0.5169 Top-10-fp:0.2472 \n",
      " Top-15:0.6617 Top-15-fp:0.1880 \n",
      " Top-20:0.7809 Top-20-fp:0.1798 \n",
      " Top-25:0.8200 Top-25-fp:0.2646 \n",
      " Top-30:0.8900 Top-30-fp:0.3333 \n",
      " Top-40:0.9650 Top-40-fp:0.4594 \n",
      " Top-50:0.9950 Top-50-fp:0.5538 \n",
      " \n",
      " Top50:0.3600 Top50-fp:0.3000 \n",
      " Top100:0.5700 Top100-fp:0.2200 \n",
      " Top150:0.7133 Top150-fp:0.1867 \n",
      " Top200:0.7800 Top200-fp:0.2200 \n",
      " Top250:0.8750 Top250-fp:0.3000 \n",
      " Top300:0.9250 Top300-fp:0.3833 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
