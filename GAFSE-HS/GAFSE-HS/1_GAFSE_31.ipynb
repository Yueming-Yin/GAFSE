{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P14416_0.3333333333333333_350\n",
      "model_file/1_GAFSE_Ki_P14416_0.3333333333333333_350_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P14416_0.3333333333333333_350_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P14416_0.3333333333333333_350_test.csv\"\n",
    "test_active = 350\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CC1CCN(C2=C1C=CC=C2CCN3CCN(CC3)C4=NSC5=CC=CC=C... -1.230449\n",
      "1  C1CN(CCN1CCCOC2=CC3=C(CNC3=O)C=C2)C4=CC=CC5=C4... -1.444045\n",
      "2  C1CN(CCN1CC2=CN=CC(=C2)C3=CC=CC=C3)C4=CC5=C(C=... -1.100371\n",
      "3  CCC1CC2=CC=CC=C2N1C(=O)CN3CCN(CC3)CC4=CC=C(C=C... -2.340444\n",
      "4  CN1CCC2=CC(=C(C=C2C3C1CCC4=C(C=CC=C34)C5=CC=C(... -1.949390\n",
      "number of all smiles:  1419\n",
      "number of successfully processed smiles:  1419\n",
      "                                              smiles     value  \\\n",
      "0  CC1CCN(C2=C1C=CC=C2CCN3CCN(CC3)C4=NSC5=CC=CC=C... -1.230449   \n",
      "1  C1CN(CCN1CCCOC2=CC3=C(CNC3=O)C=C2)C4=CC=CC5=C4... -1.444045   \n",
      "2  C1CN(CCN1CC2=CN=CC(=C2)C3=CC=CC=C3)C4=CC5=C(C=... -1.100371   \n",
      "3  CCC1CC2=CC=CC=C2N1C(=O)CN3CCN(CC3)CC4=CC=C(C=C... -2.340444   \n",
      "4  CN1CCC2=CC(=C(C=C2C3C1CCC4=C(C=CC=C34)C5=CC=C(... -1.949390   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  CC(=O)N1CCC(C)c2cccc(CCN3CCN(c4nsc5ccccc45)CC3...  \n",
      "1   O=C1NCc2ccc(OCCCN3CCN(c4cccc5ccc(F)cc45)CC3)cc21  \n",
      "2  O=c1[nH]c2ccc(N3CCN(Cc4cncc(-c5ccccc5)c4)CC3)c...  \n",
      "3       CCC1Cc2ccccc2N1C(=O)CN1CCN(Cc2ccc(Cl)cc2)CC1  \n",
      "4  CN1CCc2cc(Cl)c(O)cc2C2c3cccc(-c4ccc(CO)cc4)c3C...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1664\n",
      "number of successfully processed smiles:  1664\n",
      "(1664, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1CN(CCN1CCCCOC2=CC3=C(CNC3)C=C2)C4=CC=CC5=C4C... -1.906874   \n",
      "1  CN1CCN(CC1)C2=NC3=C(C=CC(=C3)Cl)N(C4=CC=CC=C42... -3.107210   \n",
      "2  CN1C=C(C=CC1=O)C2=NN=C(N2C)SCCCN3CCC4(C3)CC4C5... -2.940008   \n",
      "3  CCOC1=CC=CC=C1N2CCCN(CC2)CCCCOC3=CC4=C(C=C3)C=... -0.556303   \n",
      "4  C1CN(CCN1CC(CCNC(=O)C2=CC=C(C=C2)C3=CC=CC=N3)O... -2.426511   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0    Fc1ccc2cccc(N3CCN(CCCCOc4ccc5c(c4)CNC5)CC3)c2c1  \n",
      "1  CN1CCN(C2=Nc3cc(Cl)ccc3N(NC(=O)c3cc(F)c(F)c(F)...  \n",
      "2  Cn1c(SCCCN2CCC3(CC3c3ccc(C(F)(F)F)cc3)C2)nnc1-...  \n",
      "3   CCOc1ccccc1N1CCCN(CCCCOc2ccc3ccc(=O)[nH]c3c2)CC1  \n",
      "4  O=C(NCCC(O)CN1CCN(c2cccc(Cl)c2Cl)CC1)c1ccc(-c2...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P14416_0.3333333333333333_350_train.pickle\n",
      "./data/benchmark/Ki_P14416_0.3333333333333333_350_train\n",
      "3083\n",
      "Cc1ncoc1-c1nnc(SCCCN2CC3CC3(c3cccc(S(F)(F)(F)(F)F)c3)C2)n1C\n",
      "feature dicts file saved as ./data/benchmark/Ki_P14416_0.3333333333333333_350_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1135, 3) (284, 3) (1663, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_Ki_P14416_0.3333333333333333_350_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 166 Index:-0.7986 R2:0.0283 0.0402 0.0317 RMSE:0.9783 0.9395 0.9687 Tau:0.1358 0.1410 0.0869\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 2 Step: 332 Index:-0.8623 R2:0.0537 0.0791 0.0665 RMSE:1.0564 1.0429 1.0501 Tau:0.1780 0.1807 0.1838\n",
      "Epoch: 3 Step: 498 Index:-0.7343 R2:0.0804 0.0979 0.1047 RMSE:0.9669 0.9344 0.9531 Tau:0.1939 0.2001 0.1742\n",
      "Epoch: 4 Step: 664 Index:-0.7210 R2:0.0856 0.0954 0.1045 RMSE:0.9797 0.9233 0.9607 Tau:0.2017 0.2023 0.1535\n",
      "Epoch: 5 Step: 830 Index:-0.6889 R2:0.1018 0.1163 0.1209 RMSE:0.9462 0.9057 0.9317 Tau:0.2164 0.2167 0.1872\n",
      "Epoch: 6 Step: 996 Index:-0.6821 R2:0.1131 0.1248 0.1331 RMSE:0.9598 0.9047 0.9391 Tau:0.2273 0.2226 0.1960\n",
      "Epoch: 7 Step: 1162 Index:-0.6652 R2:0.1191 0.1332 0.1377 RMSE:0.9515 0.8975 0.9313 Tau:0.2333 0.2323 0.2021\n",
      "Epoch: 8 Step: 1328 Index:-0.6609 R2:0.1252 0.1407 0.1381 RMSE:0.9381 0.9020 0.9282 Tau:0.2400 0.2411 0.2023\n",
      "Epoch: 9 Step: 1494 Index:-0.6437 R2:0.1349 0.1438 0.1433 RMSE:0.9410 0.8906 0.9258 Tau:0.2492 0.2470 0.2024\n",
      "Epoch: 10 Step: 1660 Index:-0.6165 R2:0.1332 0.1518 0.1361 RMSE:0.9259 0.8784 0.9148 Tau:0.2501 0.2619 0.2140\n",
      "Epoch: 11 Step: 1826 Index:-0.6063 R2:0.1448 0.1625 0.1522 RMSE:0.9191 0.8758 0.9086 Tau:0.2583 0.2695 0.2121\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 12 Step: 1992 Index:-0.6148 R2:0.1493 0.1690 0.1504 RMSE:0.9296 0.8940 0.9263 Tau:0.2627 0.2792 0.2210\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 13 Step: 2158 Index:-0.6142 R2:0.1641 0.1668 0.1595 RMSE:0.9350 0.8867 0.9242 Tau:0.2725 0.2725 0.1977\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 14 Step: 2324 Index:-0.6231 R2:0.1711 0.1738 0.1654 RMSE:0.9529 0.9019 0.9398 Tau:0.2796 0.2788 0.2083\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 15 Step: 2490 Index:-0.6483 R2:0.1679 0.1772 0.1600 RMSE:0.9916 0.9351 0.9732 Tau:0.2812 0.2869 0.2124\n",
      "Epoch: 16 Step: 2656 Index:-0.5644 R2:0.1732 0.1876 0.1655 RMSE:0.9034 0.8598 0.8989 Tau:0.2828 0.2954 0.2235\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 17 Step: 2822 Index:-0.5742 R2:0.1854 0.1979 0.1728 RMSE:0.9115 0.8769 0.9151 Tau:0.2910 0.3027 0.2221\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 18 Step: 2988 Index:-0.5687 R2:0.1935 0.1972 0.1795 RMSE:0.9146 0.8691 0.9069 Tau:0.2984 0.3004 0.2194\n",
      "Epoch: 19 Step: 3154 Index:-0.5506 R2:0.2011 0.1985 0.1849 RMSE:0.8882 0.8543 0.8880 Tau:0.3039 0.3037 0.2235\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 20 Step: 3320 Index:-0.5911 R2:0.2134 0.2084 0.1853 RMSE:0.9446 0.9011 0.9378 Tau:0.3130 0.3100 0.2156\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 21 Step: 3486 Index:-0.5530 R2:0.2189 0.2105 0.1826 RMSE:0.9056 0.8654 0.9092 Tau:0.3154 0.3124 0.2138\n",
      "Epoch: 22 Step: 3652 Index:-0.5189 R2:0.2179 0.2226 0.1830 RMSE:0.8832 0.8437 0.8905 Tau:0.3178 0.3248 0.2260\n",
      "Epoch: 23 Step: 3818 Index:-0.5168 R2:0.2333 0.2217 0.1891 RMSE:0.8738 0.8420 0.8871 Tau:0.3279 0.3252 0.2176\n",
      "Epoch: 24 Step: 3984 Index:-0.4956 R2:0.2457 0.2373 0.2007 RMSE:0.8669 0.8337 0.8811 Tau:0.3367 0.3381 0.2320\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 25 Step: 4150 Index:-0.5304 R2:0.2406 0.2128 0.1747 RMSE:0.8744 0.8481 0.8952 Tau:0.3266 0.3177 0.2056\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 26 Step: 4316 Index:-0.5045 R2:0.2539 0.2323 0.2078 RMSE:0.8667 0.8398 0.8788 Tau:0.3443 0.3354 0.2305\n",
      "Epoch: 27 Step: 4482 Index:-0.4805 R2:0.2627 0.2512 0.2146 RMSE:0.8556 0.8328 0.8776 Tau:0.3481 0.3523 0.2471\n",
      "Epoch: 28 Step: 4648 Index:-0.4749 R2:0.2767 0.2523 0.2191 RMSE:0.8575 0.8307 0.8743 Tau:0.3602 0.3557 0.2349\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 29 Step: 4814 Index:-0.4848 R2:0.2826 0.2623 0.2129 RMSE:0.8798 0.8482 0.8995 Tau:0.3620 0.3634 0.2359\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 30 Step: 4980 Index:-0.5305 R2:0.2737 0.2468 0.1937 RMSE:0.9185 0.8852 0.9409 Tau:0.3560 0.3547 0.2151\n",
      "Epoch: 31 Step: 5146 Index:-0.4607 R2:0.3043 0.2715 0.2313 RMSE:0.8560 0.8316 0.8774 Tau:0.3783 0.3710 0.2373\n",
      "Epoch: 32 Step: 5312 Index:-0.4541 R2:0.3125 0.2772 0.2390 RMSE:0.8555 0.8310 0.8772 Tau:0.3844 0.3769 0.2293\n",
      "Epoch: 33 Step: 5478 Index:-0.4122 R2:0.3236 0.2870 0.2429 RMSE:0.8221 0.8063 0.8557 Tau:0.3921 0.3941 0.2452\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 34 Step: 5644 Index:-0.4210 R2:0.3275 0.2893 0.2455 RMSE:0.8300 0.8132 0.8605 Tau:0.3974 0.3922 0.2479\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 35 Step: 5810 Index:-0.4325 R2:0.3208 0.2749 0.2333 RMSE:0.8356 0.8250 0.8722 Tau:0.3898 0.3924 0.2283\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 36 Step: 5976 Index:-0.4196 R2:0.3368 0.2958 0.2608 RMSE:0.8195 0.8145 0.8582 Tau:0.4033 0.3949 0.2590\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 37 Step: 6142 Index:-0.4273 R2:0.3451 0.2890 0.2576 RMSE:0.8256 0.8259 0.8622 Tau:0.4095 0.3986 0.2483\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 38 Step: 6308 Index:-0.4331 R2:0.3495 0.3004 0.2683 RMSE:0.8510 0.8330 0.8745 Tau:0.4123 0.3999 0.2433\n",
      "Epoch: 39 Step: 6474 Index:-0.4032 R2:0.3621 0.3213 0.2825 RMSE:0.8126 0.8207 0.8596 Tau:0.4201 0.4175 0.2613\n",
      "Epoch: 40 Step: 6640 Index:-0.3842 R2:0.3786 0.3274 0.2891 RMSE:0.8265 0.8090 0.8574 Tau:0.4312 0.4249 0.2473\n",
      "Epoch: 41 Step: 6806 Index:-0.3771 R2:0.3768 0.3182 0.2812 RMSE:0.7924 0.7977 0.8381 Tau:0.4310 0.4205 0.2513\n",
      "Epoch: 42 Step: 6972 Index:-0.3628 R2:0.3801 0.3230 0.2766 RMSE:0.7861 0.7879 0.8373 Tau:0.4319 0.4251 0.2624\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 7138 Index:-0.4216 R2:0.3956 0.3311 0.2958 RMSE:0.8476 0.8564 0.8879 Tau:0.4415 0.4348 0.2569\n",
      "Epoch: 44 Step: 7304 Index:-0.3575 R2:0.3986 0.3352 0.2879 RMSE:0.7838 0.7949 0.8382 Tau:0.4436 0.4375 0.2653\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 45 Step: 7470 Index:-0.3950 R2:0.3564 0.3210 0.2750 RMSE:0.8039 0.8249 0.8649 Tau:0.4362 0.4299 0.2752\n",
      "Epoch: 46 Step: 7636 Index:-0.3501 R2:0.4129 0.3431 0.2963 RMSE:0.7706 0.7950 0.8325 Tau:0.4526 0.4449 0.2678\n",
      "Epoch: 47 Step: 7802 Index:-0.3273 R2:0.4042 0.3466 0.2947 RMSE:0.7680 0.7744 0.8269 Tau:0.4568 0.4471 0.2615\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 48 Step: 7968 Index:-0.3758 R2:0.4187 0.3451 0.3130 RMSE:0.7949 0.8166 0.8550 Tau:0.4567 0.4409 0.2616\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 49 Step: 8134 Index:-0.3294 R2:0.4220 0.3511 0.2987 RMSE:0.7554 0.7759 0.8240 Tau:0.4599 0.4465 0.2645\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 50 Step: 8300 Index:-0.3542 R2:0.4254 0.3449 0.3013 RMSE:0.7830 0.7982 0.8411 Tau:0.4642 0.4439 0.2565\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 51 Step: 8466 Index:-0.3399 R2:0.4327 0.3558 0.3253 RMSE:0.7703 0.7952 0.8222 Tau:0.4680 0.4553 0.2760\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 52 Step: 8632 Index:-0.3895 R2:0.4255 0.3288 0.2749 RMSE:0.7830 0.8229 0.8672 Tau:0.4581 0.4334 0.2466\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 53 Step: 8798 Index:-0.3615 R2:0.4439 0.3531 0.3243 RMSE:0.7751 0.8079 0.8355 Tau:0.4752 0.4464 0.2595\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 54 Step: 8964 Index:-0.3627 R2:0.4505 0.3535 0.3035 RMSE:0.8004 0.8167 0.8690 Tau:0.4784 0.4541 0.2526\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 55 Step: 9130 Index:-0.3318 R2:0.4494 0.3540 0.3288 RMSE:0.7374 0.7825 0.8064 Tau:0.4790 0.4507 0.2672\n",
      "Epoch: 56 Step: 9296 Index:-0.3199 R2:0.4556 0.3648 0.3027 RMSE:0.7432 0.7730 0.8282 Tau:0.4788 0.4531 0.2512\n",
      "Epoch: 57 Step: 9462 Index:-0.3015 R2:0.4597 0.3746 0.3353 RMSE:0.7303 0.7638 0.8019 Tau:0.4878 0.4623 0.2737\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 58 Step: 9628 Index:-0.3145 R2:0.4682 0.3716 0.3347 RMSE:0.7374 0.7778 0.8151 Tau:0.4938 0.4633 0.2710\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 59 Step: 9794 Index:-0.3456 R2:0.4660 0.3665 0.3232 RMSE:0.7585 0.7933 0.8307 Tau:0.4904 0.4476 0.2766\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 60 Step: 9960 Index:-0.3251 R2:0.4779 0.3680 0.3379 RMSE:0.7169 0.7782 0.8022 Tau:0.4977 0.4531 0.2798\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 61 Step: 10126 Index:-0.3046 R2:0.4800 0.3746 0.3175 RMSE:0.7193 0.7590 0.8128 Tau:0.4963 0.4544 0.2687\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 62 Step: 10292 Index:-0.3089 R2:0.4771 0.3792 0.3332 RMSE:0.7335 0.7703 0.8109 Tau:0.5016 0.4615 0.2750\n",
      "Epoch: 63 Step: 10458 Index:-0.2943 R2:0.4875 0.3824 0.3262 RMSE:0.7156 0.7559 0.8070 Tau:0.5036 0.4616 0.2699\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 64 Step: 10624 Index:-0.3510 R2:0.4718 0.3580 0.2944 RMSE:0.7589 0.7942 0.8523 Tau:0.4879 0.4432 0.2495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 65 Step: 10790 Index:-0.3011 R2:0.4945 0.3812 0.3295 RMSE:0.7082 0.7578 0.8067 Tau:0.5086 0.4567 0.2703\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 66 Step: 10956 Index:-0.3376 R2:0.4970 0.3812 0.3383 RMSE:0.7455 0.8003 0.8357 Tau:0.5097 0.4627 0.2732\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 67 Step: 11122 Index:-0.3127 R2:0.4936 0.3770 0.3372 RMSE:0.7063 0.7696 0.8022 Tau:0.5112 0.4569 0.2807\n",
      "Epoch: 68 Step: 11288 Index:-0.2830 R2:0.5035 0.3904 0.3204 RMSE:0.7084 0.7460 0.8104 Tau:0.5105 0.4630 0.2621\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 69 Step: 11454 Index:-0.3210 R2:0.4923 0.3772 0.3519 RMSE:0.7065 0.7737 0.7949 Tau:0.5082 0.4527 0.2741\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 70 Step: 11620 Index:-0.2933 R2:0.5116 0.3894 0.3285 RMSE:0.6948 0.7603 0.8090 Tau:0.5168 0.4670 0.2686\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 71 Step: 11786 Index:-0.3154 R2:0.5170 0.3777 0.3477 RMSE:0.6911 0.7746 0.7951 Tau:0.5208 0.4592 0.2879\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 72 Step: 11952 Index:-0.3573 R2:0.5174 0.3730 0.3390 RMSE:0.7473 0.8061 0.8408 Tau:0.5208 0.4488 0.2610\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 73 Step: 12118 Index:-0.3077 R2:0.5280 0.3857 0.3313 RMSE:0.7126 0.7691 0.8210 Tau:0.5270 0.4614 0.2696\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 74 Step: 12284 Index:-0.3015 R2:0.5290 0.3912 0.3575 RMSE:0.6878 0.7688 0.7987 Tau:0.5327 0.4673 0.2905\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 75 Step: 12450 Index:-0.4237 R2:0.5090 0.3647 0.3130 RMSE:0.8112 0.8655 0.9112 Tau:0.5157 0.4418 0.2507\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 76 Step: 12616 Index:-0.2894 R2:0.5434 0.3955 0.3433 RMSE:0.6830 0.7582 0.8022 Tau:0.5391 0.4688 0.2773\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 77 Step: 12782 Index:-0.3140 R2:0.5314 0.3855 0.3387 RMSE:0.6842 0.7763 0.8090 Tau:0.5319 0.4623 0.2847\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 78 Step: 12948 Index:-0.3091 R2:0.5298 0.3790 0.3522 RMSE:0.6832 0.7756 0.7975 Tau:0.5335 0.4665 0.2807\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 79 Step: 13114 Index:-0.3092 R2:0.5384 0.3750 0.3446 RMSE:0.6827 0.7577 0.7957 Tau:0.5317 0.4486 0.2642\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 80 Step: 13280 Index:-0.2985 R2:0.5336 0.3843 0.3246 RMSE:0.6844 0.7551 0.8093 Tau:0.5313 0.4566 0.2565\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 81 Step: 13446 Index:-0.2950 R2:0.5519 0.3835 0.3630 RMSE:0.6759 0.7589 0.7876 Tau:0.5447 0.4640 0.2801\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 82 Step: 13612 Index:-0.3297 R2:0.5403 0.3900 0.3559 RMSE:0.7268 0.7971 0.8272 Tau:0.5394 0.4673 0.2867\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 83 Step: 13778 Index:-0.3109 R2:0.5567 0.3898 0.3477 RMSE:0.6605 0.7741 0.7989 Tau:0.5463 0.4631 0.2884\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 84 Step: 13944 Index:-0.2918 R2:0.5594 0.3976 0.3578 RMSE:0.6735 0.7582 0.7961 Tau:0.5478 0.4665 0.2720\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 85 Step: 14110 Index:-0.3361 R2:0.5647 0.3941 0.3488 RMSE:0.7146 0.7994 0.8379 Tau:0.5523 0.4633 0.2769\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 86 Step: 14276 Index:-0.3132 R2:0.5647 0.3860 0.3395 RMSE:0.6554 0.7696 0.8053 Tau:0.5512 0.4563 0.2771\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 87 Step: 14442 Index:-0.3248 R2:0.5648 0.3818 0.3472 RMSE:0.6846 0.7860 0.8133 Tau:0.5532 0.4611 0.2769\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 88 Step: 14608 Index:-0.3354 R2:0.5668 0.3735 0.3379 RMSE:0.6647 0.7902 0.8119 Tau:0.5536 0.4548 0.2706\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 89 Step: 14774 Index:-0.3602 R2:0.5682 0.3815 0.3437 RMSE:0.7263 0.8206 0.8524 Tau:0.5559 0.4603 0.2739\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 90 Step: 14940 Index:-0.2955 R2:0.5787 0.3921 0.3596 RMSE:0.6504 0.7600 0.7911 Tau:0.5621 0.4645 0.2701\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 91 Step: 15106 Index:-0.2878 R2:0.5692 0.3920 0.3264 RMSE:0.6579 0.7514 0.8095 Tau:0.5509 0.4636 0.2676\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 92 Step: 15272 Index:-0.3339 R2:0.5781 0.3812 0.3567 RMSE:0.6762 0.7956 0.8148 Tau:0.5593 0.4617 0.2728\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 93 Step: 15438 Index:-0.2963 R2:0.5875 0.3942 0.3483 RMSE:0.6593 0.7658 0.8065 Tau:0.5643 0.4695 0.2762\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 94 Step: 15604 Index:-0.2929 R2:0.5732 0.3948 0.3337 RMSE:0.6518 0.7605 0.8068 Tau:0.5591 0.4676 0.2809\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 95 Step: 15770 Index:-0.3017 R2:0.5859 0.3876 0.3473 RMSE:0.6648 0.7648 0.8077 Tau:0.5617 0.4632 0.2742\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 96 Step: 15936 Index:-0.3097 R2:0.5806 0.3871 0.3300 RMSE:0.6444 0.7712 0.8096 Tau:0.5598 0.4615 0.2809\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 97 Step: 16102 Index:-0.2906 R2:0.5954 0.3977 0.3560 RMSE:0.6358 0.7569 0.7919 Tau:0.5695 0.4663 0.2727\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 98 Step: 16268 Index:-0.2845 R2:0.5902 0.4047 0.3753 RMSE:0.6371 0.7630 0.7813 Tau:0.5694 0.4785 0.2851\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 99 Step: 16434 Index:-0.2898 R2:0.6019 0.4055 0.3469 RMSE:0.6430 0.7570 0.8058 Tau:0.5742 0.4672 0.2824\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 100 Step: 16600 Index:-0.3002 R2:0.5962 0.3977 0.3751 RMSE:0.6323 0.7734 0.7803 Tau:0.5760 0.4732 0.2909\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 101 Step: 16766 Index:-0.3050 R2:0.6073 0.3973 0.3786 RMSE:0.6394 0.7755 0.7861 Tau:0.5821 0.4705 0.2903\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 102 Step: 16932 Index:-0.2951 R2:0.5971 0.3966 0.3676 RMSE:0.6317 0.7608 0.7861 Tau:0.5715 0.4657 0.2786\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 103 Step: 17098 Index:-0.3261 R2:0.6047 0.3794 0.3169 RMSE:0.6355 0.7774 0.8271 Tau:0.5758 0.4513 0.2661\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 104 Step: 17264 Index:-0.3837 R2:0.5231 0.3542 0.3062 RMSE:0.7024 0.8162 0.8490 Tau:0.5284 0.4326 0.2675\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 105 Step: 17430 Index:-0.3368 R2:0.6092 0.4078 0.3626 RMSE:0.6900 0.8113 0.8408 Tau:0.5789 0.4745 0.2796\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 106 Step: 17596 Index:-0.3492 R2:0.6050 0.3879 0.3362 RMSE:0.6582 0.8097 0.8398 Tau:0.5743 0.4604 0.2802\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 107 Step: 17762 Index:-0.3337 R2:0.6042 0.3890 0.3667 RMSE:0.6434 0.7950 0.7998 Tau:0.5777 0.4613 0.2975\n",
      "Epoch: 108 Step: 17928 Index:-0.2750 R2:0.6248 0.4070 0.3682 RMSE:0.6195 0.7472 0.7836 Tau:0.5914 0.4722 0.2885\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 109 Step: 18094 Index:-0.2882 R2:0.6142 0.4024 0.3921 RMSE:0.6301 0.7640 0.7754 Tau:0.5838 0.4757 0.2854\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 110 Step: 18260 Index:-0.3121 R2:0.6185 0.3987 0.3930 RMSE:0.6205 0.7805 0.7723 Tau:0.5869 0.4685 0.3045\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 111 Step: 18426 Index:-0.3253 R2:0.6170 0.4077 0.3719 RMSE:0.6479 0.8017 0.8166 Tau:0.5873 0.4764 0.3017\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 112 Step: 18592 Index:-0.2836 R2:0.6087 0.4024 0.3490 RMSE:0.6264 0.7556 0.7954 Tau:0.5803 0.4720 0.2946\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 113 Step: 18758 Index:-0.3217 R2:0.6195 0.4029 0.3781 RMSE:0.6671 0.7965 0.8130 Tau:0.5875 0.4748 0.2906\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 114 Step: 18924 Index:-0.2876 R2:0.6181 0.4060 0.3775 RMSE:0.6222 0.7635 0.7837 Tau:0.5859 0.4759 0.2936\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 115 Step: 19090 Index:-0.3078 R2:0.6354 0.4037 0.3708 RMSE:0.6566 0.7781 0.8144 Tau:0.5976 0.4703 0.2808\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 116 Step: 19256 Index:-0.2787 R2:0.6078 0.4021 0.3681 RMSE:0.6243 0.7539 0.7839 Tau:0.5812 0.4752 0.2906\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 117 Step: 19422 Index:-0.2778 R2:0.6378 0.4159 0.3926 RMSE:0.6006 0.7577 0.7720 Tau:0.6002 0.4799 0.2829\n",
      "Epoch: 118 Step: 19588 Index:-0.2664 R2:0.6341 0.4173 0.3720 RMSE:0.6050 0.7421 0.7812 Tau:0.5947 0.4757 0.2807\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 119 Step: 19754 Index:-0.2700 R2:0.6322 0.4147 0.3776 RMSE:0.6117 0.7471 0.7798 Tau:0.5956 0.4772 0.2854\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 120 Step: 19920 Index:-0.2975 R2:0.6406 0.4023 0.3797 RMSE:0.5999 0.7649 0.7818 Tau:0.6008 0.4673 0.2891\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 121 Step: 20086 Index:-0.2867 R2:0.6456 0.4160 0.3779 RMSE:0.5962 0.7646 0.7867 Tau:0.6043 0.4780 0.2931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 122 Step: 20252 Index:-0.2812 R2:0.6351 0.4144 0.3840 RMSE:0.6036 0.7569 0.7783 Tau:0.5957 0.4757 0.2850\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 123 Step: 20418 Index:-0.2978 R2:0.6409 0.4126 0.3948 RMSE:0.6283 0.7760 0.7876 Tau:0.6029 0.4782 0.2976\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 124 Step: 20584 Index:-0.2774 R2:0.6525 0.4149 0.3936 RMSE:0.5980 0.7514 0.7704 Tau:0.6114 0.4740 0.2983\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 125 Step: 20750 Index:-0.2792 R2:0.6515 0.4217 0.3920 RMSE:0.5859 0.7623 0.7721 Tau:0.6096 0.4831 0.3002\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 126 Step: 20916 Index:-0.3022 R2:0.6460 0.4053 0.3868 RMSE:0.6070 0.7738 0.7818 Tau:0.6084 0.4716 0.2994\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 127 Step: 21082 Index:-0.3090 R2:0.6410 0.4146 0.3829 RMSE:0.6241 0.7809 0.7968 Tau:0.5981 0.4719 0.2944\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 128 Step: 21248 Index:-0.3046 R2:0.6543 0.4150 0.3810 RMSE:0.6119 0.7764 0.8026 Tau:0.6096 0.4717 0.2833\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 129 Step: 21414 Index:-0.2698 R2:0.6512 0.4200 0.3748 RMSE:0.5902 0.7499 0.7838 Tau:0.6089 0.4800 0.2973\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 130 Step: 21580 Index:-0.3092 R2:0.6592 0.4119 0.3881 RMSE:0.6231 0.7855 0.8037 Tau:0.6142 0.4763 0.2874\n",
      "Epoch: 131 Step: 21746 Index:-0.2663 R2:0.6548 0.4147 0.3691 RMSE:0.5951 0.7390 0.7820 Tau:0.6106 0.4727 0.2843\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 132 Step: 21912 Index:-0.3063 R2:0.6595 0.4130 0.3668 RMSE:0.6308 0.7810 0.8187 Tau:0.6136 0.4747 0.2903\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 133 Step: 22078 Index:-0.2931 R2:0.6515 0.4024 0.3704 RMSE:0.5962 0.7642 0.7874 Tau:0.6103 0.4711 0.2950\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 134 Step: 22244 Index:-0.2876 R2:0.6603 0.4158 0.4000 RMSE:0.5800 0.7654 0.7654 Tau:0.6143 0.4778 0.3062\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 135 Step: 22410 Index:-0.3020 R2:0.6495 0.4042 0.3500 RMSE:0.5972 0.7757 0.8091 Tau:0.6065 0.4737 0.2886\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 136 Step: 22576 Index:-0.2919 R2:0.6505 0.4186 0.3724 RMSE:0.6318 0.7722 0.8112 Tau:0.6057 0.4803 0.2930\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 137 Step: 22742 Index:-0.2766 R2:0.6681 0.4228 0.3786 RMSE:0.5831 0.7585 0.7868 Tau:0.6211 0.4819 0.2959\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 138 Step: 22908 Index:-0.3697 R2:0.6344 0.4072 0.3603 RMSE:0.7093 0.8332 0.8754 Tau:0.5999 0.4635 0.2818\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 139 Step: 23074 Index:-0.2972 R2:0.6622 0.4055 0.4027 RMSE:0.5938 0.7698 0.7705 Tau:0.6162 0.4726 0.3073\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 140 Step: 23240 Index:-0.2732 R2:0.6665 0.4163 0.3862 RMSE:0.5772 0.7458 0.7741 Tau:0.6178 0.4726 0.2832\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 141 Step: 23406 Index:-0.3067 R2:0.6567 0.4176 0.3918 RMSE:0.5835 0.7822 0.7798 Tau:0.6148 0.4755 0.2985\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 142 Step: 23572 Index:-0.3010 R2:0.6589 0.4125 0.3790 RMSE:0.5946 0.7779 0.7975 Tau:0.6106 0.4769 0.2888\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 143 Step: 23738 Index:-0.2863 R2:0.6647 0.4117 0.3895 RMSE:0.5758 0.7608 0.7718 Tau:0.6203 0.4745 0.2978\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 144 Step: 23904 Index:-0.2710 R2:0.6835 0.4220 0.3825 RMSE:0.5596 0.7522 0.7782 Tau:0.6298 0.4812 0.2919\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 145 Step: 24070 Index:-0.3239 R2:0.6773 0.4152 0.3956 RMSE:0.5939 0.8010 0.8018 Tau:0.6248 0.4771 0.2982\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 146 Step: 24236 Index:-0.2907 R2:0.6863 0.4271 0.3932 RMSE:0.6031 0.7694 0.7980 Tau:0.6321 0.4787 0.2960\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 147 Step: 24402 Index:-0.2767 R2:0.6857 0.4254 0.3782 RMSE:0.5669 0.7596 0.7911 Tau:0.6308 0.4828 0.3000\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 148 Step: 24568 Index:-0.2869 R2:0.6802 0.4163 0.3779 RMSE:0.5624 0.7612 0.7841 Tau:0.6282 0.4743 0.3013\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 149 Step: 24734 Index:-0.2847 R2:0.6722 0.4211 0.4005 RMSE:0.5763 0.7662 0.7771 Tau:0.6273 0.4815 0.3108\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 150 Step: 24900 Index:-0.3021 R2:0.6713 0.4165 0.3819 RMSE:0.5909 0.7806 0.8004 Tau:0.6211 0.4785 0.2920\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 151 Step: 25066 Index:-0.3080 R2:0.6825 0.4046 0.3716 RMSE:0.5650 0.7779 0.7951 Tau:0.6284 0.4698 0.2939\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 152 Step: 25232 Index:-0.2821 R2:0.6932 0.4195 0.3928 RMSE:0.5622 0.7640 0.7788 Tau:0.6360 0.4819 0.3024\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 153 Step: 25398 Index:-0.2708 R2:0.6855 0.4233 0.4119 RMSE:0.5640 0.7547 0.7589 Tau:0.6331 0.4839 0.3111\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 154 Step: 25564 Index:-0.2878 R2:0.6855 0.4253 0.4021 RMSE:0.5916 0.7742 0.7877 Tau:0.6376 0.4864 0.3052\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 155 Step: 25730 Index:-0.2965 R2:0.6900 0.3959 0.3500 RMSE:0.5646 0.7568 0.7980 Tau:0.6357 0.4604 0.2930\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 156 Step: 25896 Index:-0.2946 R2:0.6915 0.4055 0.4011 RMSE:0.5570 0.7644 0.7665 Tau:0.6380 0.4698 0.2962\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 157 Step: 26062 Index:-0.3464 R2:0.6939 0.4267 0.3888 RMSE:0.6780 0.8339 0.8605 Tau:0.6389 0.4875 0.2989\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 158 Step: 26228 Index:-0.3218 R2:0.6854 0.3999 0.3730 RMSE:0.5919 0.7864 0.8072 Tau:0.6302 0.4646 0.2955\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 159 Step: 26394 Index:-0.3018 R2:0.6903 0.4130 0.3680 RMSE:0.5591 0.7721 0.7980 Tau:0.6299 0.4703 0.2906\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 160 Step: 26560 Index:-0.3074 R2:0.6886 0.3893 0.3537 RMSE:0.5575 0.7664 0.7959 Tau:0.6311 0.4591 0.2927\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 161 Step: 26726 Index:-0.3140 R2:0.7041 0.4288 0.3882 RMSE:0.6145 0.8008 0.8250 Tau:0.6440 0.4869 0.3034\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 162 Step: 26892 Index:-0.2715 R2:0.6948 0.4166 0.4034 RMSE:0.5512 0.7529 0.7629 Tau:0.6395 0.4813 0.2976\n",
      "Epoch: 163 Step: 27058 Index:-0.2631 R2:0.7035 0.4332 0.3819 RMSE:0.5575 0.7533 0.7919 Tau:0.6445 0.4902 0.2968\n",
      "Epoch: 164 Step: 27224 Index:-0.2599 R2:0.7046 0.4387 0.4175 RMSE:0.5400 0.7520 0.7587 Tau:0.6475 0.4921 0.3096\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 165 Step: 27390 Index:-0.3106 R2:0.6967 0.4299 0.3851 RMSE:0.6068 0.7920 0.8215 Tau:0.6368 0.4814 0.2960\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 166 Step: 27556 Index:-0.2631 R2:0.7146 0.4366 0.3894 RMSE:0.5399 0.7483 0.7821 Tau:0.6512 0.4852 0.3004\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 167 Step: 27722 Index:-0.2623 R2:0.7067 0.4457 0.4155 RMSE:0.5472 0.7568 0.7680 Tau:0.6459 0.4945 0.3074\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 168 Step: 27888 Index:-0.2636 R2:0.7069 0.4250 0.3954 RMSE:0.5523 0.7476 0.7725 Tau:0.6497 0.4840 0.3047\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 169 Step: 28054 Index:-0.2718 R2:0.6993 0.4202 0.3878 RMSE:0.5466 0.7454 0.7734 Tau:0.6420 0.4736 0.2957\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 170 Step: 28220 Index:-0.2770 R2:0.7093 0.4342 0.3965 RMSE:0.5636 0.7593 0.7866 Tau:0.6460 0.4822 0.2910\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 171 Step: 28386 Index:-0.2645 R2:0.7141 0.4408 0.4179 RMSE:0.5309 0.7520 0.7599 Tau:0.6524 0.4876 0.2975\n",
      "Epoch: 172 Step: 28552 Index:-0.2572 R2:0.7194 0.4313 0.4052 RMSE:0.5316 0.7428 0.7649 Tau:0.6556 0.4856 0.2970\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 173 Step: 28718 Index:-0.2700 R2:0.7139 0.4273 0.3884 RMSE:0.5487 0.7509 0.7837 Tau:0.6512 0.4809 0.2962\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 174 Step: 28884 Index:-0.2903 R2:0.7179 0.4146 0.3896 RMSE:0.5461 0.7665 0.7847 Tau:0.6548 0.4763 0.2989\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 175 Step: 29050 Index:-0.2608 R2:0.7180 0.4330 0.3955 RMSE:0.5312 0.7480 0.7728 Tau:0.6550 0.4872 0.3005\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 176 Step: 29216 Index:-0.2666 R2:0.7123 0.4250 0.3913 RMSE:0.5357 0.7455 0.7733 Tau:0.6488 0.4789 0.2961\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 177 Step: 29382 Index:-0.3225 R2:0.6332 0.3874 0.3345 RMSE:0.6433 0.7793 0.8317 Tau:0.6078 0.4567 0.2984\n",
      "Epoch: 178 Step: 29548 Index:-0.2326 R2:0.7253 0.4487 0.4154 RMSE:0.5242 0.7281 0.7550 Tau:0.6600 0.4956 0.3033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 179 Step: 29714 Index:-0.2689 R2:0.7178 0.4225 0.4050 RMSE:0.5317 0.7448 0.7614 Tau:0.6536 0.4759 0.3011\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 180 Step: 29880 Index:-0.2954 R2:0.7041 0.4192 0.3810 RMSE:0.5777 0.7735 0.8057 Tau:0.6436 0.4781 0.2947\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 181 Step: 30046 Index:-0.2717 R2:0.7131 0.4230 0.3972 RMSE:0.5561 0.7531 0.7767 Tau:0.6517 0.4813 0.3148\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 182 Step: 30212 Index:-0.2720 R2:0.7100 0.4232 0.4027 RMSE:0.5375 0.7521 0.7702 Tau:0.6508 0.4801 0.3078\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 183 Step: 30378 Index:-0.3023 R2:0.7227 0.4158 0.3993 RMSE:0.5303 0.7760 0.7764 Tau:0.6578 0.4737 0.3012\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 184 Step: 30544 Index:-0.2554 R2:0.7127 0.4370 0.3992 RMSE:0.5343 0.7365 0.7692 Tau:0.6526 0.4811 0.2966\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 185 Step: 30710 Index:-0.2799 R2:0.7227 0.4208 0.3863 RMSE:0.5324 0.7535 0.7832 Tau:0.6558 0.4735 0.2969\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 186 Step: 30876 Index:-0.2779 R2:0.7223 0.4250 0.3966 RMSE:0.5436 0.7584 0.7779 Tau:0.6570 0.4804 0.2938\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 187 Step: 31042 Index:-0.2500 R2:0.7129 0.4522 0.4061 RMSE:0.5367 0.7508 0.7783 Tau:0.6521 0.5008 0.3055\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 188 Step: 31208 Index:-0.2813 R2:0.7289 0.4344 0.4080 RMSE:0.5496 0.7724 0.7877 Tau:0.6613 0.4912 0.3036\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 189 Step: 31374 Index:-0.2711 R2:0.7355 0.4326 0.3971 RMSE:0.5259 0.7547 0.7801 Tau:0.6649 0.4836 0.3006\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 190 Step: 31540 Index:-0.2590 R2:0.7236 0.4295 0.3993 RMSE:0.5365 0.7429 0.7732 Tau:0.6567 0.4840 0.2990\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 191 Step: 31706 Index:-0.2567 R2:0.7235 0.4327 0.4066 RMSE:0.5336 0.7460 0.7669 Tau:0.6584 0.4893 0.3106\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 192 Step: 31872 Index:-0.3258 R2:0.7186 0.3985 0.3703 RMSE:0.5687 0.7868 0.8142 Tau:0.6514 0.4609 0.2897\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 193 Step: 32038 Index:-0.2766 R2:0.7367 0.4145 0.3860 RMSE:0.5198 0.7506 0.7789 Tau:0.6652 0.4740 0.2995\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 194 Step: 32204 Index:-0.2697 R2:0.7411 0.4277 0.3811 RMSE:0.5225 0.7532 0.7905 Tau:0.6685 0.4835 0.3003\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 195 Step: 32370 Index:-0.2512 R2:0.7389 0.4350 0.3936 RMSE:0.5173 0.7428 0.7774 Tau:0.6676 0.4916 0.3032\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 196 Step: 32536 Index:-0.2823 R2:0.7338 0.4378 0.3928 RMSE:0.5370 0.7684 0.7976 Tau:0.6622 0.4861 0.3038\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 197 Step: 32702 Index:-0.2521 R2:0.7265 0.4419 0.4194 RMSE:0.5203 0.7420 0.7578 Tau:0.6598 0.4900 0.3180\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 198 Step: 32868 Index:-0.2461 R2:0.7466 0.4484 0.4103 RMSE:0.5004 0.7387 0.7643 Tau:0.6724 0.4926 0.3046\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 199 Step: 33034 Index:-0.2698 R2:0.7376 0.4319 0.3840 RMSE:0.5339 0.7530 0.7915 Tau:0.6664 0.4832 0.3000\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 200 Step: 33200 Index:-0.3053 R2:0.7217 0.4012 0.3726 RMSE:0.5262 0.7646 0.7890 Tau:0.6538 0.4594 0.2932\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 201 Step: 33366 Index:-0.2655 R2:0.7459 0.4351 0.3848 RMSE:0.5141 0.7498 0.7893 Tau:0.6725 0.4843 0.3087\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 202 Step: 33532 Index:-0.2689 R2:0.7415 0.4295 0.3944 RMSE:0.5052 0.7545 0.7784 Tau:0.6701 0.4855 0.3098\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 203 Step: 33698 Index:-0.2546 R2:0.7483 0.4381 0.4187 RMSE:0.5000 0.7392 0.7557 Tau:0.6747 0.4845 0.3071\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 204 Step: 33864 Index:-0.2687 R2:0.7519 0.4369 0.4145 RMSE:0.5013 0.7529 0.7664 Tau:0.6769 0.4842 0.3105\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 205 Step: 34030 Index:-0.2452 R2:0.7511 0.4496 0.4131 RMSE:0.4987 0.7418 0.7664 Tau:0.6758 0.4966 0.3049\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 206 Step: 34196 Index:-0.2785 R2:0.7514 0.4580 0.3957 RMSE:0.5678 0.7787 0.8240 Tau:0.6773 0.5002 0.3029\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 207 Step: 34362 Index:-0.3056 R2:0.7387 0.4176 0.3926 RMSE:0.5496 0.7812 0.8019 Tau:0.6692 0.4756 0.3041\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 208 Step: 34528 Index:-0.2853 R2:0.7420 0.4329 0.4129 RMSE:0.5320 0.7730 0.7804 Tau:0.6732 0.4877 0.3167\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 209 Step: 34694 Index:-0.2644 R2:0.7343 0.4281 0.3991 RMSE:0.5147 0.7466 0.7709 Tau:0.6664 0.4822 0.3060\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 210 Step: 34860 Index:-0.3101 R2:0.7344 0.3996 0.3830 RMSE:0.5151 0.7670 0.7816 Tau:0.6645 0.4569 0.2983\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 211 Step: 35026 Index:-0.2636 R2:0.7523 0.4363 0.4091 RMSE:0.5017 0.7507 0.7691 Tau:0.6768 0.4871 0.3124\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 212 Step: 35192 Index:-0.2485 R2:0.7435 0.4539 0.4208 RMSE:0.5107 0.7505 0.7684 Tau:0.6733 0.5020 0.3097\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 213 Step: 35358 Index:-0.3132 R2:0.7587 0.4476 0.4190 RMSE:0.5764 0.8083 0.8301 Tau:0.6832 0.4950 0.3133\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 214 Step: 35524 Index:-0.2523 R2:0.7525 0.4478 0.4071 RMSE:0.5025 0.7439 0.7714 Tau:0.6775 0.4916 0.3004\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 215 Step: 35690 Index:-0.2440 R2:0.7539 0.4539 0.4000 RMSE:0.5176 0.7412 0.7826 Tau:0.6785 0.4972 0.3116\n",
      "Epoch: 216 Step: 35856 Index:-0.2266 R2:0.7464 0.4577 0.4171 RMSE:0.5040 0.7299 0.7626 Tau:0.6763 0.5033 0.3133\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 217 Step: 36022 Index:-0.2305 R2:0.7628 0.4673 0.4080 RMSE:0.5003 0.7387 0.7807 Tau:0.6865 0.5081 0.3097\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 218 Step: 36188 Index:-0.2834 R2:0.7466 0.4472 0.3812 RMSE:0.5282 0.7739 0.8197 Tau:0.6713 0.4905 0.3036\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 219 Step: 36354 Index:-0.2427 R2:0.7568 0.4632 0.4077 RMSE:0.4913 0.7440 0.7808 Tau:0.6808 0.5014 0.3109\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 220 Step: 36520 Index:-0.2611 R2:0.7454 0.4404 0.3882 RMSE:0.5097 0.7456 0.7894 Tau:0.6718 0.4844 0.3111\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 221 Step: 36686 Index:-0.2924 R2:0.7542 0.4229 0.3918 RMSE:0.5040 0.7714 0.7914 Tau:0.6792 0.4790 0.3094\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 222 Step: 36852 Index:-0.2429 R2:0.7670 0.4533 0.4041 RMSE:0.4794 0.7374 0.7782 Tau:0.6897 0.4944 0.3148\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 223 Step: 37018 Index:-0.2688 R2:0.7616 0.4246 0.3818 RMSE:0.4889 0.7519 0.7899 Tau:0.6867 0.4831 0.3073\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 224 Step: 37184 Index:-0.2337 R2:0.7675 0.4554 0.4204 RMSE:0.4799 0.7317 0.7604 Tau:0.6915 0.4981 0.3171\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 225 Step: 37350 Index:-0.2738 R2:0.7203 0.4332 0.4111 RMSE:0.5553 0.7629 0.7778 Tau:0.6626 0.4891 0.3060\n",
      "Epoch: 226 Step: 37516 Index:-0.2028 R2:0.7528 0.4705 0.4075 RMSE:0.4970 0.7121 0.7674 Tau:0.6794 0.5094 0.3139\n",
      "Epoch: 227 Step: 37682 Index:-0.1981 R2:0.7624 0.4730 0.4112 RMSE:0.4926 0.7059 0.7622 Tau:0.6841 0.5078 0.3064\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 228 Step: 37848 Index:-0.2259 R2:0.7639 0.4593 0.4086 RMSE:0.4891 0.7298 0.7698 Tau:0.6883 0.5039 0.3147\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 229 Step: 38014 Index:-0.2457 R2:0.7584 0.4578 0.3787 RMSE:0.5033 0.7416 0.8018 Tau:0.6824 0.4959 0.3118\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 230 Step: 38180 Index:-0.2470 R2:0.7433 0.4503 0.3811 RMSE:0.5145 0.7353 0.7915 Tau:0.6736 0.4883 0.3162\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 231 Step: 38346 Index:-0.2363 R2:0.7718 0.4572 0.4195 RMSE:0.4822 0.7336 0.7624 Tau:0.6946 0.4974 0.3172\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 232 Step: 38512 Index:-0.2727 R2:0.7659 0.4586 0.3898 RMSE:0.5305 0.7712 0.8232 Tau:0.6854 0.4985 0.3079\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 233 Step: 38678 Index:-0.2452 R2:0.7714 0.4548 0.4162 RMSE:0.4837 0.7424 0.7731 Tau:0.6931 0.4973 0.3180\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 234 Step: 38844 Index:-0.2766 R2:0.7657 0.4547 0.3708 RMSE:0.5329 0.7681 0.8354 Tau:0.6860 0.4916 0.3051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 235 Step: 39010 Index:-0.2527 R2:0.7632 0.4543 0.4078 RMSE:0.4829 0.7439 0.7757 Tau:0.6864 0.4912 0.3183\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 236 Step: 39176 Index:-0.2461 R2:0.7754 0.4532 0.4064 RMSE:0.4742 0.7378 0.7707 Tau:0.6966 0.4917 0.3166\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 237 Step: 39342 Index:-0.2660 R2:0.7618 0.4465 0.4096 RMSE:0.4900 0.7527 0.7720 Tau:0.6858 0.4867 0.3160\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 238 Step: 39508 Index:-0.2327 R2:0.7588 0.4584 0.3704 RMSE:0.4986 0.7267 0.8030 Tau:0.6867 0.4939 0.3106\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 239 Step: 39674 Index:-0.2503 R2:0.7783 0.4482 0.4087 RMSE:0.4772 0.7444 0.7771 Tau:0.6983 0.4941 0.3188\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 240 Step: 39840 Index:-0.2387 R2:0.7800 0.4557 0.4191 RMSE:0.4845 0.7350 0.7642 Tau:0.6986 0.4963 0.3147\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 241 Step: 40006 Index:-0.2472 R2:0.7743 0.4476 0.3971 RMSE:0.4759 0.7388 0.7815 Tau:0.6903 0.4916 0.3031\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 242 Step: 40172 Index:-0.2824 R2:0.7762 0.4411 0.4108 RMSE:0.5043 0.7680 0.7875 Tau:0.6952 0.4856 0.3157\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 243 Step: 40338 Index:-0.2450 R2:0.7724 0.4584 0.4212 RMSE:0.4775 0.7413 0.7717 Tau:0.6917 0.4962 0.3177\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 244 Step: 40504 Index:-0.2278 R2:0.7724 0.4598 0.4121 RMSE:0.4761 0.7280 0.7683 Tau:0.6982 0.5002 0.3239\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 245 Step: 40670 Index:-0.2473 R2:0.7793 0.4456 0.3815 RMSE:0.4706 0.7377 0.7938 Tau:0.6983 0.4904 0.3143\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 246 Step: 40836 Index:-0.2495 R2:0.7791 0.4484 0.4131 RMSE:0.4722 0.7398 0.7700 Tau:0.6980 0.4903 0.3153\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 247 Step: 41002 Index:-0.2703 R2:0.7889 0.4611 0.3971 RMSE:0.5063 0.7655 0.8131 Tau:0.7046 0.4952 0.3155\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 248 Step: 41168 Index:-0.2970 R2:0.7569 0.4410 0.3494 RMSE:0.5529 0.7854 0.8606 Tau:0.6789 0.4884 0.3047\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 249 Step: 41334 Index:-0.2289 R2:0.7929 0.4663 0.4054 RMSE:0.4543 0.7305 0.7768 Tau:0.7094 0.5016 0.3213\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 250 Step: 41500 Index:-0.2431 R2:0.7890 0.4500 0.4064 RMSE:0.4625 0.7344 0.7731 Tau:0.7039 0.4913 0.3169\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 251 Step: 41666 Index:-0.2496 R2:0.7903 0.4518 0.3955 RMSE:0.4708 0.7436 0.7886 Tau:0.7067 0.4940 0.3204\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 252 Step: 41832 Index:-0.2565 R2:0.7882 0.4521 0.3874 RMSE:0.4622 0.7517 0.7995 Tau:0.7032 0.4952 0.3123\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 253 Step: 41998 Index:-0.2716 R2:0.7834 0.4533 0.4228 RMSE:0.4753 0.7675 0.7772 Tau:0.7024 0.4959 0.3319\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 254 Step: 42164 Index:-0.2343 R2:0.7871 0.4531 0.3845 RMSE:0.4627 0.7300 0.7872 Tau:0.7039 0.4957 0.3147\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 255 Step: 42330 Index:-0.2405 R2:0.7885 0.4607 0.4188 RMSE:0.4630 0.7445 0.7700 Tau:0.7060 0.5039 0.3168\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 256 Step: 42496 Index:-0.2957 R2:0.7816 0.4402 0.4011 RMSE:0.5191 0.7818 0.8096 Tau:0.6999 0.4861 0.3101\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 257 Step: 42662 Index:-0.2210 R2:0.7926 0.4670 0.3853 RMSE:0.4627 0.7293 0.7955 Tau:0.7078 0.5082 0.3170\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 258 Step: 42828 Index:-0.2410 R2:0.7886 0.4636 0.4196 RMSE:0.4572 0.7375 0.7654 Tau:0.7041 0.4965 0.3145\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 259 Step: 42994 Index:-0.2579 R2:0.7806 0.4540 0.3952 RMSE:0.4752 0.7507 0.7955 Tau:0.7005 0.4928 0.3168\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 260 Step: 43160 Index:-0.2646 R2:0.7816 0.4300 0.4021 RMSE:0.4667 0.7463 0.7740 Tau:0.6999 0.4817 0.3109\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 261 Step: 43326 Index:-0.2325 R2:0.7986 0.4646 0.4254 RMSE:0.4466 0.7344 0.7629 Tau:0.7123 0.5019 0.3158\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 262 Step: 43492 Index:-0.2379 R2:0.7920 0.4578 0.4051 RMSE:0.4542 0.7343 0.7784 Tau:0.7069 0.4965 0.3161\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 263 Step: 43658 Index:-0.2443 R2:0.7911 0.4488 0.3904 RMSE:0.4561 0.7351 0.7860 Tau:0.7059 0.4908 0.3140\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 264 Step: 43824 Index:-0.2353 R2:0.7922 0.4583 0.4231 RMSE:0.4542 0.7314 0.7614 Tau:0.7085 0.4961 0.3251\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 265 Step: 43990 Index:-0.2587 R2:0.7986 0.4335 0.4072 RMSE:0.4648 0.7452 0.7710 Tau:0.7147 0.4864 0.3162\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 266 Step: 44156 Index:-0.2393 R2:0.8030 0.4624 0.4079 RMSE:0.4437 0.7362 0.7759 Tau:0.7150 0.4969 0.3244\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 267 Step: 44322 Index:-0.2503 R2:0.8044 0.4517 0.4071 RMSE:0.4432 0.7455 0.7767 Tau:0.7173 0.4952 0.3184\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 268 Step: 44488 Index:-0.2219 R2:0.8057 0.4789 0.4055 RMSE:0.4483 0.7364 0.7922 Tau:0.7182 0.5145 0.3206\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 269 Step: 44654 Index:-0.2476 R2:0.7825 0.4623 0.4104 RMSE:0.4658 0.7519 0.7819 Tau:0.7029 0.5043 0.3081\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 270 Step: 44820 Index:-0.2495 R2:0.7926 0.4517 0.4063 RMSE:0.4573 0.7469 0.7787 Tau:0.7062 0.4973 0.3233\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 271 Step: 44986 Index:-0.2631 R2:0.7861 0.4592 0.3714 RMSE:0.4688 0.7676 0.8258 Tau:0.7042 0.5045 0.3171\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 272 Step: 45152 Index:-0.2716 R2:0.8073 0.4441 0.3968 RMSE:0.4802 0.7613 0.8007 Tau:0.7203 0.4896 0.3162\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 273 Step: 45318 Index:-0.2712 R2:0.7994 0.4522 0.3918 RMSE:0.4829 0.7688 0.8088 Tau:0.7138 0.4976 0.3182\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 274 Step: 45484 Index:-0.2461 R2:0.8105 0.4440 0.3981 RMSE:0.4375 0.7352 0.7782 Tau:0.7218 0.4891 0.3122\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 275 Step: 45650 Index:-0.3031 R2:0.8069 0.4442 0.4035 RMSE:0.4905 0.7887 0.8150 Tau:0.7211 0.4855 0.3196\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 276 Step: 45816 Index:-0.2706 R2:0.8126 0.4567 0.4144 RMSE:0.4573 0.7688 0.7911 Tau:0.7242 0.4982 0.3295\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 277 Step: 45982 Index:-0.2612 R2:0.7983 0.4485 0.4019 RMSE:0.4458 0.7512 0.7827 Tau:0.7146 0.4900 0.3132\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 278 Step: 46148 Index:-0.2590 R2:0.8166 0.4379 0.4113 RMSE:0.4384 0.7470 0.7748 Tau:0.7284 0.4880 0.3198\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 279 Step: 46314 Index:-0.2288 R2:0.8013 0.4638 0.3977 RMSE:0.4431 0.7323 0.7885 Tau:0.7179 0.5035 0.3193\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 280 Step: 46480 Index:-0.2354 R2:0.8152 0.4633 0.4165 RMSE:0.4291 0.7394 0.7767 Tau:0.7266 0.5040 0.3188\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 281 Step: 46646 Index:-0.2634 R2:0.8115 0.4553 0.3963 RMSE:0.4861 0.7617 0.8109 Tau:0.7239 0.4983 0.3247\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 282 Step: 46812 Index:-0.2482 R2:0.8143 0.4620 0.4179 RMSE:0.4336 0.7494 0.7778 Tau:0.7259 0.5012 0.3171\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 283 Step: 46978 Index:-0.2631 R2:0.8062 0.4570 0.4008 RMSE:0.4455 0.7533 0.7906 Tau:0.7172 0.4902 0.3147\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 284 Step: 47144 Index:-0.2264 R2:0.8177 0.4655 0.4043 RMSE:0.4282 0.7307 0.7796 Tau:0.7276 0.5043 0.3273\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 285 Step: 47310 Index:-0.2572 R2:0.7798 0.4347 0.4320 RMSE:0.4726 0.7479 0.7502 Tau:0.6991 0.4908 0.3120\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 286 Step: 47476 Index:-0.2392 R2:0.8087 0.4627 0.4124 RMSE:0.4349 0.7439 0.7861 Tau:0.7211 0.5048 0.3233\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 287 Step: 47642 Index:-0.2618 R2:0.8109 0.4659 0.4119 RMSE:0.4955 0.7680 0.8104 Tau:0.7219 0.5063 0.3238\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 288 Step: 47808 Index:-0.2650 R2:0.8093 0.4448 0.4218 RMSE:0.4371 0.7601 0.7779 Tau:0.7204 0.4950 0.3254\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 289 Step: 47974 Index:-0.2553 R2:0.8137 0.4436 0.4116 RMSE:0.4377 0.7437 0.7708 Tau:0.7264 0.4884 0.3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 290 Step: 48140 Index:-0.2408 R2:0.8168 0.4642 0.4125 RMSE:0.4253 0.7361 0.7767 Tau:0.7268 0.4953 0.3278\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 291 Step: 48306 Index:-0.2446 R2:0.8098 0.4521 0.4130 RMSE:0.4379 0.7392 0.7774 Tau:0.7222 0.4945 0.3217\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 292 Step: 48472 Index:-0.2736 R2:0.8206 0.4531 0.4086 RMSE:0.4629 0.7661 0.7999 Tau:0.7316 0.4925 0.3229\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 293 Step: 48638 Index:-0.2865 R2:0.8175 0.4337 0.3965 RMSE:0.4526 0.7666 0.8008 Tau:0.7293 0.4801 0.3150\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 294 Step: 48804 Index:-0.2334 R2:0.8305 0.4705 0.4170 RMSE:0.4105 0.7371 0.7791 Tau:0.7386 0.5037 0.3223\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 295 Step: 48970 Index:-0.2288 R2:0.8226 0.4677 0.4144 RMSE:0.4233 0.7326 0.7777 Tau:0.7344 0.5039 0.3203\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 296 Step: 49136 Index:-0.2658 R2:0.8102 0.4541 0.3965 RMSE:0.4351 0.7555 0.7959 Tau:0.7222 0.4897 0.3167\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 297 Step: 49302 Index:-0.3946 R2:0.7950 0.4302 0.3653 RMSE:0.5867 0.8710 0.9121 Tau:0.7079 0.4764 0.3213\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 298 Step: 49468 Index:-0.2693 R2:0.8118 0.4456 0.4044 RMSE:0.4339 0.7544 0.7875 Tau:0.7249 0.4850 0.3210\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 299 Step: 49634 Index:-0.2332 R2:0.8204 0.4662 0.4143 RMSE:0.4212 0.7327 0.7796 Tau:0.7317 0.4995 0.3237\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 300 Step: 49800 Index:-0.2445 R2:0.8311 0.4540 0.4059 RMSE:0.4178 0.7406 0.7830 Tau:0.7398 0.4961 0.3216\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 301 Step: 49966 Index:-0.2533 R2:0.8181 0.4583 0.4164 RMSE:0.4239 0.7531 0.7845 Tau:0.7293 0.4999 0.3270\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 302 Step: 50132 Index:-0.2389 R2:0.8236 0.4632 0.4182 RMSE:0.4183 0.7415 0.7763 Tau:0.7343 0.5027 0.3299\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 303 Step: 50298 Index:-0.2751 R2:0.8218 0.4542 0.4052 RMSE:0.4323 0.7697 0.7993 Tau:0.7314 0.4946 0.3174\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 304 Step: 50464 Index:-0.2465 R2:0.8261 0.4702 0.4085 RMSE:0.4312 0.7521 0.8017 Tau:0.7356 0.5056 0.3263\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 305 Step: 50630 Index:-0.2767 R2:0.8081 0.4626 0.4096 RMSE:0.4396 0.7743 0.8043 Tau:0.7197 0.4976 0.3256\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 306 Step: 50796 Index:-0.2369 R2:0.8282 0.4657 0.4113 RMSE:0.4117 0.7382 0.7828 Tau:0.7365 0.5013 0.3293\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 307 Step: 50962 Index:-0.2604 R2:0.8159 0.4481 0.3961 RMSE:0.4256 0.7549 0.8004 Tau:0.7263 0.4945 0.3215\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 308 Step: 51128 Index:-0.2775 R2:0.8136 0.4439 0.3782 RMSE:0.4597 0.7637 0.8223 Tau:0.7224 0.4862 0.3137\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 309 Step: 51294 Index:-0.2402 R2:0.8306 0.4599 0.3836 RMSE:0.4212 0.7414 0.8102 Tau:0.7400 0.5012 0.3147\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 310 Step: 51460 Index:-0.2581 R2:0.8170 0.4528 0.4087 RMSE:0.4241 0.7497 0.7856 Tau:0.7256 0.4916 0.3175\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 311 Step: 51626 Index:-0.2469 R2:0.8287 0.4551 0.3997 RMSE:0.4299 0.7439 0.7916 Tau:0.7361 0.4970 0.3141\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 312 Step: 51792 Index:-0.2940 R2:0.8136 0.4407 0.4023 RMSE:0.4540 0.7847 0.8163 Tau:0.7254 0.4907 0.3190\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 313 Step: 51958 Index:-0.2864 R2:0.8212 0.4487 0.4067 RMSE:0.4639 0.7849 0.8160 Tau:0.7332 0.4985 0.3256\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 314 Step: 52124 Index:-0.2691 R2:0.8306 0.4315 0.4039 RMSE:0.4198 0.7486 0.7798 Tau:0.7395 0.4795 0.3193\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 315 Step: 52290 Index:-0.2597 R2:0.8267 0.4495 0.3826 RMSE:0.4178 0.7534 0.8074 Tau:0.7348 0.4937 0.3216\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 316 Step: 52456 Index:-0.2514 R2:0.8281 0.4711 0.4037 RMSE:0.4713 0.7600 0.8199 Tau:0.7380 0.5086 0.3243\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 317 Step: 52622 Index:-0.2521 R2:0.8420 0.4562 0.4030 RMSE:0.4320 0.7476 0.7956 Tau:0.7498 0.4956 0.3204\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 318 Step: 52788 Index:-0.2617 R2:0.8264 0.4597 0.4053 RMSE:0.4190 0.7563 0.8033 Tau:0.7333 0.4946 0.3180\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 319 Step: 52954 Index:-0.2608 R2:0.8365 0.4418 0.4065 RMSE:0.4152 0.7501 0.7848 Tau:0.7441 0.4893 0.3238\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 320 Step: 53120 Index:-0.2470 R2:0.8337 0.4547 0.4039 RMSE:0.4072 0.7404 0.7859 Tau:0.7413 0.4934 0.3189\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 321 Step: 53286 Index:-0.2483 R2:0.8350 0.4469 0.3958 RMSE:0.4109 0.7402 0.7863 Tau:0.7444 0.4920 0.3237\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 322 Step: 53452 Index:-0.2581 R2:0.8400 0.4525 0.4094 RMSE:0.4030 0.7554 0.7899 Tau:0.7478 0.4973 0.3306\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 323 Step: 53618 Index:-0.2165 R2:0.8371 0.4790 0.4162 RMSE:0.4021 0.7285 0.7782 Tau:0.7459 0.5120 0.3251\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 324 Step: 53784 Index:-0.2386 R2:0.8383 0.4559 0.4211 RMSE:0.4075 0.7358 0.7692 Tau:0.7472 0.4972 0.3236\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 325 Step: 53950 Index:-0.2441 R2:0.8417 0.4625 0.4204 RMSE:0.3975 0.7432 0.7759 Tau:0.7492 0.4991 0.3275\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 326 Step: 54116 Index:-0.2603 R2:0.8452 0.4515 0.4051 RMSE:0.3922 0.7537 0.7956 Tau:0.7531 0.4934 0.3265\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 327 Step: 54282 Index:-0.2678 R2:0.8303 0.4570 0.3966 RMSE:0.4230 0.7656 0.8135 Tau:0.7408 0.4978 0.3267\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau\n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 327 r2:0.4112 RMSE:0.7622 WTI:0.3121 AP:0.4176 Tau:0.3064 \n",
      " \n",
      " Top-1:0.3125 Top-1-fp:0.2500 \n",
      " Top-5:0.5181 Top-5-fp:0.3253 \n",
      " Top-10:0.5120 Top-10-fp:0.4458 \n",
      " Top-15:0.4378 Top-15-fp:0.5261 \n",
      " Top-20:0.4367 Top-20-fp:0.5572 \n",
      " Top-25:0.5000 Top-25-fp:0.5783 \n",
      " Top-30:0.5800 Top-30-fp:0.5924 \n",
      " Top-40:0.6800 Top-40-fp:0.6421 \n",
      " Top-50:0.7914 Top-50-fp:0.6667 \n",
      " \n",
      " Top50:0.5000 Top50-fp:0.3200 \n",
      " Top100:0.4800 Top100-fp:0.3900 \n",
      " Top150:0.5000 Top150-fp:0.4333 \n",
      " Top200:0.4750 Top200-fp:0.4950 \n",
      " Top250:0.4360 Top250-fp:0.5280 \n",
      " Top300:0.4433 Top300-fp:0.5433 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
