{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC50_P21453_0.5_210\n",
      "model_file/1_GAFSE_EC50_P21453_0.5_210_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/EC50_P21453_0.5_210_train.csv\"\n",
    "test_filename = \"./data/benchmark/EC50_P21453_0.5_210_test.csv\"\n",
    "test_active = 210\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CCCOC1=C(C=C(C=C1)C2=NC(=NO2)C3=CC4=C(C=C3)N(C... -0.462398\n",
      "1  CC1=CC=C(C=C1)CCCC(=O)C2=CC=C(C=C2)COCC(C)(COP... -0.845098\n",
      "2  CCOC1=C(C=C(C=N1)C2=NN=C(S2)C3=CC(=C(C=C3Cl)OC... -2.773786\n",
      "3  CC(=O)OC1=CC=C(C=C1)N2C(=C3C(=C2O)C4(C=CC3(O4)... -3.509203\n",
      "4  CCCCCCN1CCC2=C(C1=O)C=CC(=C2)C3CCC(C3)(COP(=O)... -2.740363\n",
      "number of all smiles:  938\n",
      "number of successfully processed smiles:  938\n",
      "                                              smiles     value  \\\n",
      "0  CCCOC1=C(C=C(C=C1)C2=NC(=NO2)C3=CC4=C(C=C3)N(C... -0.462398   \n",
      "1  CC1=CC=C(C=C1)CCCC(=O)C2=CC=C(C=C2)COCC(C)(COP... -0.845098   \n",
      "2  CCOC1=C(C=C(C=N1)C2=NN=C(S2)C3=CC(=C(C=C3Cl)OC... -2.773786   \n",
      "3  CC(=O)OC1=CC=C(C=C1)N2C(=C3C(=C2O)C4(C=CC3(O4)... -3.509203   \n",
      "4  CCCCCCN1CCC2=C(C1=O)C=CC(=C2)C3CCC(C3)(COP(=O)... -2.740363   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  CCCOc1ccc(-c2nc(-c3ccc4c(c3)CCN4CC(N)(CO)CO)no...  \n",
      "1  Cc1ccc(CCCC(=O)c2ccc(COCC(C)(N)COP(=O)(O)O)cc2...  \n",
      "2  CCOc1ncc(-c2nnc(-c3cc(F)c(OCC(N)CO)cc3Cl)s2)cc1Cl  \n",
      "3    CC(=O)Oc1ccc(-n2c(O)c3c(c2O)C2(C)C=CC3(C)O2)cc1  \n",
      "4    CCCCCCN1CCc2cc(C3CCC(N)(COP(=O)(O)O)C3)ccc2C1=O  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  871\n",
      "number of successfully processed smiles:  871\n",
      "(871, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1CC1(C2=CC=CC=C2)C3=NC4=C(C=C3)N=C(S4)C5=C(C=... -1.623249   \n",
      "1      CC1=CC(=C(C=C1)C(C)C)OCC2=CC=C(C=C2)C3=NN=CO3 -3.316495   \n",
      "2         CC1=C(N2C=CSC2=N1)C3=CSC(=N3)NCC4=CC=CC=C4 -3.503382   \n",
      "3  CC1=NC(=CO1)C2=CC=C(C=C2)OC3=CC=C(C=C3)CCC(CO)... -1.611723   \n",
      "4  CC1=CC(=CC(=C1OCC(CN)O)C)CCC(=O)C2=C3CCC(CC3=C... -0.845098   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  O=C(O)CCNc1ccc(-c2nc3ccc(C4(c5ccccc5)CC4)nc3s2...  \n",
      "1             Cc1ccc(C(C)C)c(OCc2ccc(-c3nnco3)cc2)c1  \n",
      "2                  Cc1nc2sccn2c1-c1csc(NCc2ccccc2)n1  \n",
      "3  Cc1nc(-c2ccc(Oc3ccc(CCC(N)(CO)COP(=O)(O)O)cc3)...  \n",
      "4  Cc1cc(CCC(=O)c2sc(C)c3c2CCC(C)(C)C3)cc(C)c1OCC...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/EC50_P21453_0.5_210_train.pickle\n",
      "./data/benchmark/EC50_P21453_0.5_210_train\n",
      "1809\n",
      "feature dicts file saved as ./data/benchmark/EC50_P21453_0.5_210_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 3) (188, 3) (871, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_EC50_P21453_0.5_210_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 87 Index:-0.6452 R2:0.3917 0.4679 0.2987 RMSE:1.2640 1.1392 1.2205 Tau:0.4598 0.4941 0.3844\n",
      "Epoch: 2 Step: 174 Index:-0.6069 R2:0.4216 0.4847 0.3154 RMSE:1.2373 1.1132 1.2021 Tau:0.4758 0.5063 0.3787\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 3 Step: 261 Index:-0.7514 R2:0.4382 0.4938 0.3316 RMSE:1.3731 1.2587 1.2970 Tau:0.4894 0.5072 0.3904\n",
      "Epoch: 4 Step: 348 Index:-0.5162 R2:0.4584 0.5084 0.3509 RMSE:1.1361 1.0316 1.2219 Tau:0.5012 0.5155 0.3934\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 5 Step: 435 Index:-0.5688 R2:0.4774 0.5143 0.3723 RMSE:1.1908 1.0806 1.1580 Tau:0.5111 0.5118 0.4007\n",
      "Epoch: 6 Step: 522 Index:-0.5051 R2:0.4902 0.5299 0.3877 RMSE:1.1195 1.0340 1.2180 Tau:0.5183 0.5288 0.4010\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 7 Step: 609 Index:-0.6408 R2:0.5128 0.5244 0.4093 RMSE:1.2574 1.1680 1.1999 Tau:0.5317 0.5272 0.3972\n",
      "Epoch: 8 Step: 696 Index:-0.4529 R2:0.5165 0.5407 0.4250 RMSE:1.0709 0.9785 1.0881 Tau:0.5336 0.5256 0.4060\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 783 Index:-0.4707 R2:0.5235 0.5398 0.4314 RMSE:1.0912 1.0003 1.0836 Tau:0.5391 0.5296 0.4082\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 10 Step: 870 Index:-0.4604 R2:0.5228 0.5402 0.4282 RMSE:1.0552 0.9866 1.1179 Tau:0.5387 0.5262 0.4079\n",
      "Epoch: 11 Step: 957 Index:-0.4512 R2:0.5305 0.5461 0.4379 RMSE:1.0481 0.9844 1.1130 Tau:0.5431 0.5332 0.4090\n",
      "Epoch: 12 Step: 1044 Index:-0.4401 R2:0.5358 0.5470 0.4474 RMSE:1.0532 0.9752 1.0642 Tau:0.5457 0.5351 0.4083\n",
      "Epoch: 13 Step: 1131 Index:-0.4281 R2:0.5404 0.5526 0.4560 RMSE:1.0341 0.9667 1.0767 Tau:0.5481 0.5387 0.4090\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 14 Step: 1218 Index:-0.6586 R2:0.5450 0.5423 0.4594 RMSE:1.2829 1.1953 1.2122 Tau:0.5503 0.5367 0.4034\n",
      "Epoch: 15 Step: 1305 Index:-0.4232 R2:0.5443 0.5564 0.4576 RMSE:1.0313 0.9615 1.0593 Tau:0.5504 0.5383 0.4129\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 16 Step: 1392 Index:-0.4546 R2:0.5505 0.5547 0.4616 RMSE:1.0620 0.9975 1.1162 Tau:0.5522 0.5429 0.4102\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 17 Step: 1479 Index:-0.4549 R2:0.5501 0.5523 0.4611 RMSE:1.0667 0.9901 1.0598 Tau:0.5530 0.5352 0.4105\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 18 Step: 1566 Index:-0.4505 R2:0.5529 0.5563 0.4619 RMSE:1.0340 0.9861 1.1037 Tau:0.5548 0.5356 0.4134\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 19 Step: 1653 Index:-0.5102 R2:0.5575 0.5563 0.4760 RMSE:1.1271 1.0493 1.0861 Tau:0.5565 0.5391 0.4098\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 20 Step: 1740 Index:-0.5020 R2:0.5603 0.5623 0.4789 RMSE:1.1276 1.0430 1.0844 Tau:0.5583 0.5411 0.4127\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 21 Step: 1827 Index:-0.4306 R2:0.5621 0.5608 0.4711 RMSE:1.0176 0.9748 1.0851 Tau:0.5595 0.5443 0.4124\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 22 Step: 1914 Index:-0.4989 R2:0.5621 0.5542 0.4691 RMSE:1.1119 1.0415 1.0866 Tau:0.5580 0.5427 0.4083\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 23 Step: 2001 Index:-0.4336 R2:0.5560 0.5600 0.4644 RMSE:1.0434 0.9671 1.0494 Tau:0.5546 0.5335 0.4177\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 24 Step: 2088 Index:-0.4898 R2:0.5643 0.5649 0.4693 RMSE:1.0707 1.0307 1.1645 Tau:0.5622 0.5408 0.4192\n",
      "Epoch: 25 Step: 2175 Index:-0.4122 R2:0.5687 0.5656 0.4785 RMSE:1.0130 0.9540 1.0338 Tau:0.5642 0.5419 0.4147\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 26 Step: 2262 Index:-0.4126 R2:0.5693 0.5717 0.4783 RMSE:1.0023 0.9547 1.0630 Tau:0.5640 0.5421 0.4182\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 27 Step: 2349 Index:-0.4352 R2:0.5603 0.5558 0.4573 RMSE:1.0166 0.9665 1.0586 Tau:0.5571 0.5312 0.4175\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 28 Step: 2436 Index:-0.4333 R2:0.5715 0.5711 0.4797 RMSE:1.0556 0.9821 1.0495 Tau:0.5656 0.5488 0.4145\n",
      "Epoch: 29 Step: 2523 Index:-0.3991 R2:0.5741 0.5679 0.4837 RMSE:0.9952 0.9475 1.0379 Tau:0.5658 0.5484 0.4136\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 30 Step: 2610 Index:-0.4005 R2:0.5775 0.5739 0.4851 RMSE:0.9934 0.9488 1.0514 Tau:0.5697 0.5483 0.4165\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 31 Step: 2697 Index:-0.4003 R2:0.5792 0.5754 0.4841 RMSE:1.0092 0.9433 1.0310 Tau:0.5697 0.5430 0.4206\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 32 Step: 2784 Index:-0.4209 R2:0.5772 0.5756 0.4806 RMSE:0.9993 0.9629 1.0756 Tau:0.5677 0.5421 0.4211\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 33 Step: 2871 Index:-0.4470 R2:0.5818 0.5649 0.4823 RMSE:0.9996 0.9904 1.0779 Tau:0.5711 0.5433 0.4146\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 34 Step: 2958 Index:-0.4915 R2:0.5851 0.5663 0.4884 RMSE:1.0959 1.0325 1.0771 Tau:0.5738 0.5411 0.4167\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 35 Step: 3045 Index:-0.5027 R2:0.5891 0.5682 0.4930 RMSE:1.1065 1.0456 1.0812 Tau:0.5759 0.5429 0.4185\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 36 Step: 3132 Index:-0.4128 R2:0.5896 0.5708 0.4932 RMSE:1.0060 0.9563 1.0234 Tau:0.5762 0.5435 0.4173\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 37 Step: 3219 Index:-0.4202 R2:0.5876 0.5658 0.4883 RMSE:1.0054 0.9583 1.0268 Tau:0.5759 0.5381 0.4224\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 38 Step: 3306 Index:-0.4059 R2:0.5881 0.5754 0.4955 RMSE:0.9773 0.9450 1.0297 Tau:0.5759 0.5391 0.4239\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 39 Step: 3393 Index:-0.5386 R2:0.5943 0.5626 0.4949 RMSE:1.1348 1.0803 1.1109 Tau:0.5800 0.5417 0.4150\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 40 Step: 3480 Index:-0.4118 R2:0.5938 0.5658 0.4887 RMSE:0.9704 0.9551 1.0324 Tau:0.5777 0.5433 0.4134\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 41 Step: 3567 Index:-0.4148 R2:0.5936 0.5648 0.4880 RMSE:0.9728 0.9580 1.0427 Tau:0.5755 0.5432 0.4126\n",
      "Epoch: 42 Step: 3654 Index:-0.3844 R2:0.5999 0.5868 0.5003 RMSE:0.9641 0.9334 1.0304 Tau:0.5840 0.5491 0.4235\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 3741 Index:-0.3867 R2:0.6055 0.5881 0.5082 RMSE:0.9925 0.9391 1.0110 Tau:0.5872 0.5524 0.4218\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 44 Step: 3828 Index:-0.3921 R2:0.6027 0.5771 0.4995 RMSE:0.9853 0.9428 1.0182 Tau:0.5822 0.5507 0.4147\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 45 Step: 3915 Index:-0.5331 R2:0.6090 0.5795 0.5049 RMSE:1.1449 1.0815 1.1225 Tau:0.5888 0.5484 0.4156\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 46 Step: 4002 Index:-0.4144 R2:0.6068 0.5862 0.5107 RMSE:0.9677 0.9656 1.0314 Tau:0.5871 0.5512 0.4196\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 47 Step: 4089 Index:-0.4273 R2:0.6137 0.5888 0.5063 RMSE:0.9811 0.9794 1.0814 Tau:0.5922 0.5520 0.4220\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 48 Step: 4176 Index:-0.3913 R2:0.6144 0.5833 0.5034 RMSE:0.9532 0.9410 1.0112 Tau:0.5917 0.5497 0.4176\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 49 Step: 4263 Index:-0.3907 R2:0.6174 0.5883 0.4992 RMSE:0.9838 0.9423 1.0232 Tau:0.5945 0.5516 0.4182\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 50 Step: 4350 Index:-0.4082 R2:0.6143 0.5943 0.5026 RMSE:0.9721 0.9552 1.0277 Tau:0.5941 0.5470 0.4268\n",
      "Epoch: 51 Step: 4437 Index:-0.3816 R2:0.6210 0.5906 0.5181 RMSE:0.9567 0.9356 0.9960 Tau:0.5957 0.5540 0.4214\n",
      "Epoch: 52 Step: 4524 Index:-0.3712 R2:0.6252 0.5914 0.5188 RMSE:0.9335 0.9240 1.0023 Tau:0.5994 0.5528 0.4209\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 53 Step: 4611 Index:-0.3740 R2:0.6266 0.5944 0.5131 RMSE:0.9335 0.9274 1.0173 Tau:0.5996 0.5534 0.4190\n",
      "Epoch: 54 Step: 4698 Index:-0.3579 R2:0.6340 0.6035 0.5200 RMSE:0.9592 0.9215 1.0012 Tau:0.6051 0.5636 0.4199\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 55 Step: 4785 Index:-0.3886 R2:0.6253 0.5853 0.5086 RMSE:0.9327 0.9380 1.0155 Tau:0.5983 0.5494 0.4170\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 56 Step: 4872 Index:-0.3888 R2:0.6353 0.6071 0.5189 RMSE:0.9834 0.9484 1.0197 Tau:0.6064 0.5596 0.4221\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 57 Step: 4959 Index:-0.3914 R2:0.6389 0.6043 0.5243 RMSE:0.9908 0.9507 1.0199 Tau:0.6094 0.5592 0.4200\n",
      "Epoch: 58 Step: 5046 Index:-0.3470 R2:0.6364 0.6084 0.5357 RMSE:0.9181 0.9088 0.9830 Tau:0.6080 0.5619 0.4227\n",
      "Epoch: 59 Step: 5133 Index:-0.3467 R2:0.6308 0.6143 0.5190 RMSE:0.9255 0.9039 1.0073 Tau:0.6060 0.5573 0.4319\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 60 Step: 5220 Index:-0.3575 R2:0.6402 0.6040 0.5285 RMSE:0.9299 0.9188 0.9853 Tau:0.6096 0.5613 0.4232\n",
      "Epoch: 61 Step: 5307 Index:-0.3257 R2:0.6457 0.6201 0.5299 RMSE:0.9185 0.8889 0.9821 Tau:0.6158 0.5632 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 Step: 5394 Index:-0.3121 R2:0.6524 0.6249 0.5352 RMSE:0.9116 0.8820 0.9791 Tau:0.6199 0.5699 0.4283\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 63 Step: 5481 Index:-0.3261 R2:0.6439 0.6299 0.5306 RMSE:0.9122 0.8911 1.0024 Tau:0.6162 0.5650 0.4309\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 64 Step: 5568 Index:-0.3309 R2:0.6479 0.6216 0.5241 RMSE:0.9049 0.8938 1.0008 Tau:0.6190 0.5629 0.4289\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 65 Step: 5655 Index:-0.3175 R2:0.6460 0.6271 0.5318 RMSE:0.9114 0.8842 0.9922 Tau:0.6182 0.5667 0.4288\n",
      "Epoch: 66 Step: 5742 Index:-0.3045 R2:0.6464 0.6340 0.5554 RMSE:0.9488 0.8901 0.9676 Tau:0.6163 0.5856 0.4258\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 67 Step: 5829 Index:-0.3092 R2:0.6572 0.6297 0.5406 RMSE:0.8938 0.8819 0.9820 Tau:0.6232 0.5727 0.4298\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 68 Step: 5916 Index:-0.3053 R2:0.6489 0.6380 0.5328 RMSE:0.9248 0.8810 0.9842 Tau:0.6194 0.5757 0.4282\n",
      "Epoch: 69 Step: 6003 Index:-0.3022 R2:0.6575 0.6361 0.5417 RMSE:0.8937 0.8759 0.9734 Tau:0.6253 0.5738 0.4319\n",
      "Epoch: 70 Step: 6090 Index:-0.2864 R2:0.6602 0.6400 0.5401 RMSE:0.8956 0.8637 0.9711 Tau:0.6275 0.5773 0.4303\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 71 Step: 6177 Index:-0.3156 R2:0.6607 0.6416 0.5421 RMSE:0.8983 0.8926 0.9994 Tau:0.6263 0.5771 0.4266\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 72 Step: 6264 Index:-0.3228 R2:0.6663 0.6417 0.5426 RMSE:0.9028 0.9012 1.0146 Tau:0.6300 0.5784 0.4283\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 73 Step: 6351 Index:-0.3164 R2:0.6642 0.6277 0.5282 RMSE:0.8961 0.8848 0.9851 Tau:0.6285 0.5684 0.4217\n",
      "Epoch: 74 Step: 6438 Index:-0.2627 R2:0.6702 0.6525 0.5486 RMSE:0.8769 0.8494 0.9631 Tau:0.6352 0.5867 0.4288\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 75 Step: 6525 Index:-0.3705 R2:0.6675 0.6366 0.5432 RMSE:0.9391 0.9449 1.0594 Tau:0.6318 0.5744 0.4306\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 76 Step: 6612 Index:-0.3470 R2:0.6711 0.6235 0.5419 RMSE:0.9497 0.9301 1.0007 Tau:0.6287 0.5830 0.4214\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 77 Step: 6699 Index:-0.2933 R2:0.6742 0.6378 0.5510 RMSE:0.8905 0.8766 0.9632 Tau:0.6347 0.5834 0.4254\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 78 Step: 6786 Index:-0.2833 R2:0.6765 0.6446 0.5437 RMSE:0.8728 0.8616 0.9672 Tau:0.6386 0.5783 0.4290\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 79 Step: 6873 Index:-0.2799 R2:0.6827 0.6467 0.5476 RMSE:0.8668 0.8653 0.9810 Tau:0.6423 0.5854 0.4292\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 80 Step: 6960 Index:-0.2746 R2:0.6826 0.6472 0.5534 RMSE:0.8581 0.8591 0.9613 Tau:0.6417 0.5845 0.4316\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 81 Step: 7047 Index:-0.2740 R2:0.6784 0.6506 0.5458 RMSE:0.8795 0.8566 0.9662 Tau:0.6403 0.5826 0.4301\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 82 Step: 7134 Index:-0.3214 R2:0.6822 0.6557 0.5578 RMSE:0.9467 0.9120 0.9957 Tau:0.6426 0.5907 0.4341\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 83 Step: 7221 Index:-0.2655 R2:0.6862 0.6498 0.5468 RMSE:0.8545 0.8564 0.9656 Tau:0.6423 0.5909 0.4256\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 84 Step: 7308 Index:-0.2645 R2:0.6869 0.6568 0.5544 RMSE:0.8737 0.8526 0.9590 Tau:0.6470 0.5882 0.4339\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 85 Step: 7395 Index:-0.2638 R2:0.6859 0.6562 0.5482 RMSE:0.8645 0.8508 0.9646 Tau:0.6457 0.5870 0.4314\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 86 Step: 7482 Index:-0.2629 R2:0.6926 0.6512 0.5566 RMSE:0.8477 0.8507 0.9577 Tau:0.6489 0.5878 0.4312\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 87 Step: 7569 Index:-0.2702 R2:0.6956 0.6548 0.5574 RMSE:0.8499 0.8628 0.9766 Tau:0.6503 0.5926 0.4305\n",
      "Epoch: 88 Step: 7656 Index:-0.2619 R2:0.6918 0.6596 0.5548 RMSE:0.8535 0.8502 0.9759 Tau:0.6494 0.5883 0.4359\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 89 Step: 7743 Index:-0.3300 R2:0.6752 0.6554 0.5559 RMSE:0.9450 0.9216 1.0048 Tau:0.6372 0.5916 0.4280\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 90 Step: 7830 Index:-0.2818 R2:0.6870 0.6599 0.5528 RMSE:0.8659 0.8704 0.9953 Tau:0.6459 0.5886 0.4353\n",
      "Epoch: 91 Step: 7917 Index:-0.2487 R2:0.6969 0.6634 0.5598 RMSE:0.8416 0.8456 0.9547 Tau:0.6521 0.5970 0.4313\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 92 Step: 8004 Index:-0.3683 R2:0.6879 0.6431 0.5416 RMSE:0.9571 0.9607 1.0333 Tau:0.6401 0.5924 0.4177\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 93 Step: 8091 Index:-0.2551 R2:0.6991 0.6613 0.5646 RMSE:0.8379 0.8507 0.9606 Tau:0.6528 0.5956 0.4349\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 94 Step: 8178 Index:-0.2493 R2:0.6997 0.6592 0.5549 RMSE:0.8350 0.8452 0.9588 Tau:0.6505 0.5959 0.4262\n",
      "Epoch: 95 Step: 8265 Index:-0.2470 R2:0.7042 0.6668 0.5667 RMSE:0.8486 0.8485 0.9507 Tau:0.6567 0.6015 0.4324\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 96 Step: 8352 Index:-0.2746 R2:0.7069 0.6612 0.5588 RMSE:0.8605 0.8703 0.9979 Tau:0.6577 0.5957 0.4331\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 97 Step: 8439 Index:-0.2806 R2:0.6945 0.6621 0.5541 RMSE:0.8663 0.8704 0.9991 Tau:0.6515 0.5898 0.4293\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 98 Step: 8526 Index:-0.2561 R2:0.7097 0.6656 0.5728 RMSE:0.8531 0.8574 0.9481 Tau:0.6606 0.6013 0.4303\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 99 Step: 8613 Index:-0.2616 R2:0.7070 0.6665 0.5631 RMSE:0.8484 0.8579 0.9847 Tau:0.6612 0.5963 0.4352\n",
      "Epoch: 100 Step: 8700 Index:-0.2368 R2:0.7076 0.6701 0.5666 RMSE:0.8267 0.8349 0.9580 Tau:0.6615 0.5981 0.4364\n",
      "Epoch: 101 Step: 8787 Index:-0.2257 R2:0.7119 0.6757 0.5693 RMSE:0.8386 0.8294 0.9422 Tau:0.6627 0.6037 0.4349\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 102 Step: 8874 Index:-0.2740 R2:0.7104 0.6595 0.5596 RMSE:0.8565 0.8637 0.9620 Tau:0.6634 0.5898 0.4354\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 103 Step: 8961 Index:-0.4517 R2:0.6934 0.6333 0.5448 RMSE:1.0404 1.0410 1.1096 Tau:0.6441 0.5893 0.4104\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 104 Step: 9048 Index:-0.2595 R2:0.7066 0.6691 0.5544 RMSE:0.8708 0.8566 0.9712 Tau:0.6600 0.5971 0.4333\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 105 Step: 9135 Index:-0.2461 R2:0.7097 0.6695 0.5657 RMSE:0.8455 0.8454 0.9518 Tau:0.6623 0.5994 0.4350\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 106 Step: 9222 Index:-0.2620 R2:0.7129 0.6664 0.5633 RMSE:0.8585 0.8670 0.9696 Tau:0.6614 0.6050 0.4237\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 107 Step: 9309 Index:-0.2285 R2:0.7085 0.6672 0.5695 RMSE:0.8290 0.8311 0.9438 Tau:0.6589 0.6026 0.4287\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 108 Step: 9396 Index:-0.2351 R2:0.7134 0.6696 0.5609 RMSE:0.8340 0.8333 0.9495 Tau:0.6654 0.5982 0.4350\n",
      "Epoch: 109 Step: 9483 Index:-0.2252 R2:0.7235 0.6742 0.5714 RMSE:0.8034 0.8304 0.9454 Tau:0.6682 0.6052 0.4337\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 110 Step: 9570 Index:-0.3077 R2:0.7261 0.6756 0.5660 RMSE:0.9169 0.9169 1.0129 Tau:0.6705 0.6092 0.4268\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 111 Step: 9657 Index:-0.2286 R2:0.7255 0.6722 0.5689 RMSE:0.8128 0.8393 0.9485 Tau:0.6687 0.6107 0.4268\n",
      "Epoch: 112 Step: 9744 Index:-0.2099 R2:0.7214 0.6788 0.5685 RMSE:0.8040 0.8180 0.9484 Tau:0.6685 0.6080 0.4329\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 113 Step: 9831 Index:-0.2550 R2:0.7139 0.6627 0.5626 RMSE:0.8364 0.8477 0.9513 Tau:0.6656 0.5927 0.4383\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 114 Step: 9918 Index:-0.2582 R2:0.7256 0.6573 0.5589 RMSE:0.8356 0.8601 0.9584 Tau:0.6663 0.6020 0.4200\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 115 Step: 10005 Index:-0.2119 R2:0.7296 0.6773 0.5706 RMSE:0.8032 0.8186 0.9385 Tau:0.6756 0.6067 0.4326\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 116 Step: 10092 Index:-0.2433 R2:0.7238 0.6750 0.5692 RMSE:0.8335 0.8529 0.9881 Tau:0.6692 0.6095 0.4262\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 117 Step: 10179 Index:-0.2159 R2:0.7266 0.6796 0.5710 RMSE:0.8040 0.8191 0.9409 Tau:0.6737 0.6031 0.4373\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 118 Step: 10266 Index:-0.2604 R2:0.7230 0.6723 0.5529 RMSE:0.8405 0.8593 1.0077 Tau:0.6698 0.5989 0.4292\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 119 Step: 10353 Index:-0.2490 R2:0.7281 0.6700 0.5756 RMSE:0.8272 0.8590 0.9490 Tau:0.6723 0.6100 0.4308\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 120 Step: 10440 Index:-0.2231 R2:0.7289 0.6725 0.5728 RMSE:0.7941 0.8347 0.9484 Tau:0.6704 0.6116 0.4278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 121 Step: 10527 Index:-0.3629 R2:0.7216 0.6646 0.5642 RMSE:0.9579 0.9735 1.0519 Tau:0.6641 0.6106 0.4179\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 122 Step: 10614 Index:-0.2522 R2:0.7309 0.6842 0.5780 RMSE:0.8621 0.8708 0.9685 Tau:0.6714 0.6186 0.4261\n",
      "Epoch: 123 Step: 10701 Index:-0.2076 R2:0.7358 0.6806 0.5737 RMSE:0.7955 0.8184 0.9359 Tau:0.6779 0.6108 0.4360\n",
      "Epoch: 124 Step: 10788 Index:-0.2013 R2:0.7360 0.6842 0.5727 RMSE:0.7984 0.8147 0.9365 Tau:0.6757 0.6133 0.4326\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 125 Step: 10875 Index:-0.2158 R2:0.7311 0.6790 0.5602 RMSE:0.7912 0.8193 0.9556 Tau:0.6767 0.6035 0.4352\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 126 Step: 10962 Index:-0.2369 R2:0.7371 0.6819 0.5756 RMSE:0.8135 0.8444 0.9820 Tau:0.6799 0.6075 0.4364\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 127 Step: 11049 Index:-0.2127 R2:0.7379 0.6849 0.5766 RMSE:0.8009 0.8231 0.9385 Tau:0.6816 0.6104 0.4353\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 128 Step: 11136 Index:-0.3891 R2:0.7270 0.6753 0.5727 RMSE:0.9416 0.9892 1.1283 Tau:0.6715 0.6002 0.4405\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 129 Step: 11223 Index:-0.2097 R2:0.7382 0.6843 0.5677 RMSE:0.7827 0.8183 0.9580 Tau:0.6795 0.6086 0.4330\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 130 Step: 11310 Index:-0.2303 R2:0.7440 0.6870 0.5721 RMSE:0.8184 0.8431 0.9608 Tau:0.6839 0.6127 0.4343\n",
      "Epoch: 131 Step: 11397 Index:-0.1959 R2:0.7365 0.6857 0.5787 RMSE:0.7838 0.8075 0.9343 Tau:0.6795 0.6116 0.4322\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 132 Step: 11484 Index:-0.2915 R2:0.7437 0.6808 0.5839 RMSE:0.8867 0.9036 0.9827 Tau:0.6839 0.6122 0.4346\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 133 Step: 11571 Index:-0.2785 R2:0.7378 0.6745 0.5709 RMSE:0.8307 0.8859 1.0128 Tau:0.6780 0.6074 0.4322\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 134 Step: 11658 Index:-0.2209 R2:0.7473 0.6756 0.5646 RMSE:0.7715 0.8217 0.9471 Tau:0.6852 0.6008 0.4353\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 135 Step: 11745 Index:-0.2113 R2:0.7427 0.6799 0.5664 RMSE:0.7734 0.8188 0.9549 Tau:0.6840 0.6075 0.4359\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 136 Step: 11832 Index:-0.2072 R2:0.7429 0.6771 0.5642 RMSE:0.7798 0.8199 0.9542 Tau:0.6789 0.6127 0.4272\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 137 Step: 11919 Index:-0.2177 R2:0.7476 0.6835 0.5666 RMSE:0.7763 0.8259 0.9712 Tau:0.6847 0.6082 0.4343\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 138 Step: 12006 Index:-0.2512 R2:0.7484 0.6802 0.5663 RMSE:0.8265 0.8568 0.9687 Tau:0.6879 0.6055 0.4368\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 139 Step: 12093 Index:-0.2128 R2:0.7434 0.6865 0.5734 RMSE:0.7937 0.8271 0.9518 Tau:0.6845 0.6143 0.4337\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 140 Step: 12180 Index:-0.2004 R2:0.7480 0.6835 0.5700 RMSE:0.7653 0.8170 0.9596 Tau:0.6849 0.6166 0.4324\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 141 Step: 12267 Index:-0.2122 R2:0.7539 0.6900 0.5694 RMSE:0.7922 0.8296 0.9774 Tau:0.6900 0.6174 0.4304\n",
      "Epoch: 142 Step: 12354 Index:-0.1954 R2:0.7517 0.6867 0.5690 RMSE:0.7598 0.8072 0.9498 Tau:0.6907 0.6118 0.4367\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 143 Step: 12441 Index:-0.2913 R2:0.7440 0.6812 0.5653 RMSE:0.8619 0.8967 1.0057 Tau:0.6872 0.6053 0.4389\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 144 Step: 12528 Index:-0.2153 R2:0.7461 0.6902 0.5663 RMSE:0.8012 0.8250 0.9576 Tau:0.6863 0.6098 0.4339\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 145 Step: 12615 Index:-0.2391 R2:0.7471 0.6735 0.5554 RMSE:0.7983 0.8366 0.9648 Tau:0.6865 0.5975 0.4388\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 146 Step: 12702 Index:-0.2179 R2:0.7455 0.6772 0.5578 RMSE:0.7750 0.8191 0.9583 Tau:0.6877 0.6012 0.4383\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 147 Step: 12789 Index:-0.2361 R2:0.7434 0.6782 0.5588 RMSE:0.7858 0.8434 0.9924 Tau:0.6789 0.6072 0.4338\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 148 Step: 12876 Index:-0.2014 R2:0.7503 0.6866 0.5668 RMSE:0.7653 0.8098 0.9563 Tau:0.6896 0.6084 0.4401\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 149 Step: 12963 Index:-0.2691 R2:0.7514 0.6807 0.5636 RMSE:0.8555 0.8863 0.9960 Tau:0.6857 0.6172 0.4299\n",
      "Epoch: 150 Step: 13050 Index:-0.1905 R2:0.7503 0.6906 0.5649 RMSE:0.7805 0.8097 0.9499 Tau:0.6864 0.6193 0.4325\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 151 Step: 13137 Index:-0.2275 R2:0.7508 0.6812 0.5673 RMSE:0.7746 0.8406 0.9789 Tau:0.6867 0.6131 0.4344\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 152 Step: 13224 Index:-0.1951 R2:0.7588 0.6818 0.5606 RMSE:0.7647 0.8166 0.9501 Tau:0.6889 0.6215 0.4270\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 153 Step: 13311 Index:-0.2045 R2:0.7559 0.6910 0.5789 RMSE:0.7598 0.8161 0.9600 Tau:0.6944 0.6116 0.4408\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 154 Step: 13398 Index:-0.1952 R2:0.7607 0.6878 0.5740 RMSE:0.7452 0.8054 0.9426 Tau:0.6939 0.6102 0.4395\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 155 Step: 13485 Index:-0.2250 R2:0.7507 0.6753 0.5615 RMSE:0.7664 0.8335 0.9597 Tau:0.6831 0.6085 0.4302\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 156 Step: 13572 Index:-0.2063 R2:0.7503 0.6774 0.5633 RMSE:0.7622 0.8217 0.9554 Tau:0.6819 0.6154 0.4227\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 157 Step: 13659 Index:-0.1940 R2:0.7616 0.6915 0.5781 RMSE:0.7570 0.8138 0.9629 Tau:0.6932 0.6198 0.4329\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 158 Step: 13746 Index:-0.2061 R2:0.7631 0.6855 0.5750 RMSE:0.7521 0.8202 0.9455 Tau:0.6945 0.6141 0.4360\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 159 Step: 13833 Index:-0.2354 R2:0.7604 0.6797 0.5611 RMSE:0.7784 0.8483 0.9780 Tau:0.6893 0.6130 0.4273\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 160 Step: 13920 Index:-0.2394 R2:0.7504 0.6836 0.5772 RMSE:0.8018 0.8519 0.9981 Tau:0.6887 0.6125 0.4342\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 161 Step: 14007 Index:-0.2958 R2:0.7328 0.6633 0.5614 RMSE:0.8526 0.8836 0.9788 Tau:0.6758 0.5878 0.4410\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 162 Step: 14094 Index:-0.2331 R2:0.7598 0.6809 0.5782 RMSE:0.7796 0.8466 0.9547 Tau:0.6902 0.6135 0.4311\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 163 Step: 14181 Index:-0.2118 R2:0.7561 0.6809 0.5691 RMSE:0.7522 0.8161 0.9574 Tau:0.6950 0.6043 0.4397\n",
      "Epoch: 164 Step: 14268 Index:-0.1801 R2:0.7657 0.6930 0.5752 RMSE:0.7501 0.8010 0.9349 Tau:0.6981 0.6209 0.4335\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 165 Step: 14355 Index:-0.2253 R2:0.7520 0.6763 0.5682 RMSE:0.7747 0.8260 0.9485 Tau:0.6907 0.6007 0.4432\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 166 Step: 14442 Index:-0.1862 R2:0.7678 0.6912 0.5750 RMSE:0.7363 0.8029 0.9502 Tau:0.7018 0.6167 0.4360\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 167 Step: 14529 Index:-0.2122 R2:0.7568 0.6874 0.5751 RMSE:0.7631 0.8200 0.9581 Tau:0.6954 0.6078 0.4444\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 168 Step: 14616 Index:-0.1984 R2:0.7687 0.6852 0.5700 RMSE:0.7512 0.8135 0.9393 Tau:0.7038 0.6151 0.4352\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 169 Step: 14703 Index:-0.1989 R2:0.7683 0.6934 0.5734 RMSE:0.7582 0.8153 0.9493 Tau:0.7027 0.6164 0.4393\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 170 Step: 14790 Index:-0.1971 R2:0.7696 0.6949 0.5778 RMSE:0.7576 0.8174 0.9487 Tau:0.7028 0.6203 0.4385\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 171 Step: 14877 Index:-0.2421 R2:0.7660 0.6908 0.5729 RMSE:0.7894 0.8562 1.0147 Tau:0.7001 0.6141 0.4420\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 172 Step: 14964 Index:-0.1979 R2:0.7665 0.6886 0.5766 RMSE:0.7400 0.8096 0.9547 Tau:0.7031 0.6117 0.4430\n",
      "Epoch: 173 Step: 15051 Index:-0.1782 R2:0.7702 0.6924 0.5719 RMSE:0.7347 0.7983 0.9430 Tau:0.7017 0.6201 0.4402\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 174 Step: 15138 Index:-0.2213 R2:0.7756 0.6920 0.5718 RMSE:0.7688 0.8364 0.9635 Tau:0.7064 0.6150 0.4367\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 175 Step: 15225 Index:-0.1938 R2:0.7630 0.6843 0.5614 RMSE:0.7465 0.8100 0.9541 Tau:0.6939 0.6162 0.4247\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 176 Step: 15312 Index:-0.1893 R2:0.7734 0.6913 0.5771 RMSE:0.7355 0.8157 0.9577 Tau:0.7011 0.6263 0.4312\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 177 Step: 15399 Index:-0.2168 R2:0.7753 0.6832 0.5627 RMSE:0.7562 0.8317 0.9597 Tau:0.7041 0.6149 0.4256\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 178 Step: 15486 Index:-0.1880 R2:0.7766 0.6944 0.5751 RMSE:0.7500 0.8185 0.9504 Tau:0.7054 0.6305 0.4283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179 Step: 15573 Index:-0.1686 R2:0.7816 0.6961 0.5804 RMSE:0.7166 0.7937 0.9360 Tau:0.7089 0.6251 0.4337\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 180 Step: 15660 Index:-0.2082 R2:0.7580 0.6842 0.5703 RMSE:0.7609 0.8179 0.9497 Tau:0.6977 0.6096 0.4347\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 182 Step: 15834 Index:-0.2101 R2:0.7765 0.6835 0.5637 RMSE:0.7249 0.8191 0.9753 Tau:0.7038 0.6090 0.4359\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 183 Step: 15921 Index:-0.1938 R2:0.7818 0.6921 0.5780 RMSE:0.7181 0.8077 0.9556 Tau:0.7082 0.6139 0.4372\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 184 Step: 16008 Index:-0.1895 R2:0.7744 0.6916 0.5756 RMSE:0.7274 0.8055 0.9440 Tau:0.7084 0.6159 0.4409\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 185 Step: 16095 Index:-0.1831 R2:0.7814 0.6934 0.5810 RMSE:0.7227 0.8029 0.9326 Tau:0.7119 0.6198 0.4397\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 186 Step: 16182 Index:-0.2063 R2:0.7530 0.6851 0.5765 RMSE:0.7602 0.8149 0.9564 Tau:0.6896 0.6086 0.4327\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 187 Step: 16269 Index:-0.2132 R2:0.7608 0.6956 0.5802 RMSE:0.7869 0.8261 0.9528 Tau:0.6959 0.6128 0.4312\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 188 Step: 16356 Index:-0.2501 R2:0.7572 0.6847 0.5675 RMSE:0.8222 0.8556 0.9796 Tau:0.6911 0.6055 0.4377\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 189 Step: 16443 Index:-0.2314 R2:0.7734 0.6916 0.5771 RMSE:0.7670 0.8495 1.0063 Tau:0.7019 0.6181 0.4370\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 190 Step: 16530 Index:-0.2387 R2:0.7742 0.6862 0.5725 RMSE:0.7848 0.8588 0.9827 Tau:0.7014 0.6201 0.4265\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 191 Step: 16617 Index:-0.2305 R2:0.7779 0.6871 0.5814 RMSE:0.7629 0.8415 0.9546 Tau:0.7061 0.6110 0.4381\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 192 Step: 16704 Index:-0.1896 R2:0.7801 0.6940 0.5748 RMSE:0.7221 0.8062 0.9592 Tau:0.7086 0.6166 0.4393\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 193 Step: 16791 Index:-0.2154 R2:0.7789 0.6941 0.5795 RMSE:0.7543 0.8335 0.9680 Tau:0.7089 0.6181 0.4363\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 194 Step: 16878 Index:-0.2533 R2:0.7731 0.6776 0.5762 RMSE:0.7854 0.8710 0.9739 Tau:0.7044 0.6177 0.4342\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 195 Step: 16965 Index:-0.1851 R2:0.7790 0.6940 0.5830 RMSE:0.7182 0.8037 0.9477 Tau:0.7097 0.6186 0.4397\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 196 Step: 17052 Index:-0.2244 R2:0.7843 0.6913 0.5732 RMSE:0.7597 0.8451 1.0003 Tau:0.7109 0.6207 0.4360\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 197 Step: 17139 Index:-0.2084 R2:0.7772 0.6907 0.5766 RMSE:0.7509 0.8281 0.9809 Tau:0.7098 0.6197 0.4391\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 198 Step: 17226 Index:-0.1779 R2:0.7857 0.6931 0.5842 RMSE:0.7112 0.8006 0.9400 Tau:0.7129 0.6227 0.4371\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 199 Step: 17313 Index:-0.1753 R2:0.7864 0.6955 0.5904 RMSE:0.7090 0.7991 0.9387 Tau:0.7158 0.6238 0.4360\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 200 Step: 17400 Index:-0.2253 R2:0.7846 0.6918 0.5871 RMSE:0.7541 0.8446 0.9981 Tau:0.7125 0.6194 0.4400\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 201 Step: 17487 Index:-0.1841 R2:0.7896 0.6896 0.5814 RMSE:0.7050 0.8081 0.9532 Tau:0.7140 0.6239 0.4318\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 202 Step: 17574 Index:-0.1799 R2:0.7882 0.6903 0.5810 RMSE:0.7028 0.8016 0.9381 Tau:0.7143 0.6218 0.4339\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 203 Step: 17661 Index:-0.1772 R2:0.7911 0.6993 0.5792 RMSE:0.7140 0.8040 0.9432 Tau:0.7149 0.6268 0.4388\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 204 Step: 17748 Index:-0.2144 R2:0.7885 0.6950 0.5942 RMSE:0.7407 0.8364 0.9501 Tau:0.7167 0.6220 0.4399\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 205 Step: 17835 Index:-0.2097 R2:0.7911 0.6877 0.5922 RMSE:0.7248 0.8325 0.9435 Tau:0.7156 0.6228 0.4320\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 206 Step: 17922 Index:-0.2896 R2:0.7889 0.6789 0.5720 RMSE:0.8064 0.9028 1.0050 Tau:0.7123 0.6132 0.4355\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 207 Step: 18009 Index:-0.1998 R2:0.7919 0.6925 0.5819 RMSE:0.7113 0.8181 0.9759 Tau:0.7170 0.6183 0.4398\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 208 Step: 18096 Index:-0.1729 R2:0.7948 0.6936 0.5900 RMSE:0.6920 0.7966 0.9290 Tau:0.7219 0.6237 0.4416\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 209 Step: 18183 Index:-0.1948 R2:0.7903 0.6885 0.5842 RMSE:0.7070 0.8085 0.9424 Tau:0.7174 0.6136 0.4387\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 210 Step: 18270 Index:-0.1971 R2:0.7947 0.6883 0.5891 RMSE:0.7102 0.8152 0.9291 Tau:0.7209 0.6181 0.4379\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 211 Step: 18357 Index:-0.2114 R2:0.7883 0.6816 0.5767 RMSE:0.7034 0.8224 0.9571 Tau:0.7173 0.6110 0.4429\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 212 Step: 18444 Index:-0.2422 R2:0.7957 0.6879 0.5857 RMSE:0.7599 0.8604 1.0023 Tau:0.7245 0.6182 0.4428\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 213 Step: 18531 Index:-0.2255 R2:0.7974 0.6978 0.5909 RMSE:0.7457 0.8489 1.0129 Tau:0.7219 0.6234 0.4397\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 214 Step: 18618 Index:-0.1750 R2:0.7998 0.6926 0.5831 RMSE:0.6818 0.7992 0.9393 Tau:0.7224 0.6242 0.4381\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 215 Step: 18705 Index:-0.1993 R2:0.7918 0.6906 0.5830 RMSE:0.7026 0.8165 0.9636 Tau:0.7172 0.6172 0.4402\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 216 Step: 18792 Index:-0.1943 R2:0.7970 0.6917 0.5815 RMSE:0.6939 0.8134 0.9725 Tau:0.7231 0.6191 0.4419\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 217 Step: 18879 Index:-0.2352 R2:0.7910 0.6634 0.5813 RMSE:0.7054 0.8353 0.9333 Tau:0.7179 0.6000 0.4345\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 218 Step: 18966 Index:-0.2215 R2:0.7985 0.6861 0.5811 RMSE:0.7269 0.8378 0.9859 Tau:0.7222 0.6163 0.4366\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 219 Step: 19053 Index:-0.2327 R2:0.8065 0.6911 0.5860 RMSE:0.7380 0.8583 0.9561 Tau:0.7280 0.6257 0.4390\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 220 Step: 19140 Index:-0.2000 R2:0.7962 0.6915 0.5735 RMSE:0.7203 0.8246 0.9550 Tau:0.7236 0.6246 0.4444\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 221 Step: 19227 Index:-0.1922 R2:0.8064 0.6998 0.5928 RMSE:0.7185 0.8256 0.9337 Tau:0.7276 0.6334 0.4361\n",
      "Epoch: 222 Step: 19314 Index:-0.1532 R2:0.8005 0.7073 0.5954 RMSE:0.6825 0.7824 0.9353 Tau:0.7241 0.6292 0.4414\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 223 Step: 19401 Index:-0.2077 R2:0.7949 0.6932 0.5828 RMSE:0.7286 0.8316 1.0022 Tau:0.7194 0.6238 0.4357\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 224 Step: 19488 Index:-0.1807 R2:0.8037 0.7014 0.5998 RMSE:0.6969 0.8147 0.9322 Tau:0.7244 0.6340 0.4376\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 225 Step: 19575 Index:-0.2152 R2:0.7948 0.6819 0.5518 RMSE:0.7266 0.8337 0.9811 Tau:0.7179 0.6185 0.4355\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 226 Step: 19662 Index:-0.1956 R2:0.8031 0.6940 0.5833 RMSE:0.7018 0.8183 0.9827 Tau:0.7282 0.6227 0.4453\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 227 Step: 19749 Index:-0.1763 R2:0.8031 0.6937 0.5800 RMSE:0.6779 0.8020 0.9582 Tau:0.7267 0.6258 0.4390\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 228 Step: 19836 Index:-0.1790 R2:0.8045 0.6913 0.5971 RMSE:0.6759 0.8079 0.9307 Tau:0.7300 0.6289 0.4387\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 229 Step: 19923 Index:-0.1708 R2:0.8033 0.6957 0.5859 RMSE:0.6784 0.7936 0.9320 Tau:0.7306 0.6228 0.4426\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 230 Step: 20010 Index:-0.1742 R2:0.8084 0.6965 0.5793 RMSE:0.6873 0.8057 0.9697 Tau:0.7292 0.6315 0.4396\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 231 Step: 20097 Index:-0.1823 R2:0.8050 0.6913 0.5947 RMSE:0.6781 0.8016 0.9329 Tau:0.7304 0.6194 0.4409\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 232 Step: 20184 Index:-0.1707 R2:0.8066 0.7010 0.5902 RMSE:0.6772 0.7985 0.9453 Tau:0.7301 0.6278 0.4399\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 233 Step: 20271 Index:-0.1687 R2:0.8110 0.6967 0.5872 RMSE:0.6655 0.7991 0.9515 Tau:0.7318 0.6303 0.4408\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 234 Step: 20358 Index:-0.1945 R2:0.8034 0.6946 0.5815 RMSE:0.6868 0.8173 0.9774 Tau:0.7298 0.6228 0.4440\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 235 Step: 20445 Index:-0.1665 R2:0.8082 0.6946 0.5814 RMSE:0.6717 0.7953 0.9391 Tau:0.7311 0.6287 0.4367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 236 Step: 20532 Index:-0.2317 R2:0.8097 0.6859 0.5788 RMSE:0.7183 0.8507 0.9595 Tau:0.7324 0.6190 0.4437\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 237 Step: 20619 Index:-0.1822 R2:0.8147 0.6946 0.5932 RMSE:0.6737 0.8120 0.9300 Tau:0.7352 0.6298 0.4392\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 238 Step: 20706 Index:-0.1652 R2:0.8131 0.6970 0.5871 RMSE:0.6644 0.7963 0.9530 Tau:0.7350 0.6310 0.4417\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 239 Step: 20793 Index:-0.1961 R2:0.8130 0.7009 0.5847 RMSE:0.6988 0.8280 1.0061 Tau:0.7316 0.6319 0.4404\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 240 Step: 20880 Index:-0.1768 R2:0.8135 0.6964 0.5956 RMSE:0.6723 0.8044 0.9238 Tau:0.7384 0.6276 0.4458\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 241 Step: 20967 Index:-0.1964 R2:0.8162 0.6941 0.5894 RMSE:0.6957 0.8293 0.9401 Tau:0.7352 0.6329 0.4417\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 242 Step: 21054 Index:-0.1628 R2:0.8136 0.7018 0.5887 RMSE:0.6638 0.7971 0.9591 Tau:0.7356 0.6342 0.4421\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 243 Step: 21141 Index:-0.1789 R2:0.8225 0.6971 0.5851 RMSE:0.6641 0.8123 0.9444 Tau:0.7395 0.6334 0.4381\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 244 Step: 21228 Index:-0.2698 R2:0.8125 0.6844 0.5788 RMSE:0.7699 0.8888 0.9796 Tau:0.7324 0.6190 0.4362\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 245 Step: 21315 Index:-0.1805 R2:0.8184 0.6912 0.5819 RMSE:0.6531 0.8043 0.9410 Tau:0.7399 0.6238 0.4415\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 246 Step: 21402 Index:-0.2004 R2:0.8163 0.6890 0.5906 RMSE:0.6729 0.8199 0.9319 Tau:0.7353 0.6195 0.4440\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 247 Step: 21489 Index:-0.1846 R2:0.8182 0.6876 0.5952 RMSE:0.6549 0.8054 0.9213 Tau:0.7414 0.6207 0.4433\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 248 Step: 21576 Index:-0.2134 R2:0.8189 0.6881 0.5884 RMSE:0.6842 0.8370 0.9984 Tau:0.7390 0.6236 0.4463\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 249 Step: 21663 Index:-0.2553 R2:0.8162 0.6973 0.5998 RMSE:0.7476 0.8856 0.9872 Tau:0.7399 0.6303 0.4391\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 250 Step: 21750 Index:-0.1686 R2:0.8172 0.6974 0.5851 RMSE:0.6570 0.8004 0.9581 Tau:0.7348 0.6318 0.4410\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 251 Step: 21837 Index:-0.2437 R2:0.8199 0.6938 0.5852 RMSE:0.7344 0.8656 0.9653 Tau:0.7410 0.6219 0.4412\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 252 Step: 21924 Index:-0.1699 R2:0.8217 0.7028 0.5926 RMSE:0.6560 0.8052 0.9661 Tau:0.7414 0.6353 0.4429\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 253 Step: 22011 Index:-0.1716 R2:0.8209 0.6905 0.5923 RMSE:0.6466 0.8019 0.9256 Tau:0.7391 0.6303 0.4337\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 254 Step: 22098 Index:-0.2287 R2:0.8125 0.6855 0.5944 RMSE:0.7082 0.8464 0.9514 Tau:0.7360 0.6178 0.4460\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 255 Step: 22185 Index:-0.2006 R2:0.8144 0.6830 0.5861 RMSE:0.6585 0.8146 0.9504 Tau:0.7365 0.6140 0.4479\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 256 Step: 22272 Index:-0.1829 R2:0.8213 0.6971 0.5911 RMSE:0.6680 0.8144 0.9767 Tau:0.7369 0.6316 0.4413\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 257 Step: 22359 Index:-0.1722 R2:0.8266 0.6947 0.5823 RMSE:0.6388 0.8031 0.9472 Tau:0.7417 0.6309 0.4422\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 258 Step: 22446 Index:-0.1904 R2:0.8081 0.6885 0.5944 RMSE:0.6699 0.8064 0.9360 Tau:0.7295 0.6161 0.4438\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 259 Step: 22533 Index:-0.1889 R2:0.8242 0.6914 0.5874 RMSE:0.6421 0.8118 0.9452 Tau:0.7428 0.6229 0.4423\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 260 Step: 22620 Index:-0.2085 R2:0.8144 0.6900 0.5926 RMSE:0.6796 0.8309 0.9767 Tau:0.7372 0.6223 0.4496\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 261 Step: 22707 Index:-0.1923 R2:0.8224 0.6932 0.6013 RMSE:0.6677 0.8182 0.9621 Tau:0.7417 0.6259 0.4453\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 262 Step: 22794 Index:-0.1929 R2:0.8269 0.6878 0.5892 RMSE:0.6402 0.8174 0.9415 Tau:0.7426 0.6245 0.4451\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 263 Step: 22881 Index:-0.2146 R2:0.8254 0.6744 0.5753 RMSE:0.6579 0.8310 0.9464 Tau:0.7449 0.6164 0.4442\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 264 Step: 22968 Index:-0.1905 R2:0.8282 0.6967 0.6008 RMSE:0.6490 0.8179 0.9689 Tau:0.7441 0.6274 0.4434\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 265 Step: 23055 Index:-0.3294 R2:0.7868 0.6550 0.5741 RMSE:0.7797 0.9245 1.0034 Tau:0.7123 0.5951 0.4414\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 266 Step: 23142 Index:-0.1813 R2:0.8208 0.6957 0.5924 RMSE:0.6594 0.8091 0.9355 Tau:0.7422 0.6278 0.4436\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 267 Step: 23229 Index:-0.1820 R2:0.8320 0.6906 0.5968 RMSE:0.6275 0.8071 0.9430 Tau:0.7495 0.6251 0.4432\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 268 Step: 23316 Index:-0.2148 R2:0.8243 0.6827 0.5898 RMSE:0.6571 0.8309 0.9515 Tau:0.7431 0.6162 0.4462\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 269 Step: 23403 Index:-0.2001 R2:0.8320 0.6871 0.5873 RMSE:0.6320 0.8264 0.9613 Tau:0.7483 0.6263 0.4395\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 270 Step: 23490 Index:-0.1796 R2:0.8315 0.6906 0.5899 RMSE:0.6344 0.8055 0.9464 Tau:0.7492 0.6259 0.4406\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 271 Step: 23577 Index:-0.1744 R2:0.8317 0.6913 0.5824 RMSE:0.6258 0.8086 0.9554 Tau:0.7451 0.6341 0.4349\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 272 Step: 23664 Index:-0.1867 R2:0.8312 0.6937 0.5880 RMSE:0.6439 0.8119 0.9584 Tau:0.7496 0.6252 0.4402\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 273 Step: 23751 Index:-0.1994 R2:0.8309 0.6852 0.5819 RMSE:0.6280 0.8197 0.9675 Tau:0.7497 0.6203 0.4424\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 274 Step: 23838 Index:-0.2098 R2:0.8245 0.6798 0.5769 RMSE:0.6440 0.8326 0.9780 Tau:0.7408 0.6228 0.4459\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 275 Step: 23925 Index:-0.2036 R2:0.8342 0.6815 0.5880 RMSE:0.6535 0.8269 0.9290 Tau:0.7510 0.6233 0.4354\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 276 Step: 24012 Index:-0.2441 R2:0.8271 0.6865 0.5948 RMSE:0.6840 0.8680 0.9823 Tau:0.7465 0.6239 0.4483\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 277 Step: 24099 Index:-0.3377 R2:0.8339 0.6694 0.5825 RMSE:0.8000 0.9544 1.0156 Tau:0.7502 0.6167 0.4301\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 278 Step: 24186 Index:-0.1966 R2:0.8198 0.6868 0.5952 RMSE:0.6488 0.8152 0.9462 Tau:0.7424 0.6186 0.4431\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 279 Step: 24273 Index:-0.1976 R2:0.8374 0.6836 0.5897 RMSE:0.6308 0.8213 0.9542 Tau:0.7536 0.6237 0.4397\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 280 Step: 24360 Index:-0.2512 R2:0.8288 0.6725 0.5904 RMSE:0.6805 0.8629 0.9535 Tau:0.7500 0.6117 0.4463\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 281 Step: 24447 Index:-0.1838 R2:0.8287 0.6932 0.5904 RMSE:0.6317 0.8110 0.9503 Tau:0.7455 0.6271 0.4420\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 282 Step: 24534 Index:-0.2150 R2:0.8265 0.6787 0.5916 RMSE:0.6439 0.8352 0.9380 Tau:0.7445 0.6202 0.4429\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 283 Step: 24621 Index:-0.1644 R2:0.8343 0.6967 0.6003 RMSE:0.6235 0.7964 0.9246 Tau:0.7521 0.6319 0.4441\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 284 Step: 24708 Index:-0.2072 R2:0.8289 0.6998 0.5857 RMSE:0.6768 0.8395 1.0109 Tau:0.7444 0.6323 0.4463\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 285 Step: 24795 Index:-0.1862 R2:0.8373 0.6911 0.5865 RMSE:0.6207 0.8104 0.9613 Tau:0.7545 0.6242 0.4460\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 286 Step: 24882 Index:-0.1912 R2:0.8334 0.6850 0.5906 RMSE:0.6249 0.8181 0.9544 Tau:0.7507 0.6269 0.4451\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 287 Step: 24969 Index:-0.1755 R2:0.8414 0.6960 0.5896 RMSE:0.6139 0.8068 0.9452 Tau:0.7545 0.6314 0.4434\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 288 Step: 25056 Index:-0.1847 R2:0.8357 0.6933 0.5976 RMSE:0.6228 0.8174 0.9478 Tau:0.7505 0.6326 0.4422\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 289 Step: 25143 Index:-0.2290 R2:0.8387 0.6888 0.5904 RMSE:0.6576 0.8563 0.9672 Tau:0.7519 0.6273 0.4406\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 290 Step: 25230 Index:-0.2168 R2:0.8383 0.6819 0.5793 RMSE:0.6477 0.8363 0.9469 Tau:0.7535 0.6195 0.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 291 Step: 25317 Index:-0.1895 R2:0.8428 0.6855 0.5858 RMSE:0.6070 0.8164 0.9488 Tau:0.7545 0.6269 0.4379\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 292 Step: 25404 Index:-0.1664 R2:0.8381 0.7041 0.5930 RMSE:0.6180 0.7981 0.9569 Tau:0.7518 0.6317 0.4429\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 293 Step: 25491 Index:-0.1909 R2:0.8429 0.6869 0.5865 RMSE:0.6084 0.8169 0.9588 Tau:0.7548 0.6260 0.4440\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 294 Step: 25578 Index:-0.1961 R2:0.8432 0.6960 0.5927 RMSE:0.6281 0.8284 0.9531 Tau:0.7571 0.6323 0.4481\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 295 Step: 25665 Index:-0.1856 R2:0.8408 0.6915 0.5960 RMSE:0.6122 0.8153 0.9512 Tau:0.7554 0.6298 0.4464\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 296 Step: 25752 Index:-0.2137 R2:0.8353 0.6809 0.5616 RMSE:0.6459 0.8358 1.0011 Tau:0.7494 0.6221 0.4366\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 297 Step: 25839 Index:-0.2275 R2:0.8348 0.6628 0.5690 RMSE:0.6198 0.8386 0.9670 Tau:0.7495 0.6111 0.4368\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 298 Step: 25926 Index:-0.2287 R2:0.8416 0.6729 0.5694 RMSE:0.6448 0.8416 0.9538 Tau:0.7588 0.6128 0.4422\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 299 Step: 26013 Index:-0.1979 R2:0.8453 0.6911 0.5867 RMSE:0.6065 0.8253 0.9733 Tau:0.7596 0.6274 0.4443\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 300 Step: 26100 Index:-0.1859 R2:0.8395 0.6895 0.5883 RMSE:0.6137 0.8124 0.9408 Tau:0.7587 0.6265 0.4493\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 301 Step: 26187 Index:-0.1858 R2:0.8504 0.6823 0.5798 RMSE:0.5976 0.8121 0.9424 Tau:0.7606 0.6263 0.4396\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 302 Step: 26274 Index:-0.1810 R2:0.8444 0.6896 0.5834 RMSE:0.6107 0.8082 0.9547 Tau:0.7585 0.6271 0.4483\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 303 Step: 26361 Index:-0.1903 R2:0.8414 0.6916 0.5846 RMSE:0.6151 0.8116 0.9670 Tau:0.7594 0.6213 0.4473\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 304 Step: 26448 Index:-0.2068 R2:0.8448 0.6955 0.5879 RMSE:0.6431 0.8390 1.0079 Tau:0.7572 0.6323 0.4497\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 305 Step: 26535 Index:-0.1964 R2:0.8462 0.6921 0.5860 RMSE:0.6222 0.8226 0.9540 Tau:0.7582 0.6262 0.4413\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 306 Step: 26622 Index:-0.2270 R2:0.8523 0.6797 0.5778 RMSE:0.6433 0.8499 1.0093 Tau:0.7638 0.6229 0.4434\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 307 Step: 26709 Index:-0.2106 R2:0.8443 0.6785 0.5781 RMSE:0.6146 0.8287 0.9475 Tau:0.7605 0.6181 0.4496\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 308 Step: 26796 Index:-0.1930 R2:0.8495 0.6929 0.5963 RMSE:0.5990 0.8211 0.9520 Tau:0.7624 0.6281 0.4441\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 309 Step: 26883 Index:-0.1898 R2:0.8519 0.6850 0.5849 RMSE:0.5885 0.8097 0.9454 Tau:0.7666 0.6198 0.4445\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 310 Step: 26970 Index:-0.2014 R2:0.8334 0.6865 0.5893 RMSE:0.6223 0.8204 0.9548 Tau:0.7487 0.6190 0.4447\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 311 Step: 27057 Index:-0.2094 R2:0.8433 0.6883 0.5992 RMSE:0.6317 0.8361 0.9365 Tau:0.7582 0.6267 0.4461\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 312 Step: 27144 Index:-0.1990 R2:0.8461 0.6915 0.5984 RMSE:0.6120 0.8267 0.9500 Tau:0.7588 0.6277 0.4457\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 313 Step: 27231 Index:-0.2861 R2:0.8271 0.6753 0.5651 RMSE:0.7369 0.9008 1.0787 Tau:0.7402 0.6147 0.4470\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 314 Step: 27318 Index:-0.1866 R2:0.8506 0.6897 0.5851 RMSE:0.5949 0.8118 0.9673 Tau:0.7632 0.6252 0.4415\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 315 Step: 27405 Index:-0.1900 R2:0.8489 0.6855 0.5780 RMSE:0.5942 0.8108 0.9616 Tau:0.7645 0.6209 0.4448\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 316 Step: 27492 Index:-0.2041 R2:0.8383 0.6875 0.5932 RMSE:0.6216 0.8294 0.9662 Tau:0.7574 0.6253 0.4477\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 317 Step: 27579 Index:-0.2644 R2:0.8362 0.6814 0.5938 RMSE:0.6827 0.8773 0.9689 Tau:0.7602 0.6128 0.4472\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 318 Step: 27666 Index:-0.1941 R2:0.8514 0.6857 0.5834 RMSE:0.5925 0.8180 0.9457 Tau:0.7650 0.6239 0.4413\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 319 Step: 27753 Index:-0.1859 R2:0.8527 0.6928 0.5951 RMSE:0.5849 0.8073 0.9424 Tau:0.7689 0.6214 0.4468\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 320 Step: 27840 Index:-0.1957 R2:0.8538 0.6873 0.5890 RMSE:0.5851 0.8213 0.9586 Tau:0.7663 0.6257 0.4462\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 321 Step: 27927 Index:-0.1840 R2:0.8544 0.6881 0.5892 RMSE:0.5832 0.8111 0.9572 Tau:0.7686 0.6271 0.4490\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 322 Step: 28014 Index:-0.2149 R2:0.8510 0.6872 0.5883 RMSE:0.6166 0.8380 1.0039 Tau:0.7636 0.6231 0.4445\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau \n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 322 r2:0.5954 RMSE:0.9353 WTI:0.3538 AP:0.6317 Tau:0.4414 \n",
      " \n",
      " Top-1:0.0000 Top-1-fp:0.8750 \n",
      " Top-5:0.3488 Top-5-fp:0.5116 \n",
      " Top-10:0.5172 Top-10-fp:0.3793 \n",
      " Top-15:0.5615 Top-15-fp:0.3462 \n",
      " Top-20:0.6897 Top-20-fp:0.3046 \n",
      " Top-25:0.6905 Top-25-fp:0.3318 \n",
      " Top-30:0.7619 Top-30-fp:0.3870 \n",
      " Top-40:0.8619 Top-40-fp:0.4799 \n",
      " Top-50:0.9000 Top-50-fp:0.5655 \n",
      " \n",
      " Top50:0.3600 Top50-fp:0.4800 \n",
      " Top100:0.5200 Top100-fp:0.3900 \n",
      " Top150:0.6267 Top150-fp:0.3333 \n",
      " Top200:0.6800 Top200-fp:0.3200 \n",
      " Top250:0.7476 Top250-fp:0.3720 \n",
      " Top300:0.8143 Top300-fp:0.4300 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
