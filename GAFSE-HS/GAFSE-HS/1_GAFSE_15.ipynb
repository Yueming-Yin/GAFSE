{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki_P61169_0.3333333333333333_150\n",
      "model_file/1_GAFSE_Ki_P61169_0.3333333333333333_150_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/Ki_P61169_0.3333333333333333_150_train.csv\"\n",
    "test_filename = \"./data/benchmark/Ki_P61169_0.3333333333333333_150_test.csv\"\n",
    "test_active = 150\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0       CN(C1CCCCC1N2CCCC2)C(=O)CC3=CC4=CC=CC=C4C=C3 -3.866405\n",
      "1                    CCCNC1CC2=C3C(=CC=C2)NC(=O)N3C1 -3.015779\n",
      "2   COC1=CC=CC=C1C2=CC=C(N2)CN3CCN(CC3)C4=CC=CC=C4OC -0.812913\n",
      "3  C1CN(CCC1C2=NOC3=C2C=CC(=C3)F)CCCCOC4=NN(C(=O)... -1.428944\n",
      "4        COC1=CC=CC=C1NCC2CCN(CC2)CC3COC4=CC=CC=C4O3 -1.838849\n",
      "number of all smiles:  780\n",
      "number of successfully processed smiles:  780\n",
      "                                              smiles     value  \\\n",
      "0       CN(C1CCCCC1N2CCCC2)C(=O)CC3=CC4=CC=CC=C4C=C3 -3.866405   \n",
      "1                    CCCNC1CC2=C3C(=CC=C2)NC(=O)N3C1 -3.015779   \n",
      "2   COC1=CC=CC=C1C2=CC=C(N2)CN3CCN(CC3)C4=CC=CC=C4OC -0.812913   \n",
      "3  C1CN(CCC1C2=NOC3=C2C=CC(=C3)F)CCCCOC4=NN(C(=O)... -1.428944   \n",
      "4        COC1=CC=CC=C1NCC2CCN(CC2)CC3COC4=CC=CC=C4O3 -1.838849   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0            CN(C(=O)Cc1ccc2ccccc2c1)C1CCCCC1N1CCCC1  \n",
      "1                    CCCNC1Cc2cccc3[nH]c(=O)n(c23)C1  \n",
      "2       COc1ccccc1-c1ccc(CN2CCN(c3ccccc3OC)CC2)[nH]1  \n",
      "3  O=c1ccc(OCCCCN2CCC(c3noc4cc(F)ccc34)CC2)nn1-c1...  \n",
      "4              COc1ccccc1NCC1CCN(CC2COc3ccccc3O2)CC1  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  814\n",
      "number of successfully processed smiles:  814\n",
      "(814, 3)\n",
      "                                              smiles     value  \\\n",
      "0  C1CN(CC2=C1NC3=C2C=C(C=C3)F)CCC4=NC5=CC=CC=C5C... -2.267172   \n",
      "1   COC1=C(C(=CC(=C1)Br)C(=O)NCCN2CCC3=CC=CC=C3C2)OC -2.633317   \n",
      "2  C1CN(CCC1O)CCCCOC2=CC=CC3=C2C(=O)C=C(O3)C4=CC=... -3.977724   \n",
      "3          CCCC1=CC2=C(S1)CNC3C2C4=CC(=C(C=C4CC3)O)O -3.146128   \n",
      "4  CN1CCC2=CC(=CC3=C2C1CC4=C3C(=CC=C4)O)C5=CC=C(C... -0.579784   \n",
      "\n",
      "                                      cano_smiles  \n",
      "0  Cl.Fc1ccc2[nH]c3c(c2c1)CN(CCc1ccc2ccccc2n1)CC3  \n",
      "1        COc1cc(Br)cc(C(=O)NCCN2CCc3ccccc3C2)c1OC  \n",
      "2   O=c1cc(-c2ccccc2)oc2cccc(OCCCCN3CCC(O)CC3)c12  \n",
      "3            CCCc1cc2c(s1)CNC1CCc3cc(O)c(O)cc3C21  \n",
      "4    CN1CCc2cc(-c3ccc(O)cc3)cc3c2C1Cc1cccc(O)c1-3  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/Ki_P61169_0.3333333333333333_150_train.pickle\n",
      "./data/benchmark/Ki_P61169_0.3333333333333333_150_train\n",
      "1594\n",
      "feature dicts file saved as ./data/benchmark/Ki_P61169_0.3333333333333333_150_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624, 3) (156, 3) (814, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_Ki_P61169_0.3333333333333333_150_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 81 Index:-1.0893 R2:0.0101 0.0002 0.0099 RMSE:1.1465 1.1110 1.1287 Tau:-0.0326 0.0218 -0.1084\n",
      "Epoch: 2 Step: 162 Index:-1.0202 R2:0.0255 0.0082 0.0035 RMSE:1.1210 1.1146 1.0946 Tau:0.1071 0.0944 0.0665\n",
      "Epoch: 3 Step: 243 Index:-0.9840 R2:0.0465 0.0139 0.0167 RMSE:1.1074 1.1008 1.1045 Tau:0.1463 0.1167 0.0895\n",
      "Epoch: 4 Step: 324 Index:-0.9562 R2:0.0635 0.0301 0.0230 RMSE:1.1079 1.1084 1.0857 Tau:0.1651 0.1522 0.0803\n",
      "Epoch: 5 Step: 405 Index:-0.9386 R2:0.0722 0.0505 0.0333 RMSE:1.1151 1.1104 1.0856 Tau:0.1735 0.1718 0.0817\n",
      "Epoch: 6 Step: 486 Index:-0.9164 R2:0.0850 0.0496 0.0397 RMSE:1.0952 1.0966 1.0764 Tau:0.1898 0.1801 0.0878\n",
      "Epoch: 7 Step: 567 Index:-0.9152 R2:0.0895 0.0515 0.0408 RMSE:1.0961 1.0970 1.0763 Tau:0.1968 0.1818 0.0905\n",
      "Epoch: 8 Step: 648 Index:-0.8762 R2:0.1041 0.0591 0.0482 RMSE:1.0679 1.0714 1.0716 Tau:0.2143 0.1952 0.0866\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 729 Index:-0.8774 R2:0.1149 0.0858 0.0569 RMSE:1.0961 1.0930 1.0740 Tau:0.2301 0.2155 0.0879\n",
      "Epoch: 10 Step: 810 Index:-0.8533 R2:0.1274 0.0867 0.0580 RMSE:1.0735 1.0766 1.0674 Tau:0.2423 0.2233 0.0871\n",
      "Epoch: 11 Step: 891 Index:-0.8473 R2:0.1407 0.1003 0.0686 RMSE:1.0859 1.0884 1.0710 Tau:0.2568 0.2410 0.0942\n",
      "Epoch: 12 Step: 972 Index:-0.8021 R2:0.1532 0.1060 0.0716 RMSE:1.0460 1.0497 1.0776 Tau:0.2690 0.2476 0.0968\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 13 Step: 1053 Index:-0.8409 R2:0.1546 0.1211 0.0701 RMSE:1.0983 1.0970 1.0810 Tau:0.2776 0.2561 0.0904\n",
      "Epoch: 14 Step: 1134 Index:-0.7874 R2:0.1686 0.1169 0.0745 RMSE:1.0393 1.0448 1.0529 Tau:0.2857 0.2574 0.1027\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 15 Step: 1215 Index:-0.8057 R2:0.1744 0.1387 0.0792 RMSE:1.0730 1.0710 1.0663 Tau:0.2924 0.2653 0.1099\n",
      "Epoch: 16 Step: 1296 Index:-0.7632 R2:0.1858 0.1352 0.0814 RMSE:1.0242 1.0302 1.0515 Tau:0.2984 0.2670 0.1049\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 17 Step: 1377 Index:-0.8308 R2:0.1824 0.1186 0.0830 RMSE:1.0711 1.0867 1.1344 Tau:0.2916 0.2559 0.1171\n",
      "Epoch: 18 Step: 1458 Index:-0.7537 R2:0.1987 0.1421 0.0902 RMSE:1.0201 1.0306 1.0449 Tau:0.3117 0.2769 0.1188\n",
      "Epoch: 19 Step: 1539 Index:-0.7259 R2:0.2128 0.1607 0.1022 RMSE:1.0103 1.0177 1.0377 Tau:0.3211 0.2918 0.1217\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 20 Step: 1620 Index:-0.7339 R2:0.2159 0.1587 0.1013 RMSE:1.0069 1.0203 1.0620 Tau:0.3251 0.2864 0.1202\n",
      "Epoch: 21 Step: 1701 Index:-0.7058 R2:0.2331 0.1802 0.1236 RMSE:1.0056 1.0130 1.0251 Tau:0.3396 0.3072 0.1364\n",
      "Epoch: 22 Step: 1782 Index:-0.6996 R2:0.2455 0.1944 0.1291 RMSE:1.0111 1.0169 1.0266 Tau:0.3477 0.3173 0.1419\n",
      "Epoch: 23 Step: 1863 Index:-0.6786 R2:0.2539 0.1951 0.1421 RMSE:0.9826 0.9956 1.0146 Tau:0.3502 0.3170 0.1484\n",
      "Epoch: 24 Step: 1944 Index:-0.6683 R2:0.2651 0.2120 0.1438 RMSE:0.9813 0.9954 1.0471 Tau:0.3596 0.3271 0.1502\n",
      "Epoch: 25 Step: 2025 Index:-0.6471 R2:0.2796 0.2196 0.1588 RMSE:0.9695 0.9825 1.0054 Tau:0.3704 0.3353 0.1455\n",
      "Epoch: 26 Step: 2106 Index:-0.6420 R2:0.2951 0.2299 0.1748 RMSE:0.9799 0.9937 0.9985 Tau:0.3845 0.3517 0.1519\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 27 Step: 2187 Index:-0.6449 R2:0.3001 0.2207 0.1753 RMSE:0.9544 0.9808 0.9939 Tau:0.3808 0.3358 0.1569\n",
      "Epoch: 28 Step: 2268 Index:-0.6171 R2:0.3181 0.2376 0.1836 RMSE:0.9401 0.9701 1.0082 Tau:0.3981 0.3530 0.1501\n",
      "Epoch: 29 Step: 2349 Index:-0.5964 R2:0.3189 0.2494 0.1934 RMSE:0.9339 0.9584 0.9868 Tau:0.3934 0.3620 0.1615\n",
      "Epoch: 30 Step: 2430 Index:-0.5891 R2:0.3488 0.2759 0.2206 RMSE:0.9442 0.9734 1.0272 Tau:0.4181 0.3843 0.1644\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 31 Step: 2511 Index:-0.6594 R2:0.3508 0.2439 0.2100 RMSE:0.9755 1.0164 0.9988 Tau:0.4154 0.3570 0.1463\n",
      "Epoch: 32 Step: 2592 Index:-0.5595 R2:0.3627 0.2745 0.2263 RMSE:0.9053 0.9427 0.9645 Tau:0.4262 0.3832 0.1694\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 33 Step: 2673 Index:-0.5929 R2:0.3760 0.2660 0.2371 RMSE:0.9173 0.9638 0.9585 Tau:0.4357 0.3709 0.1424\n",
      "Epoch: 34 Step: 2754 Index:-0.5595 R2:0.3810 0.2878 0.2432 RMSE:0.9090 0.9525 0.9946 Tau:0.4377 0.3931 0.1760\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 35 Step: 2835 Index:-0.5774 R2:0.3845 0.2796 0.2556 RMSE:0.9143 0.9597 0.9499 Tau:0.4396 0.3823 0.1580\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 36 Step: 2916 Index:-0.5887 R2:0.3863 0.2818 0.2499 RMSE:0.9059 0.9629 1.0000 Tau:0.4384 0.3742 0.1676\n",
      "Epoch: 37 Step: 2997 Index:-0.5297 R2:0.4031 0.3044 0.2552 RMSE:0.8809 0.9283 0.9462 Tau:0.4483 0.3985 0.1600\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 38 Step: 3078 Index:-0.5437 R2:0.4151 0.2916 0.2770 RMSE:0.8690 0.9302 0.9340 Tau:0.4607 0.3865 0.1504\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 39 Step: 3159 Index:-0.5321 R2:0.4124 0.3031 0.2614 RMSE:0.8652 0.9229 0.9497 Tau:0.4533 0.3908 0.1605\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 40 Step: 3240 Index:-0.5811 R2:0.4267 0.3090 0.2642 RMSE:0.9307 0.9831 0.9741 Tau:0.4612 0.4020 0.1407\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 41 Step: 3321 Index:-0.5447 R2:0.4363 0.3094 0.2906 RMSE:0.8855 0.9442 0.9294 Tau:0.4716 0.3995 0.1550\n",
      "Epoch: 42 Step: 3402 Index:-0.5122 R2:0.4385 0.3137 0.3057 RMSE:0.8470 0.9159 0.9208 Tau:0.4708 0.4037 0.1488\n",
      "Epoch: 43 Step: 3483 Index:-0.4851 R2:0.4543 0.3345 0.3040 RMSE:0.8374 0.9025 0.9185 Tau:0.4800 0.4174 0.1528\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 44 Step: 3564 Index:-0.5079 R2:0.4543 0.3377 0.2943 RMSE:0.8706 0.9273 0.9284 Tau:0.4805 0.4194 0.1573\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 45 Step: 3645 Index:-0.5142 R2:0.4545 0.3116 0.2964 RMSE:0.8328 0.9164 0.9241 Tau:0.4793 0.4022 0.1473\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 46 Step: 3726 Index:-0.4888 R2:0.4653 0.3365 0.3109 RMSE:0.8427 0.9097 0.9089 Tau:0.4862 0.4209 0.1506\n",
      "Epoch: 47 Step: 3807 Index:-0.4670 R2:0.4617 0.3510 0.3159 RMSE:0.8354 0.8943 0.9166 Tau:0.4878 0.4273 0.1579\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 48 Step: 3888 Index:-0.4972 R2:0.4803 0.3227 0.3198 RMSE:0.8241 0.9132 0.9026 Tau:0.4958 0.4161 0.1456\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 49 Step: 3969 Index:-0.4821 R2:0.4796 0.3329 0.3142 RMSE:0.8193 0.9031 0.9091 Tau:0.4968 0.4210 0.1427\n",
      "Epoch: 50 Step: 4050 Index:-0.4622 R2:0.4763 0.3511 0.3025 RMSE:0.8199 0.8912 0.9172 Tau:0.4927 0.4290 0.1606\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 51 Step: 4131 Index:-0.4684 R2:0.4964 0.3562 0.3276 RMSE:0.8274 0.9042 0.9018 Tau:0.5066 0.4358 0.1487\n",
      "Epoch: 52 Step: 4212 Index:-0.4580 R2:0.5015 0.3646 0.3439 RMSE:0.8177 0.8952 0.8896 Tau:0.5112 0.4373 0.1567\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 53 Step: 4293 Index:-0.5038 R2:0.5023 0.3236 0.3335 RMSE:0.8126 0.9194 0.8968 Tau:0.5087 0.4156 0.1406\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 54 Step: 4374 Index:-0.4914 R2:0.5074 0.3479 0.3302 RMSE:0.8350 0.9235 0.9116 Tau:0.5137 0.4321 0.1400\n",
      "Epoch: 55 Step: 4455 Index:-0.4376 R2:0.5126 0.3682 0.3390 RMSE:0.7876 0.8777 0.8949 Tau:0.5176 0.4401 0.1468\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 56 Step: 4536 Index:-0.4402 R2:0.5192 0.3699 0.3612 RMSE:0.7832 0.8768 0.8786 Tau:0.5198 0.4366 0.1516\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 57 Step: 4617 Index:-0.4654 R2:0.5262 0.3459 0.3630 RMSE:0.7820 0.8939 0.8751 Tau:0.5234 0.4285 0.1546\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 58 Step: 4698 Index:-0.4713 R2:0.5199 0.3516 0.3430 RMSE:0.7940 0.9013 0.9155 Tau:0.5177 0.4300 0.1487\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 59 Step: 4779 Index:-0.5068 R2:0.5232 0.3375 0.3465 RMSE:0.8216 0.9305 0.8983 Tau:0.5204 0.4237 0.1334\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 60 Step: 4860 Index:-0.4687 R2:0.5320 0.3649 0.3597 RMSE:0.7906 0.9032 0.9198 Tau:0.5239 0.4345 0.1548\n",
      "Epoch: 61 Step: 4941 Index:-0.4374 R2:0.5367 0.3693 0.3587 RMSE:0.7746 0.8795 0.8777 Tau:0.5300 0.4421 0.1575\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 62 Step: 5022 Index:-0.4506 R2:0.5317 0.3619 0.3559 RMSE:0.7763 0.8853 0.8819 Tau:0.5264 0.4346 0.1533\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 63 Step: 5103 Index:-0.4503 R2:0.5441 0.3821 0.3531 RMSE:0.8066 0.8979 0.8955 Tau:0.5362 0.4477 0.1577\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 64 Step: 5184 Index:-0.4682 R2:0.5337 0.3513 0.3465 RMSE:0.7760 0.8967 0.9079 Tau:0.5247 0.4285 0.1587\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 65 Step: 5265 Index:-0.4412 R2:0.5468 0.3671 0.3729 RMSE:0.7602 0.8788 0.8715 Tau:0.5329 0.4376 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 66 Step: 5346 Index:-0.4832 R2:0.5575 0.3693 0.3654 RMSE:0.8201 0.9288 0.9040 Tau:0.5408 0.4455 0.1543\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 67 Step: 5427 Index:-0.4892 R2:0.5654 0.3470 0.3695 RMSE:0.7792 0.9185 0.9173 Tau:0.5447 0.4293 0.1543\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 68 Step: 5508 Index:-0.4774 R2:0.5601 0.3382 0.3586 RMSE:0.7459 0.9021 0.8919 Tau:0.5413 0.4247 0.1536\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 69 Step: 5589 Index:-0.4433 R2:0.5589 0.3732 0.3543 RMSE:0.7649 0.8849 0.8817 Tau:0.5411 0.4416 0.1605\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 70 Step: 5670 Index:-0.5149 R2:0.5762 0.3456 0.3728 RMSE:0.8021 0.9423 0.8945 Tau:0.5517 0.4273 0.1572\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 71 Step: 5751 Index:-0.4533 R2:0.5787 0.3581 0.3747 RMSE:0.7363 0.8858 0.8755 Tau:0.5564 0.4325 0.1569\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 72 Step: 5832 Index:-0.4554 R2:0.5682 0.3803 0.3762 RMSE:0.7736 0.8900 0.8689 Tau:0.5524 0.4346 0.1744\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 73 Step: 5913 Index:-0.4484 R2:0.5640 0.3676 0.3559 RMSE:0.7549 0.8843 0.8842 Tau:0.5490 0.4359 0.1670\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 74 Step: 5994 Index:-0.5043 R2:0.5680 0.3243 0.3497 RMSE:0.7462 0.9197 0.9137 Tau:0.5453 0.4154 0.1515\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 75 Step: 6075 Index:-0.4553 R2:0.5805 0.3775 0.3998 RMSE:0.7668 0.8928 0.8541 Tau:0.5559 0.4374 0.1808\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 76 Step: 6156 Index:-0.5065 R2:0.5876 0.3218 0.3612 RMSE:0.7298 0.9158 0.8936 Tau:0.5612 0.4093 0.1621\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 77 Step: 6237 Index:-0.5451 R2:0.5643 0.3149 0.3447 RMSE:0.7709 0.9450 0.9398 Tau:0.5512 0.3999 0.1808\n",
      "Epoch: 78 Step: 6318 Index:-0.4279 R2:0.5875 0.3862 0.4046 RMSE:0.7450 0.8772 0.8519 Tau:0.5613 0.4493 0.1676\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 79 Step: 6399 Index:-0.4287 R2:0.5922 0.3815 0.3949 RMSE:0.7292 0.8708 0.8530 Tau:0.5627 0.4421 0.1689\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 80 Step: 6480 Index:-0.4586 R2:0.5935 0.3559 0.3749 RMSE:0.7206 0.8865 0.8729 Tau:0.5636 0.4278 0.1611\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 81 Step: 6561 Index:-0.4727 R2:0.5855 0.3477 0.3488 RMSE:0.7256 0.8932 0.8937 Tau:0.5601 0.4206 0.1655\n",
      "Epoch: 82 Step: 6642 Index:-0.4131 R2:0.5950 0.3917 0.3683 RMSE:0.7296 0.8667 0.8733 Tau:0.5683 0.4536 0.1749\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 83 Step: 6723 Index:-0.4860 R2:0.6029 0.3596 0.4080 RMSE:0.7406 0.9138 0.9007 Tau:0.5686 0.4278 0.1788\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 84 Step: 6804 Index:-0.4587 R2:0.5926 0.3606 0.3876 RMSE:0.7205 0.8834 0.8661 Tau:0.5621 0.4247 0.1734\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 85 Step: 6885 Index:-0.4235 R2:0.6091 0.3843 0.3911 RMSE:0.7076 0.8666 0.8609 Tau:0.5734 0.4431 0.1731\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 86 Step: 6966 Index:-0.4822 R2:0.6044 0.3474 0.3751 RMSE:0.7186 0.8976 0.8687 Tau:0.5726 0.4154 0.1627\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 87 Step: 7047 Index:-0.4849 R2:0.6048 0.3465 0.3698 RMSE:0.7360 0.9071 0.8748 Tau:0.5715 0.4222 0.1612\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 88 Step: 7128 Index:-0.5293 R2:0.5749 0.3332 0.3701 RMSE:0.7697 0.9356 0.9328 Tau:0.5508 0.4063 0.1735\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 89 Step: 7209 Index:-0.4578 R2:0.6046 0.3599 0.3760 RMSE:0.7194 0.8855 0.8661 Tau:0.5734 0.4277 0.1750\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 90 Step: 7290 Index:-0.4764 R2:0.6065 0.3530 0.3673 RMSE:0.7240 0.9054 0.9119 Tau:0.5730 0.4290 0.1658\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 91 Step: 7371 Index:-0.4752 R2:0.5988 0.3465 0.3630 RMSE:0.7160 0.8938 0.8801 Tau:0.5689 0.4186 0.1718\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 92 Step: 7452 Index:-0.4588 R2:0.6155 0.3567 0.3880 RMSE:0.7009 0.8872 0.8617 Tau:0.5793 0.4283 0.1785\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 93 Step: 7533 Index:-0.4336 R2:0.6192 0.3752 0.3903 RMSE:0.6943 0.8749 0.8667 Tau:0.5814 0.4412 0.1712\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 94 Step: 7614 Index:-0.4798 R2:0.6082 0.3728 0.4116 RMSE:0.7471 0.9147 0.9204 Tau:0.5765 0.4349 0.1882\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 95 Step: 7695 Index:-0.4540 R2:0.6197 0.3617 0.4017 RMSE:0.6940 0.8858 0.8568 Tau:0.5805 0.4318 0.1666\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 96 Step: 7776 Index:-0.4305 R2:0.6206 0.3781 0.4128 RMSE:0.6974 0.8748 0.8567 Tau:0.5828 0.4442 0.1824\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 97 Step: 7857 Index:-0.4788 R2:0.6233 0.3414 0.3820 RMSE:0.6998 0.8965 0.8628 Tau:0.5836 0.4177 0.1784\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 98 Step: 7938 Index:-0.4932 R2:0.6343 0.3573 0.4023 RMSE:0.7270 0.9228 0.9155 Tau:0.5922 0.4297 0.1760\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 99 Step: 8019 Index:-0.4586 R2:0.6358 0.3543 0.4070 RMSE:0.6846 0.8889 0.8547 Tau:0.5933 0.4303 0.1642\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 100 Step: 8100 Index:-0.4676 R2:0.6278 0.3559 0.3973 RMSE:0.6896 0.8901 0.8635 Tau:0.5875 0.4225 0.1808\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 101 Step: 8181 Index:-0.4430 R2:0.6317 0.3716 0.4089 RMSE:0.6959 0.8778 0.8428 Tau:0.5912 0.4348 0.1765\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 102 Step: 8262 Index:-0.4734 R2:0.6313 0.3654 0.4090 RMSE:0.7242 0.9057 0.8540 Tau:0.5898 0.4323 0.1720\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 103 Step: 8343 Index:-0.5117 R2:0.6233 0.3552 0.3972 RMSE:0.7268 0.9370 0.9214 Tau:0.5848 0.4254 0.1652\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 104 Step: 8424 Index:-0.4508 R2:0.6433 0.3698 0.4164 RMSE:0.6895 0.8876 0.8432 Tau:0.5997 0.4368 0.1671\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 105 Step: 8505 Index:-0.4388 R2:0.6485 0.3727 0.4061 RMSE:0.6722 0.8747 0.8481 Tau:0.6036 0.4359 0.1703\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 106 Step: 8586 Index:-0.4524 R2:0.6451 0.3644 0.4145 RMSE:0.6736 0.8814 0.8417 Tau:0.6008 0.4290 0.1801\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 107 Step: 8667 Index:-0.4306 R2:0.6413 0.3838 0.4053 RMSE:0.6824 0.8765 0.8710 Tau:0.5977 0.4459 0.1773\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 108 Step: 8748 Index:-0.4612 R2:0.6336 0.3660 0.4034 RMSE:0.6984 0.8902 0.8580 Tau:0.5918 0.4290 0.1717\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 109 Step: 8829 Index:-0.4649 R2:0.6480 0.3531 0.4081 RMSE:0.6723 0.8899 0.8495 Tau:0.6013 0.4250 0.1790\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 110 Step: 8910 Index:-0.4975 R2:0.6438 0.3424 0.4047 RMSE:0.7229 0.9242 0.8626 Tau:0.5996 0.4267 0.1821\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 111 Step: 8991 Index:-0.4420 R2:0.6465 0.3738 0.4054 RMSE:0.6696 0.8774 0.8517 Tau:0.6020 0.4354 0.1746\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 112 Step: 9072 Index:-0.4813 R2:0.6574 0.3862 0.4193 RMSE:0.7559 0.9324 0.8803 Tau:0.6089 0.4512 0.1778\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 113 Step: 9153 Index:-0.4275 R2:0.6568 0.3783 0.4256 RMSE:0.6688 0.8746 0.8331 Tau:0.6068 0.4472 0.1799\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 114 Step: 9234 Index:-0.4540 R2:0.6537 0.3649 0.4108 RMSE:0.6627 0.8872 0.8578 Tau:0.6074 0.4333 0.1723\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 115 Step: 9315 Index:-0.5113 R2:0.6434 0.3209 0.4023 RMSE:0.6763 0.9153 0.8570 Tau:0.5988 0.4040 0.1784\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 116 Step: 9396 Index:-0.4921 R2:0.6442 0.3387 0.3993 RMSE:0.6786 0.9018 0.8587 Tau:0.5981 0.4096 0.1795\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 117 Step: 9477 Index:-0.4972 R2:0.6481 0.3713 0.3928 RMSE:0.7547 0.9360 0.9004 Tau:0.6023 0.4388 0.1736\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 118 Step: 9558 Index:-0.4863 R2:0.6570 0.3479 0.4293 RMSE:0.6910 0.9123 0.8363 Tau:0.6077 0.4260 0.1860\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 119 Step: 9639 Index:-0.4717 R2:0.6566 0.3511 0.4135 RMSE:0.6728 0.8975 0.8418 Tau:0.6071 0.4258 0.1597\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 120 Step: 9720 Index:-0.4565 R2:0.6645 0.3587 0.4265 RMSE:0.6544 0.8870 0.8373 Tau:0.6143 0.4305 0.1888\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 121 Step: 9801 Index:-0.4339 R2:0.6576 0.3782 0.4183 RMSE:0.6649 0.8773 0.8427 Tau:0.6100 0.4434 0.1755\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 122 Step: 9882 Index:-0.4529 R2:0.6578 0.3654 0.4021 RMSE:0.6711 0.8860 0.8507 Tau:0.6098 0.4331 0.1953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 123 Step: 9963 Index:-0.4946 R2:0.6655 0.3528 0.4091 RMSE:0.7139 0.9267 0.8662 Tau:0.6140 0.4321 0.1756\n",
      "Epoch: 124 Step: 10044 Index:-0.4128 R2:0.6718 0.3944 0.4297 RMSE:0.6523 0.8645 0.8300 Tau:0.6179 0.4517 0.1737\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 125 Step: 10125 Index:-0.4236 R2:0.6711 0.3786 0.4244 RMSE:0.6486 0.8716 0.8368 Tau:0.6170 0.4480 0.1672\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 126 Step: 10206 Index:-0.5212 R2:0.6691 0.3201 0.4054 RMSE:0.6713 0.9294 0.8521 Tau:0.6185 0.4081 0.1719\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 127 Step: 10287 Index:-0.4212 R2:0.6765 0.3862 0.4280 RMSE:0.6558 0.8712 0.8289 Tau:0.6215 0.4500 0.1811\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 128 Step: 10368 Index:-0.4693 R2:0.6629 0.3557 0.4243 RMSE:0.6786 0.9016 0.8359 Tau:0.6105 0.4323 0.1754\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 129 Step: 10449 Index:-0.4161 R2:0.6586 0.3878 0.4059 RMSE:0.6642 0.8727 0.8646 Tau:0.6096 0.4566 0.1839\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 130 Step: 10530 Index:-0.4132 R2:0.6752 0.3865 0.4022 RMSE:0.6523 0.8690 0.8514 Tau:0.6232 0.4558 0.1917\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 131 Step: 10611 Index:-0.4672 R2:0.6582 0.3526 0.3941 RMSE:0.6580 0.8977 0.8660 Tau:0.6094 0.4305 0.1712\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 132 Step: 10692 Index:-0.4595 R2:0.6808 0.3668 0.4071 RMSE:0.6607 0.8953 0.8522 Tau:0.6267 0.4358 0.1804\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 133 Step: 10773 Index:-0.4351 R2:0.6728 0.3903 0.4117 RMSE:0.6812 0.8882 0.8609 Tau:0.6207 0.4532 0.1843\n",
      "Epoch: 134 Step: 10854 Index:-0.4088 R2:0.6662 0.3996 0.4185 RMSE:0.6498 0.8599 0.8424 Tau:0.6138 0.4512 0.1893\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 135 Step: 10935 Index:-0.4378 R2:0.6740 0.3831 0.4214 RMSE:0.6501 0.8754 0.8360 Tau:0.6173 0.4376 0.1976\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 136 Step: 11016 Index:-0.4744 R2:0.6823 0.3718 0.4224 RMSE:0.7089 0.9143 0.8585 Tau:0.6274 0.4399 0.1965\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 137 Step: 11097 Index:-0.4776 R2:0.6918 0.3527 0.4361 RMSE:0.6433 0.9077 0.8548 Tau:0.6348 0.4301 0.1807\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 138 Step: 11178 Index:-0.5029 R2:0.6837 0.3447 0.4192 RMSE:0.6964 0.9286 0.8569 Tau:0.6276 0.4257 0.1911\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 139 Step: 11259 Index:-0.4502 R2:0.6769 0.3705 0.4196 RMSE:0.6410 0.8831 0.8387 Tau:0.6217 0.4330 0.1811\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 140 Step: 11340 Index:-0.4626 R2:0.6944 0.3663 0.4331 RMSE:0.6272 0.8929 0.8446 Tau:0.6351 0.4303 0.1839\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 141 Step: 11421 Index:-0.4738 R2:0.6914 0.3494 0.4297 RMSE:0.6392 0.8976 0.8285 Tau:0.6343 0.4239 0.1814\n",
      "Epoch: 142 Step: 11502 Index:-0.3985 R2:0.6878 0.4032 0.4190 RMSE:0.6327 0.8590 0.8438 Tau:0.6315 0.4606 0.1876\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 143 Step: 11583 Index:-0.5097 R2:0.6783 0.3250 0.4141 RMSE:0.6438 0.9184 0.8454 Tau:0.6214 0.4086 0.1702\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 144 Step: 11664 Index:-0.4509 R2:0.6986 0.3703 0.4346 RMSE:0.6448 0.8920 0.8343 Tau:0.6379 0.4411 0.1896\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 145 Step: 11745 Index:-0.4768 R2:0.6731 0.3475 0.4042 RMSE:0.6444 0.9071 0.8659 Tau:0.6213 0.4303 0.1862\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 146 Step: 11826 Index:-0.4885 R2:0.6933 0.3880 0.4078 RMSE:0.7357 0.9438 0.8941 Tau:0.6344 0.4553 0.1809\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 147 Step: 11907 Index:-0.4360 R2:0.7049 0.3818 0.4265 RMSE:0.6330 0.8876 0.8412 Tau:0.6421 0.4517 0.1846\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 148 Step: 11988 Index:-0.5339 R2:0.6743 0.3431 0.3828 RMSE:0.7372 0.9529 0.9113 Tau:0.6272 0.4191 0.1879\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 149 Step: 12069 Index:-0.4345 R2:0.6991 0.3901 0.4074 RMSE:0.6526 0.8841 0.8580 Tau:0.6409 0.4497 0.1957\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 150 Step: 12150 Index:-0.4041 R2:0.6953 0.3978 0.4127 RMSE:0.6209 0.8631 0.8516 Tau:0.6365 0.4589 0.1925\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 151 Step: 12231 Index:-0.4802 R2:0.7060 0.3522 0.4268 RMSE:0.6307 0.9102 0.8612 Tau:0.6438 0.4300 0.1936\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 152 Step: 12312 Index:-0.4548 R2:0.7050 0.3876 0.4102 RMSE:0.6750 0.9053 0.8744 Tau:0.6450 0.4505 0.1900\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 153 Step: 12393 Index:-0.4569 R2:0.7075 0.3579 0.4247 RMSE:0.6111 0.8893 0.8368 Tau:0.6447 0.4325 0.2035\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 154 Step: 12474 Index:-0.4724 R2:0.7022 0.3555 0.4348 RMSE:0.6341 0.9014 0.8300 Tau:0.6371 0.4290 0.1915\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 155 Step: 12555 Index:-0.4689 R2:0.7071 0.3730 0.4492 RMSE:0.6536 0.9144 0.8708 Tau:0.6432 0.4455 0.2074\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 156 Step: 12636 Index:-0.4511 R2:0.7166 0.3661 0.4278 RMSE:0.6093 0.8857 0.8411 Tau:0.6521 0.4346 0.1970\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 157 Step: 12717 Index:-0.4529 R2:0.7064 0.3713 0.4282 RMSE:0.6283 0.8906 0.8408 Tau:0.6438 0.4378 0.1849\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 158 Step: 12798 Index:-0.4526 R2:0.7089 0.3635 0.4230 RMSE:0.6082 0.8862 0.8399 Tau:0.6466 0.4336 0.1872\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 159 Step: 12879 Index:-0.4494 R2:0.7150 0.3856 0.4298 RMSE:0.6560 0.8984 0.8533 Tau:0.6501 0.4490 0.2021\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 160 Step: 12960 Index:-0.4649 R2:0.7180 0.3580 0.4342 RMSE:0.5994 0.8926 0.8300 Tau:0.6517 0.4277 0.2024\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 161 Step: 13041 Index:-0.5088 R2:0.7162 0.3682 0.4350 RMSE:0.6964 0.9429 0.8807 Tau:0.6531 0.4341 0.1879\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 162 Step: 13122 Index:-0.4437 R2:0.7254 0.3718 0.4277 RMSE:0.5998 0.8840 0.8350 Tau:0.6600 0.4402 0.1923\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 163 Step: 13203 Index:-0.4736 R2:0.7171 0.3578 0.4267 RMSE:0.6060 0.9069 0.8564 Tau:0.6519 0.4333 0.1932\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 164 Step: 13284 Index:-0.4070 R2:0.7119 0.3986 0.4265 RMSE:0.6224 0.8656 0.8356 Tau:0.6480 0.4586 0.2038\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 165 Step: 13365 Index:-0.4201 R2:0.7284 0.3915 0.4420 RMSE:0.5963 0.8692 0.8218 Tau:0.6599 0.4492 0.2027\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 166 Step: 13446 Index:-0.4329 R2:0.7109 0.3859 0.4279 RMSE:0.6269 0.8831 0.8387 Tau:0.6446 0.4502 0.2068\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 167 Step: 13527 Index:-0.4292 R2:0.7195 0.3781 0.4267 RMSE:0.5996 0.8752 0.8337 Tau:0.6554 0.4460 0.1999\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 168 Step: 13608 Index:-0.4194 R2:0.7180 0.3968 0.4279 RMSE:0.6222 0.8790 0.8473 Tau:0.6550 0.4596 0.1803\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 169 Step: 13689 Index:-0.4836 R2:0.7292 0.3746 0.4270 RMSE:0.6612 0.9244 0.8643 Tau:0.6594 0.4407 0.1990\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 170 Step: 13770 Index:-0.5034 R2:0.7263 0.3490 0.4284 RMSE:0.6223 0.9238 0.8715 Tau:0.6565 0.4204 0.1981\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 171 Step: 13851 Index:-0.4281 R2:0.7250 0.3881 0.4258 RMSE:0.6219 0.8835 0.8445 Tau:0.6581 0.4555 0.2001\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 172 Step: 13932 Index:-0.4563 R2:0.7238 0.3635 0.4278 RMSE:0.5915 0.8910 0.8404 Tau:0.6582 0.4348 0.1862\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 173 Step: 14013 Index:-0.5301 R2:0.7030 0.3300 0.4022 RMSE:0.6606 0.9414 0.8753 Tau:0.6433 0.4113 0.1943\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 174 Step: 14094 Index:-0.5196 R2:0.7047 0.3592 0.4008 RMSE:0.7194 0.9574 0.9101 Tau:0.6400 0.4378 0.1872\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 175 Step: 14175 Index:-0.4637 R2:0.7341 0.3583 0.4279 RMSE:0.5822 0.8945 0.8347 Tau:0.6645 0.4308 0.1984\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 176 Step: 14256 Index:-0.4695 R2:0.7222 0.3599 0.4223 RMSE:0.6195 0.9030 0.8429 Tau:0.6583 0.4335 0.1804\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 177 Step: 14337 Index:-0.4716 R2:0.7353 0.3577 0.4285 RMSE:0.6008 0.9023 0.8373 Tau:0.6668 0.4306 0.1899\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 178 Step: 14418 Index:-0.4558 R2:0.7147 0.3653 0.4253 RMSE:0.6055 0.8863 0.8375 Tau:0.6521 0.4305 0.2065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 179 Step: 14499 Index:-0.4286 R2:0.7270 0.3880 0.4371 RMSE:0.5912 0.8730 0.8351 Tau:0.6587 0.4444 0.2070\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 180 Step: 14580 Index:-0.4620 R2:0.7347 0.3663 0.4176 RMSE:0.5976 0.8953 0.8456 Tau:0.6688 0.4333 0.1903\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 181 Step: 14661 Index:-0.4427 R2:0.7266 0.3958 0.4196 RMSE:0.6578 0.8982 0.8637 Tau:0.6586 0.4555 0.1891\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 182 Step: 14742 Index:-0.4120 R2:0.7351 0.3886 0.4362 RMSE:0.5822 0.8664 0.8281 Tau:0.6655 0.4545 0.2057\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 183 Step: 14823 Index:-0.4029 R2:0.7273 0.3978 0.4352 RMSE:0.5911 0.8592 0.8294 Tau:0.6595 0.4563 0.1908\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 184 Step: 14904 Index:-0.5484 R2:0.7193 0.3187 0.4126 RMSE:0.6481 0.9523 0.8712 Tau:0.6581 0.4038 0.1918\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 185 Step: 14985 Index:-0.4410 R2:0.7418 0.3852 0.4569 RMSE:0.6111 0.8920 0.8258 Tau:0.6686 0.4510 0.2053\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 186 Step: 15066 Index:-0.4972 R2:0.7401 0.3450 0.4247 RMSE:0.6213 0.9225 0.8507 Tau:0.6718 0.4254 0.1997\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 187 Step: 15147 Index:-0.4067 R2:0.7473 0.3957 0.4475 RMSE:0.5701 0.8624 0.8186 Tau:0.6735 0.4556 0.2028\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 188 Step: 15228 Index:-0.4556 R2:0.7409 0.3587 0.4381 RMSE:0.5877 0.8970 0.8293 Tau:0.6702 0.4414 0.1970\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 189 Step: 15309 Index:-0.4575 R2:0.7430 0.3879 0.4393 RMSE:0.6397 0.9102 0.8594 Tau:0.6727 0.4527 0.1799\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 190 Step: 15390 Index:-0.5015 R2:0.7257 0.3867 0.3987 RMSE:0.7009 0.9459 0.9206 Tau:0.6566 0.4444 0.2060\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 191 Step: 15471 Index:-0.4442 R2:0.7498 0.3848 0.4372 RMSE:0.6020 0.8911 0.8396 Tau:0.6775 0.4469 0.2032\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 192 Step: 15552 Index:-0.4139 R2:0.7408 0.3983 0.4428 RMSE:0.5880 0.8712 0.8375 Tau:0.6675 0.4573 0.1968\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 193 Step: 15633 Index:-0.4288 R2:0.7482 0.3859 0.4268 RMSE:0.5732 0.8757 0.8380 Tau:0.6735 0.4469 0.2100\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 194 Step: 15714 Index:-0.4502 R2:0.7510 0.3667 0.4307 RMSE:0.5646 0.8879 0.8326 Tau:0.6796 0.4378 0.1993\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 195 Step: 15795 Index:-0.4361 R2:0.7536 0.3812 0.4287 RMSE:0.5735 0.8826 0.8384 Tau:0.6775 0.4465 0.1992\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 196 Step: 15876 Index:-0.5023 R2:0.7416 0.3545 0.4293 RMSE:0.6543 0.9381 0.8737 Tau:0.6721 0.4358 0.1842\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 197 Step: 15957 Index:-0.4512 R2:0.7476 0.3735 0.4451 RMSE:0.5999 0.9006 0.8513 Tau:0.6764 0.4493 0.1981\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 199 Step: 16119 Index:-0.4401 R2:0.7565 0.3708 0.4297 RMSE:0.5754 0.8870 0.8351 Tau:0.6833 0.4469 0.2012\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 200 Step: 16200 Index:-0.4199 R2:0.7559 0.3865 0.4380 RMSE:0.5749 0.8762 0.8291 Tau:0.6817 0.4563 0.1985\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 201 Step: 16281 Index:-0.4274 R2:0.7564 0.3874 0.4450 RMSE:0.5551 0.8807 0.8277 Tau:0.6807 0.4533 0.2041\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 202 Step: 16362 Index:-0.4390 R2:0.7586 0.3735 0.4411 RMSE:0.5536 0.8845 0.8304 Tau:0.6838 0.4455 0.1938\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 203 Step: 16443 Index:-0.4834 R2:0.7481 0.3517 0.4288 RMSE:0.5967 0.9165 0.8665 Tau:0.6731 0.4331 0.1963\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 204 Step: 16524 Index:-0.4440 R2:0.7623 0.3650 0.4435 RMSE:0.5611 0.8900 0.8228 Tau:0.6855 0.4460 0.1975\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 205 Step: 16605 Index:-0.4296 R2:0.7611 0.3851 0.4434 RMSE:0.5529 0.8794 0.8281 Tau:0.6835 0.4498 0.1933\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 206 Step: 16686 Index:-0.4980 R2:0.7476 0.3427 0.4405 RMSE:0.5991 0.9260 0.8461 Tau:0.6748 0.4280 0.1646\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 207 Step: 16767 Index:-0.5427 R2:0.7205 0.3012 0.3949 RMSE:0.6053 0.9358 0.8574 Tau:0.6576 0.3931 0.2148\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 208 Step: 16848 Index:-0.4504 R2:0.7569 0.3825 0.4453 RMSE:0.5897 0.9019 0.8394 Tau:0.6813 0.4515 0.1879\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 209 Step: 16929 Index:-0.4070 R2:0.7706 0.3959 0.4514 RMSE:0.5441 0.8701 0.8222 Tau:0.6911 0.4631 0.1975\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 210 Step: 17010 Index:-0.4404 R2:0.7657 0.3798 0.4484 RMSE:0.5668 0.8873 0.8258 Tau:0.6855 0.4469 0.1989\n",
      "Epoch: 211 Step: 17091 Index:-0.3875 R2:0.7558 0.4084 0.4369 RMSE:0.5562 0.8580 0.8316 Tau:0.6778 0.4705 0.2031\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 212 Step: 17172 Index:-0.4602 R2:0.7630 0.3650 0.4615 RMSE:0.5717 0.9015 0.8295 Tau:0.6839 0.4412 0.2051\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 213 Step: 17253 Index:-0.4457 R2:0.7684 0.3782 0.4423 RMSE:0.5495 0.8907 0.8305 Tau:0.6911 0.4450 0.1889\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 214 Step: 17334 Index:-0.4106 R2:0.7712 0.3979 0.4447 RMSE:0.5545 0.8687 0.8342 Tau:0.6876 0.4581 0.2102\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 215 Step: 17415 Index:-0.4519 R2:0.7635 0.3754 0.4519 RMSE:0.5793 0.9012 0.8321 Tau:0.6827 0.4493 0.2090\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 216 Step: 17496 Index:-0.4861 R2:0.7731 0.3701 0.4554 RMSE:0.5952 0.9244 0.8609 Tau:0.6906 0.4383 0.2187\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 217 Step: 17577 Index:-0.4432 R2:0.7629 0.3775 0.4336 RMSE:0.5537 0.8854 0.8384 Tau:0.6812 0.4422 0.2174\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 218 Step: 17658 Index:-0.4060 R2:0.7670 0.4018 0.4560 RMSE:0.5582 0.8704 0.8276 Tau:0.6857 0.4644 0.1962\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 219 Step: 17739 Index:-0.4077 R2:0.7807 0.3884 0.4505 RMSE:0.5316 0.8725 0.8222 Tau:0.7000 0.4647 0.2003\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 220 Step: 17820 Index:-0.4700 R2:0.7767 0.3749 0.4360 RMSE:0.5887 0.9140 0.8573 Tau:0.6958 0.4440 0.1951\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 221 Step: 17901 Index:-0.4356 R2:0.7749 0.3869 0.4481 RMSE:0.5658 0.8904 0.8404 Tau:0.6946 0.4548 0.1970\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 222 Step: 17982 Index:-0.4826 R2:0.7722 0.3399 0.4467 RMSE:0.5475 0.9125 0.8256 Tau:0.6946 0.4300 0.1850\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 223 Step: 18063 Index:-0.4087 R2:0.7662 0.4000 0.4268 RMSE:0.5490 0.8683 0.8427 Tau:0.6850 0.4596 0.2117\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 224 Step: 18144 Index:-0.4214 R2:0.7756 0.4023 0.4379 RMSE:0.5632 0.8858 0.8489 Tau:0.6919 0.4644 0.2056\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 225 Step: 18225 Index:-0.5196 R2:0.7658 0.3265 0.4159 RMSE:0.5864 0.9389 0.8604 Tau:0.6857 0.4192 0.2108\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 226 Step: 18306 Index:-0.4534 R2:0.7770 0.3619 0.4374 RMSE:0.5384 0.8969 0.8334 Tau:0.6949 0.4436 0.2037\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 227 Step: 18387 Index:-0.4613 R2:0.7791 0.3658 0.4408 RMSE:0.5321 0.8995 0.8365 Tau:0.6983 0.4383 0.2097\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 228 Step: 18468 Index:-0.4639 R2:0.7781 0.3644 0.4387 RMSE:0.5307 0.9000 0.8385 Tau:0.6944 0.4361 0.1930\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 229 Step: 18549 Index:-0.4567 R2:0.7872 0.3755 0.4488 RMSE:0.5665 0.9071 0.8457 Tau:0.7044 0.4503 0.2065\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 230 Step: 18630 Index:-0.4636 R2:0.7825 0.3726 0.4474 RMSE:0.5641 0.9027 0.8381 Tau:0.6992 0.4391 0.2089\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 231 Step: 18711 Index:-0.4832 R2:0.7810 0.3413 0.4553 RMSE:0.5296 0.9113 0.8176 Tau:0.6984 0.4282 0.1917\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 232 Step: 18792 Index:-0.4396 R2:0.7804 0.3848 0.4392 RMSE:0.5528 0.8911 0.8490 Tau:0.6995 0.4515 0.1868\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 233 Step: 18873 Index:-0.4421 R2:0.7895 0.3709 0.4622 RMSE:0.5226 0.8893 0.8124 Tau:0.7056 0.4472 0.2105\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 234 Step: 18954 Index:-0.4384 R2:0.7898 0.3807 0.4673 RMSE:0.5337 0.8901 0.8184 Tau:0.7070 0.4517 0.1982\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 235 Step: 19035 Index:-0.5127 R2:0.7742 0.3814 0.4505 RMSE:0.6572 0.9623 0.9115 Tau:0.6929 0.4497 0.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 236 Step: 19116 Index:-0.4987 R2:0.7819 0.3345 0.4478 RMSE:0.5285 0.9241 0.8284 Tau:0.7036 0.4254 0.2038\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 237 Step: 19197 Index:-0.5017 R2:0.7889 0.3448 0.4321 RMSE:0.5647 0.9280 0.8562 Tau:0.7081 0.4263 0.2028\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 238 Step: 19278 Index:-0.4544 R2:0.7914 0.3709 0.4386 RMSE:0.5219 0.9011 0.8445 Tau:0.7091 0.4467 0.2136\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 239 Step: 19359 Index:-0.4665 R2:0.7699 0.3655 0.4410 RMSE:0.5486 0.9019 0.8348 Tau:0.6940 0.4354 0.1793\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 240 Step: 19440 Index:-0.4315 R2:0.7938 0.3725 0.4480 RMSE:0.5277 0.8812 0.8194 Tau:0.7107 0.4497 0.2006\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 241 Step: 19521 Index:-0.4507 R2:0.7802 0.3871 0.4436 RMSE:0.5461 0.8990 0.8483 Tau:0.6969 0.4484 0.1997\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 242 Step: 19602 Index:-0.4571 R2:0.7954 0.3770 0.4564 RMSE:0.5553 0.9079 0.8417 Tau:0.7099 0.4508 0.1882\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 243 Step: 19683 Index:-0.4368 R2:0.7941 0.3842 0.4303 RMSE:0.5221 0.8883 0.8474 Tau:0.7119 0.4515 0.2054\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 244 Step: 19764 Index:-0.4447 R2:0.7924 0.3682 0.4324 RMSE:0.5157 0.8919 0.8384 Tau:0.7132 0.4472 0.1849\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 245 Step: 19845 Index:-0.5564 R2:0.7519 0.3313 0.4221 RMSE:0.6278 0.9708 0.8925 Tau:0.6701 0.4144 0.2101\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 246 Step: 19926 Index:-0.4493 R2:0.7933 0.3758 0.4365 RMSE:0.5314 0.8951 0.8433 Tau:0.7096 0.4459 0.2078\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 247 Step: 20007 Index:-0.4852 R2:0.7974 0.3760 0.4443 RMSE:0.5625 0.9293 0.8635 Tau:0.7130 0.4440 0.1952\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 248 Step: 20088 Index:-0.4690 R2:0.7990 0.3642 0.4395 RMSE:0.5336 0.9107 0.8494 Tau:0.7127 0.4417 0.2092\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 249 Step: 20169 Index:-0.4363 R2:0.7920 0.3772 0.4388 RMSE:0.5160 0.8876 0.8403 Tau:0.7074 0.4513 0.1990\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 250 Step: 20250 Index:-0.4681 R2:0.7887 0.3614 0.4446 RMSE:0.5266 0.9074 0.8396 Tau:0.7033 0.4393 0.2087\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 251 Step: 20331 Index:-0.4910 R2:0.7844 0.3519 0.4285 RMSE:0.5260 0.9193 0.8553 Tau:0.7030 0.4283 0.1975\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 252 Step: 20412 Index:-0.5278 R2:0.7973 0.3570 0.4451 RMSE:0.6210 0.9676 0.9078 Tau:0.7113 0.4397 0.2039\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 253 Step: 20493 Index:-0.4969 R2:0.7920 0.3605 0.4274 RMSE:0.5478 0.9272 0.8657 Tau:0.7100 0.4303 0.2165\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 254 Step: 20574 Index:-0.5194 R2:0.8058 0.3567 0.4540 RMSE:0.5886 0.9588 0.8736 Tau:0.7222 0.4394 0.1974\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 255 Step: 20655 Index:-0.4705 R2:0.7916 0.3575 0.4586 RMSE:0.5149 0.9058 0.8227 Tau:0.7091 0.4353 0.1873\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 256 Step: 20736 Index:-0.4712 R2:0.8011 0.3766 0.4413 RMSE:0.5513 0.9143 0.8573 Tau:0.7139 0.4431 0.2105\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 257 Step: 20817 Index:-0.7125 R2:0.7025 0.3015 0.4186 RMSE:0.7645 1.1024 1.0041 Tau:0.6386 0.3899 0.1835\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 258 Step: 20898 Index:-0.5221 R2:0.7729 0.3210 0.4435 RMSE:0.5739 0.9375 0.8402 Tau:0.6902 0.4154 0.2113\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 259 Step: 20979 Index:-0.5038 R2:0.8026 0.3613 0.4591 RMSE:0.5689 0.9392 0.8639 Tau:0.7162 0.4354 0.2083\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 260 Step: 21060 Index:-0.4846 R2:0.7915 0.3531 0.4559 RMSE:0.5285 0.9189 0.8363 Tau:0.7090 0.4343 0.2087\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 261 Step: 21141 Index:-0.5068 R2:0.8029 0.3552 0.4542 RMSE:0.5548 0.9394 0.8529 Tau:0.7181 0.4326 0.2035\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 262 Step: 21222 Index:-0.5067 R2:0.8055 0.3359 0.4619 RMSE:0.5079 0.9318 0.8290 Tau:0.7231 0.4252 0.2054\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 263 Step: 21303 Index:-0.4765 R2:0.8051 0.3637 0.4446 RMSE:0.5274 0.9144 0.8496 Tau:0.7195 0.4379 0.2095\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 264 Step: 21384 Index:-0.4654 R2:0.8037 0.3651 0.4396 RMSE:0.4992 0.9025 0.8373 Tau:0.7204 0.4371 0.2110\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 265 Step: 21465 Index:-0.7995 R2:0.5701 0.2138 0.2725 RMSE:0.8943 1.1069 1.0562 Tau:0.5479 0.3074 0.1932\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 266 Step: 21546 Index:-0.5121 R2:0.7728 0.3342 0.4414 RMSE:0.5717 0.9264 0.8376 Tau:0.6924 0.4143 0.2110\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 267 Step: 21627 Index:-0.5063 R2:0.7872 0.3348 0.4390 RMSE:0.5257 0.9280 0.8445 Tau:0.7085 0.4217 0.2056\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 268 Step: 21708 Index:-0.4647 R2:0.7980 0.3621 0.4403 RMSE:0.5138 0.9021 0.8335 Tau:0.7129 0.4374 0.2072\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 269 Step: 21789 Index:-0.5013 R2:0.8043 0.3639 0.4436 RMSE:0.5793 0.9402 0.8797 Tau:0.7210 0.4389 0.2165\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 270 Step: 21870 Index:-0.4850 R2:0.8110 0.3470 0.4337 RMSE:0.5164 0.9254 0.8543 Tau:0.7250 0.4404 0.2095\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 271 Step: 21951 Index:-0.5381 R2:0.7909 0.3153 0.4497 RMSE:0.5160 0.9542 0.8380 Tau:0.7116 0.4161 0.2056\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 272 Step: 22032 Index:-0.4716 R2:0.8086 0.3506 0.4483 RMSE:0.4939 0.9108 0.8327 Tau:0.7264 0.4393 0.2159\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 273 Step: 22113 Index:-0.5061 R2:0.7930 0.3313 0.4373 RMSE:0.5333 0.9358 0.8518 Tau:0.7053 0.4297 0.2162\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 274 Step: 22194 Index:-0.4829 R2:0.8132 0.3451 0.4567 RMSE:0.4898 0.9145 0.8237 Tau:0.7253 0.4316 0.2087\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 275 Step: 22275 Index:-0.4429 R2:0.8134 0.3708 0.4409 RMSE:0.4934 0.8987 0.8416 Tau:0.7244 0.4558 0.2195\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 276 Step: 22356 Index:-0.5058 R2:0.7939 0.3484 0.4186 RMSE:0.5326 0.9375 0.8817 Tau:0.7090 0.4316 0.1997\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 277 Step: 22437 Index:-0.4931 R2:0.8141 0.3659 0.4446 RMSE:0.5431 0.9342 0.8766 Tau:0.7274 0.4411 0.2127\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 278 Step: 22518 Index:-0.4546 R2:0.8104 0.3713 0.4397 RMSE:0.4927 0.9056 0.8510 Tau:0.7239 0.4510 0.2090\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 279 Step: 22599 Index:-0.4749 R2:0.8154 0.3414 0.4416 RMSE:0.4886 0.9136 0.8317 Tau:0.7315 0.4388 0.2147\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 280 Step: 22680 Index:-0.5201 R2:0.8123 0.3469 0.4440 RMSE:0.5573 0.9557 0.8830 Tau:0.7221 0.4356 0.2170\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 281 Step: 22761 Index:-0.5533 R2:0.8166 0.3454 0.4426 RMSE:0.5950 0.9821 0.9068 Tau:0.7283 0.4288 0.1989\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 282 Step: 22842 Index:-0.4758 R2:0.8101 0.3533 0.4446 RMSE:0.5407 0.9229 0.8622 Tau:0.7242 0.4470 0.2006\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 283 Step: 22923 Index:-0.5062 R2:0.8012 0.3527 0.4402 RMSE:0.5733 0.9434 0.8798 Tau:0.7157 0.4373 0.1888\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 284 Step: 23004 Index:-0.5202 R2:0.7741 0.3064 0.4353 RMSE:0.5419 0.9367 0.8376 Tau:0.6991 0.4166 0.2028\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 285 Step: 23085 Index:-0.4914 R2:0.7999 0.3414 0.4460 RMSE:0.5369 0.9304 0.8532 Tau:0.7164 0.4389 0.2037\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 286 Step: 23166 Index:-0.4689 R2:0.8123 0.3485 0.4368 RMSE:0.4909 0.9093 0.8388 Tau:0.7288 0.4404 0.1966\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 287 Step: 23247 Index:-0.4752 R2:0.8052 0.3452 0.4604 RMSE:0.4973 0.9161 0.8282 Tau:0.7195 0.4409 0.2040\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 288 Step: 23328 Index:-0.4486 R2:0.8159 0.3667 0.4516 RMSE:0.4956 0.9047 0.8405 Tau:0.7297 0.4561 0.2109\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 289 Step: 23409 Index:-0.4804 R2:0.8198 0.3446 0.4452 RMSE:0.4808 0.9178 0.8359 Tau:0.7332 0.4374 0.1936\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 290 Step: 23490 Index:-0.5306 R2:0.8127 0.3354 0.4455 RMSE:0.5610 0.9644 0.8868 Tau:0.7243 0.4338 0.2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 291 Step: 23571 Index:-0.4346 R2:0.8191 0.3806 0.4379 RMSE:0.4817 0.8930 0.8557 Tau:0.7300 0.4584 0.2046\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 292 Step: 23652 Index:-0.4886 R2:0.8235 0.3411 0.4453 RMSE:0.4741 0.9230 0.8418 Tau:0.7375 0.4345 0.2082\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 293 Step: 23733 Index:-0.5215 R2:0.8217 0.3298 0.4431 RMSE:0.4853 0.9425 0.8512 Tau:0.7365 0.4210 0.1950\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 294 Step: 23814 Index:-0.4989 R2:0.8205 0.3525 0.4482 RMSE:0.4943 0.9375 0.8649 Tau:0.7298 0.4386 0.2092\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 295 Step: 23895 Index:-0.5138 R2:0.8077 0.3208 0.4303 RMSE:0.5084 0.9358 0.8528 Tau:0.7221 0.4220 0.2183\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 296 Step: 23976 Index:-0.5013 R2:0.8204 0.3340 0.4629 RMSE:0.4802 0.9324 0.8266 Tau:0.7298 0.4311 0.2030\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 297 Step: 24057 Index:-0.5170 R2:0.8231 0.3556 0.4396 RMSE:0.5676 0.9627 0.9018 Tau:0.7340 0.4457 0.2025\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 298 Step: 24138 Index:-0.4778 R2:0.8197 0.3573 0.4530 RMSE:0.5012 0.9162 0.8389 Tau:0.7334 0.4384 0.2032\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 299 Step: 24219 Index:-0.4984 R2:0.8249 0.3362 0.4315 RMSE:0.4859 0.9287 0.8565 Tau:0.7363 0.4303 0.1984\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 300 Step: 24300 Index:-0.5155 R2:0.8239 0.3306 0.4514 RMSE:0.4805 0.9361 0.8386 Tau:0.7349 0.4206 0.2124\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 301 Step: 24381 Index:-0.4573 R2:0.8204 0.3650 0.4364 RMSE:0.4852 0.8990 0.8454 Tau:0.7340 0.4417 0.2013\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 302 Step: 24462 Index:-0.4871 R2:0.8234 0.3597 0.4441 RMSE:0.5115 0.9275 0.8657 Tau:0.7379 0.4404 0.2169\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 303 Step: 24543 Index:-0.4763 R2:0.8259 0.3435 0.4434 RMSE:0.4755 0.9145 0.8387 Tau:0.7353 0.4383 0.2070\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 304 Step: 24624 Index:-0.5013 R2:0.8321 0.3458 0.4498 RMSE:0.4829 0.9323 0.8425 Tau:0.7435 0.4310 0.2109\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 305 Step: 24705 Index:-0.4833 R2:0.8282 0.3473 0.4480 RMSE:0.4728 0.9200 0.8448 Tau:0.7418 0.4366 0.1919\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 306 Step: 24786 Index:-0.5031 R2:0.8267 0.3437 0.4460 RMSE:0.4855 0.9339 0.8558 Tau:0.7352 0.4308 0.2107\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 307 Step: 24867 Index:-0.4723 R2:0.8330 0.3517 0.4448 RMSE:0.4644 0.9141 0.8388 Tau:0.7431 0.4417 0.2132\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 308 Step: 24948 Index:-0.5003 R2:0.8178 0.3573 0.4296 RMSE:0.5135 0.9318 0.8786 Tau:0.7306 0.4315 0.2127\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 309 Step: 25029 Index:-0.5097 R2:0.8239 0.3417 0.4625 RMSE:0.5019 0.9401 0.8455 Tau:0.7372 0.4305 0.1949\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 310 Step: 25110 Index:-0.4720 R2:0.8266 0.3468 0.4335 RMSE:0.4830 0.9104 0.8391 Tau:0.7357 0.4384 0.2194\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 311 Step: 25191 Index:-0.5017 R2:0.8279 0.3340 0.4257 RMSE:0.4765 0.9339 0.8572 Tau:0.7371 0.4321 0.2093\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau \n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 311 r2:0.4369 RMSE:0.8316 WTI:0.2712 AP:0.3196 Tau:0.2031 \n",
      " \n",
      " Top-1:0.3750 Top-1-fp:0.3750 \n",
      " Top-5:0.3750 Top-5-fp:0.5250 \n",
      " Top-10:0.3704 Top-10-fp:0.5679 \n",
      " Top-15:0.3852 Top-15-fp:0.5984 \n",
      " Top-20:0.3733 Top-20-fp:0.6543 \n",
      " Top-25:0.4467 Top-25-fp:0.6700 \n",
      " Top-30:0.5000 Top-30-fp:0.6926 \n",
      " Top-40:0.5800 Top-40-fp:0.7323 \n",
      " Top-50:0.6933 Top-50-fp:0.7445 \n",
      " \n",
      " Top50:0.4000 Top50-fp:0.5200 \n",
      " Top100:0.3800 Top100-fp:0.5800 \n",
      " Top150:0.3600 Top150-fp:0.6400 \n",
      " Top200:0.4467 Top200-fp:0.6650 \n",
      " Top250:0.5133 Top250-fp:0.6920 \n",
      " Top300:0.5600 Top300-fp:0.7200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
