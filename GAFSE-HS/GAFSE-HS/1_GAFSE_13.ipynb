{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "torch.manual_seed(8)\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP.AttentiveLayers_Sim_copy import Fingerprint, GRN, AFSE\n",
    "from AttentiveFP import Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set()\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "from AttentiveFP.utils import EarlyStopping\n",
    "from AttentiveFP.utils import Meter\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import AttentiveFP.Featurizer\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC50_P34972_3_300\n",
      "model_file/1_GAFSE_EC50_P34972_3_300_run_0\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/benchmark/EC50_P34972_3_300_train.csv\"\n",
    "test_filename = \"./data/benchmark/EC50_P34972_3_300_test.csv\"\n",
    "test_active = 300\n",
    "val_rate = 0.2\n",
    "random_seed = 68\n",
    "file_list1 = train_filename.split('/')\n",
    "file1 = file_list1[-1]\n",
    "file1 = file1[:-10]\n",
    "number = '_run_0'\n",
    "model_file = \"model_file/1_GAFSE_\"+file1+number\n",
    "log_dir = f'log/{\"1_GAFSE_\"+file1}'+number\n",
    "result_dir = './result/1_GAFSE_'+file1+number\n",
    "print(file1)\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              smiles     value\n",
      "0  CC1=NN=C(O1)C(C2(COC2)C)NC(=O)C3=NC=C(C(=C3)OC... -2.998869\n",
      "1  CCCC1=CC=C(C=C1)C(=O)C2=CC(=C(C(=C2)O)C3=CC(=C... -1.460898\n",
      "2  CC1=NC(=NO1)C(C)(CC2CC2)NC(=O)C3=NC=C(C(=C3)OC... -1.683947\n",
      "3  CC(C)(C)C1=NC2=C(N1CC3CCOCC3)C=CC(=C2)S(=O)(=O...  0.301030\n",
      "4  C1CN(CCC1NC2=NC=NC3=C2C=C(C=C3)C(C4=CC=C(C=C4)... -3.500236\n",
      "number of all smiles:  650\n",
      "number of successfully processed smiles:  650\n",
      "                                              smiles     value  \\\n",
      "0  CC1=NN=C(O1)C(C2(COC2)C)NC(=O)C3=NC=C(C(=C3)OC... -2.998869   \n",
      "1  CCCC1=CC=C(C=C1)C(=O)C2=CC(=C(C(=C2)O)C3=CC(=C... -1.460898   \n",
      "2  CC1=NC(=NO1)C(C)(CC2CC2)NC(=O)C3=NC=C(C(=C3)OC... -1.683947   \n",
      "3  CC(C)(C)C1=NC2=C(N1CC3CCOCC3)C=CC(=C2)S(=O)(=O...  0.301030   \n",
      "4  C1CN(CCC1NC2=NC=NC3=C2C=C(C=C3)C(C4=CC=C(C=C4)... -3.500236   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  Cc1nnc(C(NC(=O)c2cc(OCC(F)(F)F)c(C3CC3)cn2)C2(...  \n",
      "1  CCCc1ccc(C(=O)c2cc(O)c(-c3cc(Cl)cc(Cl)c3)c(O)c...  \n",
      "2  Cc1nc(C(C)(CC2CC2)NC(=O)c2cc(OCC(F)(F)F)c(Cl)c...  \n",
      "3  COCCCOc1cc(S(=O)(=O)c2ccc3c(c2)nc(C(C)(C)C)n3C...  \n",
      "4  O=C(O)c1cccc(N2CCC(Nc3ncnc4ccc(C(c5ccc(Cl)cc5)...  \n"
     ]
    }
   ],
   "source": [
    "# task_name = 'Malaria Bioactivity'\n",
    "tasks = ['value']\n",
    "\n",
    "# train_filename = \"../data/active_inactive/median_active/EC50/Q99500.csv\"\n",
    "feature_filename = train_filename.replace('.csv','.pickle')\n",
    "filename = train_filename.replace('.csv','')\n",
    "prefix_filename = train_filename.split('/')[-1].replace('.csv','')\n",
    "train_df = pd.read_csv(train_filename, header=0, names = [\"smiles\",\"value\"],usecols=[0,1])\n",
    "# train_df = train_df[1:]\n",
    "# train_df = train_df.drop(0,axis=1,inplace=False) \n",
    "print(train_df[:5])\n",
    "# print(train_df.iloc(1))\n",
    "def add_canonical_smiles(train_df):\n",
    "    smilesList = train_df.smiles.values\n",
    "    print(\"number of all smiles: \",len(smilesList))\n",
    "    atom_num_dist = []\n",
    "    remained_smiles = []\n",
    "    canonical_smiles_list = []\n",
    "    for smiles in smilesList:\n",
    "        try:        \n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            atom_num_dist.append(len(mol.GetAtoms()))\n",
    "            remained_smiles.append(smiles)\n",
    "            canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "        except:\n",
    "            print(smiles)\n",
    "            pass\n",
    "    print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "    train_df = train_df[train_df[\"smiles\"].isin(remained_smiles)]\n",
    "    train_df['cano_smiles'] =canonical_smiles_list\n",
    "    return train_df\n",
    "# print(train_df)\n",
    "train_df = add_canonical_smiles(train_df)\n",
    "\n",
    "print(train_df.head())\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.set(font_scale=1.5)\n",
    "# ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "# plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "p_dropout= 0.03\n",
    "fingerprint_dim = 100\n",
    "\n",
    "weight_decay = 4.3 # also known as l2_regularization_lambda\n",
    "learning_rate = 4\n",
    "radius = 2 # default: 2\n",
    "T = 1\n",
    "per_task_output_units_num = 1 # for regression model\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  983\n",
      "number of successfully processed smiles:  983\n",
      "(983, 3)\n",
      "                                              smiles     value  \\\n",
      "0  CNC(=O)CC(CCC1=CC=CC=C1)NC(=O)C2=NC(=C(C=C2)N3... -2.478566   \n",
      "1  CC(C)(C)C1=NC2=C(N1CC3CCN(CC3)C=O)C=CC(=C2)S(=... -0.342423   \n",
      "2       CC(C)(C)C1=NOC(=C1)NC(=O)C2CC(CN2CC3CCOCC3)O -2.845098   \n",
      "3  C1CC1C2=CN=C(C=C2OCC(F)(F)F)C(=O)N3CC(CC3C(=O)... -3.101541   \n",
      "4  C1C(N(CC1(F)F)C(=O)C2=NC(=C(C=C2)N3CC(C3)(F)F)... -3.067071   \n",
      "\n",
      "                                         cano_smiles  \n",
      "0  CNC(=O)CC(CCc1ccccc1)NC(=O)c1ccc(N2CC(F)(F)C2)...  \n",
      "1  CC(C)(C)c1nc2cc(S(=O)(=O)CC3CC3)ccc2n1CC1CCN(C...  \n",
      "2         CC(C)(C)c1cc(NC(=O)C2CC(O)CN2CC2CCOCC2)on1  \n",
      "3  NC(=O)C1CC(F)(F)CN1C(=O)c1cc(OCC(F)(F)F)c(C2CC...  \n",
      "4  NC(=O)C1CC(F)(F)CN1C(=O)c1ccc(N2CC(F)(F)C2)c(O...  \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_filename,header=0,names=[\"smiles\",\"value\"],usecols=[0,1])\n",
    "test_df = add_canonical_smiles(test_df)\n",
    "for l in test_df[\"cano_smiles\"]:\n",
    "    if l in train_df[\"cano_smiles\"]:\n",
    "        print(\"same smiles:\",l)\n",
    "        \n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/benchmark/EC50_P34972_3_300_train.pickle\n",
      "./data/benchmark/EC50_P34972_3_300_train\n",
      "1633\n",
      "feature dicts file saved as ./data/benchmark/EC50_P34972_3_300_train.pickle\n"
     ]
    }
   ],
   "source": [
    "print(feature_filename)\n",
    "print(filename)\n",
    "total_df = pd.concat([train_df,test_df],axis=0)\n",
    "total_smilesList = total_df['smiles'].values\n",
    "print(len(total_smilesList))\n",
    "# if os.path.isfile(feature_filename):\n",
    "#     feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "# else:\n",
    "#     feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "feature_dicts = save_smiles_dicts(total_smilesList,filename)\n",
    "remained_df = total_df[total_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = total_df.drop(remained_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 3) (130, 3) (983, 3)\n"
     ]
    }
   ],
   "source": [
    "val_df = train_df.sample(frac=val_rate,random_state=random_seed)\n",
    "train_df = train_df.drop(val_df.index)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df[val_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df[test_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([total_df[\"cano_smiles\"].values[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "amodel = AFSE(fingerprint_dim, output_units_num, p_dropout)\n",
    "gmodel = GRN(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, p_dropout)\n",
    "model.cuda()\n",
    "amodel.cuda()\n",
    "gmodel.cuda()\n",
    "\n",
    "# optimizer = optim.Adam([\n",
    "# {'params': model.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# {'params': gmodel.parameters(), 'lr': 10**(-learning_rate), 'weight_decay ': 10**-weight_decay}, \n",
    "# ])\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "optimizer_AFSE = optim.Adam(params=amodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# optimizer_AFSE = optim.SGD(params=amodel.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "optimizer_GRN = optim.Adam(params=gmodel.parameters(), lr=10**(-learning_rate), weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad:\n",
    "#         print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sorted_show_pik(dataset, p, k, k_predict, i, acc):\n",
    "    p_value = dataset[tasks[0]].astype(float).tolist()\n",
    "    x = np.arange(0,len(dataset),1)\n",
    "#     print('plt',dataset.head(),p[:10],k_predict,k)\n",
    "#     plt.figure()\n",
    "#     fig, ax1 = plt.subplots()\n",
    "#     ax1.grid(False)\n",
    "#     ax2 = ax1.twinx()\n",
    "#     plt.grid(False)\n",
    "    plt.scatter(x,p,marker='.',s=6,color='r',label='predict')\n",
    "#     plt.ylabel('predict')\n",
    "    plt.scatter(x,p_value,s=6,marker=',',color='blue',label='p_value')\n",
    "    plt.axvline(x=k-1,ls=\"-\",c=\"black\")#添加垂直直线\n",
    "    k_value = np.ones(len(dataset))\n",
    "# #     print(EC50[k-1])\n",
    "    k_value = k_value*k_predict\n",
    "    plt.plot(x,k_value,'-',color='black')\n",
    "    plt.ylabel('p_value')\n",
    "    plt.title(\"epoch: {},  top-k recall: {}\".format(i,acc))\n",
    "    plt.legend(loc=3,fontsize=5)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def topk_acc2(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "    \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    k_true = true_sort[tasks[0]].values[k-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('k_true: ',type(k_true),k_true)\n",
    "#     print('k_true: ',k_true,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=k_true,'acc_num: ',len(df3[df3['predict'].values>=k_true]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k)\n",
    "    acc = len(df3[df3[tasks[0]].values>=k_true])/k #预测值前k个中真实排在前k个的个数/k\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/k\n",
    "    if k>active_num:\n",
    "        min_active = true_sort[tasks[0]].values[active_num-1]\n",
    "        acc = len(df3[df3[tasks[0]].values>=min_active])/k\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "def topk_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    df['predict'] = predict\n",
    "    df2 = df.sort_values(by='predict',ascending=False) # 拼接预测值后对预测值进行排序\n",
    "#     print('df2:\\n',df2)\n",
    "        \n",
    "    df3 = df2[:k]  #取按预测值排完序后的前k个，因为后面的全是-4.1\n",
    "    \n",
    "    true_sort = df.sort_values(by=tasks[0],ascending=False) #返回一个新的按真实值排序列表\n",
    "    min_active = true_sort[tasks[0]].values[active_num-1]  # 真实排第k个的活性值\n",
    "#     print('df3:\\n',df3['predict'])\n",
    "#     print('min_active: ',type(min_active),min_active)\n",
    "#     print('min_active: ',min_active,'min_predict: ',df3['predict'].values[-1],'index: ',df3['predict'].values>=min_active,'acc_num: ',len(df3[df3['predict'].values>=min_active]),\n",
    "#           'fp_num: ',len(df3[df3['predict'].values>=-4.1]),'k: ',k,'active_num: ',active_num)\n",
    "    acc = len(df3[df3[tasks[0]].values>-4.1])/active_num #预测值前k个中真实排在前active_num个的个数/active_num\n",
    "    fp = len(df3[df3[tasks[0]].values==-4.1])/k  #预测值前k个中为-4.1的个数/active_num\n",
    "    \n",
    "    if(show_flag):\n",
    "        #进来的是按实际活性值排好序的\n",
    "        sorted_show_pik(true_sort,true_sort['predict'],k,k_predict,i,acc)\n",
    "    return acc,fp\n",
    "\n",
    "    \n",
    "def topk_acc_recall(df, predict, k, active_num, show_flag=False, i=0):\n",
    "    if k>active_num:\n",
    "        return topk_recall(df, predict, k, active_num, show_flag, i)\n",
    "    return topk_acc2(df,predict,k, active_num,show_flag,i)\n",
    "\n",
    "def weighted_top_index(df, predict, active_num):\n",
    "    weighted_acc_list=[]\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        acc, fp = topk_acc_recall(df, predict, k, active_num)\n",
    "        weight = (len(df)-k)/len(df)\n",
    "#         print('weight=',weight,'acc=',acc)\n",
    "        weighted_acc_list.append(acc*weight)#\n",
    "    weighted_acc_list = np.array(weighted_acc_list)\n",
    "#     print('weighted_acc_list=',weighted_acc_list)\n",
    "    return np.sum(weighted_acc_list)/weighted_acc_list.shape[0]\n",
    "\n",
    "def AP(df, predict, active_num):\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for k in np.arange(1,len(df)+1,1):\n",
    "        prec_k, fp1 = topk_acc2(df,predict,k, active_num)\n",
    "        rec_k, fp2 = topk_recall(df, predict, k, active_num)\n",
    "        prec.append(prec_k)\n",
    "        rec.append(rec_k)\n",
    "    # 取所有不同的recall对应的点处的精度值做平均\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # 计算包络线，从后往前取最大保证precise非减\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # 找出所有检测结果中recall不同的点\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "#     print(prec)\n",
    "#     print('prec='+str(prec)+'\\n\\n'+'rec='+str(rec))\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    # 用recall的间隔对精度作加权平均\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_r2(y,predict):\n",
    "#     print(y)\n",
    "#     print(predict)\n",
    "    y = torch.FloatTensor(y).reshape(-1,1)\n",
    "    predict = torch.FloatTensor(predict).reshape(-1,1)\n",
    "    y_mean = torch.mean(y)\n",
    "    predict_mean = torch.mean(predict)\n",
    "    \n",
    "    y1 = torch.pow(torch.mm((y-y_mean).t(),(predict-predict_mean)),2)\n",
    "    y2 = torch.mm((y-y_mean).t(),(y-y_mean))*torch.mm((predict-predict_mean).t(),(predict-predict_mean))\n",
    "#     print(y1,y2)\n",
    "    return y1/y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def l2_norm(input, dim):\n",
    "    norm = torch.norm(input, dim=dim, keepdim=True)\n",
    "    output = torch.div(input, norm+1e-6)\n",
    "    return output\n",
    "\n",
    "def normalize_perturbation(d,dim=-1):\n",
    "    output = l2_norm(d, dim)\n",
    "    return output\n",
    "\n",
    "def tanh(x):\n",
    "    return (torch.exp(x)-torch.exp(-x))/(torch.exp(x)+torch.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def perturb_feature(f, model, alpha=1, lamda=10**-learning_rate, output_lr=False, output_plr=False, y=None):\n",
    "    mol_prediction = model(feature=f, d=0)\n",
    "    pred = mol_prediction.detach()\n",
    "#     f = torch.div(f, torch.norm(f, dim=-1, keepdim=True)+1e-9)\n",
    "    eps = 1e-6 * normalize_perturbation(torch.randn(f.shape))\n",
    "    eps = Variable(eps, requires_grad=True)\n",
    "    # Predict on randomly perturbed image\n",
    "    eps_p = model(feature=f, d=eps.cuda())\n",
    "    eps_p_ = model(feature=f, d=-eps.cuda())\n",
    "    p_aux = nn.Sigmoid()(eps_p/(pred+1e-6))\n",
    "    p_aux_ = nn.Sigmoid()(eps_p_/(pred+1e-6))\n",
    "#     loss = nn.BCELoss()(abs(p_aux),torch.ones_like(p_aux))+nn.BCELoss()(abs(p_aux_),torch.ones_like(p_aux_))\n",
    "    loss = loss_function(p_aux,torch.ones_like(p_aux))+loss_function(p_aux_,torch.ones_like(p_aux_))\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    # Based on perturbed image, get direction of greatest error\n",
    "    eps_adv = eps.grad#/10**-learning_rate\n",
    "    optimizer_AFSE.zero_grad()\n",
    "    # Use that direction as adversarial perturbation\n",
    "    eps_adv_normed = normalize_perturbation(eps_adv)\n",
    "    d_adv = lamda * eps_adv_normed.cuda()\n",
    "    if output_lr:\n",
    "        f_p, max_lr = model(feature=f, d=d_adv, output_lr=output_lr)\n",
    "    f_p = model(feature=f, d=d_adv)\n",
    "    f_p_ = model(feature=f, d=-d_adv)\n",
    "    p = nn.Sigmoid()(f_p/(pred+1e-6))\n",
    "    p_ = nn.Sigmoid()(f_p_/(pred+1e-6))\n",
    "    vat_loss = loss_function(p,torch.ones_like(p))+loss_function(p_,torch.ones_like(p_))\n",
    "    if output_lr:\n",
    "        if output_plr:\n",
    "            loss = loss_function(mol_prediction,y)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer_AFSE.zero_grad()\n",
    "            punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "            return eps_adv, d_adv, vat_loss, mol_prediction, max_lr, punish_lr\n",
    "        return eps_adv, d_adv, vat_loss, mol_prediction, max_lr\n",
    "    return eps_adv, d_adv, vat_loss, mol_prediction\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "\n",
    "def d_loss(f, pred, model, y_val):\n",
    "    diff_loss = 0\n",
    "    length = len(pred)\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if j == i:\n",
    "                continue\n",
    "            pred_diff = model(feature_only=True, feature1=f[i], feature2=f[j])\n",
    "            true_diff = y_val[i] - y_val[j]\n",
    "            diff_loss += loss_function(pred_diff, torch.Tensor([true_diff]).view(-1,1))\n",
    "    diff_loss = diff_loss/(length*(length-1))\n",
    "    return diff_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(x,y):\n",
    "    c = 0\n",
    "    l = len(y)\n",
    "    for i in range(l):\n",
    "        if y[i]==1:\n",
    "            c += 1\n",
    "    w1 = (l-c)/l\n",
    "    w0 = c/l\n",
    "    loss = -w1*y*torch.log(x+1e-6)-w0*(1-y)*torch.log(1-x+1e-6)\n",
    "    loss = loss.mean(-1)\n",
    "    return loss\n",
    "\n",
    "def weighted_CE_loss(x,y):\n",
    "    weight = 1/(y.detach().float().mean(0)+1e-9)\n",
    "    weighted_CE = nn.CrossEntropyLoss(weight=weight)\n",
    "#     atom_weights = (atom_weights-min(atom_weights))/(max(atom_weights)-min(atom_weights))\n",
    "    return weighted_CE(x, torch.argmax(y,-1))\n",
    "\n",
    "def generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list):\n",
    "    [a,b,c] = x_atom.shape\n",
    "    [d,e,f,g] = bond_neighbor.shape\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    one_hot_loss = 0\n",
    "    interger_loss = 0\n",
    "    binary_loss = 0\n",
    "    counter_i = 0\n",
    "    counter_j = 0\n",
    "    validity_mask = torch.from_numpy(validity_mask).cuda()\n",
    "    for i in range(a):\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        one_hot_loss += weighted_CE_loss(refer_atom_list[i,:l,:16], x_atom[i,:l,:16]) - \\\n",
    "                        ((validity_mask[i,:l]*torch.log(1-atom_list[i,:l,:16]+1e-6)).sum(-1)/(validity_mask[i,:l].sum(-1)+1e-9)).mean(-1).mean(-1)+\\\n",
    "                         weighted_CE_loss(atom_list[i,:l,16:22], x_atom[i,:l,16:22])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,24:30], x_atom[i,:l,24:30])+ \\\n",
    "                         weighted_CE_loss(atom_list[i,:l,31:36], x_atom[i,:l,31:36])\n",
    "        interger_loss += loss_function(atom_list[i,:l,23], x_atom[i,:l,23])+ \\\n",
    "                        loss_function(atom_list[i,:l,24], x_atom[i,:l,24])\n",
    "        binary_loss += CE(atom_list[i,:l,30], x_atom[i,:l,30])+ \\\n",
    "                        CE(atom_list[i,:l,36], x_atom[i,:l,36])+ \\\n",
    "                        CE(atom_list[i,:l,37], x_atom[i,:l,37])+ \\\n",
    "                        CE(atom_list[i,:l,38], x_atom[i,:l,38])\n",
    "        counter_i += 1\n",
    "        for j in range(l):\n",
    "            n = (bond_neighbor[i,j].sum(-1)!=0).sum(-1)\n",
    "            if n==0:\n",
    "                continue\n",
    "            one_hot_loss += weighted_CE_loss(bond_list[i,j,:n,:4], bond_neighbor[i,j,:n,:4])+ \\\n",
    "                             weighted_CE_loss(bond_list[i,j,:n,6:], bond_neighbor[i,j,:n,6:])\n",
    "            binary_loss += CE(bond_neighbor[i,j,:n,4], bond_list[i,j,:n,4])+ \\\n",
    "                           CE(bond_neighbor[i,j,:n,5], bond_list[i,j,:n,5])\n",
    "            counter_j += 1\n",
    "    one_hot_loss = one_hot_loss/(5*counter_i+2*counter_j)\n",
    "    interger_loss = interger_loss/(2*counter_i)\n",
    "    binary_loss = binary_loss/(4*counter_i+2*counter_j)\n",
    "    total_loss = (one_hot_loss + interger_loss + binary_loss)/3\n",
    "    return total_loss, one_hot_loss, interger_loss, binary_loss\n",
    "\n",
    "\n",
    "def train(model, amodel, gmodel, dataset, test_df, optimizer_list, loss_function, epoch):\n",
    "    model.train()\n",
    "    amodel.train()\n",
    "    gmodel.train()\n",
    "    optimizer, optimizer_AFSE, optimizer_GRN = optimizer_list\n",
    "    np.random.seed(epoch)\n",
    "    max_len = np.max([len(dataset),len(test_df)])\n",
    "    valList = np.arange(0,max_len)\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, max_len, batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[batch%len(dataset),:]\n",
    "        batch_test = test_df.loc[batch%len(test_df),:]\n",
    "        global_step = epoch * len(batch_list) + counter\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        smiles_list_test = batch_test.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        x_atom_test, x_bonds_test, x_atom_index_test, x_bond_index_test, x_mask_test, smiles_to_rdkit_list_test = get_smiles_array(smiles_list_test,feature_dicts)\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),\n",
    "                                                  torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),\n",
    "                                                  mol_feature=mol_feature,activated_features=activated_features.detach())\n",
    "        \n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        \n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        eps_adv, d_adv, vat_loss, mol_prediction, conv_lr, punish_lr = perturb_feature(mol_feature, amodel, alpha=1, \n",
    "                                                                                       lamda=10**-learning_rate, output_lr=True, \n",
    "                                                                                       output_plr=True, y=torch.Tensor(y_val).view(-1,1)) # 10**-learning_rate     \n",
    "        regression_loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "#         atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "#                                       torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/1e-6,activated_features=activated_features.detach())\n",
    "#         success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(smiles_list, x_atom, \n",
    "#                             bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "#                                                      refer_atom_list, refer_bond_list,topn=1)\n",
    "#         reconstruction_loss, one_hot_loss, interger_loss,binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, \n",
    "#                                                                                               bond_neighbor, validity_mask, atom_list, \n",
    "#                                                                                               bond_list)\n",
    "        x_atom_test = torch.Tensor(x_atom_test)\n",
    "        x_bonds_test = torch.Tensor(x_bonds_test)\n",
    "        x_bond_index_test = torch.cuda.LongTensor(x_bond_index_test)\n",
    "        \n",
    "        bond_neighbor_test = [x_bonds_test[i][x_bond_index_test[i]] for i in range(len(batch_test))]\n",
    "        bond_neighbor_test = torch.stack(bond_neighbor_test, dim=0)\n",
    "        activated_features_test, mol_feature_test = model(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "                                                          torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),\n",
    "                                                          torch.Tensor(x_mask_test),output_activated_features=True)\n",
    "#         mol_feature_test = torch.div(mol_feature_test, torch.norm(mol_feature_test, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features_test = torch.div(activated_features_test, torch.norm(activated_features_test, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_test, d_test, test_vat_loss, mol_prediction_test = perturb_feature(mol_feature_test, amodel, \n",
    "                                                                                    alpha=1, lamda=10**-learning_rate)\n",
    "#         atom_list_test, bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),torch.cuda.LongTensor(x_atom_index_test),\n",
    "#                                                 torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                 mol_feature=mol_feature_test+d_test/1e-6,activated_features=activated_features_test.detach())\n",
    "#         refer_atom_list_test, refer_bond_list_test = gmodel(torch.Tensor(x_atom_test),torch.Tensor(x_bonds_test),\n",
    "#                                                             torch.cuda.LongTensor(x_atom_index_test),torch.cuda.LongTensor(x_bond_index_test),torch.Tensor(x_mask_test),\n",
    "#                                                             mol_feature=mol_feature_test,activated_features=activated_features_test.detach())\n",
    "#         success_smiles_batch_test, modified_smiles_test, success_batch_test, total_batch_test, reconstruction_test, validity_test, validity_mask_test = modify_atoms(smiles_list_test, x_atom_test, \n",
    "#                             bond_neighbor_test, atom_list_test, bond_list_test,smiles_list_test,smiles_to_rdkit_list_test,\n",
    "#                                                      refer_atom_list_test, refer_bond_list_test,topn=1)\n",
    "#         test_reconstruction_loss, test_one_hot_loss, test_interger_loss,test_binary_loss = generate_loss_function(atom_list_test, x_atom_test, bond_list_test, bond_neighbor_test, validity_mask_test, atom_list_test, bond_list_test)\n",
    "        \n",
    "        if vat_loss>1 or test_vat_loss>1:\n",
    "            vat_loss = 1*(vat_loss/(vat_loss+1e-6).item())\n",
    "            test_vat_loss = 1*(test_vat_loss/(test_vat_loss+1e-6).item())\n",
    "        \n",
    "        max_lr = 1e-3\n",
    "        conv_lr = conv_lr - conv_lr**2 + 0.06 * punish_lr\n",
    "        if conv_lr < max_lr and conv_lr >= 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = conv_lr.detach()\n",
    "                AFSE_lr = conv_lr    \n",
    "        elif conv_lr < 0:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = 0\n",
    "                AFSE_lr = 0\n",
    "        elif conv_lr >= max_lr:\n",
    "            for param_group in optimizer_AFSE.param_groups:\n",
    "                param_group[\"lr\"] = max_lr\n",
    "                AFSE_lr = max_lr\n",
    "        \n",
    "        logger.add_scalar('loss/regression', regression_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE', vat_loss, global_step)\n",
    "        logger.add_scalar('loss/AFSE_test', test_vat_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN', reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_test', test_reconstruction_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_one_hot', one_hot_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_interger', interger_loss, global_step)\n",
    "#         logger.add_scalar('loss/GRN_binary', binary_loss, global_step)\n",
    "        logger.add_scalar('lr/max_lr', conv_lr, global_step)\n",
    "        logger.add_scalar('lr/punish_lr', punish_lr, global_step)\n",
    "        logger.add_scalar('lr/AFSE_lr', AFSE_lr, global_step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        optimizer_AFSE.zero_grad()\n",
    "#         optimizer_GRN.zero_grad()\n",
    "        loss =  regression_loss + 0.6*(vat_loss + test_vat_loss) # + reconstruction_loss + test_reconstruction_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_AFSE.step()\n",
    "#         optimizer_GRN.step()\n",
    "\n",
    "        \n",
    "def clear_atom_map(mol):\n",
    "    [a.ClearProp('molAtomMapNumber') for a  in mol.GetAtoms()]\n",
    "    return mol\n",
    "\n",
    "def mol_with_atom_index( mol ):\n",
    "    atoms = mol.GetNumAtoms()\n",
    "    for idx in range( atoms ):\n",
    "        mol.GetAtomWithIdx( idx ).SetProp( 'molAtomMapNumber', str( mol.GetAtomWithIdx( idx ).GetIdx() ) )\n",
    "    return mol\n",
    "        \n",
    "def modify_atoms(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list,refer_atom_list, refer_bond_list,topn=1,viz=False):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    refer_atom_list = refer_atom_list.cpu().detach().numpy()\n",
    "    refer_bond_list = refer_bond_list.cpu().detach().numpy()\n",
    "    atom_symbol_sorted = np.argsort(x_atom[:,:,:16], axis=-1)\n",
    "    atom_symbol_generated_sorted = np.argsort(atom_list[:,:,:16], axis=-1)\n",
    "    generate_confidence_sorted = np.sort(atom_list[:,:,:16], axis=-1)\n",
    "    modified_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    confidence_threshold = 0.001\n",
    "    validity_mask = np.zeros_like(atom_list[:,:,:16])\n",
    "    symbol_list = ['B','C','N','O','F','Si','P','S','Cl','As','Se','Br','Te','I','At','other']\n",
    "    symbol_to_rdkit = [4,6,7,8,9,14,15,16,17,33,34,35,52,53,85,0]\n",
    "    for i in range(len(atom_list)):\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        first_run_flag = True\n",
    "        l = (x_atom[i].sum(-1)!=0).sum(-1)\n",
    "        cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "        mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "        counter = 0\n",
    "        for j in range(l): \n",
    "            if mol.GetAtomWithIdx(int(smiles_to_rdkit_list[cano_smiles][j])).GetAtomicNum() == \\\n",
    "                symbol_to_rdkit[refer_atom_list[i,j,:16].argmax(-1)]:\n",
    "                counter += 1\n",
    "#             print(f'atom#{smiles_to_rdkit_list[cano_smiles][j]}(f):',{symbol_list[k]: np.around(refer_atom_list[i,j,k],3) for k in range(16)},\n",
    "#                   f'\\natom#{smiles_to_rdkit_list[cano_smiles][j]}(f+d):',{symbol_list[k]: np.around(atom_list[i,j,k],3) for k in range(16)},\n",
    "#                  '\\n------------------------------------------------------------------------------------------------------------')\n",
    "#         print('预测为每个原子的平均概率：\\n',np.around(atom_list[i,:l,:16].mean(1),2))\n",
    "#         print('预测为每个原子的最大概率：\\n',np.around(atom_list[i,:l,:16].max(1),2))\n",
    "        if counter == l:\n",
    "            success_reconstruction += 1\n",
    "        while not flag==topn:\n",
    "            if rank == 16:\n",
    "                rank = 0\n",
    "                top_idx += 1\n",
    "            if top_idx == l:\n",
    "#                 print('没有满足条件的分子生成。')\n",
    "                flag += 1\n",
    "                continue\n",
    "#             if np.sum((atom_symbol_sorted[i,:l,-1]!=atom_symbol_generated_sorted[i,:l,-1-rank]).astype(int))==0:\n",
    "#                 print(f'根据预测的第{rank}大概率的原子构成的分子与原分子一致，原子位重置为0，生成下一个元素……')\n",
    "#                 rank += 1\n",
    "#                 top_idx = 0\n",
    "#                 generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "#                                              x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "#             print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            if rank == 0:\n",
    "                generate_index = np.argsort((atom_list[i,:l,:16]-refer_atom_list[i,:l,:16] -\\\n",
    "                                             x_atom[i,:l,:16]).max(-1))[-1-top_idx]\n",
    "            atom_symbol_generated = np.argsort(atom_list[i,generate_index,:16]-\\\n",
    "                                                    refer_atom_list[i,generate_index,:16] -\\\n",
    "                                                    x_atom[i,generate_index,:16])[-1-rank]\n",
    "            if atom_symbol_generated==x_atom[i,generate_index,:16].argmax(-1):\n",
    "#                 print('生成了相同元素，生成下一个元素……')\n",
    "                rank += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            if np.sort(atom_list[i,generate_index,:16]-\\\n",
    "                refer_atom_list[i,generate_index,:16] -\\\n",
    "                x_atom[i,generate_index,:16])[-1-rank]<confidence_threshold:\n",
    "#                 print(f'原子位{generate_rdkit_index}生成{symbol_list[atom_symbol_generated]}元素的置信度小于{confidence_threshold}，寻找下一个原子位……')\n",
    "                top_idx += 1\n",
    "                rank = 0\n",
    "                continue\n",
    "#             if symbol_to_rdkit[atom_symbol_generated]==6:\n",
    "#                 print('生成了不推荐的C元素')\n",
    "#                 rank += 1\n",
    "#                 continue\n",
    "            mol.GetAtomWithIdx(int(generate_rdkit_index)).SetAtomicNum(symbol_to_rdkit[atom_symbol_generated])\n",
    "            print_mol = mol\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                if first_run_flag == True:\n",
    "                    success_validity += 1\n",
    "                total[flag] += 1\n",
    "                if Chem.MolToSmiles(clear_atom_map(print_mol))==y_smiles[i]:\n",
    "                    success[flag] +=1\n",
    "#                     print('Congratulations!', success, total)\n",
    "                    success_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "#                 print(\"修改前的分子：\", smiles[i])\n",
    "#                 display(mol_init)\n",
    "                modified_smiles.append(Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 print(f\"将第{generate_rdkit_index}个原子修改为{symbol_list[atom_symbol_generated]}的分子：\", Chem.MolToSmiles(clear_atom_map(print_mol)))\n",
    "#                 display(mol_with_atom_index(mol))\n",
    "                mol_y = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "#                 print(\"高活性分子：\", y_smiles[i])\n",
    "#                 display(mol_y)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "#                 print(f\"第{generate_rdkit_index}个原子符号修改为{symbol_list[atom_symbol_generated]}不符合规范，生成下一个元素……\")\n",
    "                validity_mask[i,generate_index,atom_symbol_generated] = 1\n",
    "                rank += 1\n",
    "                first_run_flag = False\n",
    "    return success_smiles, modified_smiles, success, total, success_reconstruction, success_validity, validity_mask\n",
    "\n",
    "def modify_bonds(smiles, x_atom, bond_neighbor, atom_list, bond_list, y_smiles, smiles_to_rdkit_list):\n",
    "    x_atom = x_atom.cpu().detach().numpy()\n",
    "    bond_neighbor = bond_neighbor.cpu().detach().numpy()\n",
    "    atom_list = atom_list.cpu().detach().numpy()\n",
    "    bond_list = bond_list.cpu().detach().numpy()\n",
    "    modified_smiles = []\n",
    "    for i in range(len(bond_neighbor)):\n",
    "        l = (bond_neighbor[i].sum(-1).sum(-1)!=0).sum(-1)\n",
    "        bond_type_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        bond_type_generated_sorted = np.argsort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        generate_confidence_sorted = np.sort(bond_list[i,:l,:,:4], axis=-1)\n",
    "        rank = 0\n",
    "        top_idx = 0\n",
    "        flag = 0\n",
    "        while not flag==3:\n",
    "            cano_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles[i]))\n",
    "            if np.sum((bond_type_sorted[i,:,-1]!=bond_type_generated_sorted[:,:,-1-rank]).astype(int))==0:\n",
    "                rank += 1\n",
    "                top_idx = 0\n",
    "            print('i:',i,'top_idx:', top_idx, 'rank:',rank)\n",
    "            bond_type = bond_type_sorted[i,:,-1]\n",
    "            bond_type_generated = bond_type_generated_sorted[:,:,-1-rank]\n",
    "            generate_confidence = generate_confidence_sorted[:,:,-1-rank]\n",
    "#             print(np.sort(generate_confidence + \\\n",
    "#                                     (atom_symbol!=atom_symbol_generated).astype(int), axis=-1))\n",
    "            generate_index = np.argsort(generate_confidence + \n",
    "                                (bond_type!=bond_type_generated).astype(int), axis=-1)[-1-top_idx]\n",
    "            bond_type_generated_one = bond_type_generated[generate_index]\n",
    "            mol = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "            if generate_index >= len(smiles_to_rdkit_list[cano_smiles]):\n",
    "                top_idx += 1\n",
    "                continue\n",
    "            generate_rdkit_index = smiles_to_rdkit_list[cano_smiles][generate_index]\n",
    "            mol.GetBondWithIdx(int(generate_rdkit_index)).SetBondType(bond_type_generated_one)\n",
    "            try:\n",
    "                Chem.SanitizeMol(mol)\n",
    "                mol_init = mol_with_atom_index(Chem.MolFromSmiles(smiles[i]))\n",
    "                print(\"修改前的分子：\")\n",
    "                display(mol_init)\n",
    "                modified_smiles.append(mol)\n",
    "                print(f\"将第{generate_rdkit_index}个键修改为{atom_symbol_generated}的分子：\")\n",
    "                display(mol)\n",
    "                mol = mol_with_atom_index(Chem.MolFromSmiles(y_smiles[i]))\n",
    "                print(\"高活性分子：\")\n",
    "                display(mol)\n",
    "                rank += 1\n",
    "                flag += 1\n",
    "            except:\n",
    "                print(f\"第{generate_rdkit_index}个原子符号修改为{atom_symbol_generated}不符合规范\")\n",
    "                top_idx += 1\n",
    "    return modified_smiles\n",
    "        \n",
    "def eval(model, amodel, gmodel, dataset, topn=1, output_feature=False, generate=False, modify_atom=True,return_GRN_loss=False, viz=False):\n",
    "    model.eval()\n",
    "    amodel.eval()\n",
    "    gmodel.eval()\n",
    "    predict_list = []\n",
    "    test_MSE_list = []\n",
    "    r2_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    feature_list = []\n",
    "    d_list = []\n",
    "    success = [0 for i in range(topn)]\n",
    "    total = [0 for i in range(topn)]\n",
    "    generated_smiles = []\n",
    "    success_smiles = []\n",
    "    success_reconstruction = 0\n",
    "    success_validity = 0\n",
    "    reconstruction_loss, one_hot_loss, interger_loss, binary_loss = [0,0,0,0]\n",
    "    \n",
    "# #     取dataset中排序后的第k个\n",
    "#     sorted_dataset = dataset.sort_values(by=tasks[0],ascending=False)\n",
    "#     k_df = sorted_dataset.iloc[[k-1]]\n",
    "#     k_smiles = k_df['cano_smiles'].values\n",
    "#     k_value = k_df[tasks[0]].values.astype(float)    \n",
    "    \n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "#     print(batch_list)\n",
    "    for counter, batch in enumerate(batch_list):\n",
    "#         print(type(batch))\n",
    "        batch_df = dataset.loc[batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        matched_smiles_list = smiles_list\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values.astype(float)\n",
    "#         print(type(y_val))\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(matched_smiles_list,feature_dicts)\n",
    "        x_atom = torch.Tensor(x_atom)\n",
    "        x_bonds = torch.Tensor(x_bonds)\n",
    "        x_bond_index = torch.cuda.LongTensor(x_bond_index)\n",
    "        bond_neighbor = [x_bonds[i][x_bond_index[i]] for i in range(len(batch_df))]\n",
    "        bond_neighbor = torch.stack(bond_neighbor, dim=0)\n",
    "        \n",
    "        lamda=10**-learning_rate\n",
    "        activated_features, mol_feature = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),output_activated_features=True)\n",
    "#         mol_feature = torch.div(mol_feature, torch.norm(mol_feature, dim=-1, keepdim=True)+1e-9)\n",
    "#         activated_features = torch.div(activated_features, torch.norm(activated_features, dim=-1, keepdim=True)+1e-9)\n",
    "        eps_adv, d_adv, vat_loss, mol_prediction = perturb_feature(mol_feature, amodel, alpha=1, lamda=lamda)\n",
    "#         print(mol_feature,d_adv)\n",
    "        atom_list, bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),\n",
    "                                      torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),\n",
    "                                      torch.Tensor(x_mask),mol_feature=mol_feature+d_adv/(1e-6),activated_features=activated_features)\n",
    "        refer_atom_list, refer_bond_list = gmodel(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask),mol_feature=mol_feature,activated_features=activated_features)\n",
    "        if generate:\n",
    "            if modify_atom:\n",
    "                success_smiles_batch, modified_smiles, success_batch, total_batch, reconstruction, validity, validity_mask = modify_atoms(matched_smiles_list, x_atom, \n",
    "                            bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list,\n",
    "                                                     refer_atom_list, refer_bond_list,topn=topn,viz=viz)\n",
    "            else:\n",
    "                modified_smiles = modify_bonds(matched_smiles_list, x_atom, bond_neighbor, atom_list, bond_list,smiles_list,smiles_to_rdkit_list)\n",
    "            generated_smiles.extend(modified_smiles)\n",
    "            success_smiles.extend(success_smiles_batch)\n",
    "#             for n in range(topn):\n",
    "#                 success[n] += success_batch[n]\n",
    "#                 total[n] += total_batch[n]\n",
    "#                 print('congratulations:',success,total)\n",
    "            success_reconstruction += reconstruction\n",
    "            success_validity += validity\n",
    "            reconstruction_loss, one_hot_loss, interger_loss, binary_loss = generate_loss_function(refer_atom_list, x_atom, refer_bond_list, bond_neighbor, validity_mask, atom_list, bond_list)\n",
    "        d = d_adv.cpu().detach().numpy().tolist()\n",
    "        d_list.extend(d)\n",
    "        mol_feature_output = mol_feature.cpu().detach().numpy().tolist()\n",
    "        feature_list.extend(mol_feature_output)\n",
    "#         MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')   \n",
    "#         print(type(mol_prediction))\n",
    "        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         r2 = caculate_r2(mol_prediction, torch.Tensor(y_val).view(-1,1))\n",
    "# #         r2_list.extend(r2.cpu().detach().numpy())\n",
    "#         if r2!=r2:\n",
    "#             r2 = torch.tensor(0)\n",
    "#         r2_list.append(r2.item())\n",
    "#         predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        predict_list.extend(mol_prediction.cpu().detach().numpy())\n",
    "#         test_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        test_MSE_list.extend(MSE.data.view(-1,1).cpu().numpy())\n",
    "#     print(r2_list)\n",
    "    if generate:\n",
    "        generated_num = len(generated_smiles)\n",
    "        eval_num = len(dataset)\n",
    "        unique = generated_num\n",
    "        novelty = generated_num\n",
    "        for i in range(generated_num):\n",
    "            for j in range(generated_num-i-1):\n",
    "                if generated_smiles[i]==generated_smiles[i+j+1]:\n",
    "                    unique -= 1\n",
    "            for k in range(eval_num):\n",
    "                if generated_smiles[i]==dataset['smiles'].values[k]:\n",
    "                    novelty -= 1\n",
    "        unique_rate = unique/(generated_num+1e-9)\n",
    "        novelty_rate = novelty/(generated_num+1e-9)\n",
    "#         print(f'successfully/total generated molecules =', {f'Top-{i+1}': f'{success[i]}/{total[i]}' for i in range(topn)})\n",
    "        return success_reconstruction/len(dataset), success_validity/len(dataset), unique_rate, novelty_rate, success_smiles, generated_smiles, caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    if return_GRN_loss:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list,reconstruction_loss, one_hot_loss, interger_loss,binary_loss\n",
    "    if output_feature:\n",
    "        return d_list, feature_list,caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "    return caculate_r2(predict_list,dataset[tasks[0]].values.astype(float).tolist()),np.array(test_MSE_list).mean(),predict_list\n",
    "\n",
    "epoch = 0\n",
    "max_epoch = 1000\n",
    "batch_size = 10\n",
    "patience = 100\n",
    "stopper = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_model.pth')\n",
    "stopper_afse = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_amodel.pth')\n",
    "stopper_generate = EarlyStopping(mode='higher', patience=patience, filename=model_file + '_gmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log/1_GAFSE_EC50_P34972_3_300_run_0\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "if os.path.isdir(log_dir):\n",
    "    for files in os.listdir(log_dir):\n",
    "        os.remove(log_dir+\"/\"+files)\n",
    "    os.rmdir(log_dir)\n",
    "logger = SummaryWriter(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 98 Index:-1.0278 R2:0.1248 0.0188 0.0838 RMSE:0.9347 1.0015 0.9954 Tau:0.0839 -0.0263 0.3777\n",
      "Epoch: 2 Step: 196 Index:-0.9820 R2:0.1422 0.0242 0.0994 RMSE:0.9305 0.9653 0.9866 Tau:0.1064 -0.0167 0.3823\n",
      "Epoch: 3 Step: 294 Index:-0.9304 R2:0.1672 0.0489 0.1211 RMSE:0.9117 0.9750 0.9705 Tau:0.1518 0.0446 0.3949\n",
      "Epoch: 4 Step: 392 Index:-0.8918 R2:0.1771 0.0585 0.1298 RMSE:0.9084 0.9534 0.9689 Tau:0.1641 0.0616 0.3973\n",
      "Epoch: 5 Step: 490 Index:-0.8495 R2:0.1930 0.0685 0.1442 RMSE:0.9096 0.9302 0.9677 Tau:0.1890 0.0807 0.4044\n",
      "Epoch: 6 Step: 588 Index:-0.8322 R2:0.2003 0.0754 0.1454 RMSE:0.9071 0.9267 0.9691 Tau:0.1947 0.0945 0.4028\n",
      "Epoch: 7 Step: 686 Index:-0.7800 R2:0.2218 0.0956 0.1641 RMSE:0.8897 0.9196 0.9537 Tau:0.2297 0.1396 0.4100\n",
      "Epoch: 8 Step: 784 Index:-0.7778 R2:0.2362 0.0983 0.1666 RMSE:0.9465 0.9076 1.0074 Tau:0.2413 0.1298 0.4078\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 9 Step: 882 Index:-0.8160 R2:0.2635 0.1387 0.1883 RMSE:0.8944 1.0096 0.9668 Tau:0.2918 0.1935 0.4010\n",
      "Epoch: 10 Step: 980 Index:-0.7245 R2:0.2635 0.1296 0.1877 RMSE:0.8650 0.8994 0.9363 Tau:0.2800 0.1749 0.4073\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 11 Step: 1078 Index:-0.7327 R2:0.2961 0.1425 0.2121 RMSE:0.8573 0.9377 0.9296 Tau:0.3209 0.2050 0.3903\n",
      "Epoch: 12 Step: 1176 Index:-0.6980 R2:0.2914 0.1506 0.2034 RMSE:0.8452 0.8956 0.9247 Tau:0.3139 0.1976 0.4040\n",
      "Epoch: 13 Step: 1274 Index:-0.6950 R2:0.3018 0.1477 0.2081 RMSE:0.9382 0.8924 1.0124 Tau:0.3216 0.1974 0.3980\n",
      "Epoch: 14 Step: 1372 Index:-0.6711 R2:0.3207 0.1754 0.2240 RMSE:0.8280 0.9109 0.9136 Tau:0.3458 0.2398 0.3959\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 15 Step: 1470 Index:-0.6769 R2:0.3287 0.1759 0.2284 RMSE:0.8215 0.9170 0.9120 Tau:0.3541 0.2401 0.3905\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 16 Step: 1568 Index:-0.7570 R2:0.3365 0.2034 0.2355 RMSE:0.8864 1.0310 0.9765 Tau:0.3651 0.2740 0.4001\n",
      "Epoch: 17 Step: 1666 Index:-0.6451 R2:0.3523 0.1868 0.2454 RMSE:0.8109 0.9085 0.9024 Tau:0.3760 0.2635 0.3869\n",
      "Epoch: 18 Step: 1764 Index:-0.6132 R2:0.3515 0.1903 0.2421 RMSE:0.8090 0.8692 0.9056 Tau:0.3745 0.2561 0.3951\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 19 Step: 1862 Index:-0.6358 R2:0.3707 0.1906 0.2516 RMSE:0.8037 0.9040 0.8994 Tau:0.3903 0.2682 0.3774\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 20 Step: 1960 Index:-0.6231 R2:0.3511 0.1838 0.2371 RMSE:0.8495 0.8666 0.9547 Tau:0.3740 0.2434 0.4034\n",
      "Epoch: 21 Step: 2058 Index:-0.5635 R2:0.3803 0.2080 0.2556 RMSE:0.8090 0.8478 0.9137 Tau:0.4024 0.2842 0.3944\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 22 Step: 2156 Index:-0.6299 R2:0.3928 0.2121 0.2651 RMSE:0.7994 0.9248 0.9011 Tau:0.4146 0.2950 0.3845\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 23 Step: 2254 Index:-0.5763 R2:0.3964 0.1934 0.2489 RMSE:0.8227 0.8496 0.9234 Tau:0.4150 0.2733 0.3727\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 24 Step: 2352 Index:-0.5868 R2:0.3790 0.2023 0.2523 RMSE:0.8440 0.8565 0.9546 Tau:0.4043 0.2697 0.4126\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 25 Step: 2450 Index:-0.5931 R2:0.4031 0.2072 0.2620 RMSE:0.8005 0.8793 0.8960 Tau:0.4211 0.2861 0.3769\n",
      "Epoch: 26 Step: 2548 Index:-0.5599 R2:0.3977 0.2182 0.2639 RMSE:0.7813 0.8501 0.8955 Tau:0.4195 0.2902 0.3998\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 27 Step: 2646 Index:-0.5869 R2:0.4070 0.2003 0.2610 RMSE:0.8564 0.8580 0.9597 Tau:0.4278 0.2711 0.3956\n",
      "Epoch: 28 Step: 2744 Index:-0.5521 R2:0.4124 0.2213 0.2748 RMSE:0.7705 0.8511 0.8854 Tau:0.4315 0.2990 0.4083\n",
      "Epoch: 29 Step: 2842 Index:-0.5324 R2:0.4205 0.2306 0.2796 RMSE:0.7668 0.8469 0.8925 Tau:0.4379 0.3145 0.4011\n",
      "Epoch: 30 Step: 2940 Index:-0.5171 R2:0.4234 0.2377 0.2800 RMSE:0.7913 0.8274 0.9068 Tau:0.4424 0.3102 0.4071\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 31 Step: 3038 Index:-0.5487 R2:0.4221 0.2244 0.2795 RMSE:0.8036 0.8389 0.9226 Tau:0.4462 0.2902 0.4147\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 32 Step: 3136 Index:-0.5472 R2:0.4184 0.2240 0.2795 RMSE:0.7771 0.8405 0.8964 Tau:0.4419 0.2933 0.4197\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 33 Step: 3234 Index:-0.5479 R2:0.4313 0.2263 0.2818 RMSE:0.7913 0.8372 0.9146 Tau:0.4492 0.2892 0.4225\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 34 Step: 3332 Index:-0.5371 R2:0.4395 0.2418 0.2950 RMSE:0.7489 0.8476 0.8753 Tau:0.4544 0.3105 0.4143\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 35 Step: 3430 Index:-0.5335 R2:0.4352 0.2464 0.2851 RMSE:0.7546 0.8394 0.8889 Tau:0.4522 0.3059 0.4249\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 36 Step: 3528 Index:-0.5509 R2:0.4551 0.2210 0.2895 RMSE:0.7889 0.8395 0.9148 Tau:0.4649 0.2885 0.4173\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 37 Step: 3626 Index:-0.5593 R2:0.4667 0.2443 0.3043 RMSE:0.7442 0.8710 0.8658 Tau:0.4706 0.3117 0.4166\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 38 Step: 3724 Index:-0.5234 R2:0.4601 0.2371 0.3002 RMSE:0.7642 0.8346 0.8966 Tau:0.4710 0.3112 0.4197\n",
      "Epoch: 39 Step: 3822 Index:-0.5079 R2:0.4648 0.2563 0.3000 RMSE:0.7421 0.8286 0.8689 Tau:0.4756 0.3207 0.4211\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 40 Step: 3920 Index:-0.5350 R2:0.4640 0.2325 0.2971 RMSE:0.7920 0.8400 0.9169 Tau:0.4697 0.3050 0.4042\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 41 Step: 4018 Index:-0.5179 R2:0.4771 0.2453 0.3047 RMSE:0.7391 0.8287 0.8800 Tau:0.4820 0.3107 0.4232\n",
      "Epoch: 42 Step: 4116 Index:-0.5073 R2:0.4802 0.2565 0.3180 RMSE:0.7266 0.8318 0.8665 Tau:0.4806 0.3246 0.4270\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 43 Step: 4214 Index:-0.5238 R2:0.4701 0.2669 0.3160 RMSE:0.7304 0.8623 0.8616 Tau:0.4730 0.3384 0.4332\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 44 Step: 4312 Index:-0.5085 R2:0.4808 0.2672 0.3020 RMSE:0.7237 0.8385 0.8654 Tau:0.4809 0.3301 0.4246\n",
      "Epoch: 45 Step: 4410 Index:-0.4912 R2:0.4906 0.2612 0.3122 RMSE:0.7302 0.8196 0.8772 Tau:0.4917 0.3284 0.4259\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 46 Step: 4508 Index:-0.4993 R2:0.4776 0.2624 0.3051 RMSE:0.7361 0.8255 0.8903 Tau:0.4870 0.3262 0.4402\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 47 Step: 4606 Index:-0.5006 R2:0.4815 0.2728 0.3211 RMSE:0.7212 0.8343 0.8676 Tau:0.4876 0.3336 0.4355\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 48 Step: 4704 Index:-0.5209 R2:0.4938 0.2736 0.3213 RMSE:0.7179 0.8612 0.8552 Tau:0.4963 0.3403 0.4329\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 49 Step: 4802 Index:-0.5158 R2:0.5006 0.2770 0.3207 RMSE:0.7124 0.8559 0.8568 Tau:0.5002 0.3401 0.4360\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 50 Step: 4900 Index:-0.4982 R2:0.5028 0.2622 0.3221 RMSE:0.7133 0.8292 0.8666 Tau:0.4976 0.3310 0.4233\n",
      "Epoch: 51 Step: 4998 Index:-0.4713 R2:0.5014 0.2757 0.3235 RMSE:0.7520 0.8140 0.9066 Tau:0.5010 0.3427 0.4343\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 52 Step: 5096 Index:-0.5045 R2:0.5056 0.2603 0.3188 RMSE:0.7102 0.8317 0.8682 Tau:0.4961 0.3272 0.4289\n",
      "Epoch: 53 Step: 5194 Index:-0.4662 R2:0.4988 0.2863 0.3290 RMSE:0.7250 0.8161 0.8837 Tau:0.4994 0.3499 0.4388\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 54 Step: 5292 Index:-0.5174 R2:0.5233 0.2749 0.3359 RMSE:0.6975 0.8558 0.8449 Tau:0.5106 0.3384 0.4258\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 55 Step: 5390 Index:-0.4667 R2:0.5203 0.2821 0.3230 RMSE:0.7000 0.8137 0.8635 Tau:0.5143 0.3470 0.4420\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 56 Step: 5488 Index:-0.4800 R2:0.5137 0.2817 0.3292 RMSE:0.7306 0.8179 0.8992 Tau:0.5079 0.3379 0.4400\n",
      "Epoch: 57 Step: 5586 Index:-0.4532 R2:0.4775 0.2955 0.3242 RMSE:0.7330 0.8050 0.8671 Tau:0.4924 0.3518 0.4437\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 58 Step: 5684 Index:-0.4600 R2:0.5332 0.2914 0.3427 RMSE:0.6904 0.8125 0.8537 Tau:0.5183 0.3525 0.4339\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 59 Step: 5782 Index:-0.4914 R2:0.5330 0.2735 0.3342 RMSE:0.6862 0.8320 0.8470 Tau:0.5177 0.3406 0.4320\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 60 Step: 5880 Index:-0.4544 R2:0.5418 0.3057 0.3394 RMSE:0.6810 0.8112 0.8438 Tau:0.5247 0.3568 0.4420\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 61 Step: 5978 Index:-0.4988 R2:0.5427 0.2714 0.3392 RMSE:0.6798 0.8410 0.8424 Tau:0.5244 0.3422 0.4337\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 62 Step: 6076 Index:-0.4941 R2:0.5536 0.2742 0.3444 RMSE:0.6741 0.8294 0.8424 Tau:0.5322 0.3353 0.4231\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 63 Step: 6174 Index:-0.5513 R2:0.5374 0.2822 0.3585 RMSE:0.6975 0.8990 0.8441 Tau:0.5216 0.3477 0.4340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 64 Step: 6272 Index:-0.4539 R2:0.5505 0.2931 0.3469 RMSE:0.7130 0.8128 0.8875 Tau:0.5317 0.3589 0.4385\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 65 Step: 6370 Index:-0.4582 R2:0.5605 0.2940 0.3553 RMSE:0.6771 0.8131 0.8592 Tau:0.5400 0.3549 0.4354\n",
      "Epoch: 66 Step: 6468 Index:-0.4517 R2:0.5528 0.2989 0.3523 RMSE:0.6753 0.8123 0.8556 Tau:0.5339 0.3606 0.4415\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 67 Step: 6566 Index:-0.4915 R2:0.5694 0.2840 0.3555 RMSE:0.6588 0.8409 0.8336 Tau:0.5449 0.3494 0.4275\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 68 Step: 6664 Index:-0.4636 R2:0.5539 0.2952 0.3497 RMSE:0.6729 0.8159 0.8543 Tau:0.5378 0.3522 0.4377\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 69 Step: 6762 Index:-0.4744 R2:0.5661 0.3175 0.3583 RMSE:0.6623 0.8443 0.8387 Tau:0.5484 0.3699 0.4398\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 70 Step: 6860 Index:-0.5177 R2:0.5703 0.2811 0.3565 RMSE:0.6668 0.8664 0.8345 Tau:0.5432 0.3487 0.4288\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 71 Step: 6958 Index:-0.4623 R2:0.5805 0.2879 0.3592 RMSE:0.6628 0.8117 0.8483 Tau:0.5530 0.3494 0.4325\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 72 Step: 7056 Index:-0.4967 R2:0.5697 0.2691 0.3673 RMSE:0.6650 0.8325 0.8301 Tau:0.5416 0.3358 0.4207\n",
      "Epoch: 73 Step: 7154 Index:-0.4402 R2:0.5868 0.3080 0.3541 RMSE:0.6998 0.8027 0.9006 Tau:0.5585 0.3625 0.4336\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 74 Step: 7252 Index:-0.4434 R2:0.5866 0.3082 0.3602 RMSE:0.6909 0.8033 0.8938 Tau:0.5585 0.3599 0.4418\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 75 Step: 7350 Index:-0.4457 R2:0.5855 0.3276 0.3568 RMSE:0.6489 0.8223 0.8323 Tau:0.5584 0.3766 0.4329\n",
      "Epoch: 76 Step: 7448 Index:-0.4369 R2:0.5855 0.3224 0.3666 RMSE:0.6480 0.8030 0.8432 Tau:0.5643 0.3661 0.4421\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 77 Step: 7546 Index:-0.4760 R2:0.5994 0.3066 0.3708 RMSE:0.6382 0.8366 0.8229 Tau:0.5666 0.3606 0.4236\n",
      "Epoch: 78 Step: 7644 Index:-0.4260 R2:0.6034 0.3193 0.3733 RMSE:0.6390 0.7990 0.8318 Tau:0.5717 0.3730 0.4333\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 79 Step: 7742 Index:-0.4739 R2:0.5977 0.2956 0.3689 RMSE:0.6364 0.8331 0.8259 Tau:0.5643 0.3592 0.4291\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 80 Step: 7840 Index:-0.4280 R2:0.6065 0.3123 0.3662 RMSE:0.6553 0.7909 0.8494 Tau:0.5704 0.3630 0.4333\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 81 Step: 7938 Index:-0.4365 R2:0.6077 0.3066 0.3782 RMSE:0.6609 0.7952 0.8538 Tau:0.5764 0.3587 0.4349\n",
      "Epoch: 82 Step: 8036 Index:-0.4176 R2:0.5855 0.3287 0.3537 RMSE:0.6652 0.7949 0.8829 Tau:0.5628 0.3773 0.4479\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 83 Step: 8134 Index:-0.4494 R2:0.6071 0.2963 0.3661 RMSE:0.6461 0.8059 0.8451 Tau:0.5717 0.3565 0.4365\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 84 Step: 8232 Index:-0.4676 R2:0.6150 0.3173 0.3623 RMSE:0.6267 0.8340 0.8297 Tau:0.5770 0.3663 0.4389\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 85 Step: 8330 Index:-0.4405 R2:0.6193 0.3128 0.3698 RMSE:0.6388 0.7964 0.8514 Tau:0.5826 0.3558 0.4334\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 86 Step: 8428 Index:-0.4878 R2:0.6150 0.3156 0.3666 RMSE:0.6413 0.8548 0.8292 Tau:0.5781 0.3670 0.4343\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 87 Step: 8526 Index:-0.4465 R2:0.6210 0.3047 0.3600 RMSE:0.6263 0.8172 0.8339 Tau:0.5852 0.3706 0.4124\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 88 Step: 8624 Index:-0.4218 R2:0.6254 0.3270 0.3633 RMSE:0.6212 0.8003 0.8562 Tau:0.5866 0.3785 0.4312\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 89 Step: 8722 Index:-0.4682 R2:0.6168 0.2961 0.3647 RMSE:0.6264 0.8286 0.8419 Tau:0.5813 0.3604 0.4197\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 90 Step: 8820 Index:-0.4575 R2:0.6238 0.3043 0.3531 RMSE:0.6178 0.8277 0.8378 Tau:0.5854 0.3701 0.4203\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 91 Step: 8918 Index:-0.4338 R2:0.6310 0.3229 0.3776 RMSE:0.6184 0.8002 0.8432 Tau:0.5938 0.3663 0.4417\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 92 Step: 9016 Index:-0.4784 R2:0.6284 0.2743 0.3576 RMSE:0.6571 0.8183 0.8749 Tau:0.5878 0.3398 0.4221\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 93 Step: 9114 Index:-0.4237 R2:0.6370 0.3196 0.3711 RMSE:0.6303 0.7977 0.8593 Tau:0.5947 0.3740 0.4297\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 94 Step: 9212 Index:-0.4799 R2:0.6325 0.3121 0.3814 RMSE:0.6074 0.8500 0.8233 Tau:0.5963 0.3701 0.4230\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 95 Step: 9310 Index:-0.4815 R2:0.6303 0.2875 0.3588 RMSE:0.6907 0.8338 0.9261 Tau:0.5899 0.3522 0.4199\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 96 Step: 9408 Index:-0.4639 R2:0.6337 0.3066 0.3717 RMSE:0.6106 0.8255 0.8274 Tau:0.5946 0.3616 0.4269\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 97 Step: 9506 Index:-0.4416 R2:0.6199 0.3132 0.3653 RMSE:0.6926 0.8005 0.9206 Tau:0.5840 0.3589 0.4461\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 98 Step: 9604 Index:-0.4332 R2:0.6487 0.3261 0.3855 RMSE:0.6018 0.8031 0.8288 Tau:0.6039 0.3699 0.4308\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 99 Step: 9702 Index:-0.5249 R2:0.6363 0.2871 0.3613 RMSE:0.6067 0.8772 0.8402 Tau:0.5955 0.3522 0.4271\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 100 Step: 9800 Index:-0.4389 R2:0.6465 0.3268 0.3727 RMSE:0.5967 0.8115 0.8414 Tau:0.6017 0.3725 0.4416\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 101 Step: 9898 Index:-0.4593 R2:0.6599 0.3099 0.3730 RMSE:0.5878 0.8263 0.8282 Tau:0.6109 0.3670 0.4266\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 102 Step: 9996 Index:-0.4383 R2:0.6576 0.3342 0.3766 RMSE:0.5853 0.8184 0.8315 Tau:0.6099 0.3802 0.4378\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 103 Step: 10094 Index:-0.4482 R2:0.6483 0.3132 0.3661 RMSE:0.6545 0.8164 0.9047 Tau:0.6009 0.3682 0.4217\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 104 Step: 10192 Index:-0.4225 R2:0.6647 0.3254 0.3783 RMSE:0.6647 0.7943 0.9016 Tau:0.6126 0.3718 0.4336\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 105 Step: 10290 Index:-0.4507 R2:0.6583 0.3208 0.3724 RMSE:0.5882 0.8125 0.8434 Tau:0.6103 0.3618 0.4467\n",
      "Epoch: 106 Step: 10388 Index:-0.4159 R2:0.6573 0.3423 0.3652 RMSE:0.5882 0.8030 0.8474 Tau:0.6094 0.3871 0.4417\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 107 Step: 10486 Index:-0.4384 R2:0.6756 0.3144 0.3761 RMSE:0.5935 0.8012 0.8384 Tau:0.6227 0.3627 0.4257\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 108 Step: 10584 Index:-0.4401 R2:0.6748 0.3136 0.3757 RMSE:0.6147 0.8035 0.8727 Tau:0.6223 0.3635 0.4385\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 109 Step: 10682 Index:-0.4569 R2:0.6239 0.3098 0.3747 RMSE:0.6502 0.8184 0.8829 Tau:0.5852 0.3616 0.4317\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 110 Step: 10780 Index:-1.2161 R2:0.6028 0.2855 0.3501 RMSE:1.2675 1.5724 1.3754 Tau:0.5693 0.3563 0.4165\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 111 Step: 10878 Index:-0.4325 R2:0.6507 0.3298 0.3691 RMSE:0.5982 0.8031 0.8451 Tau:0.6070 0.3706 0.4522\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 112 Step: 10976 Index:-0.4267 R2:0.6699 0.3294 0.3769 RMSE:0.5979 0.7993 0.8552 Tau:0.6206 0.3725 0.4357\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 113 Step: 11074 Index:-0.4280 R2:0.6766 0.3241 0.3683 RMSE:0.5975 0.7941 0.8548 Tau:0.6214 0.3661 0.4387\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 114 Step: 11172 Index:-0.4613 R2:0.6760 0.3153 0.3736 RMSE:0.5833 0.8293 0.8205 Tau:0.6243 0.3680 0.4238\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 115 Step: 11270 Index:-0.4975 R2:0.6784 0.3258 0.3708 RMSE:0.5871 0.8746 0.8345 Tau:0.6252 0.3771 0.4280\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 116 Step: 11368 Index:-0.5333 R2:0.6603 0.3072 0.3727 RMSE:0.5970 0.8942 0.8440 Tau:0.6103 0.3608 0.4401\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 117 Step: 11466 Index:-0.4609 R2:0.6722 0.3062 0.3529 RMSE:0.5953 0.8225 0.8741 Tau:0.6208 0.3616 0.4332\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 118 Step: 11564 Index:-0.4346 R2:0.6743 0.3319 0.3768 RMSE:0.6051 0.8036 0.8770 Tau:0.6256 0.3690 0.4411\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 119 Step: 11662 Index:-0.4426 R2:0.6938 0.3226 0.3738 RMSE:0.5650 0.8147 0.8433 Tau:0.6327 0.3721 0.4304\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 120 Step: 11760 Index:-0.4992 R2:0.6793 0.2986 0.3527 RMSE:0.7337 0.8503 0.9974 Tau:0.6251 0.3511 0.4336\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 121 Step: 11858 Index:-0.4716 R2:0.6866 0.3159 0.3559 RMSE:0.5636 0.8324 0.8413 Tau:0.6287 0.3608 0.4234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 122 Step: 11956 Index:-0.4203 R2:0.6850 0.3419 0.3594 RMSE:0.5663 0.8010 0.8517 Tau:0.6247 0.3806 0.4438\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 123 Step: 12054 Index:-0.4284 R2:0.6890 0.3264 0.3715 RMSE:0.6093 0.7931 0.8908 Tau:0.6328 0.3647 0.4430\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 124 Step: 12152 Index:-0.4295 R2:0.7028 0.3407 0.3698 RMSE:0.5537 0.8137 0.8306 Tau:0.6414 0.3842 0.4347\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 125 Step: 12250 Index:-0.4887 R2:0.6998 0.3119 0.3560 RMSE:0.5491 0.8562 0.8536 Tau:0.6360 0.3675 0.4299\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 126 Step: 12348 Index:-0.4745 R2:0.6997 0.3088 0.3676 RMSE:0.5522 0.8365 0.8396 Tau:0.6433 0.3620 0.4265\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 127 Step: 12446 Index:-0.4730 R2:0.7032 0.3328 0.3707 RMSE:0.5472 0.8522 0.8422 Tau:0.6397 0.3792 0.4306\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 128 Step: 12544 Index:-0.4420 R2:0.7040 0.3303 0.3502 RMSE:0.5524 0.8131 0.8641 Tau:0.6424 0.3711 0.4400\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 129 Step: 12642 Index:-0.4973 R2:0.6926 0.3267 0.3753 RMSE:0.5555 0.8656 0.8511 Tau:0.6336 0.3682 0.4373\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 130 Step: 12740 Index:-0.5060 R2:0.6859 0.3129 0.3672 RMSE:0.5623 0.8721 0.8603 Tau:0.6296 0.3661 0.4344\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 131 Step: 12838 Index:-0.4501 R2:0.7073 0.3248 0.3733 RMSE:0.5490 0.8155 0.8538 Tau:0.6495 0.3654 0.4416\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 132 Step: 12936 Index:-0.5236 R2:0.6798 0.3078 0.3627 RMSE:0.5713 0.8883 0.8639 Tau:0.6225 0.3647 0.4349\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 133 Step: 13034 Index:-0.5447 R2:0.6951 0.2942 0.3757 RMSE:0.5623 0.9017 0.8456 Tau:0.6400 0.3570 0.4252\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 134 Step: 13132 Index:-0.4399 R2:0.7170 0.3188 0.3586 RMSE:0.5850 0.8034 0.8950 Tau:0.6498 0.3635 0.4317\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 135 Step: 13230 Index:-0.4632 R2:0.7106 0.3184 0.3770 RMSE:0.5418 0.8353 0.8559 Tau:0.6500 0.3721 0.4323\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 136 Step: 13328 Index:-0.5016 R2:0.6414 0.2926 0.3265 RMSE:0.6049 0.8272 0.8786 Tau:0.5896 0.3255 0.4411\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 137 Step: 13426 Index:-0.4578 R2:0.6984 0.3232 0.3776 RMSE:0.5547 0.8292 0.8624 Tau:0.6401 0.3713 0.4401\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 138 Step: 13524 Index:-0.5643 R2:0.7117 0.3126 0.3580 RMSE:0.6097 0.9292 0.8603 Tau:0.6515 0.3649 0.4239\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 139 Step: 13622 Index:-0.4965 R2:0.7018 0.2977 0.3472 RMSE:0.5478 0.8516 0.8599 Tau:0.6406 0.3551 0.4239\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 140 Step: 13720 Index:-0.4568 R2:0.7165 0.3372 0.3462 RMSE:0.5518 0.8270 0.8439 Tau:0.6517 0.3701 0.4394\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 141 Step: 13818 Index:-0.4528 R2:0.6880 0.3432 0.3498 RMSE:0.5595 0.8356 0.8664 Tau:0.6239 0.3828 0.4501\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 142 Step: 13916 Index:-0.4485 R2:0.7206 0.3262 0.3610 RMSE:0.5363 0.8213 0.8434 Tau:0.6548 0.3728 0.4339\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 143 Step: 14014 Index:-0.4600 R2:0.7332 0.3135 0.3658 RMSE:0.5435 0.8223 0.8788 Tau:0.6623 0.3623 0.4274\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 144 Step: 14112 Index:-0.5470 R2:0.7224 0.3040 0.3616 RMSE:0.5642 0.9112 0.8477 Tau:0.6591 0.3642 0.4110\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 145 Step: 14210 Index:-0.4745 R2:0.7307 0.3243 0.3591 RMSE:0.5183 0.8452 0.8574 Tau:0.6642 0.3706 0.4351\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 146 Step: 14308 Index:-0.4581 R2:0.6981 0.3272 0.3649 RMSE:0.5718 0.8280 0.9048 Tau:0.6329 0.3699 0.4342\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 147 Step: 14406 Index:-0.4673 R2:0.7288 0.2963 0.3478 RMSE:0.5415 0.8274 0.8582 Tau:0.6646 0.3601 0.4149\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 148 Step: 14504 Index:-0.4255 R2:0.7315 0.3382 0.3562 RMSE:0.5630 0.7994 0.9027 Tau:0.6609 0.3740 0.4436\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 149 Step: 14602 Index:-0.4217 R2:0.7285 0.3399 0.3552 RMSE:0.5605 0.7940 0.8873 Tau:0.6648 0.3723 0.4506\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 150 Step: 14700 Index:-0.4665 R2:0.7353 0.3392 0.3721 RMSE:0.5194 0.8354 0.8373 Tau:0.6682 0.3690 0.4355\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 151 Step: 14798 Index:-0.4612 R2:0.7421 0.3240 0.3726 RMSE:0.5135 0.8366 0.8354 Tau:0.6742 0.3754 0.4200\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 152 Step: 14896 Index:-0.4633 R2:0.7468 0.3125 0.3529 RMSE:0.5158 0.8304 0.8629 Tau:0.6762 0.3670 0.4127\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 153 Step: 14994 Index:-0.4444 R2:0.7394 0.3463 0.3744 RMSE:0.6618 0.8215 0.9732 Tau:0.6694 0.3771 0.4400\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 154 Step: 15092 Index:-0.4624 R2:0.7289 0.3031 0.3554 RMSE:0.5465 0.8240 0.8635 Tau:0.6686 0.3616 0.4341\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 155 Step: 15190 Index:-0.4768 R2:0.7222 0.3351 0.3590 RMSE:0.5310 0.8429 0.8502 Tau:0.6602 0.3661 0.4454\n",
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 156 Step: 15288 Index:-0.4659 R2:0.7330 0.3182 0.3490 RMSE:0.5530 0.8267 0.9073 Tau:0.6681 0.3608 0.4476\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 157 Step: 15386 Index:-0.4954 R2:0.7390 0.3167 0.3617 RMSE:0.5099 0.8581 0.8594 Tau:0.6731 0.3627 0.4347\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 158 Step: 15484 Index:-0.4784 R2:0.7311 0.3020 0.3510 RMSE:0.5262 0.8361 0.8602 Tau:0.6653 0.3577 0.4327\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 159 Step: 15582 Index:-0.4976 R2:0.7122 0.2815 0.3371 RMSE:0.5609 0.8486 0.8830 Tau:0.6558 0.3511 0.4232\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 160 Step: 15680 Index:-0.5049 R2:0.7500 0.3158 0.3556 RMSE:0.5053 0.8722 0.8577 Tau:0.6773 0.3673 0.4280\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 161 Step: 15778 Index:-0.4624 R2:0.7467 0.3161 0.3520 RMSE:0.5340 0.8158 0.8926 Tau:0.6791 0.3534 0.4394\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 162 Step: 15876 Index:-0.4772 R2:0.7259 0.2974 0.3126 RMSE:0.5872 0.8362 0.9324 Tau:0.6654 0.3589 0.4262\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 163 Step: 15974 Index:-0.4222 R2:0.7337 0.3470 0.3719 RMSE:0.5399 0.8066 0.8916 Tau:0.6696 0.3845 0.4528\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 164 Step: 16072 Index:-0.4756 R2:0.7479 0.3161 0.3356 RMSE:0.5080 0.8440 0.8993 Tau:0.6771 0.3685 0.4314\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 165 Step: 16170 Index:-0.4717 R2:0.7445 0.3205 0.3528 RMSE:0.5060 0.8463 0.8660 Tau:0.6789 0.3747 0.4363\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 166 Step: 16268 Index:-0.4442 R2:0.7528 0.3254 0.3461 RMSE:0.5593 0.8139 0.9207 Tau:0.6832 0.3697 0.4519\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 167 Step: 16366 Index:-0.4723 R2:0.7448 0.3254 0.3508 RMSE:0.5050 0.8468 0.8758 Tau:0.6775 0.3744 0.4329\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 168 Step: 16464 Index:-0.4435 R2:0.7574 0.3335 0.3590 RMSE:0.5764 0.8141 0.9153 Tau:0.6872 0.3706 0.4395\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 169 Step: 16562 Index:-0.4360 R2:0.7636 0.3403 0.3664 RMSE:0.5113 0.8154 0.8746 Tau:0.6907 0.3795 0.4351\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 171 Step: 16758 Index:-0.4366 R2:0.7670 0.3356 0.3589 RMSE:0.5214 0.8128 0.8894 Tau:0.6951 0.3761 0.4393\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 172 Step: 16856 Index:-0.4698 R2:0.7732 0.3178 0.3458 RMSE:0.5135 0.8318 0.9117 Tau:0.6950 0.3620 0.4395\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 173 Step: 16954 Index:-0.4884 R2:0.7620 0.3146 0.3592 RMSE:0.4886 0.8545 0.8691 Tau:0.6875 0.3661 0.4261\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 174 Step: 17052 Index:-0.4456 R2:0.7729 0.3410 0.3624 RMSE:0.4808 0.8217 0.8593 Tau:0.6963 0.3761 0.4366\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 175 Step: 17150 Index:-0.4519 R2:0.7704 0.3229 0.3630 RMSE:0.4999 0.8232 0.8600 Tau:0.6977 0.3713 0.4272\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 176 Step: 17248 Index:-0.4487 R2:0.7549 0.3418 0.3517 RMSE:0.5711 0.8255 0.9614 Tau:0.6763 0.3768 0.4419\n",
      "Epoch: 177 Step: 17346 Index:-0.4136 R2:0.7628 0.3443 0.3555 RMSE:0.5670 0.7962 0.9222 Tau:0.6907 0.3826 0.4292\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 178 Step: 17444 Index:-0.4290 R2:0.7831 0.3451 0.3507 RMSE:0.4927 0.8018 0.8830 Tau:0.7053 0.3728 0.4481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179 Step: 17542 Index:-0.4085 R2:0.7771 0.3419 0.3541 RMSE:0.5485 0.7951 0.8943 Tau:0.7017 0.3866 0.4354\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 180 Step: 17640 Index:-0.4434 R2:0.7739 0.3426 0.3613 RMSE:0.4804 0.8221 0.8677 Tau:0.6953 0.3787 0.4490\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 181 Step: 17738 Index:-0.4271 R2:0.7829 0.3477 0.3560 RMSE:0.5013 0.8047 0.8942 Tau:0.7075 0.3775 0.4503\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 182 Step: 17836 Index:-0.4405 R2:0.7814 0.3338 0.3667 RMSE:0.4821 0.8169 0.8472 Tau:0.7052 0.3763 0.4297\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 183 Step: 17934 Index:-0.4603 R2:0.7820 0.3338 0.3654 RMSE:0.4781 0.8431 0.8407 Tau:0.7057 0.3828 0.4307\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 184 Step: 18032 Index:-0.4175 R2:0.7740 0.3776 0.3739 RMSE:0.4751 0.8266 0.8726 Tau:0.7027 0.4090 0.4459\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 185 Step: 18130 Index:-0.4496 R2:0.7834 0.3268 0.3496 RMSE:0.5028 0.8178 0.8842 Tau:0.7076 0.3682 0.4292\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 186 Step: 18228 Index:-0.4088 R2:0.7787 0.3630 0.3695 RMSE:0.4796 0.8035 0.8656 Tau:0.7012 0.3947 0.4502\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 187 Step: 18326 Index:-0.4646 R2:0.7777 0.3298 0.3504 RMSE:0.4908 0.8352 0.9110 Tau:0.7014 0.3706 0.4485\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 188 Step: 18424 Index:-0.4316 R2:0.7765 0.3477 0.3477 RMSE:0.4794 0.8168 0.8736 Tau:0.6962 0.3852 0.4424\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 189 Step: 18522 Index:-0.5272 R2:0.7415 0.3065 0.3190 RMSE:0.5209 0.8907 0.8805 Tau:0.6752 0.3635 0.4184\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 190 Step: 18620 Index:-0.4495 R2:0.7896 0.3375 0.3428 RMSE:0.4642 0.8314 0.8687 Tau:0.7129 0.3818 0.4405\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 191 Step: 18718 Index:-0.4162 R2:0.7748 0.3475 0.3453 RMSE:0.5318 0.8019 0.9283 Tau:0.6943 0.3857 0.4446\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 192 Step: 18816 Index:-0.4920 R2:0.7677 0.2979 0.3409 RMSE:0.5012 0.8531 0.9065 Tau:0.6997 0.3611 0.4408\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 193 Step: 18914 Index:-0.4107 R2:0.7876 0.3519 0.3490 RMSE:0.4831 0.7966 0.8847 Tau:0.7117 0.3859 0.4543\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 194 Step: 19012 Index:-0.4223 R2:0.7897 0.3502 0.3512 RMSE:0.4718 0.8073 0.8606 Tau:0.7141 0.3849 0.4530\n",
      "Epoch: 195 Step: 19110 Index:-0.3995 R2:0.7815 0.3641 0.3554 RMSE:0.4767 0.8033 0.8772 Tau:0.7071 0.4038 0.4507\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 196 Step: 19208 Index:-0.4259 R2:0.7940 0.3505 0.3686 RMSE:0.4654 0.8170 0.8743 Tau:0.7179 0.3911 0.4450\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 197 Step: 19306 Index:-0.4056 R2:0.7990 0.3572 0.3433 RMSE:0.4781 0.7965 0.8902 Tau:0.7184 0.3909 0.4482\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 198 Step: 19404 Index:-0.4624 R2:0.7878 0.3348 0.3370 RMSE:0.4836 0.8311 0.9132 Tau:0.7074 0.3687 0.4389\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 199 Step: 19502 Index:-0.4218 R2:0.7937 0.3469 0.3440 RMSE:0.4830 0.7989 0.8855 Tau:0.7120 0.3771 0.4395\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 200 Step: 19600 Index:-0.4566 R2:0.7920 0.3185 0.3429 RMSE:0.4732 0.8301 0.8601 Tau:0.7123 0.3735 0.4359\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 201 Step: 19698 Index:-0.4368 R2:0.8027 0.3427 0.3533 RMSE:0.4571 0.8191 0.8658 Tau:0.7189 0.3823 0.4448\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 202 Step: 19796 Index:-0.5127 R2:0.8057 0.3406 0.3431 RMSE:0.5050 0.8914 0.8619 Tau:0.7230 0.3787 0.4371\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 203 Step: 19894 Index:-0.4163 R2:0.8015 0.3539 0.3638 RMSE:0.4588 0.8046 0.8583 Tau:0.7228 0.3883 0.4519\n",
      "Epoch: 204 Step: 19992 Index:-0.3897 R2:0.7883 0.3594 0.3738 RMSE:0.4855 0.7878 0.8366 Tau:0.7128 0.3981 0.4336\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 205 Step: 20090 Index:-0.4392 R2:0.8060 0.3428 0.3566 RMSE:0.4499 0.8217 0.8808 Tau:0.7270 0.3826 0.4495\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 206 Step: 20188 Index:-0.5878 R2:0.6953 0.2823 0.3376 RMSE:0.6074 0.9382 0.9968 Tau:0.6469 0.3503 0.4258\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 207 Step: 20286 Index:-0.4336 R2:0.8025 0.3532 0.3548 RMSE:0.4760 0.8121 0.9115 Tau:0.7206 0.3785 0.4557\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 208 Step: 20384 Index:-0.4154 R2:0.8054 0.3581 0.3632 RMSE:0.4625 0.8068 0.8784 Tau:0.7276 0.3914 0.4529\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 209 Step: 20482 Index:-0.4379 R2:0.7995 0.3394 0.3500 RMSE:0.5117 0.8181 0.9312 Tau:0.7192 0.3802 0.4410\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 210 Step: 20580 Index:-0.4318 R2:0.8040 0.3605 0.3610 RMSE:0.4865 0.8265 0.9319 Tau:0.7189 0.3947 0.4568\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 211 Step: 20678 Index:-0.4596 R2:0.7915 0.3158 0.3478 RMSE:0.4949 0.8266 0.8901 Tau:0.7154 0.3670 0.4394\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 212 Step: 20776 Index:-0.4603 R2:0.8004 0.3580 0.3658 RMSE:0.4549 0.8509 0.8594 Tau:0.7236 0.3907 0.4555\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 213 Step: 20874 Index:-0.4428 R2:0.7949 0.3592 0.3548 RMSE:0.4541 0.8380 0.8905 Tau:0.7118 0.3952 0.4519\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 214 Step: 20972 Index:-0.4566 R2:0.7761 0.3543 0.3555 RMSE:0.4732 0.8415 0.8897 Tau:0.6963 0.3849 0.4522\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 215 Step: 21070 Index:-0.4330 R2:0.8063 0.3604 0.3581 RMSE:0.4463 0.8179 0.8880 Tau:0.7258 0.3849 0.4629\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 216 Step: 21168 Index:-0.4527 R2:0.8050 0.3509 0.3590 RMSE:0.4481 0.8412 0.8600 Tau:0.7192 0.3885 0.4479\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 217 Step: 21266 Index:-0.4385 R2:0.7793 0.3498 0.3497 RMSE:0.5209 0.8173 0.9414 Tau:0.7006 0.3787 0.4646\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 218 Step: 21364 Index:-0.4418 R2:0.8125 0.3550 0.3565 RMSE:0.4456 0.8225 0.8952 Tau:0.7300 0.3806 0.4563\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 219 Step: 21462 Index:-0.4496 R2:0.8153 0.3601 0.3563 RMSE:0.4313 0.8395 0.8748 Tau:0.7300 0.3900 0.4567\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 220 Step: 21560 Index:-0.4460 R2:0.8027 0.3469 0.3679 RMSE:0.4463 0.8331 0.8643 Tau:0.7353 0.3871 0.4510\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 221 Step: 21658 Index:-0.4548 R2:0.7974 0.3296 0.3624 RMSE:0.4542 0.8390 0.8679 Tau:0.7245 0.3842 0.4439\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 222 Step: 21756 Index:-0.4042 R2:0.8117 0.3676 0.3534 RMSE:0.4886 0.7994 0.9228 Tau:0.7301 0.3952 0.4623\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 223 Step: 21854 Index:-0.5362 R2:0.8006 0.3210 0.3363 RMSE:0.4582 0.9046 0.8878 Tau:0.7206 0.3685 0.4533\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 224 Step: 21952 Index:-0.4514 R2:0.8030 0.3200 0.3481 RMSE:0.4798 0.8225 0.8958 Tau:0.7213 0.3711 0.4412\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 225 Step: 22050 Index:-0.4943 R2:0.8074 0.3181 0.3322 RMSE:0.4425 0.8649 0.8872 Tau:0.7259 0.3706 0.4489\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 226 Step: 22148 Index:-0.4219 R2:0.8153 0.3555 0.3559 RMSE:0.4447 0.8155 0.8757 Tau:0.7320 0.3935 0.4519\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 227 Step: 22246 Index:-0.4344 R2:0.8205 0.3526 0.3512 RMSE:0.4436 0.8208 0.9115 Tau:0.7345 0.3864 0.4520\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 228 Step: 22344 Index:-0.4631 R2:0.8186 0.3425 0.3554 RMSE:0.4314 0.8438 0.8802 Tau:0.7347 0.3806 0.4505\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 229 Step: 22442 Index:-0.5547 R2:0.8105 0.3641 0.3519 RMSE:0.5163 0.9562 0.9139 Tau:0.7309 0.4014 0.4655\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 230 Step: 22540 Index:-0.5308 R2:0.8154 0.3404 0.3583 RMSE:0.4642 0.9155 0.8698 Tau:0.7325 0.3847 0.4372\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 231 Step: 22638 Index:-0.4328 R2:0.8178 0.3463 0.3512 RMSE:0.4534 0.8194 0.8990 Tau:0.7352 0.3866 0.4497\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 232 Step: 22736 Index:-0.4192 R2:0.8126 0.3530 0.3535 RMSE:0.4586 0.8092 0.8808 Tau:0.7324 0.3900 0.4577\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 233 Step: 22834 Index:-0.4584 R2:0.7651 0.3493 0.3405 RMSE:0.5024 0.8486 0.9413 Tau:0.6917 0.3902 0.4739\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 234 Step: 22932 Index:-0.3897 R2:0.8176 0.3759 0.3354 RMSE:0.4640 0.7983 0.9213 Tau:0.7331 0.4086 0.4687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 235 Step: 23030 Index:-0.4115 R2:0.8301 0.3656 0.3672 RMSE:0.4253 0.8065 0.8674 Tau:0.7502 0.3950 0.4588\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 236 Step: 23128 Index:-0.4271 R2:0.8126 0.3717 0.3628 RMSE:0.4375 0.8316 0.9013 Tau:0.7323 0.4045 0.4655\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 237 Step: 23226 Index:-0.4104 R2:0.8237 0.3692 0.3515 RMSE:0.4811 0.8116 0.9189 Tau:0.7396 0.4012 0.4582\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 238 Step: 23324 Index:-0.4156 R2:0.8302 0.3720 0.3557 RMSE:0.4185 0.8192 0.8876 Tau:0.7499 0.4036 0.4674\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 239 Step: 23422 Index:-0.4019 R2:0.8303 0.3706 0.3537 RMSE:0.4420 0.7997 0.8943 Tau:0.7433 0.3978 0.4576\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 240 Step: 23520 Index:-0.4233 R2:0.8146 0.3551 0.3362 RMSE:0.4413 0.8297 0.8791 Tau:0.7338 0.4064 0.4495\n",
      "Epoch: 241 Step: 23618 Index:-0.3774 R2:0.8198 0.3733 0.3285 RMSE:0.4678 0.7800 0.8932 Tau:0.7364 0.4026 0.4628\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Epoch: 242 Step: 23716 Index:-0.4691 R2:0.8198 0.3667 0.3505 RMSE:0.4273 0.8617 0.8947 Tau:0.7384 0.3926 0.4588\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Epoch: 243 Step: 23814 Index:-0.4030 R2:0.8359 0.3765 0.3597 RMSE:0.4212 0.8092 0.8867 Tau:0.7511 0.4062 0.4595\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Epoch: 244 Step: 23912 Index:-0.5394 R2:0.8186 0.3053 0.3323 RMSE:0.4330 0.9038 0.8848 Tau:0.7334 0.3644 0.4426\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Epoch: 245 Step: 24010 Index:-0.5018 R2:0.8293 0.3475 0.3476 RMSE:0.4371 0.8939 0.8742 Tau:0.7460 0.3921 0.4579\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Epoch: 246 Step: 24108 Index:-0.4253 R2:0.8343 0.3664 0.3550 RMSE:0.4099 0.8262 0.8755 Tau:0.7527 0.4009 0.4650\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Epoch: 247 Step: 24206 Index:-0.4537 R2:0.8179 0.3620 0.3630 RMSE:0.4291 0.8456 0.8994 Tau:0.7428 0.3919 0.4554\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Epoch: 248 Step: 24304 Index:-0.4913 R2:0.7856 0.3327 0.3465 RMSE:0.4844 0.8815 0.8551 Tau:0.7088 0.3902 0.4278\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Epoch: 249 Step: 24402 Index:-0.4567 R2:0.8168 0.3771 0.3610 RMSE:0.4298 0.8581 0.9103 Tau:0.7311 0.4014 0.4587\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Epoch: 250 Step: 24500 Index:-0.4418 R2:0.7711 0.3378 0.3010 RMSE:0.4840 0.8160 0.9085 Tau:0.6987 0.3742 0.4737\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Epoch: 251 Step: 24598 Index:-0.4359 R2:0.8322 0.3557 0.3507 RMSE:0.4215 0.8278 0.8964 Tau:0.7500 0.3919 0.4625\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Epoch: 252 Step: 24696 Index:-0.4113 R2:0.8332 0.3712 0.3480 RMSE:0.4180 0.8072 0.8744 Tau:0.7478 0.3959 0.4681\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Epoch: 253 Step: 24794 Index:-0.4137 R2:0.8380 0.3711 0.3552 RMSE:0.4213 0.8132 0.9049 Tau:0.7539 0.3995 0.4678\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Epoch: 254 Step: 24892 Index:-0.4630 R2:0.8231 0.3466 0.3423 RMSE:0.4219 0.8441 0.8896 Tau:0.7454 0.3811 0.4562\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Epoch: 255 Step: 24990 Index:-0.4166 R2:0.8331 0.3586 0.3293 RMSE:0.4233 0.8115 0.8980 Tau:0.7475 0.3950 0.4635\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Epoch: 256 Step: 25088 Index:-0.4690 R2:0.8161 0.3457 0.3339 RMSE:0.4408 0.8606 0.8832 Tau:0.7349 0.3916 0.4682\n",
      "EarlyStopping counter: 16 out of 100\n",
      "Epoch: 257 Step: 25186 Index:-0.4165 R2:0.8377 0.3729 0.3473 RMSE:0.4100 0.8212 0.8942 Tau:0.7523 0.4047 0.4658\n",
      "EarlyStopping counter: 17 out of 100\n",
      "Epoch: 258 Step: 25284 Index:-0.4527 R2:0.8436 0.3508 0.3573 RMSE:0.4054 0.8403 0.8613 Tau:0.7551 0.3876 0.4583\n",
      "EarlyStopping counter: 18 out of 100\n",
      "Epoch: 259 Step: 25382 Index:-0.5052 R2:0.8182 0.3293 0.3432 RMSE:0.4402 0.8877 0.8807 Tau:0.7328 0.3826 0.4594\n",
      "EarlyStopping counter: 19 out of 100\n",
      "Epoch: 260 Step: 25480 Index:-0.4437 R2:0.8366 0.3600 0.3554 RMSE:0.4058 0.8399 0.8758 Tau:0.7514 0.3962 0.4705\n",
      "EarlyStopping counter: 20 out of 100\n",
      "Epoch: 261 Step: 25578 Index:-0.4792 R2:0.8142 0.3469 0.3699 RMSE:0.4369 0.8694 0.9023 Tau:0.7327 0.3902 0.4484\n",
      "EarlyStopping counter: 21 out of 100\n",
      "Epoch: 262 Step: 25676 Index:-0.3918 R2:0.8363 0.3763 0.3330 RMSE:0.4198 0.8054 0.9074 Tau:0.7496 0.4136 0.4718\n",
      "EarlyStopping counter: 22 out of 100\n",
      "Epoch: 263 Step: 25774 Index:-0.4770 R2:0.8154 0.3277 0.3197 RMSE:0.4331 0.8643 0.8945 Tau:0.7326 0.3873 0.4597\n",
      "EarlyStopping counter: 23 out of 100\n",
      "Epoch: 264 Step: 25872 Index:-0.4636 R2:0.8437 0.3723 0.3664 RMSE:0.4048 0.8693 0.8708 Tau:0.7609 0.4057 0.4648\n",
      "EarlyStopping counter: 24 out of 100\n",
      "Epoch: 265 Step: 25970 Index:-0.4725 R2:0.8256 0.3367 0.3526 RMSE:0.4204 0.8627 0.8899 Tau:0.7453 0.3902 0.4530\n",
      "EarlyStopping counter: 25 out of 100\n",
      "Epoch: 266 Step: 26068 Index:-0.4722 R2:0.8219 0.3409 0.3444 RMSE:0.4212 0.8729 0.9004 Tau:0.7413 0.4007 0.4632\n",
      "EarlyStopping counter: 26 out of 100\n",
      "Epoch: 267 Step: 26166 Index:-0.4316 R2:0.8475 0.3634 0.3586 RMSE:0.4068 0.8366 0.9131 Tau:0.7604 0.4050 0.4635\n",
      "EarlyStopping counter: 27 out of 100\n",
      "Epoch: 268 Step: 26264 Index:-0.4025 R2:0.8434 0.3638 0.3453 RMSE:0.4312 0.8111 0.9131 Tau:0.7576 0.4086 0.4701\n",
      "EarlyStopping counter: 28 out of 100\n",
      "Epoch: 269 Step: 26362 Index:-0.4346 R2:0.8549 0.3528 0.3550 RMSE:0.4237 0.8245 0.9236 Tau:0.7660 0.3900 0.4602\n",
      "EarlyStopping counter: 29 out of 100\n",
      "Epoch: 270 Step: 26460 Index:-0.3990 R2:0.8499 0.3713 0.3432 RMSE:0.4386 0.8044 0.9219 Tau:0.7603 0.4055 0.4701\n",
      "EarlyStopping counter: 30 out of 100\n",
      "Epoch: 271 Step: 26558 Index:-0.4195 R2:0.8344 0.3484 0.3468 RMSE:0.4726 0.8226 0.9234 Tau:0.7462 0.4031 0.4533\n",
      "EarlyStopping counter: 31 out of 100\n",
      "Epoch: 272 Step: 26656 Index:-0.5405 R2:0.8288 0.3545 0.3664 RMSE:0.4509 0.9414 0.8885 Tau:0.7469 0.4009 0.4522\n",
      "EarlyStopping counter: 32 out of 100\n",
      "Epoch: 273 Step: 26754 Index:-0.4829 R2:0.8466 0.3477 0.3516 RMSE:0.3934 0.8697 0.8917 Tau:0.7584 0.3869 0.4650\n",
      "EarlyStopping counter: 33 out of 100\n",
      "Epoch: 274 Step: 26852 Index:-0.4233 R2:0.8449 0.3627 0.3469 RMSE:0.4025 0.8223 0.9014 Tau:0.7583 0.3990 0.4683\n",
      "EarlyStopping counter: 34 out of 100\n",
      "Epoch: 275 Step: 26950 Index:-0.4374 R2:0.8520 0.3600 0.3404 RMSE:0.3894 0.8400 0.8912 Tau:0.7627 0.4026 0.4675\n",
      "EarlyStopping counter: 35 out of 100\n",
      "Epoch: 276 Step: 27048 Index:-0.4010 R2:0.8460 0.3687 0.3318 RMSE:0.4119 0.8098 0.9092 Tau:0.7575 0.4088 0.4717\n",
      "EarlyStopping counter: 36 out of 100\n",
      "Epoch: 277 Step: 27146 Index:-0.4382 R2:0.8394 0.3503 0.3649 RMSE:0.4139 0.8337 0.8861 Tau:0.7551 0.3954 0.4551\n",
      "EarlyStopping counter: 37 out of 100\n",
      "Epoch: 278 Step: 27244 Index:-0.4105 R2:0.8453 0.3555 0.3174 RMSE:0.4165 0.8195 0.9078 Tau:0.7577 0.4090 0.4716\n",
      "EarlyStopping counter: 38 out of 100\n",
      "Epoch: 279 Step: 27342 Index:-0.4565 R2:0.8423 0.3641 0.3471 RMSE:0.4070 0.8610 0.8802 Tau:0.7526 0.4045 0.4624\n",
      "EarlyStopping counter: 39 out of 100\n",
      "Epoch: 280 Step: 27440 Index:-0.4458 R2:0.8494 0.3521 0.3452 RMSE:0.3962 0.8382 0.8757 Tau:0.7613 0.3923 0.4586\n",
      "EarlyStopping counter: 40 out of 100\n",
      "Epoch: 281 Step: 27538 Index:-0.4515 R2:0.8524 0.3582 0.3597 RMSE:0.3883 0.8455 0.9063 Tau:0.7648 0.3940 0.4692\n",
      "EarlyStopping counter: 41 out of 100\n",
      "Epoch: 282 Step: 27636 Index:-0.4140 R2:0.8552 0.3699 0.3495 RMSE:0.4093 0.8211 0.9248 Tau:0.7639 0.4071 0.4764\n",
      "EarlyStopping counter: 42 out of 100\n",
      "Epoch: 283 Step: 27734 Index:-0.5350 R2:0.8136 0.3243 0.3350 RMSE:0.4403 0.9097 0.8948 Tau:0.7318 0.3747 0.4686\n",
      "EarlyStopping counter: 43 out of 100\n",
      "Epoch: 284 Step: 27832 Index:-0.4663 R2:0.8412 0.3707 0.3519 RMSE:0.4004 0.8739 0.8960 Tau:0.7534 0.4076 0.4686\n",
      "EarlyStopping counter: 44 out of 100\n",
      "Epoch: 285 Step: 27930 Index:-0.4552 R2:0.8515 0.3427 0.3519 RMSE:0.3927 0.8473 0.8857 Tau:0.7641 0.3921 0.4637\n",
      "EarlyStopping counter: 45 out of 100\n",
      "Epoch: 286 Step: 28028 Index:-0.4431 R2:0.8312 0.3434 0.3466 RMSE:0.4324 0.8345 0.8995 Tau:0.7427 0.3914 0.4598\n",
      "EarlyStopping counter: 46 out of 100\n",
      "Epoch: 287 Step: 28126 Index:-0.4399 R2:0.8467 0.3660 0.3602 RMSE:0.4092 0.8382 0.8543 Tau:0.7555 0.3983 0.4579\n",
      "EarlyStopping counter: 47 out of 100\n",
      "Epoch: 288 Step: 28224 Index:-0.5550 R2:0.8410 0.3739 0.3513 RMSE:0.4665 0.9593 0.9248 Tau:0.7507 0.4043 0.4679\n",
      "EarlyStopping counter: 48 out of 100\n",
      "Epoch: 289 Step: 28322 Index:-0.4221 R2:0.8569 0.3732 0.3625 RMSE:0.4116 0.8292 0.9207 Tau:0.7666 0.4071 0.4619\n",
      "EarlyStopping counter: 49 out of 100\n",
      "Epoch: 290 Step: 28420 Index:-0.4302 R2:0.8583 0.3513 0.3354 RMSE:0.4035 0.8257 0.8783 Tau:0.7682 0.3954 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 50 out of 100\n",
      "Epoch: 291 Step: 28518 Index:-0.3897 R2:0.8309 0.3677 0.3603 RMSE:0.4682 0.7968 0.9139 Tau:0.7470 0.4071 0.4629\n",
      "EarlyStopping counter: 51 out of 100\n",
      "Epoch: 292 Step: 28616 Index:-0.4488 R2:0.8299 0.3360 0.3214 RMSE:0.5567 0.8378 0.9823 Tau:0.7450 0.3890 0.4758\n",
      "EarlyStopping counter: 52 out of 100\n",
      "Epoch: 293 Step: 28714 Index:-0.4233 R2:0.8595 0.3692 0.3581 RMSE:0.3853 0.8223 0.8803 Tau:0.7711 0.3990 0.4741\n",
      "EarlyStopping counter: 53 out of 100\n",
      "Epoch: 294 Step: 28812 Index:-0.4299 R2:0.8350 0.3715 0.3521 RMSE:0.4124 0.8290 0.8859 Tau:0.7480 0.3990 0.4697\n",
      "EarlyStopping counter: 54 out of 100\n",
      "Epoch: 295 Step: 28910 Index:-0.4514 R2:0.8624 0.3470 0.3386 RMSE:0.4130 0.8402 0.9280 Tau:0.7718 0.3888 0.4685\n",
      "EarlyStopping counter: 55 out of 100\n",
      "Epoch: 296 Step: 29008 Index:-0.4718 R2:0.8607 0.3477 0.3480 RMSE:0.3726 0.8628 0.9043 Tau:0.7737 0.3909 0.4761\n",
      "EarlyStopping counter: 56 out of 100\n",
      "Epoch: 297 Step: 29106 Index:-0.5155 R2:0.8253 0.3414 0.3280 RMSE:0.4454 0.8987 0.8874 Tau:0.7355 0.3833 0.4620\n",
      "EarlyStopping counter: 57 out of 100\n",
      "Epoch: 298 Step: 29204 Index:-0.5055 R2:0.8446 0.3608 0.3300 RMSE:0.4076 0.9003 0.9220 Tau:0.7569 0.3947 0.4789\n",
      "EarlyStopping counter: 58 out of 100\n",
      "Epoch: 299 Step: 29302 Index:-0.4213 R2:0.8500 0.3677 0.3449 RMSE:0.4064 0.8258 0.9275 Tau:0.7603 0.4045 0.4768\n",
      "EarlyStopping counter: 59 out of 100\n",
      "Epoch: 300 Step: 29400 Index:-0.5511 R2:0.8368 0.3138 0.3373 RMSE:0.4204 0.9318 0.8820 Tau:0.7538 0.3806 0.4365\n",
      "EarlyStopping counter: 60 out of 100\n",
      "Epoch: 301 Step: 29498 Index:-0.5033 R2:0.8657 0.3523 0.3428 RMSE:0.3976 0.9059 0.8900 Tau:0.7761 0.4026 0.4621\n",
      "EarlyStopping counter: 61 out of 100\n",
      "Epoch: 302 Step: 29596 Index:-0.4505 R2:0.8645 0.3589 0.3530 RMSE:0.3781 0.8419 0.9019 Tau:0.7745 0.3914 0.4682\n",
      "EarlyStopping counter: 62 out of 100\n",
      "Epoch: 303 Step: 29694 Index:-0.4535 R2:0.8719 0.3472 0.3406 RMSE:0.3797 0.8423 0.9139 Tau:0.7821 0.3888 0.4764\n",
      "EarlyStopping counter: 63 out of 100\n",
      "Epoch: 304 Step: 29792 Index:-0.4603 R2:0.8479 0.3383 0.3302 RMSE:0.4072 0.8450 0.9303 Tau:0.7585 0.3847 0.4709\n",
      "EarlyStopping counter: 64 out of 100\n",
      "Epoch: 305 Step: 29890 Index:-0.4614 R2:0.8583 0.3367 0.3324 RMSE:0.3902 0.8518 0.9096 Tau:0.7695 0.3904 0.4654\n",
      "EarlyStopping counter: 65 out of 100\n",
      "Epoch: 306 Step: 29988 Index:-0.4631 R2:0.8647 0.3523 0.3464 RMSE:0.3742 0.8633 0.9233 Tau:0.7741 0.4002 0.4755\n",
      "EarlyStopping counter: 66 out of 100\n",
      "Epoch: 307 Step: 30086 Index:-0.4850 R2:0.8189 0.3214 0.3352 RMSE:0.4330 0.8643 0.9286 Tau:0.7334 0.3792 0.4759\n",
      "EarlyStopping counter: 67 out of 100\n",
      "Epoch: 308 Step: 30184 Index:-0.4761 R2:0.8641 0.3361 0.3400 RMSE:0.3775 0.8606 0.8915 Tau:0.7778 0.3845 0.4699\n",
      "EarlyStopping counter: 68 out of 100\n",
      "Epoch: 309 Step: 30282 Index:-0.4514 R2:0.8599 0.3348 0.3305 RMSE:0.3895 0.8438 0.8834 Tau:0.7713 0.3923 0.4723\n",
      "EarlyStopping counter: 69 out of 100\n",
      "Epoch: 310 Step: 30380 Index:-0.4327 R2:0.8248 0.3529 0.3481 RMSE:0.4333 0.8255 0.8936 Tau:0.7403 0.3928 0.4808\n",
      "EarlyStopping counter: 70 out of 100\n",
      "Epoch: 311 Step: 30478 Index:-0.4617 R2:0.8543 0.3484 0.3374 RMSE:0.3872 0.8588 0.9048 Tau:0.7641 0.3971 0.4728\n",
      "EarlyStopping counter: 71 out of 100\n",
      "Epoch: 312 Step: 30576 Index:-0.4764 R2:0.8558 0.3545 0.3545 RMSE:0.3795 0.8732 0.8989 Tau:0.7657 0.3969 0.4761\n",
      "EarlyStopping counter: 72 out of 100\n",
      "Epoch: 313 Step: 30674 Index:-0.4349 R2:0.8355 0.3476 0.3386 RMSE:0.4684 0.8342 0.9375 Tau:0.7549 0.3993 0.4789\n",
      "EarlyStopping counter: 73 out of 100\n",
      "Epoch: 314 Step: 30772 Index:-0.4723 R2:0.8640 0.3477 0.3495 RMSE:0.3730 0.8665 0.9138 Tau:0.7739 0.3942 0.4712\n",
      "EarlyStopping counter: 74 out of 100\n",
      "Epoch: 315 Step: 30870 Index:-0.4280 R2:0.8440 0.3457 0.3239 RMSE:0.4264 0.8283 0.9196 Tau:0.7565 0.4002 0.4755\n",
      "EarlyStopping counter: 75 out of 100\n",
      "Epoch: 316 Step: 30968 Index:-0.4366 R2:0.8761 0.3594 0.3474 RMSE:0.3692 0.8406 0.9092 Tau:0.7836 0.4040 0.4786\n",
      "EarlyStopping counter: 76 out of 100\n",
      "Epoch: 317 Step: 31066 Index:-0.4793 R2:0.8590 0.3534 0.3490 RMSE:0.4019 0.8698 0.9530 Tau:0.7710 0.3904 0.4713\n",
      "EarlyStopping counter: 77 out of 100\n",
      "Epoch: 318 Step: 31164 Index:-0.4564 R2:0.8616 0.3475 0.3509 RMSE:0.4062 0.8485 0.9237 Tau:0.7702 0.3921 0.4661\n",
      "EarlyStopping counter: 78 out of 100\n",
      "Epoch: 319 Step: 31262 Index:-0.6359 R2:0.6873 0.2264 0.3089 RMSE:0.5756 0.9502 0.9607 Tau:0.6181 0.3143 0.4366\n",
      "EarlyStopping counter: 79 out of 100\n",
      "Epoch: 320 Step: 31360 Index:-0.4575 R2:0.8414 0.3445 0.3401 RMSE:0.4071 0.8603 0.9212 Tau:0.7518 0.4028 0.4779\n",
      "EarlyStopping counter: 80 out of 100\n",
      "Epoch: 321 Step: 31458 Index:-0.4533 R2:0.8663 0.3554 0.3454 RMSE:0.3944 0.8575 0.9382 Tau:0.7736 0.4043 0.4815\n",
      "EarlyStopping counter: 81 out of 100\n",
      "Epoch: 322 Step: 31556 Index:-0.4398 R2:0.8669 0.3723 0.3551 RMSE:0.3688 0.8476 0.8961 Tau:0.7751 0.4079 0.4794\n",
      "EarlyStopping counter: 82 out of 100\n",
      "Epoch: 323 Step: 31654 Index:-0.4662 R2:0.8623 0.3657 0.3544 RMSE:0.3733 0.8745 0.8924 Tau:0.7752 0.4083 0.4806\n",
      "EarlyStopping counter: 83 out of 100\n",
      "Epoch: 324 Step: 31752 Index:-0.3907 R2:0.8745 0.3926 0.3549 RMSE:0.3674 0.8210 0.9002 Tau:0.7817 0.4303 0.4780\n",
      "EarlyStopping counter: 84 out of 100\n",
      "Epoch: 325 Step: 31850 Index:-0.4493 R2:0.8702 0.3652 0.3450 RMSE:0.3622 0.8550 0.9165 Tau:0.7798 0.4057 0.4765\n",
      "EarlyStopping counter: 85 out of 100\n",
      "Epoch: 326 Step: 31948 Index:-0.4115 R2:0.8696 0.3611 0.3572 RMSE:0.4087 0.8120 0.9050 Tau:0.7802 0.4005 0.4793\n",
      "EarlyStopping counter: 86 out of 100\n",
      "Epoch: 327 Step: 32046 Index:-0.5095 R2:0.8401 0.3513 0.3526 RMSE:0.4140 0.9047 0.9546 Tau:0.7625 0.3952 0.4713\n",
      "EarlyStopping counter: 87 out of 100\n",
      "Epoch: 328 Step: 32144 Index:-0.4687 R2:0.8566 0.3377 0.3513 RMSE:0.4016 0.8539 0.9118 Tau:0.7648 0.3852 0.4717\n",
      "EarlyStopping counter: 88 out of 100\n",
      "Epoch: 329 Step: 32242 Index:-0.4399 R2:0.8666 0.3640 0.3628 RMSE:0.3773 0.8420 0.8985 Tau:0.7794 0.4021 0.4628\n",
      "EarlyStopping counter: 89 out of 100\n",
      "Epoch: 330 Step: 32340 Index:-0.4149 R2:0.8778 0.3793 0.3542 RMSE:0.3617 0.8265 0.8801 Tau:0.7868 0.4117 0.4793\n",
      "EarlyStopping counter: 90 out of 100\n",
      "Epoch: 331 Step: 32438 Index:-0.4442 R2:0.8799 0.3504 0.3367 RMSE:0.4941 0.8382 0.9935 Tau:0.7890 0.3940 0.4718\n",
      "EarlyStopping counter: 91 out of 100\n",
      "Epoch: 332 Step: 32536 Index:-0.4652 R2:0.8755 0.3645 0.3573 RMSE:0.3541 0.8633 0.8973 Tau:0.7843 0.3981 0.4753\n",
      "EarlyStopping counter: 92 out of 100\n",
      "Epoch: 333 Step: 32634 Index:-0.4399 R2:0.8830 0.3779 0.3620 RMSE:0.3458 0.8495 0.8911 Tau:0.7906 0.4095 0.4700\n",
      "EarlyStopping counter: 93 out of 100\n",
      "Epoch: 334 Step: 32732 Index:-0.4840 R2:0.8741 0.3612 0.3628 RMSE:0.3572 0.8792 0.8901 Tau:0.7837 0.3952 0.4775\n",
      "EarlyStopping counter: 94 out of 100\n",
      "Epoch: 335 Step: 32830 Index:-0.4525 R2:0.8732 0.3686 0.3637 RMSE:0.4355 0.8596 0.9819 Tau:0.7795 0.4071 0.4691\n",
      "EarlyStopping counter: 95 out of 100\n",
      "Epoch: 336 Step: 32928 Index:-0.4238 R2:0.8810 0.3606 0.3456 RMSE:0.3640 0.8267 0.8943 Tau:0.7879 0.4028 0.4662\n",
      "EarlyStopping counter: 96 out of 100\n",
      "Epoch: 337 Step: 33026 Index:-0.4229 R2:0.8793 0.3716 0.3668 RMSE:0.4644 0.8303 0.9777 Tau:0.7914 0.4074 0.4700\n",
      "EarlyStopping counter: 97 out of 100\n",
      "Epoch: 338 Step: 33124 Index:-0.4423 R2:0.8878 0.3538 0.3353 RMSE:0.3553 0.8437 0.9225 Tau:0.7936 0.4014 0.4718\n",
      "EarlyStopping counter: 98 out of 100\n",
      "Epoch: 339 Step: 33222 Index:-0.4493 R2:0.8744 0.3577 0.3537 RMSE:0.3622 0.8498 0.9012 Tau:0.7828 0.4005 0.4699\n",
      "EarlyStopping counter: 99 out of 100\n",
      "Epoch: 340 Step: 33320 Index:-0.4673 R2:0.8810 0.3596 0.3637 RMSE:0.3529 0.8666 0.8753 Tau:0.7896 0.3993 0.4682\n",
      "EarlyStopping counter: 100 out of 100\n",
      "Epoch: 341 Step: 33418 Index:-0.4038 R2:0.8869 0.3735 0.3654 RMSE:0.3698 0.8169 0.9148 Tau:0.7971 0.4131 0.4811\n"
     ]
    }
   ],
   "source": [
    "# train_f_list=[]\n",
    "# train_mse_list=[]\n",
    "# train_r2_list=[]\n",
    "# test_f_list=[]\n",
    "# test_mse_list=[]\n",
    "# test_r2_list=[]\n",
    "# val_f_list=[]\n",
    "# val_mse_list=[]\n",
    "# val_r2_list=[]\n",
    "# epoch_list=[]\n",
    "# train_predict_list=[]\n",
    "# test_predict_list=[]\n",
    "# val_predict_list=[]\n",
    "# train_y_list=[]\n",
    "# test_y_list=[]\n",
    "# val_y_list=[]\n",
    "# train_d_list=[]\n",
    "# test_d_list=[]\n",
    "# val_d_list=[]\n",
    "\n",
    "epoch = 0\n",
    "optimizer_list = [optimizer, optimizer_AFSE, optimizer_GRN]\n",
    "max_epoch = 1000\n",
    "while epoch < max_epoch:\n",
    "    train(model, amodel, gmodel, train_df, test_df, optimizer_list, loss_function, epoch)\n",
    "#     print(train_df.shape,test_df.shape)\n",
    "    train_d, train_f, train_r2, train_MSE, train_predict, reconstruction_loss, one_hot_loss, interger_loss,binary_loss = eval(model, amodel, gmodel, train_df,output_feature=True,return_GRN_loss=True)\n",
    "    train_predict = np.array(train_predict)\n",
    "    train_WTI = weighted_top_index(train_df, train_predict, len(train_df))\n",
    "    train_tau, _ = scipy.stats.kendalltau(train_predict,train_df[tasks[0]].values.astype(float).tolist())\n",
    "    val_d, val_f, val_r2, val_MSE, val_predict, val_reconstruction_loss, val_one_hot_loss, val_interger_loss,val_binary_loss = eval(model, amodel, gmodel, val_df,output_feature=True,return_GRN_loss=True)\n",
    "    val_predict = np.array(val_predict)\n",
    "    val_WTI = weighted_top_index(val_df, val_predict, len(val_df))\n",
    "    val_AP = AP(val_df, val_predict, len(val_df))\n",
    "    val_tau, _ = scipy.stats.kendalltau(val_predict,val_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "    test_d, test_f, test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df,output_feature=True)\n",
    "    test_predict = np.array(test_predict)\n",
    "    test_WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "#     test_AP = AP(test_df, test_predict, test_active)\n",
    "    test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "    \n",
    "    k_list = [int(len(test_df)*0.01),int(len(test_df)*0.03),int(len(test_df)*0.1),10,30,100]\n",
    "    topk_list =[]\n",
    "    false_positive_rate_list = []\n",
    "    for k in k_list:\n",
    "        a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "        topk_list.append(a)\n",
    "        false_positive_rate_list.append(b)\n",
    "    \n",
    "    epoch = epoch + 1\n",
    "    global_step = epoch * int(np.max([len(train_df),len(test_df)])/batch_size)\n",
    "    logger.add_scalar('val/WTI', val_WTI, global_step)\n",
    "    logger.add_scalar('val/AP', val_AP, global_step)\n",
    "    logger.add_scalar('val/r2', val_r2, global_step)\n",
    "    logger.add_scalar('val/RMSE', val_MSE**0.5, global_step)\n",
    "    logger.add_scalar('val/Tau', val_tau, global_step)\n",
    "#     logger.add_scalar('test/TAP', test_AP, global_step)\n",
    "    logger.add_scalar('test/r2', test_r2_a, global_step)\n",
    "    logger.add_scalar('test/RMSE', test_MSE_a**0.5, global_step)\n",
    "    logger.add_scalar('test/Tau', test_tau, global_step)\n",
    "    logger.add_scalar('val/GRN', reconstruction_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_one_hot', one_hot_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_interger', interger_loss, global_step)\n",
    "    logger.add_scalar('val/GRN_binary', binary_loss, global_step)\n",
    "    logger.add_scalar('test/EF0.01', topk_list[0], global_step)\n",
    "    logger.add_scalar('test/EF0.03', topk_list[1], global_step)\n",
    "    logger.add_scalar('test/EF0.1', topk_list[2], global_step)\n",
    "    logger.add_scalar('test/EF10', topk_list[3], global_step)\n",
    "    logger.add_scalar('test/EF30', topk_list[4], global_step)\n",
    "    logger.add_scalar('test/EF100', topk_list[5], global_step)\n",
    "    \n",
    "#     train_mse_list.append(train_MSE**0.5)\n",
    "#     train_r2_list.append(train_r2)\n",
    "#     val_mse_list.append(val_MSE**0.5)  \n",
    "#     val_r2_list.append(val_r2)\n",
    "#     train_f_list.append(train_f)\n",
    "#     val_f_list.append(val_f)\n",
    "#     test_f_list.append(test_f)\n",
    "#     epoch_list.append(epoch)\n",
    "#     train_predict_list.append(train_predict.flatten())\n",
    "#     test_predict_list.append(test_predict.flatten())\n",
    "#     val_predict_list.append(val_predict.flatten())\n",
    "#     train_y_list.append(train_df[tasks[0]].values)\n",
    "#     val_y_list.append(val_df[tasks[0]].values)\n",
    "#     test_y_list.append(test_df[tasks[0]].values)\n",
    "#     train_d_list.append(train_d)\n",
    "#     val_d_list.append(val_d)\n",
    "#     test_d_list.append(test_d)\n",
    "\n",
    "    stop_index = - val_MSE**0.5 + val_tau \n",
    "    early_stop = stopper.step(stop_index, model)\n",
    "    early_stop = stopper_afse.step(stop_index, amodel, if_print=False)\n",
    "    early_stop = stopper_generate.step(stop_index, gmodel, if_print=False)\n",
    "#     print('epoch {:d}/{:d}, validation {} {:.4f}, {} {:.4f},best validation {r2} {:.4f}'.format(epoch, total_epoch, 'r2', val_r2, 'mse:',val_MSE, stopper.best_score))\n",
    "    print('Epoch:',epoch, 'Step:', global_step, 'Index:%.4f'%stop_index, 'R2:%.4f'%train_r2,'%.4f'%val_r2,'%.4f'%test_r2_a, 'RMSE:%.4f'%train_MSE**0.5, '%.4f'%val_MSE**0.5, \n",
    "          '%.4f'%test_MSE_a**0.5, 'Tau:%.4f'%train_tau,'%.4f'%val_tau,'%.4f'%test_tau)#, 'Tau:%.4f'%val_tau,'%.4f'%test_tau,'GRN:%.4f'%reconstruction_loss,'%.4f'%val_reconstruction_loss\n",
    "    if early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopper.load_checkpoint(model)\n",
    "stopper_afse.load_checkpoint(amodel)\n",
    "stopper_generate.load_checkpoint(gmodel)\n",
    "    \n",
    "test_r2, test_MSE, test_predict = eval(model, amodel, gmodel, test_df)\n",
    "test_r2_a, test_MSE_a, test_predict_a = eval(model, amodel, gmodel, test_df[:test_active])\n",
    "test_r2_ina, test_MSE_ina, test_predict_ina = eval(model, amodel, gmodel, test_df[test_active:].reset_index(drop=True))\n",
    "    \n",
    "test_predict = np.array(test_predict)\n",
    "test_tau, _ = scipy.stats.kendalltau(test_predict,test_df[tasks[0]].values.astype(float).tolist())\n",
    "\n",
    "k_list = [int(len(test_df)*0.01),int(len(test_df)*0.05),int(len(test_df)*0.1),int(len(test_df)*0.15),int(len(test_df)*0.2),int(len(test_df)*0.25),\n",
    "          int(len(test_df)*0.3),int(len(test_df)*0.4),int(len(test_df)*0.5),50,100,150,200,250,300]\n",
    "topk_list =[]\n",
    "false_positive_rate_list = []\n",
    "for k in k_list:\n",
    "    a,b = topk_acc_recall(test_df, test_predict, k, test_active, False, epoch)\n",
    "    topk_list.append(a)\n",
    "    false_positive_rate_list.append(b)\n",
    "WTI = weighted_top_index(test_df, test_predict, test_active)\n",
    "ap = AP(test_df, test_predict, test_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 341 r2:0.3285 RMSE:0.8932 WTI:0.3413 AP:0.6361 Tau:0.4628 \n",
      " \n",
      " Top-1:0.1111 Top-1-fp:0.2222 \n",
      " Top-5:0.3673 Top-5-fp:0.1429 \n",
      " Top-10:0.5204 Top-10-fp:0.1735 \n",
      " Top-15:0.5986 Top-15-fp:0.2177 \n",
      " Top-20:0.6327 Top-20-fp:0.2653 \n",
      " Top-25:0.6490 Top-25-fp:0.3102 \n",
      " Top-30:0.6701 Top-30-fp:0.3265 \n",
      " Top-40:0.7767 Top-40-fp:0.4071 \n",
      " Top-50:0.8567 Top-50-fp:0.4766 \n",
      " \n",
      " Top50:0.3600 Top50-fp:0.1400 \n",
      " Top100:0.5300 Top100-fp:0.1700 \n",
      " Top150:0.6200 Top150-fp:0.2133 \n",
      " Top200:0.6300 Top200-fp:0.2700 \n",
      " Top250:0.6520 Top250-fp:0.3120 \n",
      " Top300:0.6667 Top300-fp:0.3333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' epoch:',epoch,'r2:%.4f'%test_r2_a,'RMSE:%.4f'%test_MSE_a**0.5,'WTI:%.4f'%WTI,'AP:%.4f'%ap,'Tau:%.4f'%test_tau,'\\n','\\n',\n",
    "      'Top-1:%.4f'%topk_list[0],'Top-1-fp:%.4f'%false_positive_rate_list[0],'\\n',\n",
    "      'Top-5:%.4f'%topk_list[1],'Top-5-fp:%.4f'%false_positive_rate_list[1],'\\n',\n",
    "      'Top-10:%.4f'%topk_list[2],'Top-10-fp:%.4f'%false_positive_rate_list[2],'\\n',\n",
    "      'Top-15:%.4f'%topk_list[3],'Top-15-fp:%.4f'%false_positive_rate_list[3],'\\n',\n",
    "      'Top-20:%.4f'%topk_list[4],'Top-20-fp:%.4f'%false_positive_rate_list[4],'\\n',\n",
    "      'Top-25:%.4f'%topk_list[5],'Top-25-fp:%.4f'%false_positive_rate_list[5],'\\n',\n",
    "      'Top-30:%.4f'%topk_list[6],'Top-30-fp:%.4f'%false_positive_rate_list[6],'\\n',\n",
    "      'Top-40:%.4f'%topk_list[7],'Top-40-fp:%.4f'%false_positive_rate_list[7],'\\n',\n",
    "      'Top-50:%.4f'%topk_list[8],'Top-50-fp:%.4f'%false_positive_rate_list[8],'\\n','\\n',\n",
    "      'Top50:%.4f'%topk_list[9],'Top50-fp:%.4f'%false_positive_rate_list[9],'\\n',\n",
    "      'Top100:%.4f'%topk_list[10],'Top100-fp:%.4f'%false_positive_rate_list[10],'\\n',\n",
    "      'Top150:%.4f'%topk_list[11],'Top150-fp:%.4f'%false_positive_rate_list[11],'\\n',\n",
    "      'Top200:%.4f'%topk_list[12],'Top200-fp:%.4f'%false_positive_rate_list[12],'\\n',\n",
    "      'Top250:%.4f'%topk_list[13],'Top250-fp:%.4f'%false_positive_rate_list[13],'\\n',\n",
    "      'Top300:%.4f'%topk_list[14],'Top300-fp:%.4f'%false_positive_rate_list[14],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('target_file:',train_filename)\n",
    "# print('inactive_file:',test_filename)\n",
    "# np.savez(result_dir, epoch_list, train_f_list, train_d_list, \n",
    "#          train_predict_list, train_y_list, val_f_list, val_d_list, val_predict_list, val_y_list, test_f_list, \n",
    "#          test_d_list, test_predict_list, test_y_list)\n",
    "# sim_space = np.load(result_dir+'.npz')\n",
    "# print(sim_space['arr_10'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_function(mol_prediction,y)\n",
    "#             loss.backward(retain_graph=True)\n",
    "#             optimizer_AFSE.zero_grad()\n",
    "#             punish_lr = torch.norm(torch.mean(eps.grad,0))\n",
    "\n",
    "# loss =  regression_loss + vat_loss + test_vat_loss\n",
    "\n",
    "#         init_lr = 1e-4\n",
    "#         max_lr = 10**-(init_lr-1)\n",
    "#         conv_lr = conv_lr - conv_lr**2 + 0.1 * punish_lr\n",
    "#         if conv_lr < max_lr:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = conv_lr.detach()\n",
    "#                 AFSE_lr = conv_lr    \n",
    "#         else:\n",
    "#             for param_group in optimizer_AFSE.param_groups:\n",
    "#                 param_group[\"lr\"] = max_lr\n",
    "#                 AFSE_lr = max_lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
